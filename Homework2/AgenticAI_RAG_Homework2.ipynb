{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agentic AI with a decision process to select a 'researcher' or 'journalist' as agents using crewAI "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions:\n",
    "\n",
    "- Go to the **Assessments** tab in iCollege and click on **Assignments** to find the **Homework 2** assignment and further instructions to the assignment.\n",
    "\n",
    "- Make a copy of this homework notebook and rename the copy using your GSU username as suffix:\n",
    "\n",
    "    **AgenticAI_RAG_Homework2_<YOUR GSU USERNAME>.ipynb**\n",
    "\n",
    "- Use the **MSA8700 Python 3.12** kernel when you execute your noterbnook cells! This kernel has all the necessary Python packages already installed. You do not have to install any packages. Do **NOT** use any of the other kernels. \n",
    "\n",
    "- Work with your renamed copy to create your solution and all the necessary .txt files that will be generated and submitted with your notebook. \n",
    "\n",
    "- Complete all cells in the notebook i.e. replace missing fields (abbreviated with **'...'** in the code cells below) with your code cells, run the notebook and create the 6 necessary .txt files. \n",
    "\n",
    "- Run the tests to confirm that your .txt files were generated. Finally, submit your .txt files and your executed .ipynb notebook by running the two submission steps at the very end of the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Important Note:\n",
    "\n",
    "- When running the 'researcher' branch you might notice that the **`pdf_search_tool` might fail**, i.e. a response cannot be generated fron the PDF file and you get an error message.\n",
    "\n",
    "- When that occurs **delete the database folder db/** (e.g. with **rm -rf db** on the command line in a terminal window; you might have to restart or shutdown the kernel before you can do that) that has been generated and re-run the cells. The database folder db/ will be re-created and `pdf_search_tool` should return a result with showing an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not change the content of this cell. Execute this cell first, and everytime after you restarted the kernel.\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "from langchain_openai import ChatOpenAI\n",
    "from crewai import Agent, Task, Crew, LLM\n",
    "from crewai.tools import tool\n",
    "from crewai_tools import SerperDevTool, ScrapeWebsiteTool\n",
    "from crewai_tools import PDFSearchTool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the API keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your API keys here and create your environment variables.\n",
    "\n",
    "# IMPORTANT: Do not directly copy your API keys into your notebooks and submit them with your solution!\n",
    "\n",
    "OPENAI_API_KEY = ...\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "\n",
    "GEMINI_API_KEY = ...\n",
    "os.environ[\"GEMINI_API_KEY\"] = GEMINI_API_KEY\n",
    "\n",
    "SERPER_API_KEY = ...\n",
    "os.environ[\"SERPER_API_KEY\"] = SERPER_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the PDF document\n",
    "\n",
    "Upload NIPS 2017 paper and store locally in **data/** folder.\n",
    "\n",
    "Source: \n",
    "\n",
    "**Advances in Neural Information Processing Systems 30 (NIPS 2017)**. Edited by: I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett. ISBN: 9781510860964. https://proceedings.neurips.cc/paper_files/paper/2017\n",
    "\n",
    "**Attention is All you Need** Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, Illia Polosukhin. https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf\n",
    "\n",
    "This file is already available on the cluster at `/data/MSA8700/data/NIPS-2017-attention-is-all-you-need-Paper.pdf`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if you can see the PDF file:\n",
    "! ls -l /data/MSA8700/data/\n",
    "\n",
    "PDF_FILE = \"/data/MSA8700/data/NIPS-2017-attention-is-all-you-need-Paper.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "pdf_url = 'https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf'\n",
    "response = requests.get(pdf_url)\n",
    "\n",
    "with open('data/NIPS-2017-attention-is-all-you-need-Paper.pdf', 'wb') as file:\n",
    "    file.write(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a Gemini mode, the Gemini API key, the max_tokens and temparature parameter values:\n",
    "\n",
    "llm = ChatOpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "crew_llm = LLM(\n",
    "    model = ... ,\n",
    "    api_key = ... ,\n",
    "    max_tokens = ... ,\n",
    "    temperature = ...\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the `PDFSearchTool()` class from crewai_tools. Insert the necessary parameters.\n",
    "\n",
    "# Note: Pick the same model for the language model (llm) and for the embedding model (embedder). Otherwise using  \n",
    "# the `pdf_search_tool` within an agent task can lead to an error upon execution. \n",
    "\n",
    "pdf_search_tool = PDFSearchTool(\n",
    "    pdf = ...,\n",
    "    config=dict(\n",
    "        llm=dict(\n",
    "            provider = ..., # \"openai\", \"google\", \"anthropic\", \"llama2\", ...\n",
    "            config=dict(\n",
    "                model = ...,\n",
    "                # temperature=0.5,\n",
    "                # top_p=1,\n",
    "                # stream=true,\n",
    "            ),\n",
    "        ),\n",
    "        embedder=dict(\n",
    "            provider = ..., # \"openai\", \"google\", \"anthropic\", \"llama2\", ...\n",
    "            config=dict(\n",
    "                model = ...,\n",
    "                # task_type=\"retrieval_document\",\n",
    "                # title=\"Embeddings\",\n",
    "            ),\n",
    "        ),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom-defined tool using the @tool decrorator:\n",
    "@tool(\"Router Function\")\n",
    "def router_tool(question: str) -> str:\n",
    "  \"\"\"Router Function\"\"\"\n",
    "  if 'self-attention' in question:\n",
    "    return 'researcher'\n",
    "  else:\n",
    "    return 'journalist'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create decision router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a decision router function based on an input 'query':\n",
    "\n",
    "# The `decide_hiring()` function shall make a binary decision and return a string. \n",
    "# This function shall either return the value 'researcher' or the value 'journalist' \n",
    "# depending on whether a certain query can be answered with the content in a PDF file \n",
    "# or has to be answered via a web search with web scraping task.\n",
    "\n",
    "# An agent named 'router' shall execute a task using the tool `pdf_search_tool` to determine whether\n",
    "# the query can be answered with the PDF file content or has to be answered via a web search with web scraping activity.\n",
    "\n",
    "# Enter definitions for the variables 'role', 'goal' and 'backstory' of the Agent 'router'.\n",
    "# Enter definitions for the variables 'description', 'expected_output', 'agent', and 'tools' of the Task 'router_task'.\n",
    "# Enter definitions for the variables 'agents' and 'tasks' in the Crew class 'crew'. \n",
    "# Finally, define the 'inputs' dictionary in order to execute `result = crew.kickoff(inputs={...})` to generate an output string 'result.raw'\n",
    "\n",
    "# Note: You might have to experiment with different definitions an experiments to get a well-performing agentic workflow.\n",
    "\n",
    "def decide_hiring(query):\n",
    "    \"\"\"Router function to determine if we can answer from the existing PDF file\"\"\"    \n",
    "    \n",
    "    router = Agent(\n",
    "                role = ...,\n",
    "                goal = ...,\n",
    "                backstory=( ... ),\n",
    "                verbose=True,\n",
    "                allow_delegation=False,\n",
    "                llm=llm,\n",
    "                )\n",
    "    \n",
    "    router_task = Task(\n",
    "                    description = ( ... ),\n",
    "                    expected_output = ( ... ),\n",
    "                    agent = ...,\n",
    "                    tools = [...],\n",
    "                    )\n",
    "    \n",
    "    crew = Crew(\n",
    "            agents=[...],\n",
    "            tasks=[...],\n",
    "            verbose=1,\n",
    "            memory=False,\n",
    "            )\n",
    "    \n",
    "    result = crew.kickoff(inputs={...})\n",
    "    return result.raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create branch workflows with agents, tasks and crews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the 'researcher' branch in the process: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the 'researcher' branch, we want to define a function `hire_researcher(query)` that is executed \n",
    "# if the 'router' agent determines that the 'query' can be answered by the content avaialble in the PDF file. \n",
    "\n",
    "# Define an Agent 'researcher', Task 'researcher_task' and a Crew that will use the tool `pdf_search_tool` to\n",
    "# provide a response to the query from the PDF tile.\n",
    "\n",
    "# Similar to the 'router' workflow above:\n",
    "# Enter definitions for the variables 'role', 'goal' and 'backstory' of the Agent 'researcher'. \n",
    "# For the 'role' you can specify 'Expert Data Analyst'.\n",
    "\n",
    "# Enter definitions for the variables 'description', 'expected_output', 'agent', and 'tools' of the Task 'researcher_task'.\n",
    "# In the 'description' argument refer to the '{topic}' variable as placeholder for the input query.  \n",
    "\n",
    "# Enter definitions for the variables 'agents' and 'tasks' in the Crew class 'crew'. \n",
    "\n",
    "# By executing `result = crew.kickoff(inputs={\"topic\": query})` the response from searching the PDF file \n",
    "# is generated for the input 'query' by the agentic workflow. \n",
    "\n",
    "# Adding the PDF Searching Agent\n",
    "def hire_researcher(query):     \n",
    "    # researcher agent:\n",
    "    researcher = Agent(\n",
    "                    role = \"Expert Data Analyst\",\n",
    "                    goal = ( ... ),\n",
    "                    backstory = ( ... ),\n",
    "                    allow_delegation = False,\n",
    "                    verbose = True,\n",
    "                    llm = llm\n",
    "                    )\n",
    "    \n",
    "    researcher_task = Task(\n",
    "                        description = ( ... '{topic}' ... ),\n",
    "                        expected_output = ( ... ),\n",
    "                        tools = [ ... ],\n",
    "                        agent = researcher\n",
    "                        )\n",
    "    \n",
    "    crew = Crew(\n",
    "            agents = [...],\n",
    "            tasks = [...],\n",
    "            verbose=1,\n",
    "            memory=False,\n",
    "            ) \n",
    "    \n",
    "    print(\"The researcher was hired ...\")\n",
    "    result = crew.kickoff(inputs={\"topic\": query})\n",
    "    return result.raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the 'journalist' branch in the process: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the 'journalist' branch, alternatively, a function `hire_journalist(query)` is executed \n",
    "# if the 'router' agent determines that the 'query' cannot be answered by the content available in the PDF file \n",
    "# but needs to be answered via a web searching and web scraping activity. \n",
    "\n",
    "# See the Agent definitions of 'web_search_agent' and 'web_scraper_agent'.\n",
    "\n",
    "# Enter definitions for the variables 'description', 'expected_output', 'agent', and 'tools' \n",
    "# of the 'search_task' and 'scraping_task'.\n",
    "\n",
    "# In the 'description' argument refer to the '{topic}' variable as placeholder for the input query.  \n",
    "\n",
    "# Enter definitions for the variables 'agents' and 'tasks' in the Crew class 'crew'. \n",
    "\n",
    "# By executing `result = crew.kickoff(inputs={\"topic\": query})` the response \n",
    "# from searching and scraping the web.\n",
    "\n",
    "# Note: Focus on the content scraped from the most relevant searched website with respect to the inout 'query' \n",
    "# in order to limit the number of iterations in the web searching and web scraping process. \n",
    "\n",
    "# Adding the Web Searching and Scraping Agent\n",
    "def run_web_search_scraping(query):\n",
    "    \"\"\"Setup the web scraping agent and related components\"\"\"\n",
    "    search_tool = SerperDevTool()  # Tool for performing web searches\n",
    "    scrape_website = ScrapeWebsiteTool()  # Tool for extracting data from websites\n",
    "    \n",
    "    # Define the web search agent\n",
    "    web_search_agent = Agent(\n",
    "        role=\"Expert Web Search Agent\",\n",
    "        goal=\"Identify and retrieve relevant web data for user queries\",\n",
    "        backstory=\"An expert in identifying valuable web sources for the user's needs\",\n",
    "        allow_delegation=False,\n",
    "        verbose=True,\n",
    "        llm=crew_llm\n",
    "    )\n",
    "    \n",
    "    # Define the web scraping agent\n",
    "    web_scraper_agent = Agent(\n",
    "        role=\"Expert Web Scraper Agent\",\n",
    "        goal=\"Extract and analyze content from specific web page identified by the search agent\",\n",
    "        backstory=\"A highly skilled web scraper, capable of analyzing and summarizing website content accurately\",\n",
    "        allow_delegation=False,\n",
    "        verbose=True,\n",
    "        llm=crew_llm\n",
    "    )\n",
    "    \n",
    "    # Define the web search task\n",
    "    search_task = Task(\n",
    "                    description = ( ... '{topic}' ... ),\n",
    "                    expected_output = ( ... '{topic}' ... ),\n",
    "                    tools = [...],\n",
    "                    agent = ...,\n",
    "                    )\n",
    "    \n",
    "    # Define the web scraping task\n",
    "    scraping_task = Task(\n",
    "                        description = ( ... '{topic}' ... ),\n",
    "                        expected_output = ( ... '{topic}' ... ),\n",
    "                        tools = [...],\n",
    "                        agent = ...,\n",
    "                        )\n",
    "    \n",
    "    # Define the crew to manage agents and tasks\n",
    "    crew = Crew(\n",
    "            agents = [...],\n",
    "            tasks = [...],\n",
    "            verbose=1,\n",
    "            memory=False,\n",
    "            )\n",
    "    \n",
    "    print(\"The journalist was hired ...\")\n",
    "    result = crew.kickoff(inputs={\"topic\": query})\n",
    "    return result.raw\n",
    "\n",
    "\n",
    "# Complete the 'messages' template for the RAG application in the function `generate_journalist_answer`, \n",
    "# i.e. replace the dots in \" ... \" with an appropriate, short description of a journalist's activity.\n",
    "\n",
    "def generate_journalist_answer(context, query):\n",
    "    \"\"\"Generate final answer using LLM for RAG\"\"\"\n",
    "    messages = [\n",
    "        (\n",
    "            \"system\",\n",
    "            \" ... \",\n",
    "        ),\n",
    "        (\"system\", f\"Context: {context}\"),\n",
    "        (\"human\", query),\n",
    "    ]\n",
    "    response = llm.invoke(messages)\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hire_journalist(query): \n",
    "    # Retrieve context from web scraping\n",
    "    context = run_web_search_scraping(query)\n",
    "    # Generate final answer via RAG\n",
    "    answer = generate_journalist_answer(context, query)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the necessary process flow with the functions `decide_hiring`, `hire_researcher`, `hire_journalist` \n",
    "# defined above to create the agentic workflow as described above.\n",
    "\n",
    "# Replace the dots below (...) with your code insertions:\n",
    "\n",
    "def process_query(query):\n",
    "    \"\"\"Main function to process user query\"\"\"\n",
    "    print(f\"Processing query: {query}\")\n",
    "    \n",
    "    # Step 1: Decide which team will be hired based on the question (input query).\n",
    "    ... \n",
    "    \n",
    "    # Step 2: Generate final answer based on whether 'researcher' or 'journalist' branch was selected.\n",
    "    \n",
    "    if ...:\n",
    "    # researcher branch\n",
    "        answer = ...\n",
    "    \n",
    "    else:\n",
    "    # journalist branch         \n",
    "        answer = ... \n",
    "            \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execute process with query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create three different appropriate questions (input query) to test the execution of the 'researcher' branch\n",
    "# where the 'researcher' agent extracts an answer for the question from the uploaded PDF file:\n",
    "\n",
    "# Example: \"How did the self-attention mechanism evolve in large language models?\"\n",
    "\n",
    "# Choose a different question as input!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick your first 'question' (replace the ... and insert your string) \n",
    "# and execute the `process_query(question)`:\n",
    "question = \" ... \"\n",
    "result = process_query(question)\n",
    "\n",
    "print(\"\\nFinal Answer:\")\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"researcher_1.txt\", \"w\") as text_file:\n",
    "    text_file.write(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick your second 'question' (replace the ... and insert your string) \n",
    "# and execute the `process_query(question)`:\n",
    "question = \" ... \"\n",
    "result = process_query(question)\n",
    "\n",
    "print(\"\\nFinal Answer:\")\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"researcher_2.txt\", \"w\") as text_file:\n",
    "    text_file.write(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick your third 'question' (replace the ... and insert your string) \n",
    "# and execute the `process_query(question)`:\n",
    "question = \" ... \"\n",
    "result = process_query(question)\n",
    "\n",
    "print(\"\\nFinal Answer:\")\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"researcher_3.txt\", \"w\") as text_file:\n",
    "    text_file.write(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick three different appropriate questions (input query) to test the execution of the 'journalist' branch\n",
    "# where the 'journalist' agent extracts an answer for the question \n",
    "# via a web search and scraping of the most relavant web page found:\n",
    "\n",
    "# Example: \"How does LORA work in large language model fine-tuning?\"\n",
    "\n",
    "# Choose a different question as input!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick your first 'question' (replace the ... and insert your string) \n",
    "# and execute the `process_query(question)`:\n",
    "question = \" ... \"\n",
    "result = process_query(question)\n",
    "\n",
    "print(\"\\nFinal Answer:\")\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"journalist_1.txt\", \"w\") as text_file:\n",
    "    text_file.write(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick your second 'question' (replace the ... and insert your string) \n",
    "# and execute the `process_query(question)`:\n",
    "question = \" ... \"\n",
    "result = process_query(question)\n",
    "\n",
    "print(\"\\nFinal Answer:\")\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"journalist_2.txt\", \"w\") as text_file:\n",
    "    text_file.write(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick your third 'question' (replace the ... and insert your string) \n",
    "# and execute the `process_query(question)`:\n",
    "question = \" ... \"\n",
    "result = process_query(question)\n",
    "\n",
    "print(\"\\nFinal Answer:\")\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"journalist_3.txt\", \"w\") as text_file:\n",
    "    text_file.write(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission Instructions:\n",
    "\n",
    "- Submit your **6 responses** (three reponses each for the two branches listed above) as text files described above.\n",
    "\n",
    "- Submit your **executed (!) Jupyter notebook**. See instructions below.\n",
    "\n",
    "- **Important:** Your notebook solution needs to be executable with the Python packages listed and return correct answers with the selected queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework submission on new IFI cluster:\n",
    "- This homework is due by **2025-03-31, 2:30 PM (EDT) (Section 006)** or **2025-03-31, 6:00 PM (EDT) (Section 003)**, respectively.\n",
    "- Make sure that all your programs and output files are in the exact folder as specified in the instructions.\n",
    "- All file names on this system are case sensitive. Verify if you copy your work from a local computer to your home directory on the new cluster.\n",
    "- **Execute the cell below to submit your assignment (6 text files and executed notebook):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute this cell. DO NOT EDIT THIS CONTENT!\n",
    "from msa8700 import Homework2\n",
    "Homework2(__session__).submit().list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MSA8700 Python 3.12",
   "language": "python",
   "name": "conda-msa8700"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
