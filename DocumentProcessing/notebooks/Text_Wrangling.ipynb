{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Wrangling with BeautifulSoup, NLTK and spaCy\n",
    "\n",
    "**pip install bs4 nltk spacy textblob**\n",
    "\n",
    "Sources:\n",
    "\n",
    "- Dipanjan Sarkar, Text Analytics with Python: A Practitioner's Guide to Natural Language Processing, 3. Processing and Understanding Text, https://learning.oreilly.com/library/view/text-analytics-with/9781484243541/html/427287_2_En_3_Chapter.xhtml\n",
    "\n",
    "- Steven Bird, Ewan Klein, Edward Loper, Natural Language Processing with Python, Chapter 3. Processing Raw Text, https://learning.oreilly.com/library/view/natural-language-processing/9780596803346/ch03.html#sec-accessing-text\n",
    "\n",
    "Github:\n",
    "\n",
    "Text Analytics with Python - 2nd Edition, \n",
    "A Practitioner's Guide to Natural Language Processing, Ch03 - Processing and Understanding Text, https://github.com/dipanjanS/text-analytics-with-python/tree/master/New-Second-Edition\n",
    "\n",
    "NLTK How-To:\n",
    "\n",
    "https://www.nltk.org/howto.html\n",
    "\n",
    "spaCy:\n",
    "\n",
    "https://spacy.io/usage/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'gin-top: 0;\\r\\n    margin-bottom: 0;\\r\\n}\\r\\n#pg-header #pg-machine-header strong {\\r\\n    font-weight: normal;\\r\\n}\\r\\n#pg-header #pg-start-separator, #pg-footer #pg-end-separator {\\r\\n    margin-bottom: 3em;\\r\\n    margin-left: 0;\\r\\n    margin-right: auto;\\r\\n    margin-top: 2em;\\r\\n    text-align: center\\r\\n}\\r\\n\\r\\n    .xhtml_center {text-align: center; display: block;}\\r\\n    .xhtml_center table {\\r\\n        display: table;\\r\\n        text-align: left;\\r\\n        margin-left: auto;\\r\\n        margin-right: auto;\\r\\n        }</style><title>The Project Gutenberg eBook of The Bible, King James version, Book 1: Genesis, by Anonymous</title><style>/* ************************************************************************\\r\\n * classless css copied from https://www.pgdp.net/wiki/CSS_Cookbook/Styles\\r\\n * ********************************************************************** */\\r\\n/* ************************************************************************\\r\\n * set the body margins to allow whitespace along sides of window\\r\\n * ******************************************'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "data = requests.get('http://www.gutenberg.org/cache/epub/8001/pg8001.html')\n",
    "content = data.content\n",
    "print(content[1163:2200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aylor in November 2002.\n",
      "Book 01        Genesis\n",
      "01:001:001 In the beginning God created the heaven and the earth.\n",
      "01:001:002 And the earth was without form, and void; and darkness was\n",
      "           upon the face of the deep. And the Spirit of God moved upon\n",
      "           the face of the waters.\n",
      "01:001:003 And God said, Let there be light: and there was light.\n",
      "01:001:004 And God saw the light, that it was good: and God divided the\n",
      "           light from the darkness.\n",
      "01:001:005 And God called the light Day, and the darkness he called\n",
      "           Night. And the evening and the morning were the first day.\n",
      "01:001:006 And God said, Let there be a firmament in the midst of the\n",
      "           waters, and let it divide the waters from the waters.\n",
      "01:001:007 And God made the firmament, and divided the waters which were\n",
      "           under the firmament from the waters which were above the\n",
      "     \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def strip_html_tags(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    [s.extract() for s in soup(['iframe', 'script'])]\n",
    "    stripped_text = soup.get_text()\n",
    "    stripped_text = re.sub(r'[\\r|\\n|\\r\\n]+', '\\n', stripped_text)\n",
    "    return stripped_text\n",
    "\n",
    "clean_content = strip_html_tags(content)\n",
    "print(clean_content[1163:2045])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "# you need to add this on New ARC\n",
    "nltk.data.path.append(\"/data/nltk_data2025\")\n",
    "\n",
    "# nltk.download('gutenberg') not needed on New ARC\n",
    "from nltk.corpus import gutenberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"US unveils world's most powerful supercomputer, beats China. The US has unveiled the world's most powerful supercomputer called 'Summit', beating the previous record-holder China's Sunway TaihuLight. With a peak performance of 200,000 trillion calculations per second, it is over twice as fast as Sunway TaihuLight, which is capable of 93,000 trillion calculations per second. Summit has 4,608 servers, which reportedly take up the size of two tennis courts.\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading text corpora\n",
    "alice = nltk.corpus.gutenberg.raw('carroll-alice.txt')\n",
    "sample_text = (\"US unveils world's most powerful supercomputer, beats China. \" \n",
    "               \"The US has unveiled the world's most powerful supercomputer called 'Summit', \" \n",
    "               \"beating the previous record-holder China's Sunway TaihuLight. With a peak performance \"\n",
    "               \"of 200,000 trillion calculations per second, it is over twice as fast as Sunway TaihuLight, \"\n",
    "               \"which is capable of 93,000 trillion calculations per second. Summit has 4,608 servers, \"\n",
    "               \"which reportedly take up the size of two tennis courts.\")\n",
    "sample_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144395"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total characters in Alice in Wonderland\n",
    "len(alice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[Alice's Adventures in Wonderland by Lewis Carroll 1865]\\n\\nCHAPTER I. Down the Rabbit-Hole\\n\\nAlice was\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First 100 characters in the corpus\n",
    "alice[0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default sentence tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences in sample_text: 4\n",
      "Sample text sentences :-\n",
      "[\"US unveils world's most powerful supercomputer, beats China.\"\n",
      " \"The US has unveiled the world's most powerful supercomputer called 'Summit', beating the previous record-holder China's Sunway TaihuLight.\"\n",
      " 'With a peak performance of 200,000 trillion calculations per second, it is over twice as fast as Sunway TaihuLight, which is capable of 93,000 trillion calculations per second.'\n",
      " 'Summit has 4,608 servers, which reportedly take up the size of two tennis courts.']\n",
      "\n",
      "Total sentences in alice: 1625\n",
      "First 5 sentences in alice:-\n",
      "[\"[Alice's Adventures in Wonderland by Lewis Carroll 1865]\\n\\nCHAPTER I.\"\n",
      " \"Down the Rabbit-Hole\\n\\nAlice was beginning to get very tired of sitting by her sister on the\\nbank, and of having nothing to do: once or twice she had peeped into the\\nbook her sister was reading, but it had no pictures or conversations in\\nit, 'and what is the use of a book,' thought Alice 'without pictures or\\nconversation?'\"\n",
      " 'So she was considering in her own mind (as well as she could, for the\\nhot day made her feel very sleepy and stupid), whether the pleasure\\nof making a daisy-chain would be worth the trouble of getting up and\\npicking the daisies, when suddenly a White Rabbit with pink eyes ran\\nclose by her.'\n",
      " \"There was nothing so VERY remarkable in that; nor did Alice think it so\\nVERY much out of the way to hear the Rabbit say to itself, 'Oh dear!\"\n",
      " 'Oh dear!']\n"
     ]
    }
   ],
   "source": [
    "default_st = nltk.sent_tokenize\n",
    "alice_sentences = default_st(text=alice)\n",
    "sample_sentences = default_st(text=sample_text)\n",
    "\n",
    "print('Total sentences in sample_text:', len(sample_sentences))\n",
    "print('Sample text sentences :-')\n",
    "print(np.array(sample_sentences))\n",
    "\n",
    "print('\\nTotal sentences in alice:', len(alice_sentences))\n",
    "print('First 5 sentences in alice:-')\n",
    "print(np.array(alice_sentences[0:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other languages sentence tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('europarl_raw') not needed on ARC\n",
    "from nltk.corpus import europarl_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157171\n",
      " \n",
      "Wiederaufnahme der Sitzungsperiode Ich erkläre die am Freitag , dem 17. Dezember unterbrochene Sit\n"
     ]
    }
   ],
   "source": [
    "german_text = nltk.corpus.europarl_raw.german.raw('ep-00-01-17.de')\n",
    "# Total characters in the corpus\n",
    "print(len(german_text))\n",
    "# First 100 characters in the corpus\n",
    "print(german_text[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default sentence tokenizer \n",
    "german_sentences_def = default_st(text=german_text, language='german')\n",
    "\n",
    "# loading german text tokenizer into a PunktSentenceTokenizer instance  \n",
    "german_tokenizer = nltk.data.load(resource_url='tokenizers/punkt/german.pickle')\n",
    "german_sentences = german_tokenizer.tokenize(german_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'nltk.tokenize.punkt.PunktTokenizer'>\n"
     ]
    }
   ],
   "source": [
    "# verify the type of german_tokenizer\n",
    "# should be PunktSentenceTokenizer\n",
    "print(type(german_tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# check if results of both tokenizers match \n",
    "# should be True\n",
    "print(german_sentences_def == german_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' \\nWiederaufnahme der Sitzungsperiode Ich erkläre die am Freitag , dem 17. Dezember unterbrochene Sitzungsperiode des Europäischen Parlaments für wiederaufgenommen , wünsche Ihnen nochmals alles Gute zum Jahreswechsel und hoffe , daß Sie schöne Ferien hatten .'\n",
      " 'Wie Sie feststellen konnten , ist der gefürchtete \" Millenium-Bug \" nicht eingetreten .'\n",
      " 'Doch sind Bürger einiger unserer Mitgliedstaaten Opfer von schrecklichen Naturkatastrophen geworden .'\n",
      " 'Im Parlament besteht der Wunsch nach einer Aussprache im Verlauf dieser Sitzungsperiode in den nächsten Tagen .'\n",
      " 'Heute möchte ich Sie bitten - das ist auch der Wunsch einiger Kolleginnen und Kollegen - , allen Opfern der Stürme , insbesondere in den verschiedenen Ländern der Europäischen Union , in einer Schweigeminute zu gedenken .']\n"
     ]
    }
   ],
   "source": [
    "# print first 5 sentences of the corpus\n",
    "print(np.array(german_sentences[:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using PunktSentenceTokenizer for sentence tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"US unveils world's most powerful supercomputer, beats China.\"\n",
      " \"The US has unveiled the world's most powerful supercomputer called 'Summit', beating the previous record-holder China's Sunway TaihuLight.\"\n",
      " 'With a peak performance of 200,000 trillion calculations per second, it is over twice as fast as Sunway TaihuLight, which is capable of 93,000 trillion calculations per second.'\n",
      " 'Summit has 4,608 servers, which reportedly take up the size of two tennis courts.']\n"
     ]
    }
   ],
   "source": [
    "punkt_st = nltk.tokenize.PunktSentenceTokenizer()\n",
    "sample_sentences = punkt_st.tokenize(sample_text)\n",
    "print(np.array(sample_sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using RegexpTokenizer for sentence tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"US unveils world's most powerful supercomputer, beats China.\"\n",
      " \"The US has unveiled the world's most powerful supercomputer called 'Summit', beating the previous record-holder China's Sunway TaihuLight.\"\n",
      " 'With a peak performance of 200,000 trillion calculations per second, it is over twice as fast as Sunway TaihuLight, which is capable of 93,000 trillion calculations per second.'\n",
      " 'Summit has 4,608 servers, which reportedly take up the size of two tennis courts.']\n"
     ]
    }
   ],
   "source": [
    "SENTENCE_TOKENS_PATTERN = r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<![A-Z]\\.)(?<=\\.|\\?|\\!)\\s'\n",
    "regex_st = nltk.tokenize.RegexpTokenizer(\n",
    "            pattern=SENTENCE_TOKENS_PATTERN,\n",
    "            gaps=True)\n",
    "sample_sentences = regex_st.tokenize(sample_text)\n",
    "print(np.array(sample_sentences)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default word tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['US', 'unveils', 'world', \"'s\", 'most', 'powerful',\n",
       "       'supercomputer', ',', 'beats', 'China', '.', 'The', 'US', 'has',\n",
       "       'unveiled', 'the', 'world', \"'s\", 'most', 'powerful',\n",
       "       'supercomputer', 'called', \"'Summit\", \"'\", ',', 'beating', 'the',\n",
       "       'previous', 'record-holder', 'China', \"'s\", 'Sunway', 'TaihuLight',\n",
       "       '.', 'With', 'a', 'peak', 'performance', 'of', '200,000',\n",
       "       'trillion', 'calculations', 'per', 'second', ',', 'it', 'is',\n",
       "       'over', 'twice', 'as', 'fast', 'as', 'Sunway', 'TaihuLight', ',',\n",
       "       'which', 'is', 'capable', 'of', '93,000', 'trillion',\n",
       "       'calculations', 'per', 'second', '.', 'Summit', 'has', '4,608',\n",
       "       'servers', ',', 'which', 'reportedly', 'take', 'up', 'the', 'size',\n",
       "       'of', 'two', 'tennis', 'courts', '.'], dtype='<U13')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_wt = nltk.word_tokenize\n",
    "words = default_wt(sample_text)\n",
    "np.array(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treebank word tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['US', 'unveils', 'world', \"'s\", 'most', 'powerful',\n",
       "       'supercomputer', ',', 'beats', 'China.', 'The', 'US', 'has',\n",
       "       'unveiled', 'the', 'world', \"'s\", 'most', 'powerful',\n",
       "       'supercomputer', 'called', \"'Summit\", \"'\", ',', 'beating', 'the',\n",
       "       'previous', 'record-holder', 'China', \"'s\", 'Sunway',\n",
       "       'TaihuLight.', 'With', 'a', 'peak', 'performance', 'of', '200,000',\n",
       "       'trillion', 'calculations', 'per', 'second', ',', 'it', 'is',\n",
       "       'over', 'twice', 'as', 'fast', 'as', 'Sunway', 'TaihuLight', ',',\n",
       "       'which', 'is', 'capable', 'of', '93,000', 'trillion',\n",
       "       'calculations', 'per', 'second.', 'Summit', 'has', '4,608',\n",
       "       'servers', ',', 'which', 'reportedly', 'take', 'up', 'the', 'size',\n",
       "       'of', 'two', 'tennis', 'courts', '.'], dtype='<U13')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treebank_wt = nltk.TreebankWordTokenizer()\n",
    "words = treebank_wt.tokenize(sample_text)\n",
    "np.array(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TokTok Word Tokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['US', 'unveils', 'world', \"'\", 's', 'most', 'powerful',\n",
       "       'supercomputer', ',', 'beats', 'China.', 'The', 'US', 'has',\n",
       "       'unveiled', 'the', 'world', \"'\", 's', 'most', 'powerful',\n",
       "       'supercomputer', 'called', \"'\", 'Summit', \"'\", ',', 'beating',\n",
       "       'the', 'previous', 'record-holder', 'China', \"'\", 's', 'Sunway',\n",
       "       'TaihuLight.', 'With', 'a', 'peak', 'performance', 'of', '200,000',\n",
       "       'trillion', 'calculations', 'per', 'second', ',', 'it', 'is',\n",
       "       'over', 'twice', 'as', 'fast', 'as', 'Sunway', 'TaihuLight', ',',\n",
       "       'which', 'is', 'capable', 'of', '93,000', 'trillion',\n",
       "       'calculations', 'per', 'second.', 'Summit', 'has', '4,608',\n",
       "       'servers', ',', 'which', 'reportedly', 'take', 'up', 'the', 'size',\n",
       "       'of', 'two', 'tennis', 'courts', '.'], dtype='<U13')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "tokenizer = ToktokTokenizer()\n",
    "words = tokenizer.tokenize(sample_text)\n",
    "np.array(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regexp word tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['US', 'unveils', 'world', 's', 'most', 'powerful', 'supercomputer',\n",
       "       'beats', 'China', 'The', 'US', 'has', 'unveiled', 'the', 'world',\n",
       "       's', 'most', 'powerful', 'supercomputer', 'called', 'Summit',\n",
       "       'beating', 'the', 'previous', 'record', 'holder', 'China', 's',\n",
       "       'Sunway', 'TaihuLight', 'With', 'a', 'peak', 'performance', 'of',\n",
       "       '200', '000', 'trillion', 'calculations', 'per', 'second', 'it',\n",
       "       'is', 'over', 'twice', 'as', 'fast', 'as', 'Sunway', 'TaihuLight',\n",
       "       'which', 'is', 'capable', 'of', '93', '000', 'trillion',\n",
       "       'calculations', 'per', 'second', 'Summit', 'has', '4', '608',\n",
       "       'servers', 'which', 'reportedly', 'take', 'up', 'the', 'size',\n",
       "       'of', 'two', 'tennis', 'courts'], dtype='<U13')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOKEN_PATTERN = r'\\w+'        \n",
    "regex_wt = nltk.RegexpTokenizer(pattern=TOKEN_PATTERN,\n",
    "                                gaps=False)\n",
    "words = regex_wt.tokenize(sample_text)\n",
    "np.array(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['US', 'unveils', \"world's\", 'most', 'powerful', 'supercomputer,',\n",
       "       'beats', 'China.', 'The', 'US', 'has', 'unveiled', 'the',\n",
       "       \"world's\", 'most', 'powerful', 'supercomputer', 'called',\n",
       "       \"'Summit',\", 'beating', 'the', 'previous', 'record-holder',\n",
       "       \"China's\", 'Sunway', 'TaihuLight.', 'With', 'a', 'peak',\n",
       "       'performance', 'of', '200,000', 'trillion', 'calculations', 'per',\n",
       "       'second,', 'it', 'is', 'over', 'twice', 'as', 'fast', 'as',\n",
       "       'Sunway', 'TaihuLight,', 'which', 'is', 'capable', 'of', '93,000',\n",
       "       'trillion', 'calculations', 'per', 'second.', 'Summit', 'has',\n",
       "       '4,608', 'servers,', 'which', 'reportedly', 'take', 'up', 'the',\n",
       "       'size', 'of', 'two', 'tennis', 'courts.'], dtype='<U14')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GAP_PATTERN = r'\\s+'        \n",
    "regex_wt = nltk.RegexpTokenizer(pattern=GAP_PATTERN,\n",
    "                                gaps=True)\n",
    "words = regex_wt.tokenize(sample_text)\n",
    "np.array(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 2), (3, 10), (11, 18), (19, 23), (24, 32), (33, 47), (48, 53), (54, 60), (61, 64), (65, 67), (68, 71), (72, 80), (81, 84), (85, 92), (93, 97), (98, 106), (107, 120), (121, 127), (128, 137), (138, 145), (146, 149), (150, 158), (159, 172), (173, 180), (181, 187), (188, 199), (200, 204), (205, 206), (207, 211), (212, 223), (224, 226), (227, 234), (235, 243), (244, 256), (257, 260), (261, 268), (269, 271), (272, 274), (275, 279), (280, 285), (286, 288), (289, 293), (294, 296), (297, 303), (304, 315), (316, 321), (322, 324), (325, 332), (333, 335), (336, 342), (343, 351), (352, 364), (365, 368), (369, 376), (377, 383), (384, 387), (388, 393), (394, 402), (403, 408), (409, 419), (420, 424), (425, 427), (428, 431), (432, 436), (437, 439), (440, 443), (444, 450), (451, 458)]\n",
      "['US' 'unveils' \"world's\" 'most' 'powerful' 'supercomputer,' 'beats'\n",
      " 'China.' 'The' 'US' 'has' 'unveiled' 'the' \"world's\" 'most' 'powerful'\n",
      " 'supercomputer' 'called' \"'Summit',\" 'beating' 'the' 'previous'\n",
      " 'record-holder' \"China's\" 'Sunway' 'TaihuLight.' 'With' 'a' 'peak'\n",
      " 'performance' 'of' '200,000' 'trillion' 'calculations' 'per' 'second,'\n",
      " 'it' 'is' 'over' 'twice' 'as' 'fast' 'as' 'Sunway' 'TaihuLight,' 'which'\n",
      " 'is' 'capable' 'of' '93,000' 'trillion' 'calculations' 'per' 'second.'\n",
      " 'Summit' 'has' '4,608' 'servers,' 'which' 'reportedly' 'take' 'up' 'the'\n",
      " 'size' 'of' 'two' 'tennis' 'courts.']\n"
     ]
    }
   ],
   "source": [
    "word_indices = list(regex_wt.span_tokenize(sample_text))\n",
    "print(word_indices)\n",
    "print(np.array([sample_text[start:end] for start, end in word_indices]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derived regex tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['US', 'unveils', 'world', \"'\", 's', 'most', 'powerful',\n",
       "       'supercomputer', ',', 'beats', 'China', '.', 'The', 'US', 'has',\n",
       "       'unveiled', 'the', 'world', \"'\", 's', 'most', 'powerful',\n",
       "       'supercomputer', 'called', \"'\", 'Summit', \"',\", 'beating', 'the',\n",
       "       'previous', 'record', '-', 'holder', 'China', \"'\", 's', 'Sunway',\n",
       "       'TaihuLight', '.', 'With', 'a', 'peak', 'performance', 'of', '200',\n",
       "       ',', '000', 'trillion', 'calculations', 'per', 'second', ',', 'it',\n",
       "       'is', 'over', 'twice', 'as', 'fast', 'as', 'Sunway', 'TaihuLight',\n",
       "       ',', 'which', 'is', 'capable', 'of', '93', ',', '000', 'trillion',\n",
       "       'calculations', 'per', 'second', '.', 'Summit', 'has', '4', ',',\n",
       "       '608', 'servers', ',', 'which', 'reportedly', 'take', 'up', 'the',\n",
       "       'size', 'of', 'two', 'tennis', 'courts', '.'], dtype='<U13')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordpunkt_wt = nltk.WordPunctTokenizer()\n",
    "words = wordpunkt_wt.tokenize(sample_text)\n",
    "np.array(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['US', 'unveils', \"world's\", 'most', 'powerful', 'supercomputer,',\n",
       "       'beats', 'China.', 'The', 'US', 'has', 'unveiled', 'the',\n",
       "       \"world's\", 'most', 'powerful', 'supercomputer', 'called',\n",
       "       \"'Summit',\", 'beating', 'the', 'previous', 'record-holder',\n",
       "       \"China's\", 'Sunway', 'TaihuLight.', 'With', 'a', 'peak',\n",
       "       'performance', 'of', '200,000', 'trillion', 'calculations', 'per',\n",
       "       'second,', 'it', 'is', 'over', 'twice', 'as', 'fast', 'as',\n",
       "       'Sunway', 'TaihuLight,', 'which', 'is', 'capable', 'of', '93,000',\n",
       "       'trillion', 'calculations', 'per', 'second.', 'Summit', 'has',\n",
       "       '4,608', 'servers,', 'which', 'reportedly', 'take', 'up', 'the',\n",
       "       'size', 'of', 'two', 'tennis', 'courts.'], dtype='<U14')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whitespace_wt = nltk.WhitespaceTokenizer()\n",
    "words = whitespace_wt.tokenize(sample_text)\n",
    "np.array(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Tokenizers with NLTK and spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['US',\n",
       "  'unveils',\n",
       "  'world',\n",
       "  \"'s\",\n",
       "  'most',\n",
       "  'powerful',\n",
       "  'supercomputer',\n",
       "  ',',\n",
       "  'beats',\n",
       "  'China',\n",
       "  '.'],\n",
       " ['The',\n",
       "  'US',\n",
       "  'has',\n",
       "  'unveiled',\n",
       "  'the',\n",
       "  'world',\n",
       "  \"'s\",\n",
       "  'most',\n",
       "  'powerful',\n",
       "  'supercomputer',\n",
       "  'called',\n",
       "  \"'Summit\",\n",
       "  \"'\",\n",
       "  ',',\n",
       "  'beating',\n",
       "  'the',\n",
       "  'previous',\n",
       "  'record-holder',\n",
       "  'China',\n",
       "  \"'s\",\n",
       "  'Sunway',\n",
       "  'TaihuLight',\n",
       "  '.'],\n",
       " ['With',\n",
       "  'a',\n",
       "  'peak',\n",
       "  'performance',\n",
       "  'of',\n",
       "  '200,000',\n",
       "  'trillion',\n",
       "  'calculations',\n",
       "  'per',\n",
       "  'second',\n",
       "  ',',\n",
       "  'it',\n",
       "  'is',\n",
       "  'over',\n",
       "  'twice',\n",
       "  'as',\n",
       "  'fast',\n",
       "  'as',\n",
       "  'Sunway',\n",
       "  'TaihuLight',\n",
       "  ',',\n",
       "  'which',\n",
       "  'is',\n",
       "  'capable',\n",
       "  'of',\n",
       "  '93,000',\n",
       "  'trillion',\n",
       "  'calculations',\n",
       "  'per',\n",
       "  'second',\n",
       "  '.'],\n",
       " ['Summit',\n",
       "  'has',\n",
       "  '4,608',\n",
       "  'servers',\n",
       "  ',',\n",
       "  'which',\n",
       "  'reportedly',\n",
       "  'take',\n",
       "  'up',\n",
       "  'the',\n",
       "  'size',\n",
       "  'of',\n",
       "  'two',\n",
       "  'tennis',\n",
       "  'courts',\n",
       "  '.']]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_text(text):\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    word_tokens = [nltk.word_tokenize(sentence) for sentence in sentences] \n",
    "    return word_tokens\n",
    "\n",
    "sents = tokenize_text(sample_text)\n",
    "sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['US', 'unveils', 'world', \"'s\", 'most', 'powerful',\n",
       "       'supercomputer', ',', 'beats', 'China', '.', 'The', 'US', 'has',\n",
       "       'unveiled', 'the', 'world', \"'s\", 'most', 'powerful',\n",
       "       'supercomputer', 'called', \"'Summit\", \"'\", ',', 'beating', 'the',\n",
       "       'previous', 'record-holder', 'China', \"'s\", 'Sunway', 'TaihuLight',\n",
       "       '.', 'With', 'a', 'peak', 'performance', 'of', '200,000',\n",
       "       'trillion', 'calculations', 'per', 'second', ',', 'it', 'is',\n",
       "       'over', 'twice', 'as', 'fast', 'as', 'Sunway', 'TaihuLight', ',',\n",
       "       'which', 'is', 'capable', 'of', '93,000', 'trillion',\n",
       "       'calculations', 'per', 'second', '.', 'Summit', 'has', '4,608',\n",
       "       'servers', ',', 'which', 'reportedly', 'take', 'up', 'the', 'size',\n",
       "       'of', 'two', 'tennis', 'courts', '.'], dtype='<U13')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = [word for sentence in sents for word in sentence]\n",
    "np.array(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Not needed on New ARC !python3 -m spacy download en_core_web_md  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "text_spacy = nlp(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[US unveils world's most powerful supercomputer, beats China.,\n",
       " The US has unveiled the world's most powerful supercomputer called 'Summit', beating the previous record-holder China's Sunway TaihuLight.,\n",
       " With a peak performance of 200,000 trillion calculations per second, it is over twice as fast as Sunway TaihuLight, which is capable of 93,000 trillion calculations per second.,\n",
       " Summit has 4,608 servers, which reportedly take up the size of two tennis courts.]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents = list(text_spacy.sents)\n",
    "sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['US',\n",
       "  'unveils',\n",
       "  'world',\n",
       "  \"'s\",\n",
       "  'most',\n",
       "  'powerful',\n",
       "  'supercomputer',\n",
       "  ',',\n",
       "  'beats',\n",
       "  'China',\n",
       "  '.'],\n",
       " ['The',\n",
       "  'US',\n",
       "  'has',\n",
       "  'unveiled',\n",
       "  'the',\n",
       "  'world',\n",
       "  \"'s\",\n",
       "  'most',\n",
       "  'powerful',\n",
       "  'supercomputer',\n",
       "  'called',\n",
       "  \"'\",\n",
       "  'Summit',\n",
       "  \"'\",\n",
       "  ',',\n",
       "  'beating',\n",
       "  'the',\n",
       "  'previous',\n",
       "  'record',\n",
       "  '-',\n",
       "  'holder',\n",
       "  'China',\n",
       "  \"'s\",\n",
       "  'Sunway',\n",
       "  'TaihuLight',\n",
       "  '.'],\n",
       " ['With',\n",
       "  'a',\n",
       "  'peak',\n",
       "  'performance',\n",
       "  'of',\n",
       "  '200,000',\n",
       "  'trillion',\n",
       "  'calculations',\n",
       "  'per',\n",
       "  'second',\n",
       "  ',',\n",
       "  'it',\n",
       "  'is',\n",
       "  'over',\n",
       "  'twice',\n",
       "  'as',\n",
       "  'fast',\n",
       "  'as',\n",
       "  'Sunway',\n",
       "  'TaihuLight',\n",
       "  ',',\n",
       "  'which',\n",
       "  'is',\n",
       "  'capable',\n",
       "  'of',\n",
       "  '93,000',\n",
       "  'trillion',\n",
       "  'calculations',\n",
       "  'per',\n",
       "  'second',\n",
       "  '.'],\n",
       " ['Summit',\n",
       "  'has',\n",
       "  '4,608',\n",
       "  'servers',\n",
       "  ',',\n",
       "  'which',\n",
       "  'reportedly',\n",
       "  'take',\n",
       "  'up',\n",
       "  'the',\n",
       "  'size',\n",
       "  'of',\n",
       "  'two',\n",
       "  'tennis',\n",
       "  'courts',\n",
       "  '.']]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_words = [[word.text for word in sent] for sent in sents]\n",
    "sent_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['US',\n",
       " 'unveils',\n",
       " 'world',\n",
       " \"'s\",\n",
       " 'most',\n",
       " 'powerful',\n",
       " 'supercomputer',\n",
       " ',',\n",
       " 'beats',\n",
       " 'China',\n",
       " '.',\n",
       " 'The',\n",
       " 'US',\n",
       " 'has',\n",
       " 'unveiled',\n",
       " 'the',\n",
       " 'world',\n",
       " \"'s\",\n",
       " 'most',\n",
       " 'powerful',\n",
       " 'supercomputer',\n",
       " 'called',\n",
       " \"'\",\n",
       " 'Summit',\n",
       " \"'\",\n",
       " ',',\n",
       " 'beating',\n",
       " 'the',\n",
       " 'previous',\n",
       " 'record',\n",
       " '-',\n",
       " 'holder',\n",
       " 'China',\n",
       " \"'s\",\n",
       " 'Sunway',\n",
       " 'TaihuLight',\n",
       " '.',\n",
       " 'With',\n",
       " 'a',\n",
       " 'peak',\n",
       " 'performance',\n",
       " 'of',\n",
       " '200,000',\n",
       " 'trillion',\n",
       " 'calculations',\n",
       " 'per',\n",
       " 'second',\n",
       " ',',\n",
       " 'it',\n",
       " 'is',\n",
       " 'over',\n",
       " 'twice',\n",
       " 'as',\n",
       " 'fast',\n",
       " 'as',\n",
       " 'Sunway',\n",
       " 'TaihuLight',\n",
       " ',',\n",
       " 'which',\n",
       " 'is',\n",
       " 'capable',\n",
       " 'of',\n",
       " '93,000',\n",
       " 'trillion',\n",
       " 'calculations',\n",
       " 'per',\n",
       " 'second',\n",
       " '.',\n",
       " 'Summit',\n",
       " 'has',\n",
       " '4,608',\n",
       " 'servers',\n",
       " ',',\n",
       " 'which',\n",
       " 'reportedly',\n",
       " 'take',\n",
       " 'up',\n",
       " 'the',\n",
       " 'size',\n",
       " 'of',\n",
       " 'two',\n",
       " 'tennis',\n",
       " 'courts',\n",
       " '.']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = [word.text for word in text_spacy]\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing Accented Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Some Accented text'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unicodedata\n",
    "\n",
    "def remove_accented_chars(text):\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    return text\n",
    "\n",
    "remove_accented_chars('Sómě Áccěntěd těxt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expanding Contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contractions import CONTRACTION_MAP\n",
    "import re\n",
    "\n",
    "def expand_contractions(text, contraction_mapping=CONTRACTION_MAP):\n",
    "    \n",
    "    contractions_pattern = re.compile('({})'.format('|'.join(contraction_mapping.keys())), \n",
    "                                      flags=re.IGNORECASE|re.DOTALL)\n",
    "    def expand_match(contraction):\n",
    "        match = contraction.group(0)\n",
    "        first_char = match[0]\n",
    "        expanded_contraction = contraction_mapping.get(match)\\\n",
    "                                if contraction_mapping.get(match)\\\n",
    "                                else contraction_mapping.get(match.lower())                       \n",
    "        expanded_contraction = first_char+expanded_contraction[1:]\n",
    "        return expanded_contraction\n",
    "        \n",
    "    expanded_text = contractions_pattern.sub(expand_match, text)\n",
    "    expanded_text = re.sub(\"'\", \"\", expanded_text)\n",
    "    return expanded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You all cannot expand contractions I would think'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expand_contractions(\"Y'all can't expand contractions I'd think\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing Special Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Well this was fun What do you think '"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_special_characters(text, remove_digits=False):\n",
    "    pattern = r'[^a-zA-z0-9\\s]' if not remove_digits else r'[^a-zA-z\\s]'\n",
    "    text = re.sub(pattern, '', text)\n",
    "    return text\n",
    "\n",
    "remove_special_characters(\"Well this was fun! What do you think? 123#@!\", \n",
    "                          remove_digits=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the quick brown fox jumped over the big dog'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'The quick brown fox jumped over The Big Dog'\n",
    "text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'THE QUICK BROWN FOX JUMPED OVER THE BIG DOG'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Quick Brown Fox Jumped Over The Big Dog'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.title()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correcting repeating characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1 Word: finalllyy\n",
      "Step: 2 Word: finallly\n",
      "Step: 3 Word: finally\n",
      "Step: 4 Word: finaly\n",
      "Final word: finaly\n"
     ]
    }
   ],
   "source": [
    "old_word = 'finalllyyy'\n",
    "repeat_pattern = re.compile(r'(\\w*)(\\w)\\2(\\w*)')\n",
    "match_substitution = r'\\1\\2\\3'\n",
    "step = 1\n",
    "\n",
    "while True:\n",
    "    # remove one repeated character\n",
    "    new_word = repeat_pattern.sub(match_substitution,\n",
    "                                  old_word)\n",
    "    if new_word != old_word:\n",
    "         print('Step: {} Word: {}'.format(step, new_word))\n",
    "         step += 1 # update step\n",
    "         # update old word to last substituted state\n",
    "         old_word = new_word  \n",
    "         continue\n",
    "    else:\n",
    "         print(\"Final word:\", new_word)\n",
    "         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1 Word: finalllyy\n",
      "Step: 2 Word: finallly\n",
      "Step: 3 Word: finally\n",
      "Final correct word: finally\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "old_word = 'finalllyyy'\n",
    "repeat_pattern = re.compile(r'(\\w*)(\\w)\\2(\\w*)')\n",
    "match_substitution = r'\\1\\2\\3'\n",
    "step = 1\n",
    " \n",
    "while True:\n",
    "    # check for semantically correct word\n",
    "    if wordnet.synsets(old_word):\n",
    "        print(\"Final correct word:\", old_word)\n",
    "        break\n",
    "    # remove one repeated character\n",
    "    new_word = repeat_pattern.sub(match_substitution,\n",
    "                                  old_word)\n",
    "    if new_word != old_word:\n",
    "        print('Step: {} Word: {}'.format(step, new_word))\n",
    "        step += 1 # update step\n",
    "        # update old word to last substituted state\n",
    "        old_word = new_word  \n",
    "        continue\n",
    "    else:\n",
    "        print(\"Final word:\", new_word)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "def remove_repeated_characters(tokens):\n",
    "    repeat_pattern = re.compile(r'(\\w*)(\\w)\\2(\\w*)')\n",
    "    match_substitution = r'\\1\\2\\3'\n",
    "    def replace(old_word):\n",
    "        if wordnet.synsets(old_word):\n",
    "            return old_word\n",
    "        new_word = repeat_pattern.sub(match_substitution, old_word)\n",
    "        return replace(new_word) if new_word != old_word else new_word\n",
    "            \n",
    "    correct_tokens = [replace(word) for word in tokens]\n",
    "    return correct_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My school is really amazing'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sentence = 'My schooool is realllllyyy amaaazingggg'\n",
    "correct_tokens = remove_repeated_characters(nltk.word_tokenize(sample_sentence))\n",
    "' '.join(correct_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correcting spellings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 80030),\n",
       " ('of', 40025),\n",
       " ('and', 38313),\n",
       " ('to', 28766),\n",
       " ('in', 22050),\n",
       " ('a', 21155),\n",
       " ('that', 12512),\n",
       " ('he', 12401),\n",
       " ('was', 11410),\n",
       " ('it', 10681)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re, collections\n",
    "\n",
    "def tokens(text): \n",
    "    \"\"\"\n",
    "    Get all words from the corpus\n",
    "    \"\"\"\n",
    "    return re.findall('[a-z]+', text.lower()) \n",
    "\n",
    "WORDS = tokens(open('data/big.txt').read())\n",
    "WORD_COUNTS = collections.Counter(WORDS)\n",
    "# top 10 words in corpus\n",
    "WORD_COUNTS.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edits0(word): \n",
    "    \"\"\"\n",
    "    Return all strings that are zero edits away \n",
    "    from the input word (i.e., the word itself).\n",
    "    \"\"\"\n",
    "    return {word}\n",
    "\n",
    "\n",
    "\n",
    "def edits1(word):\n",
    "    \"\"\"\n",
    "    Return all strings that are one edit away \n",
    "    from the input word.\n",
    "    \"\"\"\n",
    "    alphabet = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    def splits(word):\n",
    "        \"\"\"\n",
    "        Return a list of all possible (first, rest) pairs \n",
    "        that the input word is made of.\n",
    "        \"\"\"\n",
    "        return [(word[:i], word[i:]) \n",
    "                for i in range(len(word)+1)]\n",
    "                \n",
    "    pairs      = splits(word)\n",
    "    deletes    = [a+b[1:]           for (a, b) in pairs if b]\n",
    "    transposes = [a+b[1]+b[0]+b[2:] for (a, b) in pairs if len(b) > 1]\n",
    "    replaces   = [a+c+b[1:]         for (a, b) in pairs for c in alphabet if b]\n",
    "    inserts    = [a+c+b             for (a, b) in pairs for c in alphabet]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "\n",
    "def edits2(word):\n",
    "    \"\"\"Return all strings that are two edits away \n",
    "    from the input word.\n",
    "    \"\"\"\n",
    "    return {e2 for e1 in edits1(word) for e2 in edits1(e1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def known(words):\n",
    "    \"\"\"\n",
    "    Return the subset of words that are actually \n",
    "    in our WORD_COUNTS dictionary.\n",
    "    \"\"\"\n",
    "    return {w for w in words if w in WORD_COUNTS}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fianlly'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input word\n",
    "In [409]: word = 'fianlly'\n",
    "\n",
    "# zero edit distance from input word\n",
    "edits0(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returns null set since it is not a valid word\n",
    "known(edits0(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'afianlly',\n",
       " 'aianlly',\n",
       " 'bfianlly',\n",
       " 'bianlly',\n",
       " 'cfianlly',\n",
       " 'cianlly',\n",
       " 'dfianlly',\n",
       " 'dianlly',\n",
       " 'efianlly',\n",
       " 'eianlly',\n",
       " 'faanlly',\n",
       " 'faianlly',\n",
       " 'fainlly',\n",
       " 'fanlly',\n",
       " 'fbanlly',\n",
       " 'fbianlly',\n",
       " 'fcanlly',\n",
       " 'fcianlly',\n",
       " 'fdanlly',\n",
       " 'fdianlly',\n",
       " 'feanlly',\n",
       " 'feianlly',\n",
       " 'ffanlly',\n",
       " 'ffianlly',\n",
       " 'fganlly',\n",
       " 'fgianlly',\n",
       " 'fhanlly',\n",
       " 'fhianlly',\n",
       " 'fiaally',\n",
       " 'fiaanlly',\n",
       " 'fiablly',\n",
       " 'fiabnlly',\n",
       " 'fiaclly',\n",
       " 'fiacnlly',\n",
       " 'fiadlly',\n",
       " 'fiadnlly',\n",
       " 'fiaelly',\n",
       " 'fiaenlly',\n",
       " 'fiaflly',\n",
       " 'fiafnlly',\n",
       " 'fiaglly',\n",
       " 'fiagnlly',\n",
       " 'fiahlly',\n",
       " 'fiahnlly',\n",
       " 'fiailly',\n",
       " 'fiainlly',\n",
       " 'fiajlly',\n",
       " 'fiajnlly',\n",
       " 'fiaklly',\n",
       " 'fiaknlly',\n",
       " 'fiallly',\n",
       " 'fially',\n",
       " 'fialnlly',\n",
       " 'fialnly',\n",
       " 'fiamlly',\n",
       " 'fiamnlly',\n",
       " 'fianally',\n",
       " 'fianaly',\n",
       " 'fianblly',\n",
       " 'fianbly',\n",
       " 'fianclly',\n",
       " 'fiancly',\n",
       " 'fiandlly',\n",
       " 'fiandly',\n",
       " 'fianelly',\n",
       " 'fianely',\n",
       " 'fianflly',\n",
       " 'fianfly',\n",
       " 'fianglly',\n",
       " 'fiangly',\n",
       " 'fianhlly',\n",
       " 'fianhly',\n",
       " 'fianilly',\n",
       " 'fianily',\n",
       " 'fianjlly',\n",
       " 'fianjly',\n",
       " 'fianklly',\n",
       " 'fiankly',\n",
       " 'fianlaly',\n",
       " 'fianlay',\n",
       " 'fianlbly',\n",
       " 'fianlby',\n",
       " 'fianlcly',\n",
       " 'fianlcy',\n",
       " 'fianldly',\n",
       " 'fianldy',\n",
       " 'fianlely',\n",
       " 'fianley',\n",
       " 'fianlfly',\n",
       " 'fianlfy',\n",
       " 'fianlgly',\n",
       " 'fianlgy',\n",
       " 'fianlhly',\n",
       " 'fianlhy',\n",
       " 'fianlily',\n",
       " 'fianliy',\n",
       " 'fianljly',\n",
       " 'fianljy',\n",
       " 'fianlkly',\n",
       " 'fianlky',\n",
       " 'fianll',\n",
       " 'fianlla',\n",
       " 'fianllay',\n",
       " 'fianllb',\n",
       " 'fianllby',\n",
       " 'fianllc',\n",
       " 'fianllcy',\n",
       " 'fianlld',\n",
       " 'fianlldy',\n",
       " 'fianlle',\n",
       " 'fianlley',\n",
       " 'fianllf',\n",
       " 'fianllfy',\n",
       " 'fianllg',\n",
       " 'fianllgy',\n",
       " 'fianllh',\n",
       " 'fianllhy',\n",
       " 'fianlli',\n",
       " 'fianlliy',\n",
       " 'fianllj',\n",
       " 'fianlljy',\n",
       " 'fianllk',\n",
       " 'fianllky',\n",
       " 'fianlll',\n",
       " 'fianllly',\n",
       " 'fianllm',\n",
       " 'fianllmy',\n",
       " 'fianlln',\n",
       " 'fianllny',\n",
       " 'fianllo',\n",
       " 'fianlloy',\n",
       " 'fianllp',\n",
       " 'fianllpy',\n",
       " 'fianllq',\n",
       " 'fianllqy',\n",
       " 'fianllr',\n",
       " 'fianllry',\n",
       " 'fianlls',\n",
       " 'fianllsy',\n",
       " 'fianllt',\n",
       " 'fianllty',\n",
       " 'fianllu',\n",
       " 'fianlluy',\n",
       " 'fianllv',\n",
       " 'fianllvy',\n",
       " 'fianllw',\n",
       " 'fianllwy',\n",
       " 'fianllx',\n",
       " 'fianllxy',\n",
       " 'fianlly',\n",
       " 'fianllya',\n",
       " 'fianllyb',\n",
       " 'fianllyc',\n",
       " 'fianllyd',\n",
       " 'fianllye',\n",
       " 'fianllyf',\n",
       " 'fianllyg',\n",
       " 'fianllyh',\n",
       " 'fianllyi',\n",
       " 'fianllyj',\n",
       " 'fianllyk',\n",
       " 'fianllyl',\n",
       " 'fianllym',\n",
       " 'fianllyn',\n",
       " 'fianllyo',\n",
       " 'fianllyp',\n",
       " 'fianllyq',\n",
       " 'fianllyr',\n",
       " 'fianllys',\n",
       " 'fianllyt',\n",
       " 'fianllyu',\n",
       " 'fianllyv',\n",
       " 'fianllyw',\n",
       " 'fianllyx',\n",
       " 'fianllyy',\n",
       " 'fianllyz',\n",
       " 'fianllz',\n",
       " 'fianllzy',\n",
       " 'fianlmly',\n",
       " 'fianlmy',\n",
       " 'fianlnly',\n",
       " 'fianlny',\n",
       " 'fianloly',\n",
       " 'fianloy',\n",
       " 'fianlply',\n",
       " 'fianlpy',\n",
       " 'fianlqly',\n",
       " 'fianlqy',\n",
       " 'fianlrly',\n",
       " 'fianlry',\n",
       " 'fianlsly',\n",
       " 'fianlsy',\n",
       " 'fianltly',\n",
       " 'fianlty',\n",
       " 'fianluly',\n",
       " 'fianluy',\n",
       " 'fianlvly',\n",
       " 'fianlvy',\n",
       " 'fianlwly',\n",
       " 'fianlwy',\n",
       " 'fianlxly',\n",
       " 'fianlxy',\n",
       " 'fianly',\n",
       " 'fianlyl',\n",
       " 'fianlyly',\n",
       " 'fianlyy',\n",
       " 'fianlzly',\n",
       " 'fianlzy',\n",
       " 'fianmlly',\n",
       " 'fianmly',\n",
       " 'fiannlly',\n",
       " 'fiannly',\n",
       " 'fianolly',\n",
       " 'fianoly',\n",
       " 'fianplly',\n",
       " 'fianply',\n",
       " 'fianqlly',\n",
       " 'fianqly',\n",
       " 'fianrlly',\n",
       " 'fianrly',\n",
       " 'fianslly',\n",
       " 'fiansly',\n",
       " 'fiantlly',\n",
       " 'fiantly',\n",
       " 'fianully',\n",
       " 'fianuly',\n",
       " 'fianvlly',\n",
       " 'fianvly',\n",
       " 'fianwlly',\n",
       " 'fianwly',\n",
       " 'fianxlly',\n",
       " 'fianxly',\n",
       " 'fianylly',\n",
       " 'fianyly',\n",
       " 'fianzlly',\n",
       " 'fianzly',\n",
       " 'fiaolly',\n",
       " 'fiaonlly',\n",
       " 'fiaplly',\n",
       " 'fiapnlly',\n",
       " 'fiaqlly',\n",
       " 'fiaqnlly',\n",
       " 'fiarlly',\n",
       " 'fiarnlly',\n",
       " 'fiaslly',\n",
       " 'fiasnlly',\n",
       " 'fiatlly',\n",
       " 'fiatnlly',\n",
       " 'fiaully',\n",
       " 'fiaunlly',\n",
       " 'fiavlly',\n",
       " 'fiavnlly',\n",
       " 'fiawlly',\n",
       " 'fiawnlly',\n",
       " 'fiaxlly',\n",
       " 'fiaxnlly',\n",
       " 'fiaylly',\n",
       " 'fiaynlly',\n",
       " 'fiazlly',\n",
       " 'fiaznlly',\n",
       " 'fibanlly',\n",
       " 'fibnlly',\n",
       " 'ficanlly',\n",
       " 'ficnlly',\n",
       " 'fidanlly',\n",
       " 'fidnlly',\n",
       " 'fieanlly',\n",
       " 'fienlly',\n",
       " 'fifanlly',\n",
       " 'fifnlly',\n",
       " 'figanlly',\n",
       " 'fignlly',\n",
       " 'fihanlly',\n",
       " 'fihnlly',\n",
       " 'fiianlly',\n",
       " 'fiinlly',\n",
       " 'fijanlly',\n",
       " 'fijnlly',\n",
       " 'fikanlly',\n",
       " 'fiknlly',\n",
       " 'filanlly',\n",
       " 'filnlly',\n",
       " 'fimanlly',\n",
       " 'fimnlly',\n",
       " 'finally',\n",
       " 'finanlly',\n",
       " 'finlly',\n",
       " 'finnlly',\n",
       " 'fioanlly',\n",
       " 'fionlly',\n",
       " 'fipanlly',\n",
       " 'fipnlly',\n",
       " 'fiqanlly',\n",
       " 'fiqnlly',\n",
       " 'firanlly',\n",
       " 'firnlly',\n",
       " 'fisanlly',\n",
       " 'fisnlly',\n",
       " 'fitanlly',\n",
       " 'fitnlly',\n",
       " 'fiuanlly',\n",
       " 'fiunlly',\n",
       " 'fivanlly',\n",
       " 'fivnlly',\n",
       " 'fiwanlly',\n",
       " 'fiwnlly',\n",
       " 'fixanlly',\n",
       " 'fixnlly',\n",
       " 'fiyanlly',\n",
       " 'fiynlly',\n",
       " 'fizanlly',\n",
       " 'fiznlly',\n",
       " 'fjanlly',\n",
       " 'fjianlly',\n",
       " 'fkanlly',\n",
       " 'fkianlly',\n",
       " 'flanlly',\n",
       " 'flianlly',\n",
       " 'fmanlly',\n",
       " 'fmianlly',\n",
       " 'fnanlly',\n",
       " 'fnianlly',\n",
       " 'foanlly',\n",
       " 'foianlly',\n",
       " 'fpanlly',\n",
       " 'fpianlly',\n",
       " 'fqanlly',\n",
       " 'fqianlly',\n",
       " 'franlly',\n",
       " 'frianlly',\n",
       " 'fsanlly',\n",
       " 'fsianlly',\n",
       " 'ftanlly',\n",
       " 'ftianlly',\n",
       " 'fuanlly',\n",
       " 'fuianlly',\n",
       " 'fvanlly',\n",
       " 'fvianlly',\n",
       " 'fwanlly',\n",
       " 'fwianlly',\n",
       " 'fxanlly',\n",
       " 'fxianlly',\n",
       " 'fyanlly',\n",
       " 'fyianlly',\n",
       " 'fzanlly',\n",
       " 'fzianlly',\n",
       " 'gfianlly',\n",
       " 'gianlly',\n",
       " 'hfianlly',\n",
       " 'hianlly',\n",
       " 'ianlly',\n",
       " 'ifanlly',\n",
       " 'ifianlly',\n",
       " 'iianlly',\n",
       " 'jfianlly',\n",
       " 'jianlly',\n",
       " 'kfianlly',\n",
       " 'kianlly',\n",
       " 'lfianlly',\n",
       " 'lianlly',\n",
       " 'mfianlly',\n",
       " 'mianlly',\n",
       " 'nfianlly',\n",
       " 'nianlly',\n",
       " 'ofianlly',\n",
       " 'oianlly',\n",
       " 'pfianlly',\n",
       " 'pianlly',\n",
       " 'qfianlly',\n",
       " 'qianlly',\n",
       " 'rfianlly',\n",
       " 'rianlly',\n",
       " 'sfianlly',\n",
       " 'sianlly',\n",
       " 'tfianlly',\n",
       " 'tianlly',\n",
       " 'ufianlly',\n",
       " 'uianlly',\n",
       " 'vfianlly',\n",
       " 'vianlly',\n",
       " 'wfianlly',\n",
       " 'wianlly',\n",
       " 'xfianlly',\n",
       " 'xianlly',\n",
       " 'yfianlly',\n",
       " 'yianlly',\n",
       " 'zfianlly',\n",
       " 'zianlly'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one edit distance from input word\n",
    "edits1(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'finally'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get correct words from above set\n",
    "known(edits1(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fijnlsy',\n",
       " 'firnlmly',\n",
       " 'fwanliy',\n",
       " 'fikilly',\n",
       " 'fikapnlly',\n",
       " 'nfiynlly',\n",
       " 'tiwanlly',\n",
       " 'fianluoly',\n",
       " 'fiawlwly',\n",
       " 'fianjllyz',\n",
       " 'fianllcqy',\n",
       " 'fianhlply',\n",
       " 'gfiadlly',\n",
       " 'fiaxlfy',\n",
       " 'fwanllyu',\n",
       " 'hfianlfly',\n",
       " 'iixanlly',\n",
       " 'fhbianlly',\n",
       " 'eianwly',\n",
       " 'fianlplny',\n",
       " 'fianlvd',\n",
       " 'fgailly',\n",
       " 'fianbllky',\n",
       " 'fikonlly',\n",
       " 'filanlll',\n",
       " 'fiabnljy',\n",
       " 'fvanllpy',\n",
       " 'bfianllt',\n",
       " 'fiabnlld',\n",
       " 'ofianllq',\n",
       " 'fialnlg',\n",
       " 'mfiajlly',\n",
       " 'kianzly',\n",
       " 'fiainnlly',\n",
       " 'wdanlly',\n",
       " 'ypianlly',\n",
       " 'fuipnlly',\n",
       " 'fimanjlly',\n",
       " 'ofianjlly',\n",
       " 'hianlhly',\n",
       " 'bxanlly',\n",
       " 'fiannlh',\n",
       " 'fianlzjy',\n",
       " 'fiatlaly',\n",
       " 'fixqanlly',\n",
       " 'fianalo',\n",
       " 'elanlly',\n",
       " 'fmianlly',\n",
       " 'fimznlly',\n",
       " 'ficnlfy',\n",
       " 'fiacznlly',\n",
       " 'xfianljly',\n",
       " 'sianlzy',\n",
       " 'ffanllj',\n",
       " 'fixnljly',\n",
       " 'fkicanlly',\n",
       " 'fianlgb',\n",
       " 'rfianllx',\n",
       " 'fxiyanlly',\n",
       " 'fixnqlly',\n",
       " 'pisnlly',\n",
       " 'fisnully',\n",
       " 'fianblk',\n",
       " 'fiyagnlly',\n",
       " 'firanilly',\n",
       " 'fianllfyb',\n",
       " 'fixanllyk',\n",
       " 'fianblyc',\n",
       " 'liaflly',\n",
       " 'fmtanlly',\n",
       " 'franlyy',\n",
       " 'fianllcyg',\n",
       " 'fiagllyq',\n",
       " 'fianlgyx',\n",
       " 'fiaunllyl',\n",
       " 'fianldyn',\n",
       " 'yfiaznlly',\n",
       " 'efaanlly',\n",
       " 'fiajknlly',\n",
       " 'fianljx',\n",
       " 'siaznlly',\n",
       " 'jfianllky',\n",
       " 'fiaonqly',\n",
       " 'fianlcyc',\n",
       " 'fibazlly',\n",
       " 'fikandly',\n",
       " 'gfkanlly',\n",
       " 'yfiandly',\n",
       " 'kianlyly',\n",
       " 'zipnlly',\n",
       " 'fbiaxlly',\n",
       " 'fiinely',\n",
       " 'fsanllyw',\n",
       " 'fiajcly',\n",
       " 'fianallyc',\n",
       " 'fuanllky',\n",
       " 'fikanlky',\n",
       " 'fiinllxy',\n",
       " 'fixanllyc',\n",
       " 'fiknllo',\n",
       " 'afianlny',\n",
       " 'fwaelly',\n",
       " 'fitanllp',\n",
       " 'fianbclly',\n",
       " 'tfianlqy',\n",
       " 'fianbllyj',\n",
       " 'liwanlly',\n",
       " 'faandly',\n",
       " 'fizagnlly',\n",
       " 'fianleyc',\n",
       " 'fianyllb',\n",
       " 'fiaalqy',\n",
       " 'fianlggy',\n",
       " 'fianllynm',\n",
       " 'aiannlly',\n",
       " 'fbanwly',\n",
       " 'fiwnllyd',\n",
       " 'ftanllyu',\n",
       " 'fiawally',\n",
       " 'ftyianlly',\n",
       " 'biznlly',\n",
       " 'dfixanlly',\n",
       " 'fainllye',\n",
       " 'fiaxnllny',\n",
       " 'bfiandlly',\n",
       " 'fsanwly',\n",
       " 'zyianlly',\n",
       " 'fiipanlly',\n",
       " 'fianlllhy',\n",
       " 'wfipanlly',\n",
       " 'fianlflyc',\n",
       " 'fuanljly',\n",
       " 'fianlyla',\n",
       " 'fianglley',\n",
       " 'fijanllr',\n",
       " 'wfiunlly',\n",
       " 'flanllty',\n",
       " 'fianlay',\n",
       " 'fviahnlly',\n",
       " 'fianllyky',\n",
       " 'fisnljly',\n",
       " 'iamlly',\n",
       " 'fitanllty',\n",
       " 'fiinlyl',\n",
       " 'kianllgy',\n",
       " 'firwlly',\n",
       " 'fikanlply',\n",
       " 'fizaally',\n",
       " 'lianluly',\n",
       " 'fiegnlly',\n",
       " 'fpianllyv',\n",
       " 'iiasnlly',\n",
       " 'htanlly',\n",
       " 'fianullyy',\n",
       " 'filnhlly',\n",
       " 'foianllvy',\n",
       " 'rpianlly',\n",
       " 'feianllh',\n",
       " 'fianolhy',\n",
       " 'efianlny',\n",
       " 'fiatllny',\n",
       " 'fizasnlly',\n",
       " 'filnlmy',\n",
       " 'cjfianlly',\n",
       " 'fcanllyn',\n",
       " 'fiaxll',\n",
       " 'zfianxly',\n",
       " 'fjarlly',\n",
       " 'fidnrlly',\n",
       " 'fianlze',\n",
       " 'fiafllyn',\n",
       " 'fimaynlly',\n",
       " 'ofianllcy',\n",
       " 'fianluny',\n",
       " 'zfianlley',\n",
       " 'fianllhvy',\n",
       " 'oianlmly',\n",
       " 'fianllfey',\n",
       " 'fidanllyx',\n",
       " 'ffiznlly',\n",
       " 'vfianlyy',\n",
       " 'fiadndly',\n",
       " 'fiafnllyf',\n",
       " 'nfwianlly',\n",
       " 'fiinlnly',\n",
       " 'fiqanllyd',\n",
       " 'nianllgy',\n",
       " 'lfikanlly',\n",
       " 'fiqplly',\n",
       " 'iianllyu',\n",
       " 'xfianllyo',\n",
       " 'ffawlly',\n",
       " 'aianlgy',\n",
       " 'ifiagnlly',\n",
       " 'fianallky',\n",
       " 'fiuqlly',\n",
       " 'wfianlnly',\n",
       " 'fiiantlly',\n",
       " 'fiamnllmy',\n",
       " 'frianlmly',\n",
       " 'wianelly',\n",
       " 'fiannally',\n",
       " 'finanllm',\n",
       " 'fianvkly',\n",
       " 'fipaolly',\n",
       " 'fiagllyo',\n",
       " 'fipnliy',\n",
       " 'flianllv',\n",
       " 'fianplyd',\n",
       " 'fivnllgy',\n",
       " 'fiarnally',\n",
       " 'ofianlply',\n",
       " 'fiarnlls',\n",
       " 'fianhlry',\n",
       " 'fianxlcy',\n",
       " 'fianllykq',\n",
       " 'fianley',\n",
       " 'xfianllay',\n",
       " 'fimanlwy',\n",
       " 'fianylyy',\n",
       " 'fimnllx',\n",
       " 'fiassnlly',\n",
       " 'xfianlply',\n",
       " 'fianllzyd',\n",
       " 'fzianlloy',\n",
       " 'cfianlyly',\n",
       " 'zfianlwy',\n",
       " 'lianlky',\n",
       " 'franxly',\n",
       " 'ienlly',\n",
       " 'fianjlg',\n",
       " 'fhianllyu',\n",
       " 'fqanlls',\n",
       " 'fialenlly',\n",
       " 'fianilyu',\n",
       " 'firavlly',\n",
       " 'pfeanlly',\n",
       " 'qianjlly',\n",
       " 'cianlhy',\n",
       " 'fjpianlly',\n",
       " 'figanlhy',\n",
       " 'fipnllya',\n",
       " 'libnlly',\n",
       " 'fianhljly',\n",
       " 'fianclym',\n",
       " 'fianjllyq',\n",
       " 'tfianllyn',\n",
       " 'fiapllx',\n",
       " 'fihaenlly',\n",
       " 'hianmlly',\n",
       " 'vfipnlly',\n",
       " 'jxfianlly',\n",
       " 'fianmllx',\n",
       " 'pfianlely',\n",
       " 'fianxlfly',\n",
       " 'fiamnlld',\n",
       " 'fvynlly',\n",
       " 'eibanlly',\n",
       " 'fcianilly',\n",
       " 'fiaznally',\n",
       " 'fuwnlly',\n",
       " 'fiqnllx',\n",
       " 'finlmly',\n",
       " 'fizaqlly',\n",
       " 'fiunllyo',\n",
       " 'ffanllyi',\n",
       " 'fiuncly',\n",
       " 'fainbly',\n",
       " 'dfiwnlly',\n",
       " 'fianflyt',\n",
       " 'fiaonlry',\n",
       " 'fianliyly',\n",
       " 'fiknslly',\n",
       " 'fiafnxly',\n",
       " 'fitanlsy',\n",
       " 'ffianllb',\n",
       " 'fpianllg',\n",
       " 'mipanlly',\n",
       " 'firanqly',\n",
       " 'fiqanhly',\n",
       " 'fihanldly',\n",
       " 'fiaionlly',\n",
       " 'fianzllyt',\n",
       " 'fiqanllym',\n",
       " 'fiany',\n",
       " 'fignllby',\n",
       " 'fiahnllyw',\n",
       " 'yfianltly',\n",
       " 'fiapnllyz',\n",
       " 'fimzlly',\n",
       " 'jfianlll',\n",
       " 'fiamhly',\n",
       " 'fianglby',\n",
       " 'fuhanlly',\n",
       " 'ooianlly',\n",
       " 'fiaenqlly',\n",
       " 'fipnllyc',\n",
       " 'iianlljy',\n",
       " 'fwanily',\n",
       " 'xfiandly',\n",
       " 'fxiancly',\n",
       " 'fitully',\n",
       " 'fianlynl',\n",
       " 'fianlvqy',\n",
       " 'ftianmly',\n",
       " 'cfnianlly',\n",
       " 'yfiaolly',\n",
       " 'fianoylly',\n",
       " 'fiacllmy',\n",
       " 'fnianlljy',\n",
       " 'nianlfly',\n",
       " 'nfhianlly',\n",
       " 'riatnlly',\n",
       " 'fianvdly',\n",
       " 'finnllyd',\n",
       " 'rihanlly',\n",
       " 'dignlly',\n",
       " 'ffianlle',\n",
       " 'fibnllc',\n",
       " 'fianhllsy',\n",
       " 'fioklly',\n",
       " 'cianllc',\n",
       " 'filnlmly',\n",
       " 'fiaanlliy',\n",
       " 'ficnqlly',\n",
       " 'fhanllb',\n",
       " 'fivanlfy',\n",
       " 'fizanolly',\n",
       " 'fiandiy',\n",
       " 'fvwanlly',\n",
       " 'fidanclly',\n",
       " 'sfianllyx',\n",
       " 'fvianlyl',\n",
       " 'fianlpply',\n",
       " 'fithanlly',\n",
       " 'fxanlldy',\n",
       " 'fibanlnly',\n",
       " 'fxianlaly',\n",
       " 'wfianlmy',\n",
       " 'fianlsls',\n",
       " 'fianllytm',\n",
       " 'pianllyj',\n",
       " 'fianlolgy',\n",
       " 'ftianllc',\n",
       " 'ffianllt',\n",
       " 'fianlkll',\n",
       " 'fianrlln',\n",
       " 'fiasnllj',\n",
       " 'fiasntly',\n",
       " 'xfuianlly',\n",
       " 'eiadlly',\n",
       " 'eiaknlly',\n",
       " 'fianllyfx',\n",
       " 'frianlny',\n",
       " 'flianllhy',\n",
       " 'fianrlq',\n",
       " 'fianllify',\n",
       " 'fianltyb',\n",
       " 'qrfianlly',\n",
       " 'fianlchly',\n",
       " 'yianljy',\n",
       " 'afianllay',\n",
       " 'fiablll',\n",
       " 'fiwabnlly',\n",
       " 'fianlloe',\n",
       " 'oianlgy',\n",
       " 'fizjanlly',\n",
       " 'nfisanlly',\n",
       " 'frianlluy',\n",
       " 'fnaclly',\n",
       " 'fiaqnllv',\n",
       " 'fqianllq',\n",
       " 'fmanuly',\n",
       " 'ftanllt',\n",
       " 'ficanbly',\n",
       " 'fiaanlqly',\n",
       " 'fiaznlky',\n",
       " 'fianzlvy',\n",
       " 'fianwcly',\n",
       " 'figanclly',\n",
       " 'ifaanlly',\n",
       " 'fiabzlly',\n",
       " 'efianlmy',\n",
       " 'fianmllyi',\n",
       " 'dfqianlly',\n",
       " 'ifianlwy',\n",
       " 'xfiuanlly',\n",
       " 'fjanxly',\n",
       " 'fnaianlly',\n",
       " 'fignllt',\n",
       " 'fikanqly',\n",
       " 'fihanlkly',\n",
       " 'fiaewly',\n",
       " 'fianlcyq',\n",
       " 'fibanllmy',\n",
       " 'fuianlvy',\n",
       " 'fiaullyd',\n",
       " 'ifanqlly',\n",
       " 'fwinanlly',\n",
       " 'fiaqlwly',\n",
       " 'fianlulv',\n",
       " 'vieanlly',\n",
       " 'fihanlla',\n",
       " 'fownlly',\n",
       " 'iianslly',\n",
       " 'fnianllyk',\n",
       " 'fdanllc',\n",
       " 'ufsanlly',\n",
       " 'fignlmly',\n",
       " 'ffimanlly',\n",
       " 'fijnoly',\n",
       " 'fisnlly',\n",
       " 'fkpianlly',\n",
       " 'fiantllby',\n",
       " 'fiaclyly',\n",
       " 'fwiaelly',\n",
       " 'finzly',\n",
       " 'wfeanlly',\n",
       " 'vianllsy',\n",
       " 'fiaknllwy',\n",
       " 'fqianllh',\n",
       " 'fianrllhy',\n",
       " 'fianylh',\n",
       " 'fifanlgly',\n",
       " 'fiaollx',\n",
       " 'gfianelly',\n",
       " 'fianjlyl',\n",
       " 'fwianllyx',\n",
       " 'iisnlly',\n",
       " 'baianlly',\n",
       " 'fisznlly',\n",
       " 'fioanyly',\n",
       " 'fianmllfy',\n",
       " 'fipnlty',\n",
       " 'ftianllyp',\n",
       " 'fiaonhlly',\n",
       " 'bfianlky',\n",
       " 'cfianllr',\n",
       " 'fmanllyi',\n",
       " 'sfianlld',\n",
       " 'fmianlle',\n",
       " 'fiaunlhy',\n",
       " 'twanlly',\n",
       " 'fiaekly',\n",
       " 'franllx',\n",
       " 'afgianlly',\n",
       " 'ficnllh',\n",
       " 'fpianlhly',\n",
       " 'fianlelty',\n",
       " 'ftiaunlly',\n",
       " 'fsaslly',\n",
       " 'fiknluly',\n",
       " 'fievnlly',\n",
       " 'fizjnlly',\n",
       " 'ziaynlly',\n",
       " 'fibainlly',\n",
       " 'fianjfly',\n",
       " 'fpantlly',\n",
       " 'feiacnlly',\n",
       " 'mipnlly',\n",
       " 'fjaglly',\n",
       " 'fianloyt',\n",
       " 'fpianllwy',\n",
       " 'aiunlly',\n",
       " 'hianllgy',\n",
       " 'fianllemy',\n",
       " 'qianlla',\n",
       " 'fiagnmlly',\n",
       " 'fuanllyn',\n",
       " 'zffanlly',\n",
       " 'fimnllyb',\n",
       " 'fiaulnlly',\n",
       " 'feanllw',\n",
       " 'faianllxy',\n",
       " 'ficnll',\n",
       " 'fiaqqlly',\n",
       " 'fciaynlly',\n",
       " 'fianlug',\n",
       " 'fumnlly',\n",
       " 'fianljkly',\n",
       " 'fiasnllym',\n",
       " 'fmanloly',\n",
       " 'sfianjlly',\n",
       " 'fivnlay',\n",
       " 'fianillyl',\n",
       " 'fiandllyv',\n",
       " 'fgianllyw',\n",
       " 'rianllyz',\n",
       " 'faklly',\n",
       " 'fwanflly',\n",
       " 'fianelm',\n",
       " 'fiaxnlhy',\n",
       " 'fhianlfy',\n",
       " 'fiancllyz',\n",
       " 'fieanlley',\n",
       " 'ftianllv',\n",
       " 'mianlwy',\n",
       " 'fmiallly',\n",
       " 'fnanlla',\n",
       " 'gianlliy',\n",
       " 'mianelly',\n",
       " 'fiadxlly',\n",
       " 'fianllpyh',\n",
       " 'ogfianlly',\n",
       " 'figglly',\n",
       " 'iiajnlly',\n",
       " 'fiaanully',\n",
       " 'jfvanlly',\n",
       " 'uianlaly',\n",
       " 'flidanlly',\n",
       " 'dfianllyn',\n",
       " 'fiaiynlly',\n",
       " 'fiamllo',\n",
       " 'nfianllyp',\n",
       " 'fiaxnll',\n",
       " 'fianlzlyu',\n",
       " 'fiablln',\n",
       " 'fcanllly',\n",
       " 'gfianllyn',\n",
       " 'fdianlfly',\n",
       " 'fifvanlly',\n",
       " 'fpanlqly',\n",
       " 'fhanllay',\n",
       " 'fyianllay',\n",
       " 'fiapnjlly',\n",
       " 'fuanley',\n",
       " 'gyianlly',\n",
       " 'fiasllk',\n",
       " 'fienqlly',\n",
       " 'fcienlly',\n",
       " 'fvqianlly',\n",
       " 'fiantllyf',\n",
       " 'firanllc',\n",
       " 'fitanllz',\n",
       " 'fxanclly',\n",
       " 'fkianclly',\n",
       " 'fxianllyk',\n",
       " 'pfianlvly',\n",
       " 'jiaully',\n",
       " 'fiainllya',\n",
       " 'fiacnllyz',\n",
       " 'fipanwlly',\n",
       " 'qianljy',\n",
       " 'xfiajnlly',\n",
       " 'fiannlyj',\n",
       " 'fivnlli',\n",
       " 'fioonlly',\n",
       " 'fiemnlly',\n",
       " 'zfianllys',\n",
       " 'lwanlly',\n",
       " 'fuiaknlly',\n",
       " 'wianldly',\n",
       " 'wxianlly',\n",
       " 'ficwanlly',\n",
       " 'rfianlqly',\n",
       " 'uiawlly',\n",
       " 'franllya',\n",
       " 'fianclya',\n",
       " 'fianjvly',\n",
       " 'fcianllyu',\n",
       " 'fidtlly',\n",
       " 'qianlmy',\n",
       " 'xianllyq',\n",
       " 'fisanljy',\n",
       " 'fianldld',\n",
       " 'gfiamnlly',\n",
       " 'fisanllyt',\n",
       " 'folanlly',\n",
       " 'ftianlcy',\n",
       " 'tially',\n",
       " 'fkianyly',\n",
       " 'fimanlbly',\n",
       " 'fiarloy',\n",
       " 'fhiaelly',\n",
       " 'wfiancly',\n",
       " 'ftianllj',\n",
       " 'fiavlgy',\n",
       " 'fianlyb',\n",
       " 'filnllyl',\n",
       " 'dianlll',\n",
       " 'fipnanlly',\n",
       " 'fiamgnlly',\n",
       " 'fiknll',\n",
       " 'fianllyt',\n",
       " 'firnllyn',\n",
       " 'fiahnlln',\n",
       " 'fiahllyv',\n",
       " 'jfianlpy',\n",
       " 'qfilnlly',\n",
       " 'fianltlyz',\n",
       " 'fhikanlly',\n",
       " 'figpanlly',\n",
       " 'ftipnlly',\n",
       " 'fibnllyv',\n",
       " 'dfdanlly',\n",
       " 'fioanllye',\n",
       " 'zfianllz',\n",
       " 'fiaqlply',\n",
       " 'fhiaanlly',\n",
       " 'fiadllgy',\n",
       " 'wimnlly',\n",
       " 'fiinllny',\n",
       " 'ffalnly',\n",
       " 'apianlly',\n",
       " 'fimamlly',\n",
       " 'fzaynlly',\n",
       " 'oianldy',\n",
       " 'fiqfanlly',\n",
       " 'ficaznlly',\n",
       " 'kfianoly',\n",
       " 'zfpianlly',\n",
       " 'fialgly',\n",
       " 'feanolly',\n",
       " 'fianllhjy',\n",
       " 'fikqlly',\n",
       " 'biacnlly',\n",
       " 'qianllyf',\n",
       " 'fiajnlry',\n",
       " 'fifanlvy',\n",
       " 'fiablhly',\n",
       " 'ficranlly',\n",
       " 'gfianuly',\n",
       " 'gfianilly',\n",
       " 'fibnllhy',\n",
       " 'fixanvlly',\n",
       " 'fyanzly',\n",
       " 'fiazllhy',\n",
       " 'fwianllyn',\n",
       " 'jianjlly',\n",
       " 'fanllcy',\n",
       " 'franly',\n",
       " 'fjanlmy',\n",
       " 'sfcianlly',\n",
       " 'qyanlly',\n",
       " 'finanllny',\n",
       " 'vianllyv',\n",
       " 'efiamlly',\n",
       " 'fiawnluy',\n",
       " 'xiaully',\n",
       " 'fdiinlly',\n",
       " 'fiallmly',\n",
       " 'fisnjlly',\n",
       " 'dfianlla',\n",
       " 'lfiqnlly',\n",
       " 'fzianllqy',\n",
       " 'fianuey',\n",
       " 'dianllqy',\n",
       " 'tianllyg',\n",
       " 'fiabllmy',\n",
       " 'fianolaly',\n",
       " 'ifanlsly',\n",
       " 'fiqanqlly',\n",
       " 'ficanluy',\n",
       " 'fiagllzy',\n",
       " 'fiwnnly',\n",
       " 'efianllyt',\n",
       " 'fipvnlly',\n",
       " 'piarlly',\n",
       " 'fbanlll',\n",
       " 'fwiablly',\n",
       " 'fianllaz',\n",
       " 'fbianllyb',\n",
       " 'fmanllny',\n",
       " 'ftantlly',\n",
       " 'fiyanluly',\n",
       " 'fanllwy',\n",
       " 'fiqanllm',\n",
       " 'fyianvly',\n",
       " 'ofjianlly',\n",
       " 'fzawlly',\n",
       " 'fiaznoly',\n",
       " 'fianflsy',\n",
       " 'fnailly',\n",
       " 'fimfanlly',\n",
       " 'jfianllhy',\n",
       " 'fmijnlly',\n",
       " 'fawlly',\n",
       " 'fuiarlly',\n",
       " 'fiarluy',\n",
       " 'uianlqy',\n",
       " 'xfiynlly',\n",
       " 'qianluly',\n",
       " 'fiaknljly',\n",
       " 'fiadnllys',\n",
       " 'fxianllm',\n",
       " 'aianlnly',\n",
       " 'flahnlly',\n",
       " 'fiknolly',\n",
       " 'fiaunlluy',\n",
       " 'fianllynf',\n",
       " 'fbianloly',\n",
       " 'fianblgly',\n",
       " 'nfiaolly',\n",
       " 'sianlfly',\n",
       " 'fionylly',\n",
       " 'fiaolily',\n",
       " 'fioanlmy',\n",
       " 'iaenlly',\n",
       " 'fiaklkly',\n",
       " 'fiahnllyc',\n",
       " 'hianlld',\n",
       " 'fidanllz',\n",
       " 'fiafnllwy',\n",
       " 'fvanllyo',\n",
       " 'fwanmly',\n",
       " 'fiwanllyk',\n",
       " 'efianlljy',\n",
       " 'fiadllya',\n",
       " 'feiwnlly',\n",
       " 'firnglly',\n",
       " 'fiaehlly',\n",
       " 'fianlhyr',\n",
       " 'fiscanlly',\n",
       " 'fianllyxs',\n",
       " 'fibanllym',\n",
       " 'fmianqlly',\n",
       " 'fsanelly',\n",
       " 'fianallty',\n",
       " 'fiarljy',\n",
       " 'wfidnlly',\n",
       " 'fianqlbly',\n",
       " 'fianluvy',\n",
       " 'fiangllyd',\n",
       " 'fisanllw',\n",
       " 'fiaynllyk',\n",
       " 'fihlnlly',\n",
       " 'fhavlly',\n",
       " 'uianzly',\n",
       " 'fiagllys',\n",
       " 'jianlry',\n",
       " 'ufianally',\n",
       " 'fwanlyly',\n",
       " 'kfiinlly',\n",
       " 'fiapllyu',\n",
       " 'ctfianlly',\n",
       " 'fianhlu',\n",
       " 'fianhlo',\n",
       " 'jfianlhly',\n",
       " 'fcanbly',\n",
       " 'fanllyc',\n",
       " 'fianflyg',\n",
       " 'feanllye',\n",
       " 'lfianlnly',\n",
       " 'fiazhnlly',\n",
       " 'fianlavly',\n",
       " 'finalxy',\n",
       " 'filqanlly',\n",
       " 'finalry',\n",
       " 'fianalyg',\n",
       " 'fiaonllt',\n",
       " 'fianlsyly',\n",
       " 'fnanjlly',\n",
       " 'piapnlly',\n",
       " 'fianlklyu',\n",
       " 'fqianzly',\n",
       " 'fxancly',\n",
       " 'fianlleyw',\n",
       " 'fpanlny',\n",
       " 'frianllyd',\n",
       " 'mianllx',\n",
       " 'fiuanllh',\n",
       " 'fianluyd',\n",
       " 'pbanlly',\n",
       " 'qfiunlly',\n",
       " 'finlzy',\n",
       " 'fihnllcy',\n",
       " 'fiandllyu',\n",
       " 'fisankly',\n",
       " 'fialllyp',\n",
       " 'fianlgmly',\n",
       " 'fifanllcy',\n",
       " 'fialoly',\n",
       " 'fianldfly',\n",
       " 'fmianlbly',\n",
       " 'finllym',\n",
       " 'ziaslly',\n",
       " 'fianmllyd',\n",
       " 'fzanlily',\n",
       " 'fifanllj',\n",
       " 'pianlzly',\n",
       " 'bfianllye',\n",
       " 'fcanlli',\n",
       " 'fiaxnlgy',\n",
       " 'filandly',\n",
       " 'fyanllys',\n",
       " 'fimnflly',\n",
       " 'fiaknlwly',\n",
       " 'fianalyly',\n",
       " 'fanilly',\n",
       " 'fianyry',\n",
       " 'fianmllyu',\n",
       " 'flanelly',\n",
       " 'fdianlyl',\n",
       " 'fianyzy',\n",
       " 'vianlmly',\n",
       " 'fxmnlly',\n",
       " 'fianllaky',\n",
       " 'fiaqlny',\n",
       " 'fianwlg',\n",
       " 'niatlly',\n",
       " 'jianllfy',\n",
       " 'fqunlly',\n",
       " 'fioaunlly',\n",
       " 'dianlxly',\n",
       " 'fiznlny',\n",
       " 'figangly',\n",
       " 'fsanmly',\n",
       " 'eialnly',\n",
       " 'finnlloy',\n",
       " 'fianollp',\n",
       " 'fhanlvy',\n",
       " 'fiagnllh',\n",
       " 'wianllyo',\n",
       " 'fcanlnly',\n",
       " 'fianlyp',\n",
       " 'faianlvly',\n",
       " 'fpaslly',\n",
       " 'fianlklpy',\n",
       " 'fianrllcy',\n",
       " 'ffianllyy',\n",
       " 'hfiarnlly',\n",
       " 'ffifnlly',\n",
       " 'jhianlly',\n",
       " 'fianqltly',\n",
       " 'ffianlvy',\n",
       " 'xianlely',\n",
       " 'vfially',\n",
       " 'fwianllym',\n",
       " 'uifanlly',\n",
       " 'fiaoknlly',\n",
       " 'xivnlly',\n",
       " 'ciagnlly',\n",
       " 'fiaocly',\n",
       " 'fganllyt',\n",
       " 'fianljcly',\n",
       " 'nianrly',\n",
       " 'fianllwc',\n",
       " 'fixnllsy',\n",
       " 'fianlglyb',\n",
       " 'fiaonllv',\n",
       " 'fivanllz',\n",
       " 'fiaelyy',\n",
       " 'liuanlly',\n",
       " 'fianllli',\n",
       " 'fsiatnlly',\n",
       " 'fianllwa',\n",
       " 'fiapznlly',\n",
       " 'efianllvy',\n",
       " 'fipanrlly',\n",
       " 'wfianaly',\n",
       " 'fiafllg',\n",
       " 'fiaqnllwy',\n",
       " 'fianecy',\n",
       " 'fixunlly',\n",
       " 'fihanlsly',\n",
       " 'hfiacnlly',\n",
       " 'fijanlky',\n",
       " 'fvaqnlly',\n",
       " 'ftanzly',\n",
       " 'kiwnlly',\n",
       " 'nfxianlly',\n",
       " 'cfivanlly',\n",
       " 'ianflly',\n",
       " 'liaglly',\n",
       " 'hfianllyt',\n",
       " 'fieanllyf',\n",
       " 'vfianley',\n",
       " 'fwiaynlly',\n",
       " 'fianlyyy',\n",
       " 'fianlhlqy',\n",
       " 'fiabnhlly',\n",
       " 'fsianllyr',\n",
       " 'fixanlln',\n",
       " 'baanlly',\n",
       " 'fxianlldy',\n",
       " 'foanlkly',\n",
       " 'fiankllys',\n",
       " 'ftiadlly',\n",
       " 'hfianllvy',\n",
       " 'fiakndly',\n",
       " 'inlly',\n",
       " 'cfianlvy',\n",
       " 'fianjsy',\n",
       " 'fihaglly',\n",
       " 'fivanlcy',\n",
       " 'finanlzly',\n",
       " 'fiakzly',\n",
       " 'fiajnlluy',\n",
       " 'fianulfly',\n",
       " 'mfianlry',\n",
       " 'fiaulqy',\n",
       " 'xitnlly',\n",
       " 'fiadnlll',\n",
       " 'fiazlln',\n",
       " 'fibaunlly',\n",
       " 'fiinllb',\n",
       " 'mianlle',\n",
       " 'sfianlzly',\n",
       " 'fiaqtlly',\n",
       " 'fiually',\n",
       " 'fiapnllh',\n",
       " 'fihnlvy',\n",
       " 'pfianqly',\n",
       " 'fiantlle',\n",
       " 'fianrgy',\n",
       " 'fiatnllk',\n",
       " 'ifanllky',\n",
       " 'fainlbly',\n",
       " 'fifnllxy',\n",
       " 'foanllt',\n",
       " 'fbaylly',\n",
       " 'fipnilly',\n",
       " 'fdianllp',\n",
       " 'fiafnllyz',\n",
       " 'fianlnlwy',\n",
       " 'fiavnllyn',\n",
       " 'rianoly',\n",
       " 'gfkianlly',\n",
       " 'iiaknlly',\n",
       " 'fianlnlyo',\n",
       " 'fianlglgy',\n",
       " 'fijnqlly',\n",
       " 'fianljyv',\n",
       " 'flanclly',\n",
       " 'dfianlhy',\n",
       " 'fianjlv',\n",
       " 'ftanllby',\n",
       " 'fianlgxly',\n",
       " 'fiaqlxly',\n",
       " 'mfianlmy',\n",
       " 'yiablly',\n",
       " 'fianlqlvy',\n",
       " 'fianollyk',\n",
       " 'fsianlluy',\n",
       " 'fienlxy',\n",
       " 'fianhlym',\n",
       " 'fiatllw',\n",
       " 'fianllupy',\n",
       " 'fiadllyh',\n",
       " 'vfibnlly',\n",
       " 'ifatlly',\n",
       " 'fiahnlyy',\n",
       " 'fianlolx',\n",
       " 'fiaillyd',\n",
       " 'fiagvly',\n",
       " 'lianlply',\n",
       " 'fihanllyh',\n",
       " 'fianowly',\n",
       " 'fianleym',\n",
       " 'fianbljly',\n",
       " 'feianjlly',\n",
       " 'foaynlly',\n",
       " 'tianllhy',\n",
       " 'fwapnlly',\n",
       " 'oianlely',\n",
       " 'fianclt',\n",
       " 'fitanlly',\n",
       " 'hianilly',\n",
       " 'fianlzj',\n",
       " 'foisanlly',\n",
       " 'ftianlfy',\n",
       " 'ruianlly',\n",
       " 'lianllly',\n",
       " 'fiazluy',\n",
       " 'fianbllg',\n",
       " 'fizklly',\n",
       " 'faianaly',\n",
       " 'fiaolls',\n",
       " 'fianlliyh',\n",
       " 'qianply',\n",
       " 'fiabolly',\n",
       " 'fiasnnlly',\n",
       " 'efiaxnlly',\n",
       " 'mianglly',\n",
       " 'fitanjlly',\n",
       " 'fbiagnlly',\n",
       " 'fypanlly',\n",
       " 'fkanjlly',\n",
       " 'fiansldy',\n",
       " 'fdianlty',\n",
       " 'wianllyc',\n",
       " 'fibnllk',\n",
       " 'fianswlly',\n",
       " 'fianllsv',\n",
       " 'bianllyq',\n",
       " 'fiajliy',\n",
       " 'fianrllu',\n",
       " 'fietnlly',\n",
       " 'fvianllcy',\n",
       " 'fianllyio',\n",
       " 'fjablly',\n",
       " 'fianhlp',\n",
       " 'mwianlly',\n",
       " 'wiallly',\n",
       " 'fianledy',\n",
       " 'zianllu',\n",
       " 'fbanlzy',\n",
       " 'fjanlyly',\n",
       " 'fiarnlply',\n",
       " 'fmiajlly',\n",
       " ...}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# two edit distances from input word\n",
    "edits2(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'finally'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get correct words from above set\n",
    "known(edits1(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fijnlsy',\n",
       " 'firnlmly',\n",
       " 'fwanliy',\n",
       " 'fikilly',\n",
       " 'fikapnlly',\n",
       " 'nfiynlly',\n",
       " 'tiwanlly',\n",
       " 'fianluoly',\n",
       " 'fiawlwly',\n",
       " 'fianjllyz',\n",
       " 'fianllcqy',\n",
       " 'fianhlply',\n",
       " 'gfiadlly',\n",
       " 'fiaxlfy',\n",
       " 'fwanllyu',\n",
       " 'hfianlfly',\n",
       " 'iixanlly',\n",
       " 'fhbianlly',\n",
       " 'eianwly',\n",
       " 'fianlplny',\n",
       " 'fianlvd',\n",
       " 'fgailly',\n",
       " 'fianbllky',\n",
       " 'fikonlly',\n",
       " 'filanlll',\n",
       " 'fiabnljy',\n",
       " 'fvanllpy',\n",
       " 'bfianllt',\n",
       " 'fiabnlld',\n",
       " 'ofianllq',\n",
       " 'fialnlg',\n",
       " 'mfiajlly',\n",
       " 'kianzly',\n",
       " 'fiainnlly',\n",
       " 'wdanlly',\n",
       " 'ypianlly',\n",
       " 'fuipnlly',\n",
       " 'fimanjlly',\n",
       " 'ofianjlly',\n",
       " 'hianlhly',\n",
       " 'bxanlly',\n",
       " 'fiannlh',\n",
       " 'fianlzjy',\n",
       " 'fiatlaly',\n",
       " 'fixqanlly',\n",
       " 'fianalo',\n",
       " 'elanlly',\n",
       " 'fmianlly',\n",
       " 'fimznlly',\n",
       " 'ficnlfy',\n",
       " 'fiacznlly',\n",
       " 'xfianljly',\n",
       " 'sianlzy',\n",
       " 'ffanllj',\n",
       " 'fixnljly',\n",
       " 'fkicanlly',\n",
       " 'fianlgb',\n",
       " 'rfianllx',\n",
       " 'fxiyanlly',\n",
       " 'fixnqlly',\n",
       " 'pisnlly',\n",
       " 'fisnully',\n",
       " 'fianblk',\n",
       " 'fiyagnlly',\n",
       " 'firanilly',\n",
       " 'fianllfyb',\n",
       " 'fixanllyk',\n",
       " 'fianblyc',\n",
       " 'liaflly',\n",
       " 'fmtanlly',\n",
       " 'franlyy',\n",
       " 'fianllcyg',\n",
       " 'fiagllyq',\n",
       " 'fianlgyx',\n",
       " 'fiaunllyl',\n",
       " 'fianldyn',\n",
       " 'yfiaznlly',\n",
       " 'efaanlly',\n",
       " 'fiajknlly',\n",
       " 'fianljx',\n",
       " 'siaznlly',\n",
       " 'jfianllky',\n",
       " 'fiaonqly',\n",
       " 'fianlcyc',\n",
       " 'fibazlly',\n",
       " 'fikandly',\n",
       " 'gfkanlly',\n",
       " 'yfiandly',\n",
       " 'kianlyly',\n",
       " 'zipnlly',\n",
       " 'fbiaxlly',\n",
       " 'fiinely',\n",
       " 'fsanllyw',\n",
       " 'fiajcly',\n",
       " 'fianallyc',\n",
       " 'fuanllky',\n",
       " 'fikanlky',\n",
       " 'fiinllxy',\n",
       " 'fixanllyc',\n",
       " 'fiknllo',\n",
       " 'afianlny',\n",
       " 'fwaelly',\n",
       " 'fitanllp',\n",
       " 'fianbclly',\n",
       " 'tfianlqy',\n",
       " 'fianbllyj',\n",
       " 'liwanlly',\n",
       " 'faandly',\n",
       " 'fizagnlly',\n",
       " 'fianleyc',\n",
       " 'fianyllb',\n",
       " 'fiaalqy',\n",
       " 'fianlggy',\n",
       " 'fianllynm',\n",
       " 'aiannlly',\n",
       " 'fbanwly',\n",
       " 'fiwnllyd',\n",
       " 'ftanllyu',\n",
       " 'fiawally',\n",
       " 'ftyianlly',\n",
       " 'biznlly',\n",
       " 'dfixanlly',\n",
       " 'fainllye',\n",
       " 'fiaxnllny',\n",
       " 'bfiandlly',\n",
       " 'fsanwly',\n",
       " 'zyianlly',\n",
       " 'fiipanlly',\n",
       " 'fianlllhy',\n",
       " 'wfipanlly',\n",
       " 'fianlflyc',\n",
       " 'fuanljly',\n",
       " 'fianlyla',\n",
       " 'fianglley',\n",
       " 'fijanllr',\n",
       " 'wfiunlly',\n",
       " 'flanllty',\n",
       " 'fianlay',\n",
       " 'fviahnlly',\n",
       " 'fianllyky',\n",
       " 'fisnljly',\n",
       " 'iamlly',\n",
       " 'fitanllty',\n",
       " 'fiinlyl',\n",
       " 'kianllgy',\n",
       " 'firwlly',\n",
       " 'fikanlply',\n",
       " 'fizaally',\n",
       " 'lianluly',\n",
       " 'fiegnlly',\n",
       " 'fpianllyv',\n",
       " 'iiasnlly',\n",
       " 'htanlly',\n",
       " 'fianullyy',\n",
       " 'filnhlly',\n",
       " 'foianllvy',\n",
       " 'rpianlly',\n",
       " 'feianllh',\n",
       " 'fianolhy',\n",
       " 'efianlny',\n",
       " 'fiatllny',\n",
       " 'fizasnlly',\n",
       " 'filnlmy',\n",
       " 'cjfianlly',\n",
       " 'fcanllyn',\n",
       " 'fiaxll',\n",
       " 'zfianxly',\n",
       " 'fjarlly',\n",
       " 'fidnrlly',\n",
       " 'fianlze',\n",
       " 'fiafllyn',\n",
       " 'fimaynlly',\n",
       " 'ofianllcy',\n",
       " 'fianluny',\n",
       " 'zfianlley',\n",
       " 'fianllhvy',\n",
       " 'oianlmly',\n",
       " 'fianllfey',\n",
       " 'fidanllyx',\n",
       " 'ffiznlly',\n",
       " 'vfianlyy',\n",
       " 'fiadndly',\n",
       " 'fiafnllyf',\n",
       " 'nfwianlly',\n",
       " 'fiinlnly',\n",
       " 'fiqanllyd',\n",
       " 'nianllgy',\n",
       " 'lfikanlly',\n",
       " 'fiqplly',\n",
       " 'iianllyu',\n",
       " 'xfianllyo',\n",
       " 'ffawlly',\n",
       " 'aianlgy',\n",
       " 'ifiagnlly',\n",
       " 'fianallky',\n",
       " 'fiuqlly',\n",
       " 'wfianlnly',\n",
       " 'fiiantlly',\n",
       " 'fiamnllmy',\n",
       " 'frianlmly',\n",
       " 'wianelly',\n",
       " 'fiannally',\n",
       " 'finanllm',\n",
       " 'fianvkly',\n",
       " 'fipaolly',\n",
       " 'fiagllyo',\n",
       " 'fipnliy',\n",
       " 'flianllv',\n",
       " 'fianplyd',\n",
       " 'fivnllgy',\n",
       " 'fiarnally',\n",
       " 'ofianlply',\n",
       " 'fiarnlls',\n",
       " 'fianhlry',\n",
       " 'fianxlcy',\n",
       " 'fianllykq',\n",
       " 'fianley',\n",
       " 'xfianllay',\n",
       " 'fimanlwy',\n",
       " 'fianylyy',\n",
       " 'fimnllx',\n",
       " 'fiassnlly',\n",
       " 'xfianlply',\n",
       " 'fianllzyd',\n",
       " 'fzianlloy',\n",
       " 'cfianlyly',\n",
       " 'zfianlwy',\n",
       " 'lianlky',\n",
       " 'franxly',\n",
       " 'ienlly',\n",
       " 'fianjlg',\n",
       " 'fhianllyu',\n",
       " 'fqanlls',\n",
       " 'fialenlly',\n",
       " 'fianilyu',\n",
       " 'firavlly',\n",
       " 'pfeanlly',\n",
       " 'qianjlly',\n",
       " 'cianlhy',\n",
       " 'fjpianlly',\n",
       " 'figanlhy',\n",
       " 'fipnllya',\n",
       " 'libnlly',\n",
       " 'fianhljly',\n",
       " 'fianclym',\n",
       " 'fianjllyq',\n",
       " 'tfianllyn',\n",
       " 'fiapllx',\n",
       " 'fihaenlly',\n",
       " 'hianmlly',\n",
       " 'vfipnlly',\n",
       " 'jxfianlly',\n",
       " 'fianmllx',\n",
       " 'pfianlely',\n",
       " 'fianxlfly',\n",
       " 'fiamnlld',\n",
       " 'fvynlly',\n",
       " 'eibanlly',\n",
       " 'fcianilly',\n",
       " 'fiaznally',\n",
       " 'fuwnlly',\n",
       " 'fiqnllx',\n",
       " 'finlmly',\n",
       " 'fizaqlly',\n",
       " 'fiunllyo',\n",
       " 'ffanllyi',\n",
       " 'fiuncly',\n",
       " 'fainbly',\n",
       " 'dfiwnlly',\n",
       " 'fianflyt',\n",
       " 'fiaonlry',\n",
       " 'fianliyly',\n",
       " 'fiknslly',\n",
       " 'fiafnxly',\n",
       " 'fitanlsy',\n",
       " 'ffianllb',\n",
       " 'fpianllg',\n",
       " 'mipanlly',\n",
       " 'firanqly',\n",
       " 'fiqanhly',\n",
       " 'fihanldly',\n",
       " 'fiaionlly',\n",
       " 'fianzllyt',\n",
       " 'fiqanllym',\n",
       " 'fiany',\n",
       " 'fignllby',\n",
       " 'fiahnllyw',\n",
       " 'yfianltly',\n",
       " 'fiapnllyz',\n",
       " 'fimzlly',\n",
       " 'jfianlll',\n",
       " 'fiamhly',\n",
       " 'fianglby',\n",
       " 'fuhanlly',\n",
       " 'ooianlly',\n",
       " 'fiaenqlly',\n",
       " 'fipnllyc',\n",
       " 'iianlljy',\n",
       " 'fwanily',\n",
       " 'xfiandly',\n",
       " 'fxiancly',\n",
       " 'fitully',\n",
       " 'fianlynl',\n",
       " 'fianlvqy',\n",
       " 'ftianmly',\n",
       " 'cfnianlly',\n",
       " 'yfiaolly',\n",
       " 'fianoylly',\n",
       " 'fiacllmy',\n",
       " 'fnianlljy',\n",
       " 'nianlfly',\n",
       " 'nfhianlly',\n",
       " 'riatnlly',\n",
       " 'fianvdly',\n",
       " 'finnllyd',\n",
       " 'rihanlly',\n",
       " 'dignlly',\n",
       " 'ffianlle',\n",
       " 'fibnllc',\n",
       " 'fianhllsy',\n",
       " 'fioklly',\n",
       " 'cianllc',\n",
       " 'filnlmly',\n",
       " 'fiaanlliy',\n",
       " 'ficnqlly',\n",
       " 'fhanllb',\n",
       " 'fivanlfy',\n",
       " 'fizanolly',\n",
       " 'fiandiy',\n",
       " 'fvwanlly',\n",
       " 'fidanclly',\n",
       " 'sfianllyx',\n",
       " 'fvianlyl',\n",
       " 'fianlpply',\n",
       " 'fithanlly',\n",
       " 'fxanlldy',\n",
       " 'fibanlnly',\n",
       " 'fxianlaly',\n",
       " 'wfianlmy',\n",
       " 'fianlsls',\n",
       " 'fianllytm',\n",
       " 'pianllyj',\n",
       " 'fianlolgy',\n",
       " 'ftianllc',\n",
       " 'ffianllt',\n",
       " 'fianlkll',\n",
       " 'fianrlln',\n",
       " 'fiasnllj',\n",
       " 'fiasntly',\n",
       " 'xfuianlly',\n",
       " 'eiadlly',\n",
       " 'eiaknlly',\n",
       " 'fianllyfx',\n",
       " 'frianlny',\n",
       " 'flianllhy',\n",
       " 'fianrlq',\n",
       " 'fianllify',\n",
       " 'fianltyb',\n",
       " 'qrfianlly',\n",
       " 'fianlchly',\n",
       " 'yianljy',\n",
       " 'afianllay',\n",
       " 'fiablll',\n",
       " 'fiwabnlly',\n",
       " 'fianlloe',\n",
       " 'oianlgy',\n",
       " 'fizjanlly',\n",
       " 'nfisanlly',\n",
       " 'frianlluy',\n",
       " 'fnaclly',\n",
       " 'fiaqnllv',\n",
       " 'fqianllq',\n",
       " 'fmanuly',\n",
       " 'ftanllt',\n",
       " 'ficanbly',\n",
       " 'fiaanlqly',\n",
       " 'fiaznlky',\n",
       " 'fianzlvy',\n",
       " 'fianwcly',\n",
       " 'figanclly',\n",
       " 'ifaanlly',\n",
       " 'fiabzlly',\n",
       " 'efianlmy',\n",
       " 'fianmllyi',\n",
       " 'dfqianlly',\n",
       " 'ifianlwy',\n",
       " 'xfiuanlly',\n",
       " 'fjanxly',\n",
       " 'fnaianlly',\n",
       " 'fignllt',\n",
       " 'fikanqly',\n",
       " 'fihanlkly',\n",
       " 'fiaewly',\n",
       " 'fianlcyq',\n",
       " 'fibanllmy',\n",
       " 'fuianlvy',\n",
       " 'fiaullyd',\n",
       " 'ifanqlly',\n",
       " 'fwinanlly',\n",
       " 'fiaqlwly',\n",
       " 'fianlulv',\n",
       " 'vieanlly',\n",
       " 'fihanlla',\n",
       " 'fownlly',\n",
       " 'iianslly',\n",
       " 'fnianllyk',\n",
       " 'fdanllc',\n",
       " 'ufsanlly',\n",
       " 'fignlmly',\n",
       " 'ffimanlly',\n",
       " 'fijnoly',\n",
       " 'fisnlly',\n",
       " 'fkpianlly',\n",
       " 'fiantllby',\n",
       " 'fiaclyly',\n",
       " 'fwiaelly',\n",
       " 'finzly',\n",
       " 'wfeanlly',\n",
       " 'vianllsy',\n",
       " 'fiaknllwy',\n",
       " 'fqianllh',\n",
       " 'fianrllhy',\n",
       " 'fianylh',\n",
       " 'fifanlgly',\n",
       " 'fiaollx',\n",
       " 'gfianelly',\n",
       " 'fianjlyl',\n",
       " 'fwianllyx',\n",
       " 'iisnlly',\n",
       " 'baianlly',\n",
       " 'fisznlly',\n",
       " 'fioanyly',\n",
       " 'fianmllfy',\n",
       " 'fipnlty',\n",
       " 'ftianllyp',\n",
       " 'fiaonhlly',\n",
       " 'bfianlky',\n",
       " 'cfianllr',\n",
       " 'fmanllyi',\n",
       " 'sfianlld',\n",
       " 'fmianlle',\n",
       " 'fiaunlhy',\n",
       " 'twanlly',\n",
       " 'fiaekly',\n",
       " 'franllx',\n",
       " 'afgianlly',\n",
       " 'ficnllh',\n",
       " 'fpianlhly',\n",
       " 'fianlelty',\n",
       " 'ftiaunlly',\n",
       " 'fsaslly',\n",
       " 'fiknluly',\n",
       " 'fievnlly',\n",
       " 'fizjnlly',\n",
       " 'ziaynlly',\n",
       " 'fibainlly',\n",
       " 'fianjfly',\n",
       " 'fpantlly',\n",
       " 'feiacnlly',\n",
       " 'mipnlly',\n",
       " 'fjaglly',\n",
       " 'fianloyt',\n",
       " 'fpianllwy',\n",
       " 'aiunlly',\n",
       " 'hianllgy',\n",
       " 'fianllemy',\n",
       " 'qianlla',\n",
       " 'fiagnmlly',\n",
       " 'fuanllyn',\n",
       " 'zffanlly',\n",
       " 'fimnllyb',\n",
       " 'fiaulnlly',\n",
       " 'feanllw',\n",
       " 'faianllxy',\n",
       " 'ficnll',\n",
       " 'fiaqqlly',\n",
       " 'fciaynlly',\n",
       " 'fianlug',\n",
       " 'fumnlly',\n",
       " 'fianljkly',\n",
       " 'fiasnllym',\n",
       " 'fmanloly',\n",
       " 'sfianjlly',\n",
       " 'fivnlay',\n",
       " 'fianillyl',\n",
       " 'fiandllyv',\n",
       " 'fgianllyw',\n",
       " 'rianllyz',\n",
       " 'faklly',\n",
       " 'fwanflly',\n",
       " 'fianelm',\n",
       " 'fiaxnlhy',\n",
       " 'fhianlfy',\n",
       " 'fiancllyz',\n",
       " 'fieanlley',\n",
       " 'ftianllv',\n",
       " 'mianlwy',\n",
       " 'fmiallly',\n",
       " 'fnanlla',\n",
       " 'gianlliy',\n",
       " 'mianelly',\n",
       " 'fiadxlly',\n",
       " 'fianllpyh',\n",
       " 'ogfianlly',\n",
       " 'figglly',\n",
       " 'iiajnlly',\n",
       " 'fiaanully',\n",
       " 'jfvanlly',\n",
       " 'uianlaly',\n",
       " 'flidanlly',\n",
       " 'dfianllyn',\n",
       " 'fiaiynlly',\n",
       " 'fiamllo',\n",
       " 'nfianllyp',\n",
       " 'fiaxnll',\n",
       " 'fianlzlyu',\n",
       " 'fiablln',\n",
       " 'fcanllly',\n",
       " 'gfianllyn',\n",
       " 'fdianlfly',\n",
       " 'fifvanlly',\n",
       " 'fpanlqly',\n",
       " 'fhanllay',\n",
       " 'fyianllay',\n",
       " 'fiapnjlly',\n",
       " 'fuanley',\n",
       " 'gyianlly',\n",
       " 'fiasllk',\n",
       " 'fienqlly',\n",
       " 'fcienlly',\n",
       " 'fvqianlly',\n",
       " 'fiantllyf',\n",
       " 'firanllc',\n",
       " 'fitanllz',\n",
       " 'fxanclly',\n",
       " 'fkianclly',\n",
       " 'fxianllyk',\n",
       " 'pfianlvly',\n",
       " 'jiaully',\n",
       " 'fiainllya',\n",
       " 'fiacnllyz',\n",
       " 'fipanwlly',\n",
       " 'qianljy',\n",
       " 'xfiajnlly',\n",
       " 'fiannlyj',\n",
       " 'fivnlli',\n",
       " 'fioonlly',\n",
       " 'fiemnlly',\n",
       " 'zfianllys',\n",
       " 'lwanlly',\n",
       " 'fuiaknlly',\n",
       " 'wianldly',\n",
       " 'wxianlly',\n",
       " 'ficwanlly',\n",
       " 'rfianlqly',\n",
       " 'uiawlly',\n",
       " 'franllya',\n",
       " 'fianclya',\n",
       " 'fianjvly',\n",
       " 'fcianllyu',\n",
       " 'fidtlly',\n",
       " 'qianlmy',\n",
       " 'xianllyq',\n",
       " 'fisanljy',\n",
       " 'fianldld',\n",
       " 'gfiamnlly',\n",
       " 'fisanllyt',\n",
       " 'folanlly',\n",
       " 'ftianlcy',\n",
       " 'tially',\n",
       " 'fkianyly',\n",
       " 'fimanlbly',\n",
       " 'fiarloy',\n",
       " 'fhiaelly',\n",
       " 'wfiancly',\n",
       " 'ftianllj',\n",
       " 'fiavlgy',\n",
       " 'fianlyb',\n",
       " 'filnllyl',\n",
       " 'dianlll',\n",
       " 'fipnanlly',\n",
       " 'fiamgnlly',\n",
       " 'fiknll',\n",
       " 'fianllyt',\n",
       " 'firnllyn',\n",
       " 'fiahnlln',\n",
       " 'fiahllyv',\n",
       " 'jfianlpy',\n",
       " 'qfilnlly',\n",
       " 'fianltlyz',\n",
       " 'fhikanlly',\n",
       " 'figpanlly',\n",
       " 'ftipnlly',\n",
       " 'fibnllyv',\n",
       " 'dfdanlly',\n",
       " 'fioanllye',\n",
       " 'zfianllz',\n",
       " 'fiaqlply',\n",
       " 'fhiaanlly',\n",
       " 'fiadllgy',\n",
       " 'wimnlly',\n",
       " 'fiinllny',\n",
       " 'ffalnly',\n",
       " 'apianlly',\n",
       " 'fimamlly',\n",
       " 'fzaynlly',\n",
       " 'oianldy',\n",
       " 'fiqfanlly',\n",
       " 'ficaznlly',\n",
       " 'kfianoly',\n",
       " 'zfpianlly',\n",
       " 'fialgly',\n",
       " 'feanolly',\n",
       " 'fianllhjy',\n",
       " 'fikqlly',\n",
       " 'biacnlly',\n",
       " 'qianllyf',\n",
       " 'fiajnlry',\n",
       " 'fifanlvy',\n",
       " 'fiablhly',\n",
       " 'ficranlly',\n",
       " 'gfianuly',\n",
       " 'gfianilly',\n",
       " 'fibnllhy',\n",
       " 'fixanvlly',\n",
       " 'fyanzly',\n",
       " 'fiazllhy',\n",
       " 'fwianllyn',\n",
       " 'jianjlly',\n",
       " 'fanllcy',\n",
       " 'franly',\n",
       " 'fjanlmy',\n",
       " 'sfcianlly',\n",
       " 'qyanlly',\n",
       " 'finanllny',\n",
       " 'vianllyv',\n",
       " 'efiamlly',\n",
       " 'fiawnluy',\n",
       " 'xiaully',\n",
       " 'fdiinlly',\n",
       " 'fiallmly',\n",
       " 'fisnjlly',\n",
       " 'dfianlla',\n",
       " 'lfiqnlly',\n",
       " 'fzianllqy',\n",
       " 'fianuey',\n",
       " 'dianllqy',\n",
       " 'tianllyg',\n",
       " 'fiabllmy',\n",
       " 'fianolaly',\n",
       " 'ifanlsly',\n",
       " 'fiqanqlly',\n",
       " 'ficanluy',\n",
       " 'fiagllzy',\n",
       " 'fiwnnly',\n",
       " 'efianllyt',\n",
       " 'fipvnlly',\n",
       " 'piarlly',\n",
       " 'fbanlll',\n",
       " 'fwiablly',\n",
       " 'fianllaz',\n",
       " 'fbianllyb',\n",
       " 'fmanllny',\n",
       " 'ftantlly',\n",
       " 'fiyanluly',\n",
       " 'fanllwy',\n",
       " 'fiqanllm',\n",
       " 'fyianvly',\n",
       " 'ofjianlly',\n",
       " 'fzawlly',\n",
       " 'fiaznoly',\n",
       " 'fianflsy',\n",
       " 'fnailly',\n",
       " 'fimfanlly',\n",
       " 'jfianllhy',\n",
       " 'fmijnlly',\n",
       " 'fawlly',\n",
       " 'fuiarlly',\n",
       " 'fiarluy',\n",
       " 'uianlqy',\n",
       " 'xfiynlly',\n",
       " 'qianluly',\n",
       " 'fiaknljly',\n",
       " 'fiadnllys',\n",
       " 'fxianllm',\n",
       " 'aianlnly',\n",
       " 'flahnlly',\n",
       " 'fiknolly',\n",
       " 'fiaunlluy',\n",
       " 'fianllynf',\n",
       " 'fbianloly',\n",
       " 'fianblgly',\n",
       " 'nfiaolly',\n",
       " 'sianlfly',\n",
       " 'fionylly',\n",
       " 'fiaolily',\n",
       " 'fioanlmy',\n",
       " 'iaenlly',\n",
       " 'fiaklkly',\n",
       " 'fiahnllyc',\n",
       " 'hianlld',\n",
       " 'fidanllz',\n",
       " 'fiafnllwy',\n",
       " 'fvanllyo',\n",
       " 'fwanmly',\n",
       " 'fiwanllyk',\n",
       " 'efianlljy',\n",
       " 'fiadllya',\n",
       " 'feiwnlly',\n",
       " 'firnglly',\n",
       " 'fiaehlly',\n",
       " 'fianlhyr',\n",
       " 'fiscanlly',\n",
       " 'fianllyxs',\n",
       " 'fibanllym',\n",
       " 'fmianqlly',\n",
       " 'fsanelly',\n",
       " 'fianallty',\n",
       " 'fiarljy',\n",
       " 'wfidnlly',\n",
       " 'fianqlbly',\n",
       " 'fianluvy',\n",
       " 'fiangllyd',\n",
       " 'fisanllw',\n",
       " 'fiaynllyk',\n",
       " 'fihlnlly',\n",
       " 'fhavlly',\n",
       " 'uianzly',\n",
       " 'fiagllys',\n",
       " 'jianlry',\n",
       " 'ufianally',\n",
       " 'fwanlyly',\n",
       " 'kfiinlly',\n",
       " 'fiapllyu',\n",
       " 'ctfianlly',\n",
       " 'fianhlu',\n",
       " 'fianhlo',\n",
       " 'jfianlhly',\n",
       " 'fcanbly',\n",
       " 'fanllyc',\n",
       " 'fianflyg',\n",
       " 'feanllye',\n",
       " 'lfianlnly',\n",
       " 'fiazhnlly',\n",
       " 'fianlavly',\n",
       " 'finalxy',\n",
       " 'filqanlly',\n",
       " 'finalry',\n",
       " 'fianalyg',\n",
       " 'fiaonllt',\n",
       " 'fianlsyly',\n",
       " 'fnanjlly',\n",
       " 'piapnlly',\n",
       " 'fianlklyu',\n",
       " 'fqianzly',\n",
       " 'fxancly',\n",
       " 'fianlleyw',\n",
       " 'fpanlny',\n",
       " 'frianllyd',\n",
       " 'mianllx',\n",
       " 'fiuanllh',\n",
       " 'fianluyd',\n",
       " 'pbanlly',\n",
       " 'qfiunlly',\n",
       " 'finlzy',\n",
       " 'fihnllcy',\n",
       " 'fiandllyu',\n",
       " 'fisankly',\n",
       " 'fialllyp',\n",
       " 'fianlgmly',\n",
       " 'fifanllcy',\n",
       " 'fialoly',\n",
       " 'fianldfly',\n",
       " 'fmianlbly',\n",
       " 'finllym',\n",
       " 'ziaslly',\n",
       " 'fianmllyd',\n",
       " 'fzanlily',\n",
       " 'fifanllj',\n",
       " 'pianlzly',\n",
       " 'bfianllye',\n",
       " 'fcanlli',\n",
       " 'fiaxnlgy',\n",
       " 'filandly',\n",
       " 'fyanllys',\n",
       " 'fimnflly',\n",
       " 'fiaknlwly',\n",
       " 'fianalyly',\n",
       " 'fanilly',\n",
       " 'fianyry',\n",
       " 'fianmllyu',\n",
       " 'flanelly',\n",
       " 'fdianlyl',\n",
       " 'fianyzy',\n",
       " 'vianlmly',\n",
       " 'fxmnlly',\n",
       " 'fianllaky',\n",
       " 'fiaqlny',\n",
       " 'fianwlg',\n",
       " 'niatlly',\n",
       " 'jianllfy',\n",
       " 'fqunlly',\n",
       " 'fioaunlly',\n",
       " 'dianlxly',\n",
       " 'fiznlny',\n",
       " 'figangly',\n",
       " 'fsanmly',\n",
       " 'eialnly',\n",
       " 'finnlloy',\n",
       " 'fianollp',\n",
       " 'fhanlvy',\n",
       " 'fiagnllh',\n",
       " 'wianllyo',\n",
       " 'fcanlnly',\n",
       " 'fianlyp',\n",
       " 'faianlvly',\n",
       " 'fpaslly',\n",
       " 'fianlklpy',\n",
       " 'fianrllcy',\n",
       " 'ffianllyy',\n",
       " 'hfiarnlly',\n",
       " 'ffifnlly',\n",
       " 'jhianlly',\n",
       " 'fianqltly',\n",
       " 'ffianlvy',\n",
       " 'xianlely',\n",
       " 'vfially',\n",
       " 'fwianllym',\n",
       " 'uifanlly',\n",
       " 'fiaoknlly',\n",
       " 'xivnlly',\n",
       " 'ciagnlly',\n",
       " 'fiaocly',\n",
       " 'fganllyt',\n",
       " 'fianljcly',\n",
       " 'nianrly',\n",
       " 'fianllwc',\n",
       " 'fixnllsy',\n",
       " 'fianlglyb',\n",
       " 'fiaonllv',\n",
       " 'fivanllz',\n",
       " 'fiaelyy',\n",
       " 'liuanlly',\n",
       " 'fianllli',\n",
       " 'fsiatnlly',\n",
       " 'fianllwa',\n",
       " 'fiapznlly',\n",
       " 'efianllvy',\n",
       " 'fipanrlly',\n",
       " 'wfianaly',\n",
       " 'fiafllg',\n",
       " 'fiaqnllwy',\n",
       " 'fianecy',\n",
       " 'fixunlly',\n",
       " 'fihanlsly',\n",
       " 'hfiacnlly',\n",
       " 'fijanlky',\n",
       " 'fvaqnlly',\n",
       " 'ftanzly',\n",
       " 'kiwnlly',\n",
       " 'nfxianlly',\n",
       " 'cfivanlly',\n",
       " 'ianflly',\n",
       " 'liaglly',\n",
       " 'hfianllyt',\n",
       " 'fieanllyf',\n",
       " 'vfianley',\n",
       " 'fwiaynlly',\n",
       " 'fianlyyy',\n",
       " 'fianlhlqy',\n",
       " 'fiabnhlly',\n",
       " 'fsianllyr',\n",
       " 'fixanlln',\n",
       " 'baanlly',\n",
       " 'fxianlldy',\n",
       " 'foanlkly',\n",
       " 'fiankllys',\n",
       " 'ftiadlly',\n",
       " 'hfianllvy',\n",
       " 'fiakndly',\n",
       " 'inlly',\n",
       " 'cfianlvy',\n",
       " 'fianjsy',\n",
       " 'fihaglly',\n",
       " 'fivanlcy',\n",
       " 'finanlzly',\n",
       " 'fiakzly',\n",
       " 'fiajnlluy',\n",
       " 'fianulfly',\n",
       " 'mfianlry',\n",
       " 'fiaulqy',\n",
       " 'xitnlly',\n",
       " 'fiadnlll',\n",
       " 'fiazlln',\n",
       " 'fibaunlly',\n",
       " 'fiinllb',\n",
       " 'mianlle',\n",
       " 'sfianlzly',\n",
       " 'fiaqtlly',\n",
       " 'fiually',\n",
       " 'fiapnllh',\n",
       " 'fihnlvy',\n",
       " 'pfianqly',\n",
       " 'fiantlle',\n",
       " 'fianrgy',\n",
       " 'fiatnllk',\n",
       " 'ifanllky',\n",
       " 'fainlbly',\n",
       " 'fifnllxy',\n",
       " 'foanllt',\n",
       " 'fbaylly',\n",
       " 'fipnilly',\n",
       " 'fdianllp',\n",
       " 'fiafnllyz',\n",
       " 'fianlnlwy',\n",
       " 'fiavnllyn',\n",
       " 'rianoly',\n",
       " 'gfkianlly',\n",
       " 'iiaknlly',\n",
       " 'fianlnlyo',\n",
       " 'fianlglgy',\n",
       " 'fijnqlly',\n",
       " 'fianljyv',\n",
       " 'flanclly',\n",
       " 'dfianlhy',\n",
       " 'fianjlv',\n",
       " 'ftanllby',\n",
       " 'fianlgxly',\n",
       " 'fiaqlxly',\n",
       " 'mfianlmy',\n",
       " 'yiablly',\n",
       " 'fianlqlvy',\n",
       " 'fianollyk',\n",
       " 'fsianlluy',\n",
       " 'fienlxy',\n",
       " 'fianhlym',\n",
       " 'fiatllw',\n",
       " 'fianllupy',\n",
       " 'fiadllyh',\n",
       " 'vfibnlly',\n",
       " 'ifatlly',\n",
       " 'fiahnlyy',\n",
       " 'fianlolx',\n",
       " 'fiaillyd',\n",
       " 'fiagvly',\n",
       " 'lianlply',\n",
       " 'fihanllyh',\n",
       " 'fianowly',\n",
       " 'fianleym',\n",
       " 'fianbljly',\n",
       " 'feianjlly',\n",
       " 'foaynlly',\n",
       " 'tianllhy',\n",
       " 'fwapnlly',\n",
       " 'oianlely',\n",
       " 'fianclt',\n",
       " 'fitanlly',\n",
       " 'hianilly',\n",
       " 'fianlzj',\n",
       " 'foisanlly',\n",
       " 'ftianlfy',\n",
       " 'ruianlly',\n",
       " 'lianllly',\n",
       " 'fiazluy',\n",
       " 'fianbllg',\n",
       " 'fizklly',\n",
       " 'faianaly',\n",
       " 'fiaolls',\n",
       " 'fianlliyh',\n",
       " 'qianply',\n",
       " 'fiabolly',\n",
       " 'fiasnnlly',\n",
       " 'efiaxnlly',\n",
       " 'mianglly',\n",
       " 'fitanjlly',\n",
       " 'fbiagnlly',\n",
       " 'fypanlly',\n",
       " 'fkanjlly',\n",
       " 'fiansldy',\n",
       " 'fdianlty',\n",
       " 'wianllyc',\n",
       " 'fibnllk',\n",
       " 'fianswlly',\n",
       " 'fianllsv',\n",
       " 'bianllyq',\n",
       " 'fiajliy',\n",
       " 'fianrllu',\n",
       " 'fietnlly',\n",
       " 'fvianllcy',\n",
       " 'fianllyio',\n",
       " 'fjablly',\n",
       " 'fianhlp',\n",
       " 'mwianlly',\n",
       " 'wiallly',\n",
       " 'fianledy',\n",
       " 'zianllu',\n",
       " 'fbanlzy',\n",
       " 'fjanlyly',\n",
       " 'fiarnlply',\n",
       " 'fmiajlly',\n",
       " ...}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# two edit distances from input word\n",
    "edits2(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'faintly', 'finally', 'finely', 'frankly'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get correct words from above set\n",
    "known(edits2(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'finally'}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates = (known(edits0(word)) or \n",
    "              known(edits1(word)) or \n",
    "              known(edits2(word)) or \n",
    "              [word])\n",
    "candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct(word):\n",
    "    \"\"\"\n",
    "    Get the best correct spelling for the input word\n",
    "    \"\"\"\n",
    "    # Priority is for edit distance 0, then 1, then 2\n",
    "    # else defaults to the input word itself.\n",
    "    candidates = (known(edits0(word)) or \n",
    "                  known(edits1(word)) or \n",
    "                  known(edits2(word)) or \n",
    "                  [word])\n",
    "    return max(candidates, key=WORD_COUNTS.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'finally'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct('fianlly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FIANLLY'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct('FIANLLY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_match(match):\n",
    "    \"\"\"\n",
    "    Spell-correct word in match, \n",
    "    and preserve proper upper/lower/title case.\n",
    "    \"\"\"\n",
    "    \n",
    "    word = match.group()\n",
    "    def case_of(text):\n",
    "        \"\"\"\n",
    "        Return the case-function appropriate \n",
    "        for text: upper, lower, title, or just str.:\n",
    "            \"\"\"\n",
    "        return (str.upper if text.isupper() else\n",
    "                str.lower if text.islower() else\n",
    "                str.title if text.istitle() else\n",
    "                str)\n",
    "    return case_of(word)(correct(word.lower()))\n",
    "\n",
    "    \n",
    "def correct_text_generic(text):\n",
    "    \"\"\"\n",
    "    Correct all the words within a text, \n",
    "    returning the corrected text.\n",
    "    \"\"\"\n",
    "    return re.sub('[a-zA-Z]+', correct_match, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'finally'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_text_generic('fianlly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FINALLY'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_text_generic('FIANLLY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'finally'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import Word\n",
    "\n",
    "w = Word('fianlly')\n",
    "w.correct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('finally', 1.0)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.spellcheck()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('flat', 0.85), ('float', 0.15)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = Word('flaot')\n",
    "w.spellcheck()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('jump', 'jump', 'jump')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Porter Stemmer\n",
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "\n",
    "ps.stem('jumping'), ps.stem('jumps'), ps.stem('jumped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lie'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps.stem('lying')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'strang'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps.stem('strange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('jump', 'jump', 'jump')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lancaster Stemmer\n",
    "from nltk.stem import LancasterStemmer\n",
    "ls = LancasterStemmer()\n",
    "\n",
    "ls.stem('jumping'), ls.stem('jumps'), ls.stem('jumped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lying'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls.stem('lying')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'strange'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls.stem('strange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('jump', 'jump', 'jump')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Regex based stemmer\n",
    "from nltk.stem import RegexpStemmer\n",
    "rs = RegexpStemmer('ing$|s$|ed$', min=4)\n",
    "rs.stem('jumping'), rs.stem('jumps'), rs.stem('jumped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ly'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs.stem('lying')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'strange'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs.stem('strange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supported Languages: ('arabic', 'danish', 'dutch', 'english', 'finnish', 'french', 'german', 'hungarian', 'italian', 'norwegian', 'porter', 'portuguese', 'romanian', 'russian', 'spanish', 'swedish')\n"
     ]
    }
   ],
   "source": [
    "# Snowball Stemmer\n",
    "from nltk.stem import SnowballStemmer\n",
    "ss = SnowballStemmer(\"german\")\n",
    "print('Supported Languages:', SnowballStemmer.languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'autobahn'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stemming on German words\n",
    "# autobahnen -> cars\n",
    "# autobahn -> car\n",
    "ss.stem('autobahnen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spring'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# springen -> jumping\n",
    "# spring -> jump\n",
    "ss.stem('springen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my system keep crash hi crash yesterday, our crash daili'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def simple_stemmer(text):\n",
    "    ps = nltk.porter.PorterStemmer()\n",
    "    text = ' '.join([ps.stem(word) for word in text.split()])\n",
    "    return text\n",
    "\n",
    "simple_stemmer(\"My system keeps crashing his crashed yesterday, ours crashes daily\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "wnl = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car\n",
      "men\n"
     ]
    }
   ],
   "source": [
    "# lemmatize nouns\n",
    "print(wnl.lemmatize('cars', 'n'))\n",
    "print(wnl.lemmatize('men', 'n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run\n",
      "eat\n"
     ]
    }
   ],
   "source": [
    "# lemmatize verbs\n",
    "print(wnl.lemmatize('running', 'v'))\n",
    "print(wnl.lemmatize('ate', 'v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sad\n",
      "fancy\n"
     ]
    }
   ],
   "source": [
    "# lemmatize adjectives\n",
    "print(wnl.lemmatize('saddest', 'a'))\n",
    "print(wnl.lemmatize('fancier', 'a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ate\n",
      "fancier\n"
     ]
    }
   ],
   "source": [
    "# ineffective lemmatization\n",
    "print(wnl.lemmatize('ate', 'n'))\n",
    "print(wnl.lemmatize('fancier', 'v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python3 -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my system keep crash ! his crash yesterday , ours crash daily'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "text = 'My system keeps crashing his crashed yesterday, ours crashes daily'\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    text = nlp(text)\n",
    "    text = ' '.join([word.lemma_ if word.lemma_ != '-PRON-' else word.text for word in text])\n",
    "    return text\n",
    "\n",
    "lemmatize_text(\"My system keeps crashing! his crashed yesterday, ours crashes daily\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "tokenizer = ToktokTokenizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('stopwords') # not needed on New ARC\n",
    "from nltk.corpus import stopwords\n",
    "stopword_list = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text, is_lower_case=False, stopwords=stopword_list):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    if is_lower_case:\n",
    "        filtered_tokens = [token for token in tokens if token not in stopwords]\n",
    "    else:\n",
    "        filtered_tokens = [token for token in tokens if token.lower() not in stopwords]\n",
    "    filtered_text = ' '.join(filtered_tokens)    \n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "', , stopwords , computer'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_stopwords(\"The, and, if are stopwords, computer is not\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_corpus(corpus, html_stripping=True, contraction_expansion=True,\n",
    "                     accented_char_removal=True, text_lower_case=True, \n",
    "                     text_lemmatization=True, special_char_removal=True, \n",
    "                     stopword_removal=True, remove_digits=True):\n",
    "    \n",
    "    normalized_corpus = []\n",
    "    # normalize each document in the corpus\n",
    "    for doc in corpus:\n",
    "        # strip HTML\n",
    "        if html_stripping:\n",
    "            doc = strip_html_tags(doc)\n",
    "        # remove accented characters\n",
    "        if accented_char_removal:\n",
    "            doc = remove_accented_chars(doc)\n",
    "        # expand contractions    \n",
    "        if contraction_expansion:\n",
    "            doc = expand_contractions(doc)\n",
    "        # lowercase the text    \n",
    "        if text_lower_case:\n",
    "            doc = doc.lower()\n",
    "        # remove extra newlines\n",
    "        doc = re.sub(r'[\\r|\\n|\\r\\n]+', ' ',doc)\n",
    "        # lemmatize text\n",
    "        if text_lemmatization:\n",
    "            doc = lemmatize_text(doc)\n",
    "        # remove special characters and\\or digits    \n",
    "        if special_char_removal:\n",
    "            # insert spaces between special characters to isolate them    \n",
    "            special_char_pattern = re.compile(r'([{.(-)!}])')\n",
    "            doc = special_char_pattern.sub(\" \\\\1 \", doc)\n",
    "            doc = remove_special_characters(doc, remove_digits=remove_digits)  \n",
    "        # remove extra whitespace\n",
    "        doc = re.sub(' +', ' ', doc)\n",
    "        # remove stopwords\n",
    "        if stopword_removal:\n",
    "            doc = remove_stopwords(doc, is_lower_case=text_lower_case)\n",
    "            \n",
    "        normalized_corpus.append(doc)\n",
    "        \n",
    "    return normalized_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Original': \"US unveils world's most powerful supercomputer, beats China. The US has unveiled the world's most powerful supercomputer called 'Summit', beating the previous record-holder China's Sunway TaihuLight. With a peak performance of 200,000 trillion calculations per second, it is over twice as fast as Sunway TaihuLight, which is capable of 93,000 trillion calculations per second. Summit has 4,608 servers, which reportedly take up the size of two tennis courts.\",\n",
       " 'Processed': 'unveil world powerful supercomputer beat china us unveil world powerful supercomputer call summit beat previous record holder chinas sunway taihulight peak performance trillion calculation per second twice fast sunway taihulight capable trillion calculation per second summit server reportedly take size two tennis court'}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'Original': sample_text,\n",
    " 'Processed': normalize_corpus([sample_text])[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Conda Python 3.12",
   "language": "python",
   "name": "conda-python3.12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
