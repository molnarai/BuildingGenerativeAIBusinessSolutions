{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High-Performance Search using FAISS\n",
    "\n",
    "**pip install faiss-cpu**\n",
    "\n",
    "Source: \n",
    "\n",
    "Pratyush Khare, How to perform High-Performance Search using FAISS\n",
    "A Beginnerâ€™s Guide to FAISS, use-cases, Mathematical foundations & implementation\n",
    "\n",
    "https://kharepratyush.medium.com/how-to-perform-high-performance-search-using-faiss-da2ab12f606c\n",
    "\n",
    "Correction:\n",
    "https://sidshome.wordpress.com/2023/12/30/deep-dive-into-faiss-indexivfpq-for-vector-search/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mathematical Foundations of FAISS\n",
    "\n",
    "FAISS is built on the concept of indexing, which is a method of preprocessing a dataset to make it more searchable. \n",
    "\n",
    "By grouping comparable components together, indexing reduces the number of elements that must be compared throughout the search. \n",
    "\n",
    "Product quantization (PQ) and inverted file indexing structures are the two main types of indexing structures employed in FAISS (IVF):\n",
    "\n",
    "- **Product Quantization (PQ)** is a technique for reducing the number of discrete values in high-dimensional vectors:\n",
    "\n",
    "    - The vectors are subdivided, and each subvector is quantized independently. \n",
    "\n",
    "    - This yields a vector representation that is small enough to be utilised for similarity search.\n",
    "\n",
    "- **The Inverted File (IVF)** method generates an inverted index of the dataset:\n",
    "\n",
    "    - The inverted index is a data structure that allows you to quickly discover objects in a dataset that match a specified query. \n",
    "\n",
    "    - The inverted index is constructed by dividing the dataset into a number of **small clusters** (known as **inverted lists**) and identifying each element with the cluster to which it belongs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanation of Each Index\n",
    "\n",
    "**LSH (Locality Sensitive Hashing):**\n",
    "Uses a hashing function that maps similar vectors to the same \"bucket\" with a high probability, allowing for fast lookups by only checking vectors within the same bucket, but can sometimes have lower precision compared to other methods. \n",
    "\n",
    "**IVF (Inverted File):**\n",
    "Divides the data space into a set of \"centroids\" and assigns each data point to its closest centroid, creating an inverted index where each centroid stores a list of associated data points, enabling faster search by only checking vectors close to the query's assigned centroid. \n",
    "\n",
    "**PQ (Product Quantization):**\n",
    "Breaks down high-dimensional vectors into smaller subvectors and quantizes each subvector separately, significantly reducing memory usage while still maintaining reasonable search accuracy. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Benefits of FAISS\n",
    "\n",
    "**Efficient similarity search:** FAISS provides efficient methods for similarity search and grouping, which can handle large-scale, high-dimensional data.\n",
    "\n",
    "**Approximate nearest neighbour search:** FAISS offers an approximate closest neighbour search that delivers approximate nearest neighbours with a quality guarantee.\n",
    "\n",
    "**GPU support:** FAISS includes GPU support, which enables for further search acceleration and can greatly increase search performance on large-scale datasets.\n",
    "\n",
    "**Scalability:** FAISS is designed to be extremely scalable and capable of handling large-scale datasets including billions of components.\n",
    "\n",
    "**Flexibility:** FAISS provides a number of indexing structures, including as **LSH, IVF,** and **PQ,** that can be utilised to speed up searches and handle various types of data and use cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: Nearest neighbour search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11.100926  11.496892  11.525411  11.669714  11.747231  12.017442\n",
      "  12.307231  12.484753  12.5091715 12.5371065]]\n",
      "[[295 488 668 629 717 559 529 544 211 499]]\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "# Generate a dataset of 1000 points in 100 dimensions\n",
    "X = np.random.rand(1000, 100).astype('float32')\n",
    "\n",
    "# Create an index for the dataset\n",
    "index = faiss.IndexFlatL2(100)\n",
    "\n",
    "# Add the dataset to the index\n",
    "index.add(X)\n",
    "\n",
    "# Perform a nearest neighbor search for a query vector\n",
    "query = np.random.rand(1, 100).astype('float32')\n",
    "D, I = index.search(query, k=10)\n",
    "\n",
    "# Print the distances and indices of the nearest neighbors\n",
    "print(D)\n",
    "print(I)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: Approximate nearest neighbour search\n",
    "\n",
    "Use of the **IVFPQ** indexing structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10.226586  10.2682705 10.345407  10.408644  10.483592  10.723971\n",
      "  10.745865  10.75904   10.849054  10.906368 ]]\n",
      "[[724 575 177 743 742  89  55   7 595 390]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING clustering 1000 points to 256 centroids: please provide at least 9984 training points\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "# Generate a dataset of 1000 points in 100 dimensions\n",
    "X = np.random.rand(1000, 100).astype('float32')\n",
    "\n",
    "# Create an index for the dataset\n",
    "nlist = 100\n",
    "quantizer = faiss.IndexFlatL2(100)  # this remains the same\n",
    "# index = faiss.IndexIVFPQ(quantizer, X.shape[1], nlist, 8, 8)\n",
    "\n",
    "index = faiss.IndexIVFPQ(quantizer, X.shape[1], 4, 4, 8)\n",
    "\n",
    "# Train the index\n",
    "index.train(X)\n",
    "\n",
    "# Add the dataset to the index\n",
    "index.add(X)\n",
    "\n",
    "# Perform an approximate nearest neighbor search for a query vector\n",
    "query = np.random.rand(1, 100).astype('float32')\n",
    "D, I = index.search(query, k=10)\n",
    "\n",
    "# Print the distances and indices of the nearest neighbors\n",
    "print(D)\n",
    "print(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: Real-world implementation of FAISS in an integrated machine-learning system:\n",
    "\n",
    "https://medium.com/mlearning-ai/how-do-online-marketplaces-know-your-shopping-preferences-57405d83516a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Conda Python 3.12",
   "language": "python",
   "name": "conda-python3.12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
