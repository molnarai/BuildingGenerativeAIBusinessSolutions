{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding Assistant with crewAI\n",
    "\n",
    "Source:\n",
    "\n",
    "Examples for crewAI\n",
    "https://github.com/crewAIInc/crewAI-examples/tree/main\n",
    "\n",
    "Notebooks:\n",
    "https://github.com/crewAIInc/crewAI-examples/tree/main/Notebooks\n",
    "\n",
    "Notebook (modified):\n",
    "https://github.com/crewAIInc/crewAI-examples/blob/main/Notebooks/CrewAI%20Flows%20%26%20Langgraph/Coding%20Assistant/coding_assistant_eval.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "GROQ_API_KEY = open(\"/Users/mjack6/.secrets/groq_mjack.apikey\", \"r\").read().strip()\n",
    "OPENAI_API_KEY = open(\"/Users/mjack6/.secrets/openai_mjack.apikey\", \"r\").read().strip()\n",
    "os.environ[\"GROQ_API_KEY\"] = GROQ_API_KEY\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply a patch to allow nested asyncio loops in Jupyter\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as Soup\n",
    "from langchain_community.document_loaders.recursive_url_loader import RecursiveUrlLoader\n",
    "\n",
    "# LCEL docs\n",
    "url = \"https://python.langchain.com/docs/how_to/sequence/#related\"\n",
    "loader = RecursiveUrlLoader(\n",
    "    url=url, max_depth=20, extractor=lambda x: Soup(x, \"html.parser\").text\n",
    ")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the list based on the URLs and get the text\n",
    "d_sorted = sorted(docs, key=lambda x: x.metadata[\"source\"])\n",
    "d_reversed = list(reversed(d_sorted))\n",
    "concatenated_content = \"\\n\\n\\n --- \\n\\n\\n\".join(\n",
    "    [doc.page_content for doc in d_reversed]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Crew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjack6/GSU_Spring2025/MSA8700/venv_agenticai/lib/python3.11/site-packages/pydantic/_internal/_config.py:295: PydanticDeprecatedSince20: Support for class-based `config` is deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  warnings.warn(DEPRECATION_MESSAGE, DeprecationWarning)\n",
      "/Users/mjack6/GSU_Spring2025/MSA8700/venv_agenticai/lib/python3.11/site-packages/pydantic/_internal/_generate_schema.py:502: UserWarning: <built-in function callable> is not a Python type (it may be an instance of an object), Pydantic will allow any object with no validation since we cannot even enforce that the input is an instance of the given type. To get rid of this error wrap the type with `pydantic.SkipValidation`.\n",
      "  warn(\n",
      "/Users/mjack6/GSU_Spring2025/MSA8700/venv_agenticai/lib/python3.11/site-packages/crewai_tools/tools/scrapegraph_scrape_tool/scrapegraph_scrape_tool.py:34: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  @validator(\"website_url\")\n",
      "/Users/mjack6/GSU_Spring2025/MSA8700/venv_agenticai/lib/python3.11/site-packages/crewai_tools/tools/selenium_scraping_tool/selenium_scraping_tool.py:26: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  @validator(\"website_url\")\n",
      "/Users/mjack6/GSU_Spring2025/MSA8700/venv_agenticai/lib/python3.11/site-packages/crewai_tools/tools/vision_tool/vision_tool.py:15: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  @validator(\"image_path_url\")\n"
     ]
    }
   ],
   "source": [
    "# Importing Crew related components\n",
    "from crewai import Agent, Task, Crew\n",
    "\n",
    "# Importing CrewAI Tools\n",
    "from crewai_tools import WebsiteSearchTool\n",
    "\n",
    "# Importing Pydantic\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class CodeSolution(BaseModel):\n",
    "  prefix: str = Field(description=\"Description of the problem and approach\")\n",
    "  imports: str = Field(description=\"Code block import statements\")\n",
    "  code: str = Field(description=\"Code block not including import statements\")\n",
    "\n",
    "# Create the coding assistant agent\n",
    "coding_assistant = Agent(\n",
    "    role='Coding Assistant',\n",
    "    goal='Provide accurate and executable code solutions using LCEL',\n",
    "    backstory=\"\"\"You are a coding assistant with expertise in LCEL, LangChain expression language. \\n\n",
    "    Here is the LCEL documentation:  \\n ------- \\n  {context} \\n ------- \\n\n",
    "    Answer the user  question based on the \\n\n",
    "    above provided documentation. Ensure any code you provide can be executed with all required imports and variables \\n\n",
    "    defined.\"\"\",\n",
    "    verbose=False,\n",
    "    llm='gpt-4o'\n",
    ")\n",
    "\n",
    "# Create task for code generation\n",
    "code_generation_task = Task(\n",
    "    description=\"\"\"Answer the user question based on the above provided documentation. Ensure any code you provide can be executed\n",
    "    with all required imports and variables defined. Structure your answer:\n",
    "    1) a prefix describing the code solution\n",
    "    2) the imports\n",
    "    3) the functioning code block\n",
    "\n",
    "    Your coding task:\n",
    "    {question}\n",
    "    \"\"\",\n",
    "    expected_output=\"Code solution with prefix description, imports, and executable code block\",\n",
    "    agent=coding_assistant,\n",
    "    output_pydantic=CodeSolution\n",
    ")\n",
    "\n",
    "# Create the crew\n",
    "code_crew = Crew(\n",
    "    agents=[coding_assistant],\n",
    "    tasks=[code_generation_task],\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code_crew.train(\n",
    "#   n_iterations=2,\n",
    "#   filename=\"code_crew.pkl\",\n",
    "#   inputs={\n",
    "#     \"question\": 'How do I build a RAG chain in LCEL?',\n",
    "#     \"context\": str(concatenated_content)\n",
    "#   }\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Flow State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "class CodeGenState(BaseModel):\n",
    "    \"\"\"\n",
    "    State for the code generation flow\n",
    "    \"\"\"\n",
    "    error: str = \"\"\n",
    "    question: str = \"\"\n",
    "    messages: List = []\n",
    "    generation: str = \"\"\n",
    "    iterations: int = 0\n",
    "    max_iterations: int = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Code Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing CrewAI Flow related components\n",
    "from crewai.flow.flow import Flow, listen, start, router\n",
    "\n",
    "class CodeGenFlow(Flow[CodeGenState]):\n",
    "  def check_code(self):\n",
    "    print(\"---CHECKING CODE---\")\n",
    "\n",
    "    code_solution = self.state.generation\n",
    "    imports = code_solution.imports\n",
    "    code = code_solution.code\n",
    "\n",
    "    try:\n",
    "      exec(imports)\n",
    "    except Exception as e:\n",
    "      print(\"---CODE IMPORT CHECK: FAILED---\")\n",
    "      self.state.error = str(e)\n",
    "      return \"code_failed\"\n",
    "\n",
    "    try:\n",
    "      exec(imports + \"\\n\" + code)\n",
    "    except Exception as e:\n",
    "      print(\"---CODE BLOCK CHECK: FAILED---\")\n",
    "      self.state.error = str(e)\n",
    "      return \"code_failed\"\n",
    "\n",
    "    print(\"---NO CODE TEST FAILURES---\")\n",
    "    return \"success\"\n",
    "\n",
    "  def fix_code(self):\n",
    "    if self.state.error != \"\":\n",
    "      print(\"---FIXING CODE---\")\n",
    "      # Create task for fixing code\n",
    "      code_fix_task = Task(\n",
    "          description=\"\"\"You are a coding assistant with expertise in LCEL, LangChain expression language.\n",
    "          Here is a full set of LCEL documentation:\n",
    "          -------\n",
    "          {context}\n",
    "          -------\n",
    "\n",
    "          The previous code attempt failed with the following error:\n",
    "          {error}\n",
    "\n",
    "          Your coding task:\n",
    "          {question}\n",
    "\n",
    "          Previous code attempt:\n",
    "          {explanation}\n",
    "          {imports}\n",
    "          {code}\n",
    "\n",
    "          Answer with a description of the code solution, followed by the imports, and finally the functioning code block.\n",
    "          Ensure all imports are correct and the code is executable.\"\"\",\n",
    "          expected_output= \"A working code solution to the problem\",\n",
    "          agent=coding_assistant,\n",
    "          output_pydantic=CodeSolution\n",
    "      )\n",
    "\n",
    "      # Create crew for fixing code\n",
    "      fix_crew = Crew(\n",
    "          agents=[coding_assistant],\n",
    "          tasks=[code_fix_task]\n",
    "      )\n",
    "\n",
    "      # Execute fix\n",
    "      result = fix_crew.kickoff(\n",
    "          inputs={\n",
    "              \"error\": self.state.error,\n",
    "              \"question\": self.state.question,\n",
    "              \"explanation\": self.state.generation.prefix,\n",
    "              \"imports\": self.state.generation.imports,\n",
    "              \"code\": self.state.generation.code,\n",
    "              \"context\": concatenated_content\n",
    "          }\n",
    "      )\n",
    "      self.state.generation = result.pydantic\n",
    "      self.state.error = \"\"\n",
    "\n",
    "  @start()\n",
    "  def generate_code(self):\n",
    "    print(\"---GENERATING CODE SOLUTION---\")\n",
    "    result = code_crew.kickoff(\n",
    "      inputs={\n",
    "        \"question\": self.state.question,\n",
    "        \"context\": concatenated_content\n",
    "      }\n",
    "    )\n",
    "    self.state.generation = result.pydantic\n",
    "    self.state.error = \"\"\n",
    "\n",
    "  @router(generate_code)\n",
    "  def run_check(self):\n",
    "    result = self.check_code()\n",
    "    if result != \"success\":\n",
    "      return \"fix_code\"\n",
    "\n",
    "  @listen('fix_code')\n",
    "  def run_fix(self):\n",
    "    self.fix_code()\n",
    "\n",
    "  @router(run_fix)\n",
    "  def re_run_check(self):\n",
    "    result = self.check_code()\n",
    "    if result != \"success\":\n",
    "      return \"refix_code\"\n",
    "\n",
    "  @listen('refix_code')\n",
    "  def re_run_fix(self):\n",
    "    self.fix_code()\n",
    "\n",
    "  @listen(re_run_fix)\n",
    "  def re_re_run_check(self):\n",
    "    self.check_code()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:36:54][🌊 FLOW CREATED: 'CODEGENFLOW']: 2025-03-13 15:36:54.654062\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:36:54][🤖 FLOW STARTED: 'CODEGENFLOW', 590F0381-7A49-46E0-8193-B34ACA1A30DA]: 2025-03-13 15:36:54.654597\u001b[00m\n",
      "\u001b[1m\u001b[35m Flow started with ID: 590f0381-7a49-46e0-8193-b34aca1a30da\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:36:54][🤖 FLOW METHOD STARTED: 'GENERATE_CODE']: 2025-03-13 15:36:54.654873\u001b[00m\n",
      "---GENERATING CODE SOLUTION---\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:36:54][🚀 CREW 'CREW' STARTED, 368F5772-413F-4BF5-BD01-847C2CD6098D]: 2025-03-13 15:36:54.655074\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:36:54][📋 TASK STARTED: ANSWER THE USER QUESTION BASED ON THE ABOVE PROVIDED DOCUMENTATION. ENSURE ANY CODE YOU PROVIDE CAN BE EXECUTED\n",
      "    WITH ALL REQUIRED IMPORTS AND VARIABLES DEFINED. STRUCTURE YOUR ANSWER:\n",
      "    1) A PREFIX DESCRIBING THE CODE SOLUTION\n",
      "    2) THE IMPORTS\n",
      "    3) THE FUNCTIONING CODE BLOCK\n",
      "\n",
      "    YOUR CODING TASK:\n",
      "    HOW DO I BUILD A RAG CHAIN IN LCEL?\n",
      "    ]: 2025-03-13 15:36:54.660945\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:36:54][🤖 AGENT 'CODING ASSISTANT' STARTED TASK]: 2025-03-13 15:36:54.661967\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:36:54][🤖 LLM CALL STARTED]: 2025-03-13 15:36:54.662109\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:36:57][✅ LLM CALL COMPLETED]: 2025-03-13 15:36:57.196595\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:36:57][✅ AGENT 'CODING ASSISTANT' COMPLETED TASK]: 2025-03-13 15:36:57.197073\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:36:57][✅ TASK COMPLETED: ANSWER THE USER QUESTION BASED ON THE ABOVE PROVIDED DOCUMENTATION. ENSURE ANY CODE YOU PROVIDE CAN BE EXECUTED\n",
      "    WITH ALL REQUIRED IMPORTS AND VARIABLES DEFINED. STRUCTURE YOUR ANSWER:\n",
      "    1) A PREFIX DESCRIBING THE CODE SOLUTION\n",
      "    2) THE IMPORTS\n",
      "    3) THE FUNCTIONING CODE BLOCK\n",
      "\n",
      "    YOUR CODING TASK:\n",
      "    HOW DO I BUILD A RAG CHAIN IN LCEL?\n",
      "    ]: 2025-03-13 15:36:57.197293\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:36:57][✅ CREW 'CREW' COMPLETED, 368F5772-413F-4BF5-BD01-847C2CD6098D]: 2025-03-13 15:36:57.199742\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:36:57][👍 FLOW METHOD FINISHED: 'GENERATE_CODE']: 2025-03-13 15:36:57.199894\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:36:57][🤖 FLOW METHOD STARTED: 'RUN_CHECK']: 2025-03-13 15:36:57.200002\u001b[00m\n",
      "---CHECKING CODE---\n",
      "---CODE BLOCK CHECK: FAILED---\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:36:58][👍 FLOW METHOD FINISHED: 'RUN_CHECK']: 2025-03-13 15:36:58.127214\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:36:58][🤖 FLOW METHOD STARTED: 'RUN_FIX']: 2025-03-13 15:36:58.127687\u001b[00m\n",
      "---FIXING CODE---\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:36:58][🚀 CREW 'CREW' STARTED, 8C2B92EC-4748-4DDD-98F0-BF9B1CB37B47]: 2025-03-13 15:36:58.129285\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:36:58][📋 TASK STARTED: YOU ARE A CODING ASSISTANT WITH EXPERTISE IN LCEL, LANGCHAIN EXPRESSION LANGUAGE.\n",
      "          HERE IS A FULL SET OF LCEL DOCUMENTATION:\n",
      "          -------\n",
      "          \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "HOW TO CHAIN RUNNABLES | 🦜️🔗 LANGCHAIN\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "SKIP TO MAIN CONTENTJOIN US AT  INTERRUPT: THE AGENT AI CONFERENCE BY LANGCHAIN ON MAY 13 & 14 IN SAN FRANCISCO!INTEGRATIONSAPI REFERENCEMORECONTRIBUTINGPEOPLEERROR REFERENCELANGSMITHLANGGRAPHLANGCHAIN HUBLANGCHAIN JS/TSV0.3V0.3V0.2V0.1💬SEARCHINTRODUCTIONTUTORIALSBUILD A QUESTION ANSWERING APPLICATION OVER A GRAPH DATABASETUTORIALSBUILD A SIMPLE LLM APPLICATION WITH CHAT MODELS AND PROMPT TEMPLATESBUILD A CHATBOTBUILD A RETRIEVAL AUGMENTED GENERATION (RAG) APP: PART 2BUILD AN EXTRACTION CHAINBUILD AN AGENTTAGGINGBUILD A RETRIEVAL AUGMENTED GENERATION (RAG) APP: PART 1BUILD A SEMANTIC SEARCH ENGINEBUILD A QUESTION/ANSWERING SYSTEM OVER SQL DATASUMMARIZE TEXTHOW-TO GUIDESHOW-TO GUIDESHOW TO USE TOOLS IN A CHAINHOW TO USE A VECTORSTORE AS A RETRIEVERHOW TO ADD MEMORY TO CHATBOTSHOW TO USE EXAMPLE SELECTORSHOW TO ADD A SEMANTIC LAYER OVER GRAPH DATABASEHOW TO INVOKE RUNNABLES IN PARALLELHOW TO STREAM CHAT MODEL RESPONSESHOW TO ADD DEFAULT INVOCATION ARGS TO A RUNNABLEHOW TO ADD RETRIEVAL TO CHATBOTSHOW TO USE FEW SHOT EXAMPLES IN CHAT MODELSHOW TO DO TOOL/FUNCTION CALLINGHOW TO INSTALL LANGCHAIN PACKAGESHOW TO ADD EXAMPLES TO THE PROMPT FOR QUERY ANALYSISHOW TO USE FEW SHOT EXAMPLESHOW TO RUN CUSTOM FUNCTIONSHOW TO USE OUTPUT PARSERS TO PARSE AN LLM RESPONSE INTO STRUCTURED FORMATHOW TO HANDLE CASES WHERE NO QUERIES ARE GENERATEDHOW TO ROUTE BETWEEN SUB-CHAINSHOW TO RETURN STRUCTURED DATA FROM A MODELHOW TO SUMMARIZE TEXT THROUGH PARALLELIZATIONHOW TO SUMMARIZE TEXT THROUGH ITERATIVE REFINEMENTHOW TO SUMMARIZE TEXT IN A SINGLE LLM CALLHOW TO USE TOOLKITSHOW TO ADD AD-HOC TOOL CALLING CAPABILITY TO LLMS AND CHAT MODELSBUILD AN AGENT WITH AGENTEXECUTOR (LEGACY)HOW TO CONSTRUCT KNOWLEDGE GRAPHSHOW TO PARTIALLY FORMAT PROMPT TEMPLATESHOW TO HANDLE MULTIPLE QUERIES WHEN DOING QUERY ANALYSISHOW TO USE BUILT-IN TOOLS AND TOOLKITSHOW TO PASS THROUGH ARGUMENTS FROM ONE STEP TO THE NEXTHOW TO COMPOSE PROMPTS TOGETHERHOW TO HANDLE MULTIPLE RETRIEVERS WHEN DOING QUERY ANALYSISHOW TO ADD VALUES TO A CHAIN'S STATEHOW TO CONSTRUCT FILTERS FOR QUERY ANALYSISHOW TO CONFIGURE RUNTIME CHAIN INTERNALSHOW DEAL WITH HIGH CARDINALITY CATEGORICALS WHEN DOING QUERY ANALYSISCUSTOM DOCUMENT LOADERHOW TO USE THE MULTIQUERYRETRIEVERHOW TO ADD SCORES TO RETRIEVER RESULTSCACHINGHOW TO USE CALLBACKS IN ASYNC ENVIRONMENTSHOW TO ATTACH CALLBACKS TO A RUNNABLEHOW TO PROPAGATE CALLBACKS  CONSTRUCTORHOW TO DISPATCH CUSTOM CALLBACK EVENTSHOW TO PASS CALLBACKS IN AT RUNTIMEHOW TO SPLIT BY CHARACTERHOW TO CACHE CHAT MODEL RESPONSESHOW TO HANDLE RATE LIMITSHOW TO INIT ANY MODEL IN ONE LINEHOW TO TRACK TOKEN USAGE IN CHATMODELSHOW TO ADD TOOLS TO CHATBOTSHOW TO SPLIT CODEHOW TO DO RETRIEVAL WITH CONTEXTUAL COMPRESSIONHOW TO CONVERT RUNNABLES TO TOOLSHOW TO CREATE CUSTOM CALLBACK HANDLERSHOW TO CREATE A CUSTOM CHAT MODEL CLASSCUSTOM EMBEDDINGSHOW TO CREATE A CUSTOM LLM CLASSCUSTOM RETRIEVERHOW TO CREATE TOOLSHOW TO DEBUG YOUR LLM APPSHOW TO LOAD CSVSHOW TO LOAD DOCUMENTS FROM A DIRECTORYHOW TO LOAD HTMLHOW TO LOAD JSONHOW TO LOAD MARKDOWNHOW TO LOAD MICROSOFT OFFICE FILESHOW TO LOAD PDFSHOW TO LOAD WEB PAGESHOW TO CREATE A DYNAMIC (SELF-CONSTRUCTING) CHAINTEXT EMBEDDING MODELSHOW TO COMBINE RESULTS FROM MULTIPLE RETRIEVERSHOW TO SELECT EXAMPLES FROM A LANGSMITH DATASETHOW TO SELECT EXAMPLES BY LENGTHHOW TO SELECT EXAMPLES BY MAXIMAL MARGINAL RELEVANCE (MMR)HOW TO SELECT EXAMPLES BY N-GRAM OVERLAPHOW TO SELECT EXAMPLES BY SIMILARITYHOW TO USE REFERENCE EXAMPLES WHEN DOING EXTRACTIONHOW TO HANDLE LONG TEXT WHEN DOING EXTRACTIONHOW TO USE PROMPTING ALONE (NO TOOL CALLING) TO DO EXTRACTIONHOW TO ADD FALLBACKS TO A RUNNABLEHOW TO FILTER MESSAGESHYBRID SEARCHHOW TO USE THE LANGCHAIN INDEXING APIHOW TO INSPECT RUNNABLESLANGCHAIN EXPRESSION LANGUAGE CHEATSHEETHOW TO CACHE LLM RESPONSESHOW TO TRACK TOKEN USAGE FOR LLMSRUN MODELS LOCALLYHOW TO GET LOG PROBABILITIESHOW TO REORDER RETRIEVED RESULTS TO MITIGATE THE \"LOST IN THE MIDDLE\" EFFECTHOW TO SPLIT MARKDOWN BY HEADERSHOW TO MERGE CONSECUTIVE MESSAGES OF THE SAME TYPEHOW TO ADD MESSAGE HISTORYHOW TO MIGRATE FROM LEGACY LANGCHAIN AGENTS TO LANGGRAPHHOW TO RETRIEVE USING MULTIPLE VECTORS PER DOCUMENTHOW TO PASS MULTIMODAL DATA DIRECTLY TO MODELSHOW TO USE MULTIMODAL PROMPTSHOW TO CREATE A CUSTOM OUTPUT PARSERHOW TO USE THE OUTPUT-FIXING PARSERHOW TO PARSE JSON OUTPUTHOW TO RETRY WHEN A PARSING ERROR OCCURSHOW TO PARSE TEXT FROM MESSAGE OBJECTSHOW TO PARSE XML OUTPUTHOW TO PARSE YAML OUTPUTHOW TO USE THE PARENT DOCUMENT RETRIEVERHOW TO USE LANGCHAIN WITH DIFFERENT PYDANTIC VERSIONSHOW TO ADD CHAT HISTORYHOW TO GET A RAG APPLICATION TO ADD CITATIONSHOW TO DO PER-USER RETRIEVALHOW TO GET YOUR RAG APPLICATION TO RETURN SOURCESHOW TO STREAM RESULTS FROM YOUR RAG APPLICATIONHOW TO SPLIT JSON DATAHOW TO RECURSIVELY SPLIT TEXT BY CHARACTERSRESPONSE METADATAHOW TO PASS RUNTIME SECRETS TO RUNNABLESHOW TO DO \"SELF-QUERYING\" RETRIEVALHOW TO SPLIT TEXT BASED ON SEMANTIC SIMILARITYHOW TO CHAIN RUNNABLESHOW TO SAVE AND LOAD LANGCHAIN OBJECTSHOW TO SPLIT TEXT BY TOKENSHOW TO SPLIT HTMLHOW TO DO QUESTION ANSWERING OVER CSVSHOW TO DEAL WITH LARGE DATABASES WHEN DOING SQL QUESTION-ANSWERINGHOW TO BETTER PROMPT WHEN DOING SQL QUESTION-ANSWERINGHOW TO DO QUERY VALIDATION AS PART OF SQL QUESTION-ANSWERINGHOW TO STREAM RUNNABLESHOW TO STREAM RESPONSES FROM AN LLMHOW TO USE A TIME-WEIGHTED VECTOR STORE RETRIEVERHOW TO RETURN ARTIFACTS FROM A TOOLHOW TO USE CHAT MODELS TO CALL TOOLSHOW TO DISABLE PARALLEL TOOL CALLINGHOW TO FORCE MODELS TO CALL A TOOLHOW TO ACCESS THE RUNNABLECONFIG FROM A TOOLHOW TO PASS TOOL OUTPUTS TO CHAT MODELSHOW TO PASS RUN TIME VALUES TO TOOLSHOW TO STREAM EVENTS FROM A TOOLHOW TO STREAM TOOL CALLSHOW TO CONVERT TOOLS TO OPENAI FUNCTIONSHOW TO HANDLE TOOL ERRORSHOW TO USE FEW-SHOT PROMPTING WITH TOOL CALLINGHOW TO ADD A HUMAN-IN-THE-LOOP FOR TOOLSHOW TO BIND MODEL-SPECIFIC TOOLSHOW TO TRIM MESSAGESHOW TO CREATE AND QUERY VECTOR STORESCONCEPTUAL GUIDEAGENTSARCHITECTUREASYNC PROGRAMMING WITH LANGCHAINCALLBACKSCHAT HISTORYCHAT MODELSDOCUMENT LOADERSEMBEDDING MODELSEVALUATIONEXAMPLE SELECTORSFEW-SHOT PROMPTINGCONCEPTUAL GUIDEKEY-VALUE STORESLANGCHAIN EXPRESSION LANGUAGE (LCEL)MESSAGESMULTIMODALITYOUTPUT PARSERSPROMPT TEMPLATESRETRIEVAL AUGMENTED GENERATION (RAG)RETRIEVALRETRIEVERSRUNNABLE INTERFACESTREAMINGSTRUCTURED OUTPUTSTESTINGSTRING-IN, STRING-OUT LLMSTEXT SPLITTERSTOKENSTOOL CALLINGTOOLSTRACINGVECTOR STORESWHY LANGCHAIN?ECOSYSTEM🦜🛠️ LANGSMITH🦜🕸️ LANGGRAPHVERSIONSV0.3V0.2PYDANTIC COMPATIBILITYMIGRATING FROM V0.0 CHAINSHOW TO MIGRATE FROM V0.0 CHAINSMIGRATING FROM CONSTITUTIONALCHAINMIGRATING FROM CONVERSATIONALCHAINMIGRATING FROM CONVERSATIONALRETRIEVALCHAINMIGRATING FROM LLMCHAINMIGRATING FROM LLMMATHCHAINMIGRATING FROM LLMROUTERCHAINMIGRATING FROM MAPREDUCEDOCUMENTSCHAINMIGRATING FROM MAPRERANKDOCUMENTSCHAINMIGRATING FROM MULTIPROMPTCHAINMIGRATING FROM REFINEDOCUMENTSCHAINMIGRATING FROM RETRIEVALQAMIGRATING FROM STUFFDOCUMENTSCHAINUPGRADING TO LANGGRAPH MEMORYHOW TO MIGRATE TO LANGGRAPH MEMORYHOW TO USE BASECHATMESSAGEHISTORY WITH LANGGRAPHMIGRATING OFF CONVERSATIONBUFFERMEMORY OR CONVERSATIONSTRINGBUFFERMEMORYMIGRATING OFF CONVERSATIONBUFFERWINDOWMEMORY OR CONVERSATIONTOKENBUFFERMEMORYMIGRATING OFF CONVERSATIONSUMMARYMEMORY OR CONVERSATIONSUMMARYBUFFERMEMORYA LONG-TERM MEMORY AGENTRELEASE POLICYSECURITY POLICYHOW-TO GUIDESHOW TO CHAIN RUNNABLESON THIS PAGEHOW TO CHAIN RUNNABLES\n",
      "PREREQUISITESTHIS GUIDE ASSUMES FAMILIARITY WITH THE FOLLOWING CONCEPTS:\n",
      "LANGCHAIN EXPRESSION LANGUAGE (LCEL)\n",
      "PROMPT TEMPLATES\n",
      "CHAT MODELS\n",
      "OUTPUT PARSER\n",
      "\n",
      "ONE POINT ABOUT LANGCHAIN EXPRESSION LANGUAGE IS THAT ANY TWO RUNNABLES CAN BE \"CHAINED\" TOGETHER INTO SEQUENCES. THE OUTPUT OF THE PREVIOUS RUNNABLE'S .INVOKE() CALL IS PASSED AS INPUT TO THE NEXT RUNNABLE. THIS CAN BE DONE USING THE PIPE OPERATOR (|), OR THE MORE EXPLICIT .PIPE() METHOD, WHICH DOES THE SAME THING.\n",
      "THE RESULTING RUNNABLESEQUENCE IS ITSELF A RUNNABLE, WHICH MEANS IT CAN BE INVOKED, STREAMED, OR FURTHER CHAINED JUST LIKE ANY OTHER RUNNABLE. ADVANTAGES OF CHAINING RUNNABLES IN THIS WAY ARE EFFICIENT STREAMING (THE SEQUENCE WILL STREAM OUTPUT AS SOON AS IT IS AVAILABLE), AND DEBUGGING AND TRACING WITH TOOLS LIKE LANGSMITH.\n",
      "THE PIPE OPERATOR: |​\n",
      "TO SHOW OFF HOW THIS WORKS, LET'S GO THROUGH AN EXAMPLE. WE'LL WALK THROUGH A COMMON PATTERN IN LANGCHAIN: USING A PROMPT TEMPLATE TO FORMAT INPUT INTO A CHAT MODEL, AND FINALLY CONVERTING THE CHAT MESSAGE OUTPUT INTO A STRING WITH AN OUTPUT PARSER.\n",
      "\n",
      "SELECT CHAT MODEL:GROQ▾GROQOPENAIANTHROPICAZUREGOOGLE VERTEXAWSCOHERENVIDIAFIREWORKS AIMISTRAL AITOGETHER AIIBM WATSONXDATABRICKSXAIPIP INSTALL -QU \"LANGCHAIN[GROQ]\"IMPORT GETPASSIMPORT OSIF NOT OS.ENVIRON.GET(\"GROQ_API_KEY\"):  OS.ENVIRON[\"GROQ_API_KEY\"] = GETPASS.GETPASS(\"ENTER API KEY FOR GROQ: \")FROM LANGCHAIN.CHAT_MODELS IMPORT INIT_CHAT_MODELMODEL = INIT_CHAT_MODEL(\"LLAMA3-8B-8192\", MODEL_PROVIDER=\"GROQ\")\n",
      "FROM LANGCHAIN_CORE.OUTPUT_PARSERS IMPORT STROUTPUTPARSERFROM LANGCHAIN_CORE.PROMPTS IMPORT CHATPROMPTTEMPLATEPROMPT = CHATPROMPTTEMPLATE.FROM_TEMPLATE(\"TELL ME A JOKE ABOUT {TOPIC}\")CHAIN = PROMPT | MODEL | STROUTPUTPARSER()API REFERENCE:STROUTPUTPARSER | CHATPROMPTTEMPLATE\n",
      "PROMPTS AND MODELS ARE BOTH RUNNABLE, AND THE OUTPUT TYPE FROM THE PROMPT CALL IS THE SAME AS THE INPUT TYPE OF THE CHAT MODEL, SO WE CAN CHAIN THEM TOGETHER. WE CAN THEN INVOKE THE RESULTING SEQUENCE LIKE ANY OTHER RUNNABLE:\n",
      "CHAIN.INVOKE({\"TOPIC\": \"BEARS\"})\n",
      "\"HERE'S A BEAR JOKE FOR YOU:\\N\\NWHY DID THE BEAR DISSOLVE IN WATER?\\NBECAUSE IT WAS A POLAR BEAR!\"\n",
      "COERCION​\n",
      "WE CAN EVEN COMBINE THIS CHAIN WITH MORE RUNNABLES TO CREATE ANOTHER CHAIN. THIS MAY INVOLVE SOME INPUT/OUTPUT FORMATTING USING OTHER TYPES OF RUNNABLES, DEPENDING ON THE REQUIRED INPUTS AND OUTPUTS OF THE CHAIN COMPONENTS.\n",
      "FOR EXAMPLE, LET'S SAY WE WANTED TO COMPOSE THE JOKE GENERATING CHAIN WITH ANOTHER CHAIN THAT EVALUATES WHETHER OR NOT THE GENERATED JOKE WAS FUNNY.\n",
      "WE WOULD NEED TO BE CAREFUL WITH HOW WE FORMAT THE INPUT INTO THE NEXT CHAIN. IN THE BELOW EXAMPLE, THE DICT IN THE CHAIN IS AUTOMATICALLY PARSED AND CONVERTED INTO A RUNNABLEPARALLEL, WHICH RUNS ALL OF ITS VALUES IN PARALLEL AND RETURNS A DICT WITH THE RESULTS.\n",
      "THIS HAPPENS TO BE THE SAME FORMAT THE NEXT PROMPT TEMPLATE EXPECTS. HERE IT IS IN ACTION:\n",
      "FROM LANGCHAIN_CORE.OUTPUT_PARSERS IMPORT STROUTPUTPARSERANALYSIS_PROMPT = CHATPROMPTTEMPLATE.FROM_TEMPLATE(\"IS THIS A FUNNY JOKE? {JOKE}\")COMPOSED_CHAIN = {\"JOKE\": CHAIN} | ANALYSIS_PROMPT | MODEL | STROUTPUTPARSER()COMPOSED_CHAIN.INVOKE({\"TOPIC\": \"BEARS\"})API REFERENCE:STROUTPUTPARSER\n",
      "'HAHA, THAT\\'S A CLEVER PLAY ON WORDS! USING \"POLAR\" TO IMPLY THE BEAR DISSOLVED OR BECAME POLAR/POLARIZED WHEN PUT IN WATER. NOT THE MOST HILARIOUS JOKE EVER, BUT IT HAS A CUTE, GROAN-WORTHY PUN THAT MAKES IT MILDLY AMUSING. I APPRECIATE A GOOD PUN OR WORDPLAY JOKE.'\n",
      "FUNCTIONS WILL ALSO BE COERCED INTO RUNNABLES, SO YOU CAN ADD CUSTOM LOGIC TO YOUR CHAINS TOO. THE BELOW CHAIN RESULTS IN THE SAME LOGICAL FLOW AS BEFORE:\n",
      "COMPOSED_CHAIN_WITH_LAMBDA = (    CHAIN    | (LAMBDA INPUT: {\"JOKE\": INPUT})    | ANALYSIS_PROMPT    | MODEL    | STROUTPUTPARSER())COMPOSED_CHAIN_WITH_LAMBDA.INVOKE({\"TOPIC\": \"BEETS\"})\n",
      "\"HAHA, THAT'S A CUTE AND PUNNY JOKE! I LIKE HOW IT PLAYS ON THE IDEA OF BEETS BLUSHING OR TURNING RED LIKE SOMEONE BLUSHING. FOOD PUNS CAN BE QUITE AMUSING. WHILE NOT A TOTAL KNEE-SLAPPER, IT'S A LIGHT-HEARTED, GROAN-WORTHY DAD JOKE THAT WOULD MAKE ME CHUCKLE AND SHAKE MY HEAD. SIMPLE VEGETABLE HUMOR!\"\n",
      "HOWEVER, KEEP IN MIND THAT USING FUNCTIONS LIKE THIS MAY INTERFERE WITH OPERATIONS LIKE STREAMING. SEE THIS SECTION FOR MORE INFORMATION.\n",
      "THE .PIPE() METHOD​\n",
      "WE COULD ALSO COMPOSE THE SAME SEQUENCE USING THE .PIPE() METHOD. HERE'S WHAT THAT LOOKS LIKE:\n",
      "FROM LANGCHAIN_CORE.RUNNABLES IMPORT RUNNABLEPARALLELCOMPOSED_CHAIN_WITH_PIPE = (    RUNNABLEPARALLEL({\"JOKE\": CHAIN})    .PIPE(ANALYSIS_PROMPT)    .PIPE(MODEL)    .PIPE(STROUTPUTPARSER()))COMPOSED_CHAIN_WITH_PIPE.INVOKE({\"TOPIC\": \"BATTLESTAR GALACTICA\"})API REFERENCE:RUNNABLEPARALLEL\n",
      "\"I CANNOT REPRODUCE ANY COPYRIGHTED MATERIAL VERBATIM, BUT I CAN TRY TO ANALYZE THE HUMOR IN THE JOKE YOU PROVIDED WITHOUT QUOTING IT DIRECTLY.\\N\\NTHE JOKE PLAYS ON THE IDEA THAT THE CYLON RAIDERS, WHO ARE THE ANTAGONISTS IN THE BATTLESTAR GALACTICA UNIVERSE, FAILED TO LOCATE THE HUMAN SURVIVORS AFTER ATTACKING THEIR HOME PLANETS (THE TWELVE COLONIES) DUE TO USING AN OUTDATED AND POORLY PERFORMING OPERATING SYSTEM (WINDOWS VISTA) FOR THEIR TARGETING SYSTEMS.\\N\\NTHE HUMOR STEMS FROM THE JUXTAPOSITION OF A FUTURISTIC SCIENCE FICTION SETTING WITH A RELATABLE REAL-WORLD FRUSTRATION – THE USE OF BUGGY, SLOW, OR UNRELIABLE SOFTWARE OR TECHNOLOGY. IT POKES FUN AT THE PERCEIVED INADEQUACIES OF WINDOWS VISTA, WHICH WAS WIDELY CRITICIZED FOR ITS PERFORMANCE ISSUES AND OTHER PROBLEMS WHEN IT WAS RELEASED.\\N\\NBY ATTRIBUTING THE CYLONS' FAILURE TO LOCATE THE HUMANS TO THEIR USE OF VISTA, THE JOKE CREATES AN AMUSING AND UNEXPECTED CONNECTION BETWEEN A FICTIONAL ADVANCED RACE OF ROBOTS AND A FAMILIAR TECHNOLOGICAL ANNOYANCE EXPERIENCED BY MANY PEOPLE IN THE REAL WORLD.\\N\\NOVERALL, THE JOKE RELIES ON INCONGRUITY AND RELATABILITY TO GENERATE HUMOR, BUT WITHOUT REPRODUCING ANY COPYRIGHTED MATERIAL DIRECTLY.\"\n",
      "OR THE ABBREVIATED:\n",
      "COMPOSED_CHAIN_WITH_PIPE = RUNNABLEPARALLEL({\"JOKE\": CHAIN}).PIPE(    ANALYSIS_PROMPT, MODEL, STROUTPUTPARSER())\n",
      "RELATED​\n",
      "\n",
      "STREAMING: CHECK OUT THE STREAMING GUIDE TO UNDERSTAND THE STREAMING BEHAVIOR OF A CHAIN\n",
      "EDIT THIS PAGEWAS THIS PAGE HELPFUL?PREVIOUSHOW TO SPLIT TEXT BASED ON SEMANTIC SIMILARITYNEXTHOW TO SAVE AND LOAD LANGCHAIN OBJECTSTHE PIPE OPERATOR: |COERCIONTHE .PIPE() METHODRELATEDCOMMUNITYTWITTERGITHUBORGANIZATIONPYTHONJS/TSMOREHOMEPAGEBLOGYOUTUBECOPYRIGHT © 2025 LANGCHAIN, INC.\n",
      "\n",
      "\n",
      "          -------\n",
      "\n",
      "          THE PREVIOUS CODE ATTEMPT FAILED WITH THE FOLLOWING ERROR:\n",
      "          INVALID INPUT TYPE <CLASS 'DICT'>. MUST BE A PROMPTVALUE, STR, OR LIST OF BASEMESSAGES.\n",
      "\n",
      "          YOUR CODING TASK:\n",
      "          HOW DO I BUILD A RAG CHAIN IN LCEL?\n",
      "\n",
      "          PREVIOUS CODE ATTEMPT:\n",
      "          TO BUILD A RETRIEVAL AUGMENTED GENERATION (RAG) CHAIN IN LCEL, YOU WILL NEED TO SET UP A PROMPT THAT RETRIEVES INFORMATION, PASS IT THROUGH A CHAT MODEL, AND FORMAT THE OUTPUTS. THIS TYPICALLY INVOLVES USING A PROMPT TEMPLATE, AN LLM OR CHAT MODEL, AND AN OUTPUT PARSER.\n",
      "          FROM LANGCHAIN_CORE.PROMPTS IMPORT CHATPROMPTTEMPLATE\n",
      "FROM LANGCHAIN.CHAT_MODELS IMPORT INIT_CHAT_MODEL\n",
      "FROM LANGCHAIN_CORE.OUTPUT_PARSERS IMPORT STROUTPUTPARSER\n",
      "FROM LANGCHAIN_CORE.RUNNABLES IMPORT RUNNABLEPARALLEL\n",
      "          PROMPT = CHATPROMPTTEMPLATE.FROM_TEMPLATE(\"RETRIEVE INFORMATION ABOUT {QUERY}\")\n",
      "MODEL = INIT_CHAT_MODEL(\"LLAMA3-8B-8192\", MODEL_PROVIDER=\"GROQ\")\n",
      "RETRIEVER_CHAIN = PROMPT | MODEL | STROUTPUTPARSER()\n",
      "RETRIEVAL_AUGMENTED_CHAIN = {\"RETRIEVED_INFO\": RETRIEVER_CHAIN} | MODEL | STROUTPUTPARSER()\n",
      "RESPONSE = RETRIEVAL_AUGMENTED_CHAIN.INVOKE({\"QUERY\": \"QUANTUM COMPUTING\"})\n",
      "PRINT(RESPONSE)\n",
      "\n",
      "          ANSWER WITH A DESCRIPTION OF THE CODE SOLUTION, FOLLOWED BY THE IMPORTS, AND FINALLY THE FUNCTIONING CODE BLOCK.\n",
      "          ENSURE ALL IMPORTS ARE CORRECT AND THE CODE IS EXECUTABLE.]: 2025-03-13 15:36:58.132937\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:36:58][🤖 AGENT 'CODING ASSISTANT' STARTED TASK]: 2025-03-13 15:36:58.133661\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:36:58][🤖 LLM CALL STARTED]: 2025-03-13 15:36:58.133795\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:01][✅ LLM CALL COMPLETED]: 2025-03-13 15:37:01.606939\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:01][✅ AGENT 'CODING ASSISTANT' COMPLETED TASK]: 2025-03-13 15:37:01.608105\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:01][✅ TASK COMPLETED: YOU ARE A CODING ASSISTANT WITH EXPERTISE IN LCEL, LANGCHAIN EXPRESSION LANGUAGE.\n",
      "          HERE IS A FULL SET OF LCEL DOCUMENTATION:\n",
      "          -------\n",
      "          \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "HOW TO CHAIN RUNNABLES | 🦜️🔗 LANGCHAIN\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "SKIP TO MAIN CONTENTJOIN US AT  INTERRUPT: THE AGENT AI CONFERENCE BY LANGCHAIN ON MAY 13 & 14 IN SAN FRANCISCO!INTEGRATIONSAPI REFERENCEMORECONTRIBUTINGPEOPLEERROR REFERENCELANGSMITHLANGGRAPHLANGCHAIN HUBLANGCHAIN JS/TSV0.3V0.3V0.2V0.1💬SEARCHINTRODUCTIONTUTORIALSBUILD A QUESTION ANSWERING APPLICATION OVER A GRAPH DATABASETUTORIALSBUILD A SIMPLE LLM APPLICATION WITH CHAT MODELS AND PROMPT TEMPLATESBUILD A CHATBOTBUILD A RETRIEVAL AUGMENTED GENERATION (RAG) APP: PART 2BUILD AN EXTRACTION CHAINBUILD AN AGENTTAGGINGBUILD A RETRIEVAL AUGMENTED GENERATION (RAG) APP: PART 1BUILD A SEMANTIC SEARCH ENGINEBUILD A QUESTION/ANSWERING SYSTEM OVER SQL DATASUMMARIZE TEXTHOW-TO GUIDESHOW-TO GUIDESHOW TO USE TOOLS IN A CHAINHOW TO USE A VECTORSTORE AS A RETRIEVERHOW TO ADD MEMORY TO CHATBOTSHOW TO USE EXAMPLE SELECTORSHOW TO ADD A SEMANTIC LAYER OVER GRAPH DATABASEHOW TO INVOKE RUNNABLES IN PARALLELHOW TO STREAM CHAT MODEL RESPONSESHOW TO ADD DEFAULT INVOCATION ARGS TO A RUNNABLEHOW TO ADD RETRIEVAL TO CHATBOTSHOW TO USE FEW SHOT EXAMPLES IN CHAT MODELSHOW TO DO TOOL/FUNCTION CALLINGHOW TO INSTALL LANGCHAIN PACKAGESHOW TO ADD EXAMPLES TO THE PROMPT FOR QUERY ANALYSISHOW TO USE FEW SHOT EXAMPLESHOW TO RUN CUSTOM FUNCTIONSHOW TO USE OUTPUT PARSERS TO PARSE AN LLM RESPONSE INTO STRUCTURED FORMATHOW TO HANDLE CASES WHERE NO QUERIES ARE GENERATEDHOW TO ROUTE BETWEEN SUB-CHAINSHOW TO RETURN STRUCTURED DATA FROM A MODELHOW TO SUMMARIZE TEXT THROUGH PARALLELIZATIONHOW TO SUMMARIZE TEXT THROUGH ITERATIVE REFINEMENTHOW TO SUMMARIZE TEXT IN A SINGLE LLM CALLHOW TO USE TOOLKITSHOW TO ADD AD-HOC TOOL CALLING CAPABILITY TO LLMS AND CHAT MODELSBUILD AN AGENT WITH AGENTEXECUTOR (LEGACY)HOW TO CONSTRUCT KNOWLEDGE GRAPHSHOW TO PARTIALLY FORMAT PROMPT TEMPLATESHOW TO HANDLE MULTIPLE QUERIES WHEN DOING QUERY ANALYSISHOW TO USE BUILT-IN TOOLS AND TOOLKITSHOW TO PASS THROUGH ARGUMENTS FROM ONE STEP TO THE NEXTHOW TO COMPOSE PROMPTS TOGETHERHOW TO HANDLE MULTIPLE RETRIEVERS WHEN DOING QUERY ANALYSISHOW TO ADD VALUES TO A CHAIN'S STATEHOW TO CONSTRUCT FILTERS FOR QUERY ANALYSISHOW TO CONFIGURE RUNTIME CHAIN INTERNALSHOW DEAL WITH HIGH CARDINALITY CATEGORICALS WHEN DOING QUERY ANALYSISCUSTOM DOCUMENT LOADERHOW TO USE THE MULTIQUERYRETRIEVERHOW TO ADD SCORES TO RETRIEVER RESULTSCACHINGHOW TO USE CALLBACKS IN ASYNC ENVIRONMENTSHOW TO ATTACH CALLBACKS TO A RUNNABLEHOW TO PROPAGATE CALLBACKS  CONSTRUCTORHOW TO DISPATCH CUSTOM CALLBACK EVENTSHOW TO PASS CALLBACKS IN AT RUNTIMEHOW TO SPLIT BY CHARACTERHOW TO CACHE CHAT MODEL RESPONSESHOW TO HANDLE RATE LIMITSHOW TO INIT ANY MODEL IN ONE LINEHOW TO TRACK TOKEN USAGE IN CHATMODELSHOW TO ADD TOOLS TO CHATBOTSHOW TO SPLIT CODEHOW TO DO RETRIEVAL WITH CONTEXTUAL COMPRESSIONHOW TO CONVERT RUNNABLES TO TOOLSHOW TO CREATE CUSTOM CALLBACK HANDLERSHOW TO CREATE A CUSTOM CHAT MODEL CLASSCUSTOM EMBEDDINGSHOW TO CREATE A CUSTOM LLM CLASSCUSTOM RETRIEVERHOW TO CREATE TOOLSHOW TO DEBUG YOUR LLM APPSHOW TO LOAD CSVSHOW TO LOAD DOCUMENTS FROM A DIRECTORYHOW TO LOAD HTMLHOW TO LOAD JSONHOW TO LOAD MARKDOWNHOW TO LOAD MICROSOFT OFFICE FILESHOW TO LOAD PDFSHOW TO LOAD WEB PAGESHOW TO CREATE A DYNAMIC (SELF-CONSTRUCTING) CHAINTEXT EMBEDDING MODELSHOW TO COMBINE RESULTS FROM MULTIPLE RETRIEVERSHOW TO SELECT EXAMPLES FROM A LANGSMITH DATASETHOW TO SELECT EXAMPLES BY LENGTHHOW TO SELECT EXAMPLES BY MAXIMAL MARGINAL RELEVANCE (MMR)HOW TO SELECT EXAMPLES BY N-GRAM OVERLAPHOW TO SELECT EXAMPLES BY SIMILARITYHOW TO USE REFERENCE EXAMPLES WHEN DOING EXTRACTIONHOW TO HANDLE LONG TEXT WHEN DOING EXTRACTIONHOW TO USE PROMPTING ALONE (NO TOOL CALLING) TO DO EXTRACTIONHOW TO ADD FALLBACKS TO A RUNNABLEHOW TO FILTER MESSAGESHYBRID SEARCHHOW TO USE THE LANGCHAIN INDEXING APIHOW TO INSPECT RUNNABLESLANGCHAIN EXPRESSION LANGUAGE CHEATSHEETHOW TO CACHE LLM RESPONSESHOW TO TRACK TOKEN USAGE FOR LLMSRUN MODELS LOCALLYHOW TO GET LOG PROBABILITIESHOW TO REORDER RETRIEVED RESULTS TO MITIGATE THE \"LOST IN THE MIDDLE\" EFFECTHOW TO SPLIT MARKDOWN BY HEADERSHOW TO MERGE CONSECUTIVE MESSAGES OF THE SAME TYPEHOW TO ADD MESSAGE HISTORYHOW TO MIGRATE FROM LEGACY LANGCHAIN AGENTS TO LANGGRAPHHOW TO RETRIEVE USING MULTIPLE VECTORS PER DOCUMENTHOW TO PASS MULTIMODAL DATA DIRECTLY TO MODELSHOW TO USE MULTIMODAL PROMPTSHOW TO CREATE A CUSTOM OUTPUT PARSERHOW TO USE THE OUTPUT-FIXING PARSERHOW TO PARSE JSON OUTPUTHOW TO RETRY WHEN A PARSING ERROR OCCURSHOW TO PARSE TEXT FROM MESSAGE OBJECTSHOW TO PARSE XML OUTPUTHOW TO PARSE YAML OUTPUTHOW TO USE THE PARENT DOCUMENT RETRIEVERHOW TO USE LANGCHAIN WITH DIFFERENT PYDANTIC VERSIONSHOW TO ADD CHAT HISTORYHOW TO GET A RAG APPLICATION TO ADD CITATIONSHOW TO DO PER-USER RETRIEVALHOW TO GET YOUR RAG APPLICATION TO RETURN SOURCESHOW TO STREAM RESULTS FROM YOUR RAG APPLICATIONHOW TO SPLIT JSON DATAHOW TO RECURSIVELY SPLIT TEXT BY CHARACTERSRESPONSE METADATAHOW TO PASS RUNTIME SECRETS TO RUNNABLESHOW TO DO \"SELF-QUERYING\" RETRIEVALHOW TO SPLIT TEXT BASED ON SEMANTIC SIMILARITYHOW TO CHAIN RUNNABLESHOW TO SAVE AND LOAD LANGCHAIN OBJECTSHOW TO SPLIT TEXT BY TOKENSHOW TO SPLIT HTMLHOW TO DO QUESTION ANSWERING OVER CSVSHOW TO DEAL WITH LARGE DATABASES WHEN DOING SQL QUESTION-ANSWERINGHOW TO BETTER PROMPT WHEN DOING SQL QUESTION-ANSWERINGHOW TO DO QUERY VALIDATION AS PART OF SQL QUESTION-ANSWERINGHOW TO STREAM RUNNABLESHOW TO STREAM RESPONSES FROM AN LLMHOW TO USE A TIME-WEIGHTED VECTOR STORE RETRIEVERHOW TO RETURN ARTIFACTS FROM A TOOLHOW TO USE CHAT MODELS TO CALL TOOLSHOW TO DISABLE PARALLEL TOOL CALLINGHOW TO FORCE MODELS TO CALL A TOOLHOW TO ACCESS THE RUNNABLECONFIG FROM A TOOLHOW TO PASS TOOL OUTPUTS TO CHAT MODELSHOW TO PASS RUN TIME VALUES TO TOOLSHOW TO STREAM EVENTS FROM A TOOLHOW TO STREAM TOOL CALLSHOW TO CONVERT TOOLS TO OPENAI FUNCTIONSHOW TO HANDLE TOOL ERRORSHOW TO USE FEW-SHOT PROMPTING WITH TOOL CALLINGHOW TO ADD A HUMAN-IN-THE-LOOP FOR TOOLSHOW TO BIND MODEL-SPECIFIC TOOLSHOW TO TRIM MESSAGESHOW TO CREATE AND QUERY VECTOR STORESCONCEPTUAL GUIDEAGENTSARCHITECTUREASYNC PROGRAMMING WITH LANGCHAINCALLBACKSCHAT HISTORYCHAT MODELSDOCUMENT LOADERSEMBEDDING MODELSEVALUATIONEXAMPLE SELECTORSFEW-SHOT PROMPTINGCONCEPTUAL GUIDEKEY-VALUE STORESLANGCHAIN EXPRESSION LANGUAGE (LCEL)MESSAGESMULTIMODALITYOUTPUT PARSERSPROMPT TEMPLATESRETRIEVAL AUGMENTED GENERATION (RAG)RETRIEVALRETRIEVERSRUNNABLE INTERFACESTREAMINGSTRUCTURED OUTPUTSTESTINGSTRING-IN, STRING-OUT LLMSTEXT SPLITTERSTOKENSTOOL CALLINGTOOLSTRACINGVECTOR STORESWHY LANGCHAIN?ECOSYSTEM🦜🛠️ LANGSMITH🦜🕸️ LANGGRAPHVERSIONSV0.3V0.2PYDANTIC COMPATIBILITYMIGRATING FROM V0.0 CHAINSHOW TO MIGRATE FROM V0.0 CHAINSMIGRATING FROM CONSTITUTIONALCHAINMIGRATING FROM CONVERSATIONALCHAINMIGRATING FROM CONVERSATIONALRETRIEVALCHAINMIGRATING FROM LLMCHAINMIGRATING FROM LLMMATHCHAINMIGRATING FROM LLMROUTERCHAINMIGRATING FROM MAPREDUCEDOCUMENTSCHAINMIGRATING FROM MAPRERANKDOCUMENTSCHAINMIGRATING FROM MULTIPROMPTCHAINMIGRATING FROM REFINEDOCUMENTSCHAINMIGRATING FROM RETRIEVALQAMIGRATING FROM STUFFDOCUMENTSCHAINUPGRADING TO LANGGRAPH MEMORYHOW TO MIGRATE TO LANGGRAPH MEMORYHOW TO USE BASECHATMESSAGEHISTORY WITH LANGGRAPHMIGRATING OFF CONVERSATIONBUFFERMEMORY OR CONVERSATIONSTRINGBUFFERMEMORYMIGRATING OFF CONVERSATIONBUFFERWINDOWMEMORY OR CONVERSATIONTOKENBUFFERMEMORYMIGRATING OFF CONVERSATIONSUMMARYMEMORY OR CONVERSATIONSUMMARYBUFFERMEMORYA LONG-TERM MEMORY AGENTRELEASE POLICYSECURITY POLICYHOW-TO GUIDESHOW TO CHAIN RUNNABLESON THIS PAGEHOW TO CHAIN RUNNABLES\n",
      "PREREQUISITESTHIS GUIDE ASSUMES FAMILIARITY WITH THE FOLLOWING CONCEPTS:\n",
      "LANGCHAIN EXPRESSION LANGUAGE (LCEL)\n",
      "PROMPT TEMPLATES\n",
      "CHAT MODELS\n",
      "OUTPUT PARSER\n",
      "\n",
      "ONE POINT ABOUT LANGCHAIN EXPRESSION LANGUAGE IS THAT ANY TWO RUNNABLES CAN BE \"CHAINED\" TOGETHER INTO SEQUENCES. THE OUTPUT OF THE PREVIOUS RUNNABLE'S .INVOKE() CALL IS PASSED AS INPUT TO THE NEXT RUNNABLE. THIS CAN BE DONE USING THE PIPE OPERATOR (|), OR THE MORE EXPLICIT .PIPE() METHOD, WHICH DOES THE SAME THING.\n",
      "THE RESULTING RUNNABLESEQUENCE IS ITSELF A RUNNABLE, WHICH MEANS IT CAN BE INVOKED, STREAMED, OR FURTHER CHAINED JUST LIKE ANY OTHER RUNNABLE. ADVANTAGES OF CHAINING RUNNABLES IN THIS WAY ARE EFFICIENT STREAMING (THE SEQUENCE WILL STREAM OUTPUT AS SOON AS IT IS AVAILABLE), AND DEBUGGING AND TRACING WITH TOOLS LIKE LANGSMITH.\n",
      "THE PIPE OPERATOR: |​\n",
      "TO SHOW OFF HOW THIS WORKS, LET'S GO THROUGH AN EXAMPLE. WE'LL WALK THROUGH A COMMON PATTERN IN LANGCHAIN: USING A PROMPT TEMPLATE TO FORMAT INPUT INTO A CHAT MODEL, AND FINALLY CONVERTING THE CHAT MESSAGE OUTPUT INTO A STRING WITH AN OUTPUT PARSER.\n",
      "\n",
      "SELECT CHAT MODEL:GROQ▾GROQOPENAIANTHROPICAZUREGOOGLE VERTEXAWSCOHERENVIDIAFIREWORKS AIMISTRAL AITOGETHER AIIBM WATSONXDATABRICKSXAIPIP INSTALL -QU \"LANGCHAIN[GROQ]\"IMPORT GETPASSIMPORT OSIF NOT OS.ENVIRON.GET(\"GROQ_API_KEY\"):  OS.ENVIRON[\"GROQ_API_KEY\"] = GETPASS.GETPASS(\"ENTER API KEY FOR GROQ: \")FROM LANGCHAIN.CHAT_MODELS IMPORT INIT_CHAT_MODELMODEL = INIT_CHAT_MODEL(\"LLAMA3-8B-8192\", MODEL_PROVIDER=\"GROQ\")\n",
      "FROM LANGCHAIN_CORE.OUTPUT_PARSERS IMPORT STROUTPUTPARSERFROM LANGCHAIN_CORE.PROMPTS IMPORT CHATPROMPTTEMPLATEPROMPT = CHATPROMPTTEMPLATE.FROM_TEMPLATE(\"TELL ME A JOKE ABOUT {TOPIC}\")CHAIN = PROMPT | MODEL | STROUTPUTPARSER()API REFERENCE:STROUTPUTPARSER | CHATPROMPTTEMPLATE\n",
      "PROMPTS AND MODELS ARE BOTH RUNNABLE, AND THE OUTPUT TYPE FROM THE PROMPT CALL IS THE SAME AS THE INPUT TYPE OF THE CHAT MODEL, SO WE CAN CHAIN THEM TOGETHER. WE CAN THEN INVOKE THE RESULTING SEQUENCE LIKE ANY OTHER RUNNABLE:\n",
      "CHAIN.INVOKE({\"TOPIC\": \"BEARS\"})\n",
      "\"HERE'S A BEAR JOKE FOR YOU:\\N\\NWHY DID THE BEAR DISSOLVE IN WATER?\\NBECAUSE IT WAS A POLAR BEAR!\"\n",
      "COERCION​\n",
      "WE CAN EVEN COMBINE THIS CHAIN WITH MORE RUNNABLES TO CREATE ANOTHER CHAIN. THIS MAY INVOLVE SOME INPUT/OUTPUT FORMATTING USING OTHER TYPES OF RUNNABLES, DEPENDING ON THE REQUIRED INPUTS AND OUTPUTS OF THE CHAIN COMPONENTS.\n",
      "FOR EXAMPLE, LET'S SAY WE WANTED TO COMPOSE THE JOKE GENERATING CHAIN WITH ANOTHER CHAIN THAT EVALUATES WHETHER OR NOT THE GENERATED JOKE WAS FUNNY.\n",
      "WE WOULD NEED TO BE CAREFUL WITH HOW WE FORMAT THE INPUT INTO THE NEXT CHAIN. IN THE BELOW EXAMPLE, THE DICT IN THE CHAIN IS AUTOMATICALLY PARSED AND CONVERTED INTO A RUNNABLEPARALLEL, WHICH RUNS ALL OF ITS VALUES IN PARALLEL AND RETURNS A DICT WITH THE RESULTS.\n",
      "THIS HAPPENS TO BE THE SAME FORMAT THE NEXT PROMPT TEMPLATE EXPECTS. HERE IT IS IN ACTION:\n",
      "FROM LANGCHAIN_CORE.OUTPUT_PARSERS IMPORT STROUTPUTPARSERANALYSIS_PROMPT = CHATPROMPTTEMPLATE.FROM_TEMPLATE(\"IS THIS A FUNNY JOKE? {JOKE}\")COMPOSED_CHAIN = {\"JOKE\": CHAIN} | ANALYSIS_PROMPT | MODEL | STROUTPUTPARSER()COMPOSED_CHAIN.INVOKE({\"TOPIC\": \"BEARS\"})API REFERENCE:STROUTPUTPARSER\n",
      "'HAHA, THAT\\'S A CLEVER PLAY ON WORDS! USING \"POLAR\" TO IMPLY THE BEAR DISSOLVED OR BECAME POLAR/POLARIZED WHEN PUT IN WATER. NOT THE MOST HILARIOUS JOKE EVER, BUT IT HAS A CUTE, GROAN-WORTHY PUN THAT MAKES IT MILDLY AMUSING. I APPRECIATE A GOOD PUN OR WORDPLAY JOKE.'\n",
      "FUNCTIONS WILL ALSO BE COERCED INTO RUNNABLES, SO YOU CAN ADD CUSTOM LOGIC TO YOUR CHAINS TOO. THE BELOW CHAIN RESULTS IN THE SAME LOGICAL FLOW AS BEFORE:\n",
      "COMPOSED_CHAIN_WITH_LAMBDA = (    CHAIN    | (LAMBDA INPUT: {\"JOKE\": INPUT})    | ANALYSIS_PROMPT    | MODEL    | STROUTPUTPARSER())COMPOSED_CHAIN_WITH_LAMBDA.INVOKE({\"TOPIC\": \"BEETS\"})\n",
      "\"HAHA, THAT'S A CUTE AND PUNNY JOKE! I LIKE HOW IT PLAYS ON THE IDEA OF BEETS BLUSHING OR TURNING RED LIKE SOMEONE BLUSHING. FOOD PUNS CAN BE QUITE AMUSING. WHILE NOT A TOTAL KNEE-SLAPPER, IT'S A LIGHT-HEARTED, GROAN-WORTHY DAD JOKE THAT WOULD MAKE ME CHUCKLE AND SHAKE MY HEAD. SIMPLE VEGETABLE HUMOR!\"\n",
      "HOWEVER, KEEP IN MIND THAT USING FUNCTIONS LIKE THIS MAY INTERFERE WITH OPERATIONS LIKE STREAMING. SEE THIS SECTION FOR MORE INFORMATION.\n",
      "THE .PIPE() METHOD​\n",
      "WE COULD ALSO COMPOSE THE SAME SEQUENCE USING THE .PIPE() METHOD. HERE'S WHAT THAT LOOKS LIKE:\n",
      "FROM LANGCHAIN_CORE.RUNNABLES IMPORT RUNNABLEPARALLELCOMPOSED_CHAIN_WITH_PIPE = (    RUNNABLEPARALLEL({\"JOKE\": CHAIN})    .PIPE(ANALYSIS_PROMPT)    .PIPE(MODEL)    .PIPE(STROUTPUTPARSER()))COMPOSED_CHAIN_WITH_PIPE.INVOKE({\"TOPIC\": \"BATTLESTAR GALACTICA\"})API REFERENCE:RUNNABLEPARALLEL\n",
      "\"I CANNOT REPRODUCE ANY COPYRIGHTED MATERIAL VERBATIM, BUT I CAN TRY TO ANALYZE THE HUMOR IN THE JOKE YOU PROVIDED WITHOUT QUOTING IT DIRECTLY.\\N\\NTHE JOKE PLAYS ON THE IDEA THAT THE CYLON RAIDERS, WHO ARE THE ANTAGONISTS IN THE BATTLESTAR GALACTICA UNIVERSE, FAILED TO LOCATE THE HUMAN SURVIVORS AFTER ATTACKING THEIR HOME PLANETS (THE TWELVE COLONIES) DUE TO USING AN OUTDATED AND POORLY PERFORMING OPERATING SYSTEM (WINDOWS VISTA) FOR THEIR TARGETING SYSTEMS.\\N\\NTHE HUMOR STEMS FROM THE JUXTAPOSITION OF A FUTURISTIC SCIENCE FICTION SETTING WITH A RELATABLE REAL-WORLD FRUSTRATION – THE USE OF BUGGY, SLOW, OR UNRELIABLE SOFTWARE OR TECHNOLOGY. IT POKES FUN AT THE PERCEIVED INADEQUACIES OF WINDOWS VISTA, WHICH WAS WIDELY CRITICIZED FOR ITS PERFORMANCE ISSUES AND OTHER PROBLEMS WHEN IT WAS RELEASED.\\N\\NBY ATTRIBUTING THE CYLONS' FAILURE TO LOCATE THE HUMANS TO THEIR USE OF VISTA, THE JOKE CREATES AN AMUSING AND UNEXPECTED CONNECTION BETWEEN A FICTIONAL ADVANCED RACE OF ROBOTS AND A FAMILIAR TECHNOLOGICAL ANNOYANCE EXPERIENCED BY MANY PEOPLE IN THE REAL WORLD.\\N\\NOVERALL, THE JOKE RELIES ON INCONGRUITY AND RELATABILITY TO GENERATE HUMOR, BUT WITHOUT REPRODUCING ANY COPYRIGHTED MATERIAL DIRECTLY.\"\n",
      "OR THE ABBREVIATED:\n",
      "COMPOSED_CHAIN_WITH_PIPE = RUNNABLEPARALLEL({\"JOKE\": CHAIN}).PIPE(    ANALYSIS_PROMPT, MODEL, STROUTPUTPARSER())\n",
      "RELATED​\n",
      "\n",
      "STREAMING: CHECK OUT THE STREAMING GUIDE TO UNDERSTAND THE STREAMING BEHAVIOR OF A CHAIN\n",
      "EDIT THIS PAGEWAS THIS PAGE HELPFUL?PREVIOUSHOW TO SPLIT TEXT BASED ON SEMANTIC SIMILARITYNEXTHOW TO SAVE AND LOAD LANGCHAIN OBJECTSTHE PIPE OPERATOR: |COERCIONTHE .PIPE() METHODRELATEDCOMMUNITYTWITTERGITHUBORGANIZATIONPYTHONJS/TSMOREHOMEPAGEBLOGYOUTUBECOPYRIGHT © 2025 LANGCHAIN, INC.\n",
      "\n",
      "\n",
      "          -------\n",
      "\n",
      "          THE PREVIOUS CODE ATTEMPT FAILED WITH THE FOLLOWING ERROR:\n",
      "          INVALID INPUT TYPE <CLASS 'DICT'>. MUST BE A PROMPTVALUE, STR, OR LIST OF BASEMESSAGES.\n",
      "\n",
      "          YOUR CODING TASK:\n",
      "          HOW DO I BUILD A RAG CHAIN IN LCEL?\n",
      "\n",
      "          PREVIOUS CODE ATTEMPT:\n",
      "          TO BUILD A RETRIEVAL AUGMENTED GENERATION (RAG) CHAIN IN LCEL, YOU WILL NEED TO SET UP A PROMPT THAT RETRIEVES INFORMATION, PASS IT THROUGH A CHAT MODEL, AND FORMAT THE OUTPUTS. THIS TYPICALLY INVOLVES USING A PROMPT TEMPLATE, AN LLM OR CHAT MODEL, AND AN OUTPUT PARSER.\n",
      "          FROM LANGCHAIN_CORE.PROMPTS IMPORT CHATPROMPTTEMPLATE\n",
      "FROM LANGCHAIN.CHAT_MODELS IMPORT INIT_CHAT_MODEL\n",
      "FROM LANGCHAIN_CORE.OUTPUT_PARSERS IMPORT STROUTPUTPARSER\n",
      "FROM LANGCHAIN_CORE.RUNNABLES IMPORT RUNNABLEPARALLEL\n",
      "          PROMPT = CHATPROMPTTEMPLATE.FROM_TEMPLATE(\"RETRIEVE INFORMATION ABOUT {QUERY}\")\n",
      "MODEL = INIT_CHAT_MODEL(\"LLAMA3-8B-8192\", MODEL_PROVIDER=\"GROQ\")\n",
      "RETRIEVER_CHAIN = PROMPT | MODEL | STROUTPUTPARSER()\n",
      "RETRIEVAL_AUGMENTED_CHAIN = {\"RETRIEVED_INFO\": RETRIEVER_CHAIN} | MODEL | STROUTPUTPARSER()\n",
      "RESPONSE = RETRIEVAL_AUGMENTED_CHAIN.INVOKE({\"QUERY\": \"QUANTUM COMPUTING\"})\n",
      "PRINT(RESPONSE)\n",
      "\n",
      "          ANSWER WITH A DESCRIPTION OF THE CODE SOLUTION, FOLLOWED BY THE IMPORTS, AND FINALLY THE FUNCTIONING CODE BLOCK.\n",
      "          ENSURE ALL IMPORTS ARE CORRECT AND THE CODE IS EXECUTABLE.]: 2025-03-13 15:37:01.608623\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:01][✅ CREW 'CREW' COMPLETED, 8C2B92EC-4748-4DDD-98F0-BF9B1CB37B47]: 2025-03-13 15:37:01.613051\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:01][👍 FLOW METHOD FINISHED: 'RUN_FIX']: 2025-03-13 15:37:01.613388\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:01][🤖 FLOW METHOD STARTED: 'RE_RUN_CHECK']: 2025-03-13 15:37:01.613532\u001b[00m\n",
      "---CHECKING CODE---\n",
      "This is a comprehensive and well-structured overview of quantum computing! You've covered the key concepts, applications, challenges, and current status of the field, as well as future prospects. Here are some additional thoughts and suggestions to consider:\n",
      "\n",
      "**Key Concepts:**\n",
      "\n",
      "* You might want to expand on the concept of superposition and entanglement, as they are fundamental to understanding quantum computing.\n",
      "* Consider adding a section on quantum decoherence, which is the loss of quantum coherence due to interactions with the environment.\n",
      "\n",
      "**Applications:**\n",
      "\n",
      "* You might want to explore the potential applications of quantum computing in more depth, such as in finance, healthcare, and climate modeling.\n",
      "* Consider mentioning the potential for quantum computing to accelerate scientific discovery and innovation.\n",
      "\n",
      "**Challenges:**\n",
      "\n",
      "* You're right to highlight the challenges of error correction, scalability, noise and interference, and quantum control. These are significant hurdles that need to be addressed.\n",
      "* Consider mentioning the need for a standardized framework for quantum computing, including a common language and set of protocols.\n",
      "\n",
      "**Current Status:**\n",
      "\n",
      "* You've listed several companies and startups working on quantum computing, but you might want to provide more details on their specific projects and progress.\n",
      "* Consider mentioning the role of government agencies and research institutions in supporting quantum computing research and development.\n",
      "\n",
      "**Future Prospects:**\n",
      "\n",
      "* You're right to highlight the potential for quantum supremacy, error correction, and quantum-classical hybrid systems.\n",
      "* Consider mentioning the potential for quantum computing to revolutionize industries such as transportation, energy, and manufacturing.\n",
      "* You might want to explore the potential societal impacts of quantum computing, such as increased efficiency, productivity, and innovation.\n",
      "\n",
      "**Additional Thoughts:**\n",
      "\n",
      "* Consider mentioning the need for a diverse and inclusive community of quantum computing researchers and developers.\n",
      "* You might want to explore the potential for quantum computing to address some of the world's most pressing challenges, such as climate change and healthcare disparities.\n",
      "* Consider highlighting the role of international collaborations and partnerships in advancing quantum computing research and development.\n",
      "\n",
      "Overall, your overview provides a solid foundation for understanding quantum computing. By expanding on these key concepts and addressing the challenges and future prospects, you can create a comprehensive and engaging guide for readers.\n",
      "---NO CODE TEST FAILURES---\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:03][👍 FLOW METHOD FINISHED: 'RE_RUN_CHECK']: 2025-03-13 15:37:03.304628\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:03][👍 FLOW FINISHED: 'CODEGENFLOW', 590F0381-7A49-46E0-8193-B34ACA1A30DA]: 2025-03-13 15:37:03.305621\u001b[00m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CodeSolution(prefix=\"To build a Retrieval Augmented Generation (RAG) chain in LCEL, you need to correctly configure and connect each step in your chain. The issue you're experiencing is likely due to a mismatch between expected inputs and the outputs being provided. The RAG chain generally involves a retrieval step followed by some processing and generating step. Hence, it needs appropriate setup for input types and operation flow. Below is a detailed and corrected code example that demonstrates setting up a RAG chain.\", imports='from langchain_core.prompts import ChatPromptTemplate\\nfrom langchain.chat_models import init_chat_model\\nfrom langchain_core.output_parsers import StrOutputParser\\nfrom langchain_core.runnables import RunnableParallel', code='prompt = ChatPromptTemplate.from_template(\"retrieve information about {query}\")\\nmodel = init_chat_model(\"llama3-8b-8192\", model_provider=\"groq\")\\nretriever_chain = prompt | model | StrOutputParser()  # Ensure it matches expected types\\n\\n# If the output of retriever_chain might be dict-like, ensure it converts to a suitable format for the model\\n\\nretrieval_augmented_chain = retriever_chain | StrOutputParser() | model | StrOutputParser()  # Adapt if necessary\\n\\nresponse = retrieval_augmented_chain.invoke({\"query\": \"quantum computing\"})\\nprint(response)')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_flow = CodeGenFlow()\n",
    "code_flow.kickoff(inputs={\"question\": 'How do I build a RAG chain in LCEL?'})\n",
    "code_flow.state.generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluations\n",
    "\n",
    "We will check for imports, code execution and overall compare with the correct solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_import(solution) -> dict:\n",
    "    imports = solution.imports\n",
    "    try:\n",
    "        exec(imports)\n",
    "        return {\"key\": \"import_check\", \"score\": 1}\n",
    "    except Exception:\n",
    "        return {\"key\": \"import_check\", \"score\": 0}\n",
    "\n",
    "\n",
    "def check_execution(solution) -> dict:\n",
    "    imports = solution.imports\n",
    "    code = solution.code\n",
    "    try:\n",
    "        exec(imports + \"\\n\" + code)\n",
    "        return {\"key\": \"code_execution_check\", \"score\": 1}\n",
    "    except Exception:\n",
    "        return {\"key\": \"code_execution_check\", \"score\": 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# # Load the evaluation data\n",
    "# df = pd.read_csv(\"eval.csv\")\n",
    "\n",
    "data = {'question':\n",
    "    [\n",
    "    'How can I use a prompt and model to create a custom RAG example?',  \n",
    "    'How can I add memory to an arbitrary chain using LangChain?',  \n",
    "    'How can I make the output of my LCEL chain a string?',  \n",
    "    'How can I apply a custom function to one of the chains?',  \n",
    "    'With a RAG chain in LCEL, why are documents required?',    \n",
    "    'How can I configure the temperature of an LLM?' ,   \n",
    "    'How can we apply a function call to an LLM in a chain?' ,   \n",
    "    'How can I run two LCEL chains in parallel and sequentially?' ,   \n",
    "    'How can I directly pass a string to a runnable chain?',   \n",
    "    'How can I use a custom function to route between two chains?',   \n",
    "    'How do I set up a retrieval-augmented generation agent?',   \n",
    "    'How can I create a LCEL chain that queries a SQL database?',   \n",
    "    'How do I structure output of an LCEL chain?', \n",
    "    ]   \n",
    "}\n",
    "df = pd.DataFrame.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:03][🌊 FLOW CREATED: 'CODEGENFLOW']: 2025-03-13 15:37:03.567882\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:03][🤖 FLOW STARTED: 'CODEGENFLOW', 4ED925FE-3884-482C-A71D-BFD077CA3899]: 2025-03-13 15:37:03.568620\u001b[00m\n",
      "\u001b[1m\u001b[35m Flow started with ID: 4ed925fe-3884-482c-a71d-bfd077ca3899\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:03][🤖 FLOW METHOD STARTED: 'GENERATE_CODE']: 2025-03-13 15:37:03.568930\u001b[00m\n",
      "---GENERATING CODE SOLUTION---\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:03][🚀 CREW 'CREW' STARTED, 368F5772-413F-4BF5-BD01-847C2CD6098D]: 2025-03-13 15:37:03.569179\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:03][📋 TASK STARTED: ANSWER THE USER QUESTION BASED ON THE ABOVE PROVIDED DOCUMENTATION. ENSURE ANY CODE YOU PROVIDE CAN BE EXECUTED\n",
      "    WITH ALL REQUIRED IMPORTS AND VARIABLES DEFINED. STRUCTURE YOUR ANSWER:\n",
      "    1) A PREFIX DESCRIBING THE CODE SOLUTION\n",
      "    2) THE IMPORTS\n",
      "    3) THE FUNCTIONING CODE BLOCK\n",
      "\n",
      "    YOUR CODING TASK:\n",
      "    HOW CAN I USE A PROMPT AND MODEL TO CREATE A CUSTOM RAG EXAMPLE?\n",
      "    ]: 2025-03-13 15:37:03.571481\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:03][🤖 AGENT 'CODING ASSISTANT' STARTED TASK]: 2025-03-13 15:37:03.573697\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:03][🤖 LLM CALL STARTED]: 2025-03-13 15:37:03.574047\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:06][✅ LLM CALL COMPLETED]: 2025-03-13 15:37:06.350269\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:06][✅ AGENT 'CODING ASSISTANT' COMPLETED TASK]: 2025-03-13 15:37:06.351398\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:06][✅ TASK COMPLETED: ANSWER THE USER QUESTION BASED ON THE ABOVE PROVIDED DOCUMENTATION. ENSURE ANY CODE YOU PROVIDE CAN BE EXECUTED\n",
      "    WITH ALL REQUIRED IMPORTS AND VARIABLES DEFINED. STRUCTURE YOUR ANSWER:\n",
      "    1) A PREFIX DESCRIBING THE CODE SOLUTION\n",
      "    2) THE IMPORTS\n",
      "    3) THE FUNCTIONING CODE BLOCK\n",
      "\n",
      "    YOUR CODING TASK:\n",
      "    HOW CAN I USE A PROMPT AND MODEL TO CREATE A CUSTOM RAG EXAMPLE?\n",
      "    ]: 2025-03-13 15:37:06.351735\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:06][✅ CREW 'CREW' COMPLETED, 368F5772-413F-4BF5-BD01-847C2CD6098D]: 2025-03-13 15:37:06.355723\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:06][👍 FLOW METHOD FINISHED: 'GENERATE_CODE']: 2025-03-13 15:37:06.355975\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:06][🤖 FLOW METHOD STARTED: 'RUN_CHECK']: 2025-03-13 15:37:06.356125\u001b[00m\n",
      "---CHECKING CODE---\n",
      "Why did the penguin take his credit card to the Antarctic?\n",
      "\n",
      "Because he wanted to freeze his assets!\n",
      "---NO CODE TEST FAILURES---\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:06][👍 FLOW METHOD FINISHED: 'RUN_CHECK']: 2025-03-13 15:37:06.642166\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:06][👍 FLOW FINISHED: 'CODEGENFLOW', 4ED925FE-3884-482C-A71D-BFD077CA3899]: 2025-03-13 15:37:06.642974\u001b[00m\n",
      "Why did the penguin take his credit card to the Antarctic?\n",
      "\n",
      "Because he wanted to freeze his assets!\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:06][🌊 FLOW CREATED: 'CODEGENFLOW']: 2025-03-13 15:37:06.870336\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:06][🤖 FLOW STARTED: 'CODEGENFLOW', A54275CB-541D-4A15-8031-37DF750CC696]: 2025-03-13 15:37:06.870777\u001b[00m\n",
      "\u001b[1m\u001b[35m Flow started with ID: a54275cb-541d-4a15-8031-37df750cc696\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:06][🤖 FLOW METHOD STARTED: 'GENERATE_CODE']: 2025-03-13 15:37:06.871184\u001b[00m\n",
      "---GENERATING CODE SOLUTION---\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:06][🚀 CREW 'CREW' STARTED, 368F5772-413F-4BF5-BD01-847C2CD6098D]: 2025-03-13 15:37:06.871443\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:06][📋 TASK STARTED: ANSWER THE USER QUESTION BASED ON THE ABOVE PROVIDED DOCUMENTATION. ENSURE ANY CODE YOU PROVIDE CAN BE EXECUTED\n",
      "    WITH ALL REQUIRED IMPORTS AND VARIABLES DEFINED. STRUCTURE YOUR ANSWER:\n",
      "    1) A PREFIX DESCRIBING THE CODE SOLUTION\n",
      "    2) THE IMPORTS\n",
      "    3) THE FUNCTIONING CODE BLOCK\n",
      "\n",
      "    YOUR CODING TASK:\n",
      "    HOW CAN I ADD MEMORY TO AN ARBITRARY CHAIN USING LANGCHAIN?\n",
      "    ]: 2025-03-13 15:37:06.875395\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:06][🤖 AGENT 'CODING ASSISTANT' STARTED TASK]: 2025-03-13 15:37:06.875949\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:06][🤖 LLM CALL STARTED]: 2025-03-13 15:37:06.876060\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:09][✅ LLM CALL COMPLETED]: 2025-03-13 15:37:09.711883\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:09][✅ AGENT 'CODING ASSISTANT' COMPLETED TASK]: 2025-03-13 15:37:09.713116\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:09][✅ TASK COMPLETED: ANSWER THE USER QUESTION BASED ON THE ABOVE PROVIDED DOCUMENTATION. ENSURE ANY CODE YOU PROVIDE CAN BE EXECUTED\n",
      "    WITH ALL REQUIRED IMPORTS AND VARIABLES DEFINED. STRUCTURE YOUR ANSWER:\n",
      "    1) A PREFIX DESCRIBING THE CODE SOLUTION\n",
      "    2) THE IMPORTS\n",
      "    3) THE FUNCTIONING CODE BLOCK\n",
      "\n",
      "    YOUR CODING TASK:\n",
      "    HOW CAN I ADD MEMORY TO AN ARBITRARY CHAIN USING LANGCHAIN?\n",
      "    ]: 2025-03-13 15:37:09.713441\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:09][✅ CREW 'CREW' COMPLETED, 368F5772-413F-4BF5-BD01-847C2CD6098D]: 2025-03-13 15:37:09.717865\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:09][👍 FLOW METHOD FINISHED: 'GENERATE_CODE']: 2025-03-13 15:37:09.718146\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:09][🤖 FLOW METHOD STARTED: 'RUN_CHECK']: 2025-03-13 15:37:09.718399\u001b[00m\n",
      "---CHECKING CODE---\n",
      "---CODE IMPORT CHECK: FAILED---\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:09][👍 FLOW METHOD FINISHED: 'RUN_CHECK']: 2025-03-13 15:37:09.718729\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:09][🤖 FLOW METHOD STARTED: 'RUN_FIX']: 2025-03-13 15:37:09.719079\u001b[00m\n",
      "---FIXING CODE---\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:09][🚀 CREW 'CREW' STARTED, A374A684-6E5C-4BE6-BF93-53175854D953]: 2025-03-13 15:37:09.721350\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:09][📋 TASK STARTED: YOU ARE A CODING ASSISTANT WITH EXPERTISE IN LCEL, LANGCHAIN EXPRESSION LANGUAGE.\n",
      "          HERE IS A FULL SET OF LCEL DOCUMENTATION:\n",
      "          -------\n",
      "          \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "HOW TO CHAIN RUNNABLES | 🦜️🔗 LANGCHAIN\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "SKIP TO MAIN CONTENTJOIN US AT  INTERRUPT: THE AGENT AI CONFERENCE BY LANGCHAIN ON MAY 13 & 14 IN SAN FRANCISCO!INTEGRATIONSAPI REFERENCEMORECONTRIBUTINGPEOPLEERROR REFERENCELANGSMITHLANGGRAPHLANGCHAIN HUBLANGCHAIN JS/TSV0.3V0.3V0.2V0.1💬SEARCHINTRODUCTIONTUTORIALSBUILD A QUESTION ANSWERING APPLICATION OVER A GRAPH DATABASETUTORIALSBUILD A SIMPLE LLM APPLICATION WITH CHAT MODELS AND PROMPT TEMPLATESBUILD A CHATBOTBUILD A RETRIEVAL AUGMENTED GENERATION (RAG) APP: PART 2BUILD AN EXTRACTION CHAINBUILD AN AGENTTAGGINGBUILD A RETRIEVAL AUGMENTED GENERATION (RAG) APP: PART 1BUILD A SEMANTIC SEARCH ENGINEBUILD A QUESTION/ANSWERING SYSTEM OVER SQL DATASUMMARIZE TEXTHOW-TO GUIDESHOW-TO GUIDESHOW TO USE TOOLS IN A CHAINHOW TO USE A VECTORSTORE AS A RETRIEVERHOW TO ADD MEMORY TO CHATBOTSHOW TO USE EXAMPLE SELECTORSHOW TO ADD A SEMANTIC LAYER OVER GRAPH DATABASEHOW TO INVOKE RUNNABLES IN PARALLELHOW TO STREAM CHAT MODEL RESPONSESHOW TO ADD DEFAULT INVOCATION ARGS TO A RUNNABLEHOW TO ADD RETRIEVAL TO CHATBOTSHOW TO USE FEW SHOT EXAMPLES IN CHAT MODELSHOW TO DO TOOL/FUNCTION CALLINGHOW TO INSTALL LANGCHAIN PACKAGESHOW TO ADD EXAMPLES TO THE PROMPT FOR QUERY ANALYSISHOW TO USE FEW SHOT EXAMPLESHOW TO RUN CUSTOM FUNCTIONSHOW TO USE OUTPUT PARSERS TO PARSE AN LLM RESPONSE INTO STRUCTURED FORMATHOW TO HANDLE CASES WHERE NO QUERIES ARE GENERATEDHOW TO ROUTE BETWEEN SUB-CHAINSHOW TO RETURN STRUCTURED DATA FROM A MODELHOW TO SUMMARIZE TEXT THROUGH PARALLELIZATIONHOW TO SUMMARIZE TEXT THROUGH ITERATIVE REFINEMENTHOW TO SUMMARIZE TEXT IN A SINGLE LLM CALLHOW TO USE TOOLKITSHOW TO ADD AD-HOC TOOL CALLING CAPABILITY TO LLMS AND CHAT MODELSBUILD AN AGENT WITH AGENTEXECUTOR (LEGACY)HOW TO CONSTRUCT KNOWLEDGE GRAPHSHOW TO PARTIALLY FORMAT PROMPT TEMPLATESHOW TO HANDLE MULTIPLE QUERIES WHEN DOING QUERY ANALYSISHOW TO USE BUILT-IN TOOLS AND TOOLKITSHOW TO PASS THROUGH ARGUMENTS FROM ONE STEP TO THE NEXTHOW TO COMPOSE PROMPTS TOGETHERHOW TO HANDLE MULTIPLE RETRIEVERS WHEN DOING QUERY ANALYSISHOW TO ADD VALUES TO A CHAIN'S STATEHOW TO CONSTRUCT FILTERS FOR QUERY ANALYSISHOW TO CONFIGURE RUNTIME CHAIN INTERNALSHOW DEAL WITH HIGH CARDINALITY CATEGORICALS WHEN DOING QUERY ANALYSISCUSTOM DOCUMENT LOADERHOW TO USE THE MULTIQUERYRETRIEVERHOW TO ADD SCORES TO RETRIEVER RESULTSCACHINGHOW TO USE CALLBACKS IN ASYNC ENVIRONMENTSHOW TO ATTACH CALLBACKS TO A RUNNABLEHOW TO PROPAGATE CALLBACKS  CONSTRUCTORHOW TO DISPATCH CUSTOM CALLBACK EVENTSHOW TO PASS CALLBACKS IN AT RUNTIMEHOW TO SPLIT BY CHARACTERHOW TO CACHE CHAT MODEL RESPONSESHOW TO HANDLE RATE LIMITSHOW TO INIT ANY MODEL IN ONE LINEHOW TO TRACK TOKEN USAGE IN CHATMODELSHOW TO ADD TOOLS TO CHATBOTSHOW TO SPLIT CODEHOW TO DO RETRIEVAL WITH CONTEXTUAL COMPRESSIONHOW TO CONVERT RUNNABLES TO TOOLSHOW TO CREATE CUSTOM CALLBACK HANDLERSHOW TO CREATE A CUSTOM CHAT MODEL CLASSCUSTOM EMBEDDINGSHOW TO CREATE A CUSTOM LLM CLASSCUSTOM RETRIEVERHOW TO CREATE TOOLSHOW TO DEBUG YOUR LLM APPSHOW TO LOAD CSVSHOW TO LOAD DOCUMENTS FROM A DIRECTORYHOW TO LOAD HTMLHOW TO LOAD JSONHOW TO LOAD MARKDOWNHOW TO LOAD MICROSOFT OFFICE FILESHOW TO LOAD PDFSHOW TO LOAD WEB PAGESHOW TO CREATE A DYNAMIC (SELF-CONSTRUCTING) CHAINTEXT EMBEDDING MODELSHOW TO COMBINE RESULTS FROM MULTIPLE RETRIEVERSHOW TO SELECT EXAMPLES FROM A LANGSMITH DATASETHOW TO SELECT EXAMPLES BY LENGTHHOW TO SELECT EXAMPLES BY MAXIMAL MARGINAL RELEVANCE (MMR)HOW TO SELECT EXAMPLES BY N-GRAM OVERLAPHOW TO SELECT EXAMPLES BY SIMILARITYHOW TO USE REFERENCE EXAMPLES WHEN DOING EXTRACTIONHOW TO HANDLE LONG TEXT WHEN DOING EXTRACTIONHOW TO USE PROMPTING ALONE (NO TOOL CALLING) TO DO EXTRACTIONHOW TO ADD FALLBACKS TO A RUNNABLEHOW TO FILTER MESSAGESHYBRID SEARCHHOW TO USE THE LANGCHAIN INDEXING APIHOW TO INSPECT RUNNABLESLANGCHAIN EXPRESSION LANGUAGE CHEATSHEETHOW TO CACHE LLM RESPONSESHOW TO TRACK TOKEN USAGE FOR LLMSRUN MODELS LOCALLYHOW TO GET LOG PROBABILITIESHOW TO REORDER RETRIEVED RESULTS TO MITIGATE THE \"LOST IN THE MIDDLE\" EFFECTHOW TO SPLIT MARKDOWN BY HEADERSHOW TO MERGE CONSECUTIVE MESSAGES OF THE SAME TYPEHOW TO ADD MESSAGE HISTORYHOW TO MIGRATE FROM LEGACY LANGCHAIN AGENTS TO LANGGRAPHHOW TO RETRIEVE USING MULTIPLE VECTORS PER DOCUMENTHOW TO PASS MULTIMODAL DATA DIRECTLY TO MODELSHOW TO USE MULTIMODAL PROMPTSHOW TO CREATE A CUSTOM OUTPUT PARSERHOW TO USE THE OUTPUT-FIXING PARSERHOW TO PARSE JSON OUTPUTHOW TO RETRY WHEN A PARSING ERROR OCCURSHOW TO PARSE TEXT FROM MESSAGE OBJECTSHOW TO PARSE XML OUTPUTHOW TO PARSE YAML OUTPUTHOW TO USE THE PARENT DOCUMENT RETRIEVERHOW TO USE LANGCHAIN WITH DIFFERENT PYDANTIC VERSIONSHOW TO ADD CHAT HISTORYHOW TO GET A RAG APPLICATION TO ADD CITATIONSHOW TO DO PER-USER RETRIEVALHOW TO GET YOUR RAG APPLICATION TO RETURN SOURCESHOW TO STREAM RESULTS FROM YOUR RAG APPLICATIONHOW TO SPLIT JSON DATAHOW TO RECURSIVELY SPLIT TEXT BY CHARACTERSRESPONSE METADATAHOW TO PASS RUNTIME SECRETS TO RUNNABLESHOW TO DO \"SELF-QUERYING\" RETRIEVALHOW TO SPLIT TEXT BASED ON SEMANTIC SIMILARITYHOW TO CHAIN RUNNABLESHOW TO SAVE AND LOAD LANGCHAIN OBJECTSHOW TO SPLIT TEXT BY TOKENSHOW TO SPLIT HTMLHOW TO DO QUESTION ANSWERING OVER CSVSHOW TO DEAL WITH LARGE DATABASES WHEN DOING SQL QUESTION-ANSWERINGHOW TO BETTER PROMPT WHEN DOING SQL QUESTION-ANSWERINGHOW TO DO QUERY VALIDATION AS PART OF SQL QUESTION-ANSWERINGHOW TO STREAM RUNNABLESHOW TO STREAM RESPONSES FROM AN LLMHOW TO USE A TIME-WEIGHTED VECTOR STORE RETRIEVERHOW TO RETURN ARTIFACTS FROM A TOOLHOW TO USE CHAT MODELS TO CALL TOOLSHOW TO DISABLE PARALLEL TOOL CALLINGHOW TO FORCE MODELS TO CALL A TOOLHOW TO ACCESS THE RUNNABLECONFIG FROM A TOOLHOW TO PASS TOOL OUTPUTS TO CHAT MODELSHOW TO PASS RUN TIME VALUES TO TOOLSHOW TO STREAM EVENTS FROM A TOOLHOW TO STREAM TOOL CALLSHOW TO CONVERT TOOLS TO OPENAI FUNCTIONSHOW TO HANDLE TOOL ERRORSHOW TO USE FEW-SHOT PROMPTING WITH TOOL CALLINGHOW TO ADD A HUMAN-IN-THE-LOOP FOR TOOLSHOW TO BIND MODEL-SPECIFIC TOOLSHOW TO TRIM MESSAGESHOW TO CREATE AND QUERY VECTOR STORESCONCEPTUAL GUIDEAGENTSARCHITECTUREASYNC PROGRAMMING WITH LANGCHAINCALLBACKSCHAT HISTORYCHAT MODELSDOCUMENT LOADERSEMBEDDING MODELSEVALUATIONEXAMPLE SELECTORSFEW-SHOT PROMPTINGCONCEPTUAL GUIDEKEY-VALUE STORESLANGCHAIN EXPRESSION LANGUAGE (LCEL)MESSAGESMULTIMODALITYOUTPUT PARSERSPROMPT TEMPLATESRETRIEVAL AUGMENTED GENERATION (RAG)RETRIEVALRETRIEVERSRUNNABLE INTERFACESTREAMINGSTRUCTURED OUTPUTSTESTINGSTRING-IN, STRING-OUT LLMSTEXT SPLITTERSTOKENSTOOL CALLINGTOOLSTRACINGVECTOR STORESWHY LANGCHAIN?ECOSYSTEM🦜🛠️ LANGSMITH🦜🕸️ LANGGRAPHVERSIONSV0.3V0.2PYDANTIC COMPATIBILITYMIGRATING FROM V0.0 CHAINSHOW TO MIGRATE FROM V0.0 CHAINSMIGRATING FROM CONSTITUTIONALCHAINMIGRATING FROM CONVERSATIONALCHAINMIGRATING FROM CONVERSATIONALRETRIEVALCHAINMIGRATING FROM LLMCHAINMIGRATING FROM LLMMATHCHAINMIGRATING FROM LLMROUTERCHAINMIGRATING FROM MAPREDUCEDOCUMENTSCHAINMIGRATING FROM MAPRERANKDOCUMENTSCHAINMIGRATING FROM MULTIPROMPTCHAINMIGRATING FROM REFINEDOCUMENTSCHAINMIGRATING FROM RETRIEVALQAMIGRATING FROM STUFFDOCUMENTSCHAINUPGRADING TO LANGGRAPH MEMORYHOW TO MIGRATE TO LANGGRAPH MEMORYHOW TO USE BASECHATMESSAGEHISTORY WITH LANGGRAPHMIGRATING OFF CONVERSATIONBUFFERMEMORY OR CONVERSATIONSTRINGBUFFERMEMORYMIGRATING OFF CONVERSATIONBUFFERWINDOWMEMORY OR CONVERSATIONTOKENBUFFERMEMORYMIGRATING OFF CONVERSATIONSUMMARYMEMORY OR CONVERSATIONSUMMARYBUFFERMEMORYA LONG-TERM MEMORY AGENTRELEASE POLICYSECURITY POLICYHOW-TO GUIDESHOW TO CHAIN RUNNABLESON THIS PAGEHOW TO CHAIN RUNNABLES\n",
      "PREREQUISITESTHIS GUIDE ASSUMES FAMILIARITY WITH THE FOLLOWING CONCEPTS:\n",
      "LANGCHAIN EXPRESSION LANGUAGE (LCEL)\n",
      "PROMPT TEMPLATES\n",
      "CHAT MODELS\n",
      "OUTPUT PARSER\n",
      "\n",
      "ONE POINT ABOUT LANGCHAIN EXPRESSION LANGUAGE IS THAT ANY TWO RUNNABLES CAN BE \"CHAINED\" TOGETHER INTO SEQUENCES. THE OUTPUT OF THE PREVIOUS RUNNABLE'S .INVOKE() CALL IS PASSED AS INPUT TO THE NEXT RUNNABLE. THIS CAN BE DONE USING THE PIPE OPERATOR (|), OR THE MORE EXPLICIT .PIPE() METHOD, WHICH DOES THE SAME THING.\n",
      "THE RESULTING RUNNABLESEQUENCE IS ITSELF A RUNNABLE, WHICH MEANS IT CAN BE INVOKED, STREAMED, OR FURTHER CHAINED JUST LIKE ANY OTHER RUNNABLE. ADVANTAGES OF CHAINING RUNNABLES IN THIS WAY ARE EFFICIENT STREAMING (THE SEQUENCE WILL STREAM OUTPUT AS SOON AS IT IS AVAILABLE), AND DEBUGGING AND TRACING WITH TOOLS LIKE LANGSMITH.\n",
      "THE PIPE OPERATOR: |​\n",
      "TO SHOW OFF HOW THIS WORKS, LET'S GO THROUGH AN EXAMPLE. WE'LL WALK THROUGH A COMMON PATTERN IN LANGCHAIN: USING A PROMPT TEMPLATE TO FORMAT INPUT INTO A CHAT MODEL, AND FINALLY CONVERTING THE CHAT MESSAGE OUTPUT INTO A STRING WITH AN OUTPUT PARSER.\n",
      "\n",
      "SELECT CHAT MODEL:GROQ▾GROQOPENAIANTHROPICAZUREGOOGLE VERTEXAWSCOHERENVIDIAFIREWORKS AIMISTRAL AITOGETHER AIIBM WATSONXDATABRICKSXAIPIP INSTALL -QU \"LANGCHAIN[GROQ]\"IMPORT GETPASSIMPORT OSIF NOT OS.ENVIRON.GET(\"GROQ_API_KEY\"):  OS.ENVIRON[\"GROQ_API_KEY\"] = GETPASS.GETPASS(\"ENTER API KEY FOR GROQ: \")FROM LANGCHAIN.CHAT_MODELS IMPORT INIT_CHAT_MODELMODEL = INIT_CHAT_MODEL(\"LLAMA3-8B-8192\", MODEL_PROVIDER=\"GROQ\")\n",
      "FROM LANGCHAIN_CORE.OUTPUT_PARSERS IMPORT STROUTPUTPARSERFROM LANGCHAIN_CORE.PROMPTS IMPORT CHATPROMPTTEMPLATEPROMPT = CHATPROMPTTEMPLATE.FROM_TEMPLATE(\"TELL ME A JOKE ABOUT {TOPIC}\")CHAIN = PROMPT | MODEL | STROUTPUTPARSER()API REFERENCE:STROUTPUTPARSER | CHATPROMPTTEMPLATE\n",
      "PROMPTS AND MODELS ARE BOTH RUNNABLE, AND THE OUTPUT TYPE FROM THE PROMPT CALL IS THE SAME AS THE INPUT TYPE OF THE CHAT MODEL, SO WE CAN CHAIN THEM TOGETHER. WE CAN THEN INVOKE THE RESULTING SEQUENCE LIKE ANY OTHER RUNNABLE:\n",
      "CHAIN.INVOKE({\"TOPIC\": \"BEARS\"})\n",
      "\"HERE'S A BEAR JOKE FOR YOU:\\N\\NWHY DID THE BEAR DISSOLVE IN WATER?\\NBECAUSE IT WAS A POLAR BEAR!\"\n",
      "COERCION​\n",
      "WE CAN EVEN COMBINE THIS CHAIN WITH MORE RUNNABLES TO CREATE ANOTHER CHAIN. THIS MAY INVOLVE SOME INPUT/OUTPUT FORMATTING USING OTHER TYPES OF RUNNABLES, DEPENDING ON THE REQUIRED INPUTS AND OUTPUTS OF THE CHAIN COMPONENTS.\n",
      "FOR EXAMPLE, LET'S SAY WE WANTED TO COMPOSE THE JOKE GENERATING CHAIN WITH ANOTHER CHAIN THAT EVALUATES WHETHER OR NOT THE GENERATED JOKE WAS FUNNY.\n",
      "WE WOULD NEED TO BE CAREFUL WITH HOW WE FORMAT THE INPUT INTO THE NEXT CHAIN. IN THE BELOW EXAMPLE, THE DICT IN THE CHAIN IS AUTOMATICALLY PARSED AND CONVERTED INTO A RUNNABLEPARALLEL, WHICH RUNS ALL OF ITS VALUES IN PARALLEL AND RETURNS A DICT WITH THE RESULTS.\n",
      "THIS HAPPENS TO BE THE SAME FORMAT THE NEXT PROMPT TEMPLATE EXPECTS. HERE IT IS IN ACTION:\n",
      "FROM LANGCHAIN_CORE.OUTPUT_PARSERS IMPORT STROUTPUTPARSERANALYSIS_PROMPT = CHATPROMPTTEMPLATE.FROM_TEMPLATE(\"IS THIS A FUNNY JOKE? {JOKE}\")COMPOSED_CHAIN = {\"JOKE\": CHAIN} | ANALYSIS_PROMPT | MODEL | STROUTPUTPARSER()COMPOSED_CHAIN.INVOKE({\"TOPIC\": \"BEARS\"})API REFERENCE:STROUTPUTPARSER\n",
      "'HAHA, THAT\\'S A CLEVER PLAY ON WORDS! USING \"POLAR\" TO IMPLY THE BEAR DISSOLVED OR BECAME POLAR/POLARIZED WHEN PUT IN WATER. NOT THE MOST HILARIOUS JOKE EVER, BUT IT HAS A CUTE, GROAN-WORTHY PUN THAT MAKES IT MILDLY AMUSING. I APPRECIATE A GOOD PUN OR WORDPLAY JOKE.'\n",
      "FUNCTIONS WILL ALSO BE COERCED INTO RUNNABLES, SO YOU CAN ADD CUSTOM LOGIC TO YOUR CHAINS TOO. THE BELOW CHAIN RESULTS IN THE SAME LOGICAL FLOW AS BEFORE:\n",
      "COMPOSED_CHAIN_WITH_LAMBDA = (    CHAIN    | (LAMBDA INPUT: {\"JOKE\": INPUT})    | ANALYSIS_PROMPT    | MODEL    | STROUTPUTPARSER())COMPOSED_CHAIN_WITH_LAMBDA.INVOKE({\"TOPIC\": \"BEETS\"})\n",
      "\"HAHA, THAT'S A CUTE AND PUNNY JOKE! I LIKE HOW IT PLAYS ON THE IDEA OF BEETS BLUSHING OR TURNING RED LIKE SOMEONE BLUSHING. FOOD PUNS CAN BE QUITE AMUSING. WHILE NOT A TOTAL KNEE-SLAPPER, IT'S A LIGHT-HEARTED, GROAN-WORTHY DAD JOKE THAT WOULD MAKE ME CHUCKLE AND SHAKE MY HEAD. SIMPLE VEGETABLE HUMOR!\"\n",
      "HOWEVER, KEEP IN MIND THAT USING FUNCTIONS LIKE THIS MAY INTERFERE WITH OPERATIONS LIKE STREAMING. SEE THIS SECTION FOR MORE INFORMATION.\n",
      "THE .PIPE() METHOD​\n",
      "WE COULD ALSO COMPOSE THE SAME SEQUENCE USING THE .PIPE() METHOD. HERE'S WHAT THAT LOOKS LIKE:\n",
      "FROM LANGCHAIN_CORE.RUNNABLES IMPORT RUNNABLEPARALLELCOMPOSED_CHAIN_WITH_PIPE = (    RUNNABLEPARALLEL({\"JOKE\": CHAIN})    .PIPE(ANALYSIS_PROMPT)    .PIPE(MODEL)    .PIPE(STROUTPUTPARSER()))COMPOSED_CHAIN_WITH_PIPE.INVOKE({\"TOPIC\": \"BATTLESTAR GALACTICA\"})API REFERENCE:RUNNABLEPARALLEL\n",
      "\"I CANNOT REPRODUCE ANY COPYRIGHTED MATERIAL VERBATIM, BUT I CAN TRY TO ANALYZE THE HUMOR IN THE JOKE YOU PROVIDED WITHOUT QUOTING IT DIRECTLY.\\N\\NTHE JOKE PLAYS ON THE IDEA THAT THE CYLON RAIDERS, WHO ARE THE ANTAGONISTS IN THE BATTLESTAR GALACTICA UNIVERSE, FAILED TO LOCATE THE HUMAN SURVIVORS AFTER ATTACKING THEIR HOME PLANETS (THE TWELVE COLONIES) DUE TO USING AN OUTDATED AND POORLY PERFORMING OPERATING SYSTEM (WINDOWS VISTA) FOR THEIR TARGETING SYSTEMS.\\N\\NTHE HUMOR STEMS FROM THE JUXTAPOSITION OF A FUTURISTIC SCIENCE FICTION SETTING WITH A RELATABLE REAL-WORLD FRUSTRATION – THE USE OF BUGGY, SLOW, OR UNRELIABLE SOFTWARE OR TECHNOLOGY. IT POKES FUN AT THE PERCEIVED INADEQUACIES OF WINDOWS VISTA, WHICH WAS WIDELY CRITICIZED FOR ITS PERFORMANCE ISSUES AND OTHER PROBLEMS WHEN IT WAS RELEASED.\\N\\NBY ATTRIBUTING THE CYLONS' FAILURE TO LOCATE THE HUMANS TO THEIR USE OF VISTA, THE JOKE CREATES AN AMUSING AND UNEXPECTED CONNECTION BETWEEN A FICTIONAL ADVANCED RACE OF ROBOTS AND A FAMILIAR TECHNOLOGICAL ANNOYANCE EXPERIENCED BY MANY PEOPLE IN THE REAL WORLD.\\N\\NOVERALL, THE JOKE RELIES ON INCONGRUITY AND RELATABILITY TO GENERATE HUMOR, BUT WITHOUT REPRODUCING ANY COPYRIGHTED MATERIAL DIRECTLY.\"\n",
      "OR THE ABBREVIATED:\n",
      "COMPOSED_CHAIN_WITH_PIPE = RUNNABLEPARALLEL({\"JOKE\": CHAIN}).PIPE(    ANALYSIS_PROMPT, MODEL, STROUTPUTPARSER())\n",
      "RELATED​\n",
      "\n",
      "STREAMING: CHECK OUT THE STREAMING GUIDE TO UNDERSTAND THE STREAMING BEHAVIOR OF A CHAIN\n",
      "EDIT THIS PAGEWAS THIS PAGE HELPFUL?PREVIOUSHOW TO SPLIT TEXT BASED ON SEMANTIC SIMILARITYNEXTHOW TO SAVE AND LOAD LANGCHAIN OBJECTSTHE PIPE OPERATOR: |COERCIONTHE .PIPE() METHODRELATEDCOMMUNITYTWITTERGITHUBORGANIZATIONPYTHONJS/TSMOREHOMEPAGEBLOGYOUTUBECOPYRIGHT © 2025 LANGCHAIN, INC.\n",
      "\n",
      "\n",
      "          -------\n",
      "\n",
      "          THE PREVIOUS CODE ATTEMPT FAILED WITH THE FOLLOWING ERROR:\n",
      "          CANNOT IMPORT NAME 'CONVERSATIONBUFFERMEMORY' FROM 'LANGCHAIN_CORE.MEMORY' (/USERS/MJACK6/GSU_SPRING2025/MSA8700/VENV_AGENTICAI/LIB/PYTHON3.11/SITE-PACKAGES/LANGCHAIN_CORE/MEMORY.PY)\n",
      "\n",
      "          YOUR CODING TASK:\n",
      "          HOW CAN I ADD MEMORY TO AN ARBITRARY CHAIN USING LANGCHAIN?\n",
      "\n",
      "          PREVIOUS CODE ATTEMPT:\n",
      "          TO ADD MEMORY TO AN ARBITRARY CHAIN USING LANGCHAIN, YOU CAN UTILIZE MEMORY MODULES SUCH AS CONVERSATIONBUFFERMEMORY, CONVERSATIONSTRINGBUFFERMEMORY, OR CONVERSATIONSUMMARYMEMORY. HERE IS AN EXAMPLE THAT DEMONSTRATES HOW TO INTEGRATE SUCH A MEMORY MODULE INTO A SIMPLE CHAIN THAT USES A CHAT MODEL.\n",
      "          FROM LANGCHAIN_CORE.MEMORY IMPORT CONVERSATIONBUFFERMEMORY\n",
      "FROM LANGCHAIN.CHAT_MODELS IMPORT INIT_CHAT_MODEL\n",
      "FROM LANGCHAIN_CORE.PROMPTS IMPORT CHATPROMPTTEMPLATE\n",
      "FROM LANGCHAIN_CORE.OUTPUT_PARSERS IMPORT STROUTPUTPARSER\n",
      "          MEMORY = CONVERSATIONBUFFERMEMORY()\n",
      "MODEL = INIT_CHAT_MODEL('LLAMA3-8B-8192', MODEL_PROVIDER='GROQ')\n",
      "PROMPT = CHATPROMPTTEMPLATE.FROM_TEMPLATE('TELL ME A JOKE ABOUT {TOPIC}')\n",
      "CHAIN = PROMPT | MODEL | STROUTPUTPARSER()  \n",
      "# EXAMPLE OF ADDING MEMORY TO THE CHAIN \n",
      "CHAIN_WITH_MEMORY = CHAIN.PIPE(MEMORY)\n",
      "# INVOKING THE CHAIN WITH MEMORY TO KEEP TRACK OF CONVERSATION HISTORY\n",
      "RESULT = CHAIN_WITH_MEMORY.INVOKE({'TOPIC': 'SPACE'})\n",
      "PRINT(RESULT)\n",
      "\n",
      "          ANSWER WITH A DESCRIPTION OF THE CODE SOLUTION, FOLLOWED BY THE IMPORTS, AND FINALLY THE FUNCTIONING CODE BLOCK.\n",
      "          ENSURE ALL IMPORTS ARE CORRECT AND THE CODE IS EXECUTABLE.]: 2025-03-13 15:37:09.724875\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:09][🤖 AGENT 'CODING ASSISTANT' STARTED TASK]: 2025-03-13 15:37:09.725639\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:09][🤖 LLM CALL STARTED]: 2025-03-13 15:37:09.725779\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:12][✅ LLM CALL COMPLETED]: 2025-03-13 15:37:12.121372\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:12][✅ AGENT 'CODING ASSISTANT' COMPLETED TASK]: 2025-03-13 15:37:12.122491\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:12][✅ TASK COMPLETED: YOU ARE A CODING ASSISTANT WITH EXPERTISE IN LCEL, LANGCHAIN EXPRESSION LANGUAGE.\n",
      "          HERE IS A FULL SET OF LCEL DOCUMENTATION:\n",
      "          -------\n",
      "          \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "HOW TO CHAIN RUNNABLES | 🦜️🔗 LANGCHAIN\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "SKIP TO MAIN CONTENTJOIN US AT  INTERRUPT: THE AGENT AI CONFERENCE BY LANGCHAIN ON MAY 13 & 14 IN SAN FRANCISCO!INTEGRATIONSAPI REFERENCEMORECONTRIBUTINGPEOPLEERROR REFERENCELANGSMITHLANGGRAPHLANGCHAIN HUBLANGCHAIN JS/TSV0.3V0.3V0.2V0.1💬SEARCHINTRODUCTIONTUTORIALSBUILD A QUESTION ANSWERING APPLICATION OVER A GRAPH DATABASETUTORIALSBUILD A SIMPLE LLM APPLICATION WITH CHAT MODELS AND PROMPT TEMPLATESBUILD A CHATBOTBUILD A RETRIEVAL AUGMENTED GENERATION (RAG) APP: PART 2BUILD AN EXTRACTION CHAINBUILD AN AGENTTAGGINGBUILD A RETRIEVAL AUGMENTED GENERATION (RAG) APP: PART 1BUILD A SEMANTIC SEARCH ENGINEBUILD A QUESTION/ANSWERING SYSTEM OVER SQL DATASUMMARIZE TEXTHOW-TO GUIDESHOW-TO GUIDESHOW TO USE TOOLS IN A CHAINHOW TO USE A VECTORSTORE AS A RETRIEVERHOW TO ADD MEMORY TO CHATBOTSHOW TO USE EXAMPLE SELECTORSHOW TO ADD A SEMANTIC LAYER OVER GRAPH DATABASEHOW TO INVOKE RUNNABLES IN PARALLELHOW TO STREAM CHAT MODEL RESPONSESHOW TO ADD DEFAULT INVOCATION ARGS TO A RUNNABLEHOW TO ADD RETRIEVAL TO CHATBOTSHOW TO USE FEW SHOT EXAMPLES IN CHAT MODELSHOW TO DO TOOL/FUNCTION CALLINGHOW TO INSTALL LANGCHAIN PACKAGESHOW TO ADD EXAMPLES TO THE PROMPT FOR QUERY ANALYSISHOW TO USE FEW SHOT EXAMPLESHOW TO RUN CUSTOM FUNCTIONSHOW TO USE OUTPUT PARSERS TO PARSE AN LLM RESPONSE INTO STRUCTURED FORMATHOW TO HANDLE CASES WHERE NO QUERIES ARE GENERATEDHOW TO ROUTE BETWEEN SUB-CHAINSHOW TO RETURN STRUCTURED DATA FROM A MODELHOW TO SUMMARIZE TEXT THROUGH PARALLELIZATIONHOW TO SUMMARIZE TEXT THROUGH ITERATIVE REFINEMENTHOW TO SUMMARIZE TEXT IN A SINGLE LLM CALLHOW TO USE TOOLKITSHOW TO ADD AD-HOC TOOL CALLING CAPABILITY TO LLMS AND CHAT MODELSBUILD AN AGENT WITH AGENTEXECUTOR (LEGACY)HOW TO CONSTRUCT KNOWLEDGE GRAPHSHOW TO PARTIALLY FORMAT PROMPT TEMPLATESHOW TO HANDLE MULTIPLE QUERIES WHEN DOING QUERY ANALYSISHOW TO USE BUILT-IN TOOLS AND TOOLKITSHOW TO PASS THROUGH ARGUMENTS FROM ONE STEP TO THE NEXTHOW TO COMPOSE PROMPTS TOGETHERHOW TO HANDLE MULTIPLE RETRIEVERS WHEN DOING QUERY ANALYSISHOW TO ADD VALUES TO A CHAIN'S STATEHOW TO CONSTRUCT FILTERS FOR QUERY ANALYSISHOW TO CONFIGURE RUNTIME CHAIN INTERNALSHOW DEAL WITH HIGH CARDINALITY CATEGORICALS WHEN DOING QUERY ANALYSISCUSTOM DOCUMENT LOADERHOW TO USE THE MULTIQUERYRETRIEVERHOW TO ADD SCORES TO RETRIEVER RESULTSCACHINGHOW TO USE CALLBACKS IN ASYNC ENVIRONMENTSHOW TO ATTACH CALLBACKS TO A RUNNABLEHOW TO PROPAGATE CALLBACKS  CONSTRUCTORHOW TO DISPATCH CUSTOM CALLBACK EVENTSHOW TO PASS CALLBACKS IN AT RUNTIMEHOW TO SPLIT BY CHARACTERHOW TO CACHE CHAT MODEL RESPONSESHOW TO HANDLE RATE LIMITSHOW TO INIT ANY MODEL IN ONE LINEHOW TO TRACK TOKEN USAGE IN CHATMODELSHOW TO ADD TOOLS TO CHATBOTSHOW TO SPLIT CODEHOW TO DO RETRIEVAL WITH CONTEXTUAL COMPRESSIONHOW TO CONVERT RUNNABLES TO TOOLSHOW TO CREATE CUSTOM CALLBACK HANDLERSHOW TO CREATE A CUSTOM CHAT MODEL CLASSCUSTOM EMBEDDINGSHOW TO CREATE A CUSTOM LLM CLASSCUSTOM RETRIEVERHOW TO CREATE TOOLSHOW TO DEBUG YOUR LLM APPSHOW TO LOAD CSVSHOW TO LOAD DOCUMENTS FROM A DIRECTORYHOW TO LOAD HTMLHOW TO LOAD JSONHOW TO LOAD MARKDOWNHOW TO LOAD MICROSOFT OFFICE FILESHOW TO LOAD PDFSHOW TO LOAD WEB PAGESHOW TO CREATE A DYNAMIC (SELF-CONSTRUCTING) CHAINTEXT EMBEDDING MODELSHOW TO COMBINE RESULTS FROM MULTIPLE RETRIEVERSHOW TO SELECT EXAMPLES FROM A LANGSMITH DATASETHOW TO SELECT EXAMPLES BY LENGTHHOW TO SELECT EXAMPLES BY MAXIMAL MARGINAL RELEVANCE (MMR)HOW TO SELECT EXAMPLES BY N-GRAM OVERLAPHOW TO SELECT EXAMPLES BY SIMILARITYHOW TO USE REFERENCE EXAMPLES WHEN DOING EXTRACTIONHOW TO HANDLE LONG TEXT WHEN DOING EXTRACTIONHOW TO USE PROMPTING ALONE (NO TOOL CALLING) TO DO EXTRACTIONHOW TO ADD FALLBACKS TO A RUNNABLEHOW TO FILTER MESSAGESHYBRID SEARCHHOW TO USE THE LANGCHAIN INDEXING APIHOW TO INSPECT RUNNABLESLANGCHAIN EXPRESSION LANGUAGE CHEATSHEETHOW TO CACHE LLM RESPONSESHOW TO TRACK TOKEN USAGE FOR LLMSRUN MODELS LOCALLYHOW TO GET LOG PROBABILITIESHOW TO REORDER RETRIEVED RESULTS TO MITIGATE THE \"LOST IN THE MIDDLE\" EFFECTHOW TO SPLIT MARKDOWN BY HEADERSHOW TO MERGE CONSECUTIVE MESSAGES OF THE SAME TYPEHOW TO ADD MESSAGE HISTORYHOW TO MIGRATE FROM LEGACY LANGCHAIN AGENTS TO LANGGRAPHHOW TO RETRIEVE USING MULTIPLE VECTORS PER DOCUMENTHOW TO PASS MULTIMODAL DATA DIRECTLY TO MODELSHOW TO USE MULTIMODAL PROMPTSHOW TO CREATE A CUSTOM OUTPUT PARSERHOW TO USE THE OUTPUT-FIXING PARSERHOW TO PARSE JSON OUTPUTHOW TO RETRY WHEN A PARSING ERROR OCCURSHOW TO PARSE TEXT FROM MESSAGE OBJECTSHOW TO PARSE XML OUTPUTHOW TO PARSE YAML OUTPUTHOW TO USE THE PARENT DOCUMENT RETRIEVERHOW TO USE LANGCHAIN WITH DIFFERENT PYDANTIC VERSIONSHOW TO ADD CHAT HISTORYHOW TO GET A RAG APPLICATION TO ADD CITATIONSHOW TO DO PER-USER RETRIEVALHOW TO GET YOUR RAG APPLICATION TO RETURN SOURCESHOW TO STREAM RESULTS FROM YOUR RAG APPLICATIONHOW TO SPLIT JSON DATAHOW TO RECURSIVELY SPLIT TEXT BY CHARACTERSRESPONSE METADATAHOW TO PASS RUNTIME SECRETS TO RUNNABLESHOW TO DO \"SELF-QUERYING\" RETRIEVALHOW TO SPLIT TEXT BASED ON SEMANTIC SIMILARITYHOW TO CHAIN RUNNABLESHOW TO SAVE AND LOAD LANGCHAIN OBJECTSHOW TO SPLIT TEXT BY TOKENSHOW TO SPLIT HTMLHOW TO DO QUESTION ANSWERING OVER CSVSHOW TO DEAL WITH LARGE DATABASES WHEN DOING SQL QUESTION-ANSWERINGHOW TO BETTER PROMPT WHEN DOING SQL QUESTION-ANSWERINGHOW TO DO QUERY VALIDATION AS PART OF SQL QUESTION-ANSWERINGHOW TO STREAM RUNNABLESHOW TO STREAM RESPONSES FROM AN LLMHOW TO USE A TIME-WEIGHTED VECTOR STORE RETRIEVERHOW TO RETURN ARTIFACTS FROM A TOOLHOW TO USE CHAT MODELS TO CALL TOOLSHOW TO DISABLE PARALLEL TOOL CALLINGHOW TO FORCE MODELS TO CALL A TOOLHOW TO ACCESS THE RUNNABLECONFIG FROM A TOOLHOW TO PASS TOOL OUTPUTS TO CHAT MODELSHOW TO PASS RUN TIME VALUES TO TOOLSHOW TO STREAM EVENTS FROM A TOOLHOW TO STREAM TOOL CALLSHOW TO CONVERT TOOLS TO OPENAI FUNCTIONSHOW TO HANDLE TOOL ERRORSHOW TO USE FEW-SHOT PROMPTING WITH TOOL CALLINGHOW TO ADD A HUMAN-IN-THE-LOOP FOR TOOLSHOW TO BIND MODEL-SPECIFIC TOOLSHOW TO TRIM MESSAGESHOW TO CREATE AND QUERY VECTOR STORESCONCEPTUAL GUIDEAGENTSARCHITECTUREASYNC PROGRAMMING WITH LANGCHAINCALLBACKSCHAT HISTORYCHAT MODELSDOCUMENT LOADERSEMBEDDING MODELSEVALUATIONEXAMPLE SELECTORSFEW-SHOT PROMPTINGCONCEPTUAL GUIDEKEY-VALUE STORESLANGCHAIN EXPRESSION LANGUAGE (LCEL)MESSAGESMULTIMODALITYOUTPUT PARSERSPROMPT TEMPLATESRETRIEVAL AUGMENTED GENERATION (RAG)RETRIEVALRETRIEVERSRUNNABLE INTERFACESTREAMINGSTRUCTURED OUTPUTSTESTINGSTRING-IN, STRING-OUT LLMSTEXT SPLITTERSTOKENSTOOL CALLINGTOOLSTRACINGVECTOR STORESWHY LANGCHAIN?ECOSYSTEM🦜🛠️ LANGSMITH🦜🕸️ LANGGRAPHVERSIONSV0.3V0.2PYDANTIC COMPATIBILITYMIGRATING FROM V0.0 CHAINSHOW TO MIGRATE FROM V0.0 CHAINSMIGRATING FROM CONSTITUTIONALCHAINMIGRATING FROM CONVERSATIONALCHAINMIGRATING FROM CONVERSATIONALRETRIEVALCHAINMIGRATING FROM LLMCHAINMIGRATING FROM LLMMATHCHAINMIGRATING FROM LLMROUTERCHAINMIGRATING FROM MAPREDUCEDOCUMENTSCHAINMIGRATING FROM MAPRERANKDOCUMENTSCHAINMIGRATING FROM MULTIPROMPTCHAINMIGRATING FROM REFINEDOCUMENTSCHAINMIGRATING FROM RETRIEVALQAMIGRATING FROM STUFFDOCUMENTSCHAINUPGRADING TO LANGGRAPH MEMORYHOW TO MIGRATE TO LANGGRAPH MEMORYHOW TO USE BASECHATMESSAGEHISTORY WITH LANGGRAPHMIGRATING OFF CONVERSATIONBUFFERMEMORY OR CONVERSATIONSTRINGBUFFERMEMORYMIGRATING OFF CONVERSATIONBUFFERWINDOWMEMORY OR CONVERSATIONTOKENBUFFERMEMORYMIGRATING OFF CONVERSATIONSUMMARYMEMORY OR CONVERSATIONSUMMARYBUFFERMEMORYA LONG-TERM MEMORY AGENTRELEASE POLICYSECURITY POLICYHOW-TO GUIDESHOW TO CHAIN RUNNABLESON THIS PAGEHOW TO CHAIN RUNNABLES\n",
      "PREREQUISITESTHIS GUIDE ASSUMES FAMILIARITY WITH THE FOLLOWING CONCEPTS:\n",
      "LANGCHAIN EXPRESSION LANGUAGE (LCEL)\n",
      "PROMPT TEMPLATES\n",
      "CHAT MODELS\n",
      "OUTPUT PARSER\n",
      "\n",
      "ONE POINT ABOUT LANGCHAIN EXPRESSION LANGUAGE IS THAT ANY TWO RUNNABLES CAN BE \"CHAINED\" TOGETHER INTO SEQUENCES. THE OUTPUT OF THE PREVIOUS RUNNABLE'S .INVOKE() CALL IS PASSED AS INPUT TO THE NEXT RUNNABLE. THIS CAN BE DONE USING THE PIPE OPERATOR (|), OR THE MORE EXPLICIT .PIPE() METHOD, WHICH DOES THE SAME THING.\n",
      "THE RESULTING RUNNABLESEQUENCE IS ITSELF A RUNNABLE, WHICH MEANS IT CAN BE INVOKED, STREAMED, OR FURTHER CHAINED JUST LIKE ANY OTHER RUNNABLE. ADVANTAGES OF CHAINING RUNNABLES IN THIS WAY ARE EFFICIENT STREAMING (THE SEQUENCE WILL STREAM OUTPUT AS SOON AS IT IS AVAILABLE), AND DEBUGGING AND TRACING WITH TOOLS LIKE LANGSMITH.\n",
      "THE PIPE OPERATOR: |​\n",
      "TO SHOW OFF HOW THIS WORKS, LET'S GO THROUGH AN EXAMPLE. WE'LL WALK THROUGH A COMMON PATTERN IN LANGCHAIN: USING A PROMPT TEMPLATE TO FORMAT INPUT INTO A CHAT MODEL, AND FINALLY CONVERTING THE CHAT MESSAGE OUTPUT INTO A STRING WITH AN OUTPUT PARSER.\n",
      "\n",
      "SELECT CHAT MODEL:GROQ▾GROQOPENAIANTHROPICAZUREGOOGLE VERTEXAWSCOHERENVIDIAFIREWORKS AIMISTRAL AITOGETHER AIIBM WATSONXDATABRICKSXAIPIP INSTALL -QU \"LANGCHAIN[GROQ]\"IMPORT GETPASSIMPORT OSIF NOT OS.ENVIRON.GET(\"GROQ_API_KEY\"):  OS.ENVIRON[\"GROQ_API_KEY\"] = GETPASS.GETPASS(\"ENTER API KEY FOR GROQ: \")FROM LANGCHAIN.CHAT_MODELS IMPORT INIT_CHAT_MODELMODEL = INIT_CHAT_MODEL(\"LLAMA3-8B-8192\", MODEL_PROVIDER=\"GROQ\")\n",
      "FROM LANGCHAIN_CORE.OUTPUT_PARSERS IMPORT STROUTPUTPARSERFROM LANGCHAIN_CORE.PROMPTS IMPORT CHATPROMPTTEMPLATEPROMPT = CHATPROMPTTEMPLATE.FROM_TEMPLATE(\"TELL ME A JOKE ABOUT {TOPIC}\")CHAIN = PROMPT | MODEL | STROUTPUTPARSER()API REFERENCE:STROUTPUTPARSER | CHATPROMPTTEMPLATE\n",
      "PROMPTS AND MODELS ARE BOTH RUNNABLE, AND THE OUTPUT TYPE FROM THE PROMPT CALL IS THE SAME AS THE INPUT TYPE OF THE CHAT MODEL, SO WE CAN CHAIN THEM TOGETHER. WE CAN THEN INVOKE THE RESULTING SEQUENCE LIKE ANY OTHER RUNNABLE:\n",
      "CHAIN.INVOKE({\"TOPIC\": \"BEARS\"})\n",
      "\"HERE'S A BEAR JOKE FOR YOU:\\N\\NWHY DID THE BEAR DISSOLVE IN WATER?\\NBECAUSE IT WAS A POLAR BEAR!\"\n",
      "COERCION​\n",
      "WE CAN EVEN COMBINE THIS CHAIN WITH MORE RUNNABLES TO CREATE ANOTHER CHAIN. THIS MAY INVOLVE SOME INPUT/OUTPUT FORMATTING USING OTHER TYPES OF RUNNABLES, DEPENDING ON THE REQUIRED INPUTS AND OUTPUTS OF THE CHAIN COMPONENTS.\n",
      "FOR EXAMPLE, LET'S SAY WE WANTED TO COMPOSE THE JOKE GENERATING CHAIN WITH ANOTHER CHAIN THAT EVALUATES WHETHER OR NOT THE GENERATED JOKE WAS FUNNY.\n",
      "WE WOULD NEED TO BE CAREFUL WITH HOW WE FORMAT THE INPUT INTO THE NEXT CHAIN. IN THE BELOW EXAMPLE, THE DICT IN THE CHAIN IS AUTOMATICALLY PARSED AND CONVERTED INTO A RUNNABLEPARALLEL, WHICH RUNS ALL OF ITS VALUES IN PARALLEL AND RETURNS A DICT WITH THE RESULTS.\n",
      "THIS HAPPENS TO BE THE SAME FORMAT THE NEXT PROMPT TEMPLATE EXPECTS. HERE IT IS IN ACTION:\n",
      "FROM LANGCHAIN_CORE.OUTPUT_PARSERS IMPORT STROUTPUTPARSERANALYSIS_PROMPT = CHATPROMPTTEMPLATE.FROM_TEMPLATE(\"IS THIS A FUNNY JOKE? {JOKE}\")COMPOSED_CHAIN = {\"JOKE\": CHAIN} | ANALYSIS_PROMPT | MODEL | STROUTPUTPARSER()COMPOSED_CHAIN.INVOKE({\"TOPIC\": \"BEARS\"})API REFERENCE:STROUTPUTPARSER\n",
      "'HAHA, THAT\\'S A CLEVER PLAY ON WORDS! USING \"POLAR\" TO IMPLY THE BEAR DISSOLVED OR BECAME POLAR/POLARIZED WHEN PUT IN WATER. NOT THE MOST HILARIOUS JOKE EVER, BUT IT HAS A CUTE, GROAN-WORTHY PUN THAT MAKES IT MILDLY AMUSING. I APPRECIATE A GOOD PUN OR WORDPLAY JOKE.'\n",
      "FUNCTIONS WILL ALSO BE COERCED INTO RUNNABLES, SO YOU CAN ADD CUSTOM LOGIC TO YOUR CHAINS TOO. THE BELOW CHAIN RESULTS IN THE SAME LOGICAL FLOW AS BEFORE:\n",
      "COMPOSED_CHAIN_WITH_LAMBDA = (    CHAIN    | (LAMBDA INPUT: {\"JOKE\": INPUT})    | ANALYSIS_PROMPT    | MODEL    | STROUTPUTPARSER())COMPOSED_CHAIN_WITH_LAMBDA.INVOKE({\"TOPIC\": \"BEETS\"})\n",
      "\"HAHA, THAT'S A CUTE AND PUNNY JOKE! I LIKE HOW IT PLAYS ON THE IDEA OF BEETS BLUSHING OR TURNING RED LIKE SOMEONE BLUSHING. FOOD PUNS CAN BE QUITE AMUSING. WHILE NOT A TOTAL KNEE-SLAPPER, IT'S A LIGHT-HEARTED, GROAN-WORTHY DAD JOKE THAT WOULD MAKE ME CHUCKLE AND SHAKE MY HEAD. SIMPLE VEGETABLE HUMOR!\"\n",
      "HOWEVER, KEEP IN MIND THAT USING FUNCTIONS LIKE THIS MAY INTERFERE WITH OPERATIONS LIKE STREAMING. SEE THIS SECTION FOR MORE INFORMATION.\n",
      "THE .PIPE() METHOD​\n",
      "WE COULD ALSO COMPOSE THE SAME SEQUENCE USING THE .PIPE() METHOD. HERE'S WHAT THAT LOOKS LIKE:\n",
      "FROM LANGCHAIN_CORE.RUNNABLES IMPORT RUNNABLEPARALLELCOMPOSED_CHAIN_WITH_PIPE = (    RUNNABLEPARALLEL({\"JOKE\": CHAIN})    .PIPE(ANALYSIS_PROMPT)    .PIPE(MODEL)    .PIPE(STROUTPUTPARSER()))COMPOSED_CHAIN_WITH_PIPE.INVOKE({\"TOPIC\": \"BATTLESTAR GALACTICA\"})API REFERENCE:RUNNABLEPARALLEL\n",
      "\"I CANNOT REPRODUCE ANY COPYRIGHTED MATERIAL VERBATIM, BUT I CAN TRY TO ANALYZE THE HUMOR IN THE JOKE YOU PROVIDED WITHOUT QUOTING IT DIRECTLY.\\N\\NTHE JOKE PLAYS ON THE IDEA THAT THE CYLON RAIDERS, WHO ARE THE ANTAGONISTS IN THE BATTLESTAR GALACTICA UNIVERSE, FAILED TO LOCATE THE HUMAN SURVIVORS AFTER ATTACKING THEIR HOME PLANETS (THE TWELVE COLONIES) DUE TO USING AN OUTDATED AND POORLY PERFORMING OPERATING SYSTEM (WINDOWS VISTA) FOR THEIR TARGETING SYSTEMS.\\N\\NTHE HUMOR STEMS FROM THE JUXTAPOSITION OF A FUTURISTIC SCIENCE FICTION SETTING WITH A RELATABLE REAL-WORLD FRUSTRATION – THE USE OF BUGGY, SLOW, OR UNRELIABLE SOFTWARE OR TECHNOLOGY. IT POKES FUN AT THE PERCEIVED INADEQUACIES OF WINDOWS VISTA, WHICH WAS WIDELY CRITICIZED FOR ITS PERFORMANCE ISSUES AND OTHER PROBLEMS WHEN IT WAS RELEASED.\\N\\NBY ATTRIBUTING THE CYLONS' FAILURE TO LOCATE THE HUMANS TO THEIR USE OF VISTA, THE JOKE CREATES AN AMUSING AND UNEXPECTED CONNECTION BETWEEN A FICTIONAL ADVANCED RACE OF ROBOTS AND A FAMILIAR TECHNOLOGICAL ANNOYANCE EXPERIENCED BY MANY PEOPLE IN THE REAL WORLD.\\N\\NOVERALL, THE JOKE RELIES ON INCONGRUITY AND RELATABILITY TO GENERATE HUMOR, BUT WITHOUT REPRODUCING ANY COPYRIGHTED MATERIAL DIRECTLY.\"\n",
      "OR THE ABBREVIATED:\n",
      "COMPOSED_CHAIN_WITH_PIPE = RUNNABLEPARALLEL({\"JOKE\": CHAIN}).PIPE(    ANALYSIS_PROMPT, MODEL, STROUTPUTPARSER())\n",
      "RELATED​\n",
      "\n",
      "STREAMING: CHECK OUT THE STREAMING GUIDE TO UNDERSTAND THE STREAMING BEHAVIOR OF A CHAIN\n",
      "EDIT THIS PAGEWAS THIS PAGE HELPFUL?PREVIOUSHOW TO SPLIT TEXT BASED ON SEMANTIC SIMILARITYNEXTHOW TO SAVE AND LOAD LANGCHAIN OBJECTSTHE PIPE OPERATOR: |COERCIONTHE .PIPE() METHODRELATEDCOMMUNITYTWITTERGITHUBORGANIZATIONPYTHONJS/TSMOREHOMEPAGEBLOGYOUTUBECOPYRIGHT © 2025 LANGCHAIN, INC.\n",
      "\n",
      "\n",
      "          -------\n",
      "\n",
      "          THE PREVIOUS CODE ATTEMPT FAILED WITH THE FOLLOWING ERROR:\n",
      "          CANNOT IMPORT NAME 'CONVERSATIONBUFFERMEMORY' FROM 'LANGCHAIN_CORE.MEMORY' (/USERS/MJACK6/GSU_SPRING2025/MSA8700/VENV_AGENTICAI/LIB/PYTHON3.11/SITE-PACKAGES/LANGCHAIN_CORE/MEMORY.PY)\n",
      "\n",
      "          YOUR CODING TASK:\n",
      "          HOW CAN I ADD MEMORY TO AN ARBITRARY CHAIN USING LANGCHAIN?\n",
      "\n",
      "          PREVIOUS CODE ATTEMPT:\n",
      "          TO ADD MEMORY TO AN ARBITRARY CHAIN USING LANGCHAIN, YOU CAN UTILIZE MEMORY MODULES SUCH AS CONVERSATIONBUFFERMEMORY, CONVERSATIONSTRINGBUFFERMEMORY, OR CONVERSATIONSUMMARYMEMORY. HERE IS AN EXAMPLE THAT DEMONSTRATES HOW TO INTEGRATE SUCH A MEMORY MODULE INTO A SIMPLE CHAIN THAT USES A CHAT MODEL.\n",
      "          FROM LANGCHAIN_CORE.MEMORY IMPORT CONVERSATIONBUFFERMEMORY\n",
      "FROM LANGCHAIN.CHAT_MODELS IMPORT INIT_CHAT_MODEL\n",
      "FROM LANGCHAIN_CORE.PROMPTS IMPORT CHATPROMPTTEMPLATE\n",
      "FROM LANGCHAIN_CORE.OUTPUT_PARSERS IMPORT STROUTPUTPARSER\n",
      "          MEMORY = CONVERSATIONBUFFERMEMORY()\n",
      "MODEL = INIT_CHAT_MODEL('LLAMA3-8B-8192', MODEL_PROVIDER='GROQ')\n",
      "PROMPT = CHATPROMPTTEMPLATE.FROM_TEMPLATE('TELL ME A JOKE ABOUT {TOPIC}')\n",
      "CHAIN = PROMPT | MODEL | STROUTPUTPARSER()  \n",
      "# EXAMPLE OF ADDING MEMORY TO THE CHAIN \n",
      "CHAIN_WITH_MEMORY = CHAIN.PIPE(MEMORY)\n",
      "# INVOKING THE CHAIN WITH MEMORY TO KEEP TRACK OF CONVERSATION HISTORY\n",
      "RESULT = CHAIN_WITH_MEMORY.INVOKE({'TOPIC': 'SPACE'})\n",
      "PRINT(RESULT)\n",
      "\n",
      "          ANSWER WITH A DESCRIPTION OF THE CODE SOLUTION, FOLLOWED BY THE IMPORTS, AND FINALLY THE FUNCTIONING CODE BLOCK.\n",
      "          ENSURE ALL IMPORTS ARE CORRECT AND THE CODE IS EXECUTABLE.]: 2025-03-13 15:37:12.123119\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:12][✅ CREW 'CREW' COMPLETED, A374A684-6E5C-4BE6-BF93-53175854D953]: 2025-03-13 15:37:12.128408\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:12][👍 FLOW METHOD FINISHED: 'RUN_FIX']: 2025-03-13 15:37:12.128851\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:12][🤖 FLOW METHOD STARTED: 'RE_RUN_CHECK']: 2025-03-13 15:37:12.129164\u001b[00m\n",
      "---CHECKING CODE---\n",
      "---CODE IMPORT CHECK: FAILED---\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:12][👍 FLOW METHOD FINISHED: 'RE_RUN_CHECK']: 2025-03-13 15:37:12.129464\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:12][🤖 FLOW METHOD STARTED: 'RE_RUN_FIX']: 2025-03-13 15:37:12.132656\u001b[00m\n",
      "---FIXING CODE---\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:12][🚀 CREW 'CREW' STARTED, 535D9A82-D305-456D-AB3A-AB6AA6934923]: 2025-03-13 15:37:12.134052\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:12][📋 TASK STARTED: YOU ARE A CODING ASSISTANT WITH EXPERTISE IN LCEL, LANGCHAIN EXPRESSION LANGUAGE.\n",
      "          HERE IS A FULL SET OF LCEL DOCUMENTATION:\n",
      "          -------\n",
      "          \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "HOW TO CHAIN RUNNABLES | 🦜️🔗 LANGCHAIN\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "SKIP TO MAIN CONTENTJOIN US AT  INTERRUPT: THE AGENT AI CONFERENCE BY LANGCHAIN ON MAY 13 & 14 IN SAN FRANCISCO!INTEGRATIONSAPI REFERENCEMORECONTRIBUTINGPEOPLEERROR REFERENCELANGSMITHLANGGRAPHLANGCHAIN HUBLANGCHAIN JS/TSV0.3V0.3V0.2V0.1💬SEARCHINTRODUCTIONTUTORIALSBUILD A QUESTION ANSWERING APPLICATION OVER A GRAPH DATABASETUTORIALSBUILD A SIMPLE LLM APPLICATION WITH CHAT MODELS AND PROMPT TEMPLATESBUILD A CHATBOTBUILD A RETRIEVAL AUGMENTED GENERATION (RAG) APP: PART 2BUILD AN EXTRACTION CHAINBUILD AN AGENTTAGGINGBUILD A RETRIEVAL AUGMENTED GENERATION (RAG) APP: PART 1BUILD A SEMANTIC SEARCH ENGINEBUILD A QUESTION/ANSWERING SYSTEM OVER SQL DATASUMMARIZE TEXTHOW-TO GUIDESHOW-TO GUIDESHOW TO USE TOOLS IN A CHAINHOW TO USE A VECTORSTORE AS A RETRIEVERHOW TO ADD MEMORY TO CHATBOTSHOW TO USE EXAMPLE SELECTORSHOW TO ADD A SEMANTIC LAYER OVER GRAPH DATABASEHOW TO INVOKE RUNNABLES IN PARALLELHOW TO STREAM CHAT MODEL RESPONSESHOW TO ADD DEFAULT INVOCATION ARGS TO A RUNNABLEHOW TO ADD RETRIEVAL TO CHATBOTSHOW TO USE FEW SHOT EXAMPLES IN CHAT MODELSHOW TO DO TOOL/FUNCTION CALLINGHOW TO INSTALL LANGCHAIN PACKAGESHOW TO ADD EXAMPLES TO THE PROMPT FOR QUERY ANALYSISHOW TO USE FEW SHOT EXAMPLESHOW TO RUN CUSTOM FUNCTIONSHOW TO USE OUTPUT PARSERS TO PARSE AN LLM RESPONSE INTO STRUCTURED FORMATHOW TO HANDLE CASES WHERE NO QUERIES ARE GENERATEDHOW TO ROUTE BETWEEN SUB-CHAINSHOW TO RETURN STRUCTURED DATA FROM A MODELHOW TO SUMMARIZE TEXT THROUGH PARALLELIZATIONHOW TO SUMMARIZE TEXT THROUGH ITERATIVE REFINEMENTHOW TO SUMMARIZE TEXT IN A SINGLE LLM CALLHOW TO USE TOOLKITSHOW TO ADD AD-HOC TOOL CALLING CAPABILITY TO LLMS AND CHAT MODELSBUILD AN AGENT WITH AGENTEXECUTOR (LEGACY)HOW TO CONSTRUCT KNOWLEDGE GRAPHSHOW TO PARTIALLY FORMAT PROMPT TEMPLATESHOW TO HANDLE MULTIPLE QUERIES WHEN DOING QUERY ANALYSISHOW TO USE BUILT-IN TOOLS AND TOOLKITSHOW TO PASS THROUGH ARGUMENTS FROM ONE STEP TO THE NEXTHOW TO COMPOSE PROMPTS TOGETHERHOW TO HANDLE MULTIPLE RETRIEVERS WHEN DOING QUERY ANALYSISHOW TO ADD VALUES TO A CHAIN'S STATEHOW TO CONSTRUCT FILTERS FOR QUERY ANALYSISHOW TO CONFIGURE RUNTIME CHAIN INTERNALSHOW DEAL WITH HIGH CARDINALITY CATEGORICALS WHEN DOING QUERY ANALYSISCUSTOM DOCUMENT LOADERHOW TO USE THE MULTIQUERYRETRIEVERHOW TO ADD SCORES TO RETRIEVER RESULTSCACHINGHOW TO USE CALLBACKS IN ASYNC ENVIRONMENTSHOW TO ATTACH CALLBACKS TO A RUNNABLEHOW TO PROPAGATE CALLBACKS  CONSTRUCTORHOW TO DISPATCH CUSTOM CALLBACK EVENTSHOW TO PASS CALLBACKS IN AT RUNTIMEHOW TO SPLIT BY CHARACTERHOW TO CACHE CHAT MODEL RESPONSESHOW TO HANDLE RATE LIMITSHOW TO INIT ANY MODEL IN ONE LINEHOW TO TRACK TOKEN USAGE IN CHATMODELSHOW TO ADD TOOLS TO CHATBOTSHOW TO SPLIT CODEHOW TO DO RETRIEVAL WITH CONTEXTUAL COMPRESSIONHOW TO CONVERT RUNNABLES TO TOOLSHOW TO CREATE CUSTOM CALLBACK HANDLERSHOW TO CREATE A CUSTOM CHAT MODEL CLASSCUSTOM EMBEDDINGSHOW TO CREATE A CUSTOM LLM CLASSCUSTOM RETRIEVERHOW TO CREATE TOOLSHOW TO DEBUG YOUR LLM APPSHOW TO LOAD CSVSHOW TO LOAD DOCUMENTS FROM A DIRECTORYHOW TO LOAD HTMLHOW TO LOAD JSONHOW TO LOAD MARKDOWNHOW TO LOAD MICROSOFT OFFICE FILESHOW TO LOAD PDFSHOW TO LOAD WEB PAGESHOW TO CREATE A DYNAMIC (SELF-CONSTRUCTING) CHAINTEXT EMBEDDING MODELSHOW TO COMBINE RESULTS FROM MULTIPLE RETRIEVERSHOW TO SELECT EXAMPLES FROM A LANGSMITH DATASETHOW TO SELECT EXAMPLES BY LENGTHHOW TO SELECT EXAMPLES BY MAXIMAL MARGINAL RELEVANCE (MMR)HOW TO SELECT EXAMPLES BY N-GRAM OVERLAPHOW TO SELECT EXAMPLES BY SIMILARITYHOW TO USE REFERENCE EXAMPLES WHEN DOING EXTRACTIONHOW TO HANDLE LONG TEXT WHEN DOING EXTRACTIONHOW TO USE PROMPTING ALONE (NO TOOL CALLING) TO DO EXTRACTIONHOW TO ADD FALLBACKS TO A RUNNABLEHOW TO FILTER MESSAGESHYBRID SEARCHHOW TO USE THE LANGCHAIN INDEXING APIHOW TO INSPECT RUNNABLESLANGCHAIN EXPRESSION LANGUAGE CHEATSHEETHOW TO CACHE LLM RESPONSESHOW TO TRACK TOKEN USAGE FOR LLMSRUN MODELS LOCALLYHOW TO GET LOG PROBABILITIESHOW TO REORDER RETRIEVED RESULTS TO MITIGATE THE \"LOST IN THE MIDDLE\" EFFECTHOW TO SPLIT MARKDOWN BY HEADERSHOW TO MERGE CONSECUTIVE MESSAGES OF THE SAME TYPEHOW TO ADD MESSAGE HISTORYHOW TO MIGRATE FROM LEGACY LANGCHAIN AGENTS TO LANGGRAPHHOW TO RETRIEVE USING MULTIPLE VECTORS PER DOCUMENTHOW TO PASS MULTIMODAL DATA DIRECTLY TO MODELSHOW TO USE MULTIMODAL PROMPTSHOW TO CREATE A CUSTOM OUTPUT PARSERHOW TO USE THE OUTPUT-FIXING PARSERHOW TO PARSE JSON OUTPUTHOW TO RETRY WHEN A PARSING ERROR OCCURSHOW TO PARSE TEXT FROM MESSAGE OBJECTSHOW TO PARSE XML OUTPUTHOW TO PARSE YAML OUTPUTHOW TO USE THE PARENT DOCUMENT RETRIEVERHOW TO USE LANGCHAIN WITH DIFFERENT PYDANTIC VERSIONSHOW TO ADD CHAT HISTORYHOW TO GET A RAG APPLICATION TO ADD CITATIONSHOW TO DO PER-USER RETRIEVALHOW TO GET YOUR RAG APPLICATION TO RETURN SOURCESHOW TO STREAM RESULTS FROM YOUR RAG APPLICATIONHOW TO SPLIT JSON DATAHOW TO RECURSIVELY SPLIT TEXT BY CHARACTERSRESPONSE METADATAHOW TO PASS RUNTIME SECRETS TO RUNNABLESHOW TO DO \"SELF-QUERYING\" RETRIEVALHOW TO SPLIT TEXT BASED ON SEMANTIC SIMILARITYHOW TO CHAIN RUNNABLESHOW TO SAVE AND LOAD LANGCHAIN OBJECTSHOW TO SPLIT TEXT BY TOKENSHOW TO SPLIT HTMLHOW TO DO QUESTION ANSWERING OVER CSVSHOW TO DEAL WITH LARGE DATABASES WHEN DOING SQL QUESTION-ANSWERINGHOW TO BETTER PROMPT WHEN DOING SQL QUESTION-ANSWERINGHOW TO DO QUERY VALIDATION AS PART OF SQL QUESTION-ANSWERINGHOW TO STREAM RUNNABLESHOW TO STREAM RESPONSES FROM AN LLMHOW TO USE A TIME-WEIGHTED VECTOR STORE RETRIEVERHOW TO RETURN ARTIFACTS FROM A TOOLHOW TO USE CHAT MODELS TO CALL TOOLSHOW TO DISABLE PARALLEL TOOL CALLINGHOW TO FORCE MODELS TO CALL A TOOLHOW TO ACCESS THE RUNNABLECONFIG FROM A TOOLHOW TO PASS TOOL OUTPUTS TO CHAT MODELSHOW TO PASS RUN TIME VALUES TO TOOLSHOW TO STREAM EVENTS FROM A TOOLHOW TO STREAM TOOL CALLSHOW TO CONVERT TOOLS TO OPENAI FUNCTIONSHOW TO HANDLE TOOL ERRORSHOW TO USE FEW-SHOT PROMPTING WITH TOOL CALLINGHOW TO ADD A HUMAN-IN-THE-LOOP FOR TOOLSHOW TO BIND MODEL-SPECIFIC TOOLSHOW TO TRIM MESSAGESHOW TO CREATE AND QUERY VECTOR STORESCONCEPTUAL GUIDEAGENTSARCHITECTUREASYNC PROGRAMMING WITH LANGCHAINCALLBACKSCHAT HISTORYCHAT MODELSDOCUMENT LOADERSEMBEDDING MODELSEVALUATIONEXAMPLE SELECTORSFEW-SHOT PROMPTINGCONCEPTUAL GUIDEKEY-VALUE STORESLANGCHAIN EXPRESSION LANGUAGE (LCEL)MESSAGESMULTIMODALITYOUTPUT PARSERSPROMPT TEMPLATESRETRIEVAL AUGMENTED GENERATION (RAG)RETRIEVALRETRIEVERSRUNNABLE INTERFACESTREAMINGSTRUCTURED OUTPUTSTESTINGSTRING-IN, STRING-OUT LLMSTEXT SPLITTERSTOKENSTOOL CALLINGTOOLSTRACINGVECTOR STORESWHY LANGCHAIN?ECOSYSTEM🦜🛠️ LANGSMITH🦜🕸️ LANGGRAPHVERSIONSV0.3V0.2PYDANTIC COMPATIBILITYMIGRATING FROM V0.0 CHAINSHOW TO MIGRATE FROM V0.0 CHAINSMIGRATING FROM CONSTITUTIONALCHAINMIGRATING FROM CONVERSATIONALCHAINMIGRATING FROM CONVERSATIONALRETRIEVALCHAINMIGRATING FROM LLMCHAINMIGRATING FROM LLMMATHCHAINMIGRATING FROM LLMROUTERCHAINMIGRATING FROM MAPREDUCEDOCUMENTSCHAINMIGRATING FROM MAPRERANKDOCUMENTSCHAINMIGRATING FROM MULTIPROMPTCHAINMIGRATING FROM REFINEDOCUMENTSCHAINMIGRATING FROM RETRIEVALQAMIGRATING FROM STUFFDOCUMENTSCHAINUPGRADING TO LANGGRAPH MEMORYHOW TO MIGRATE TO LANGGRAPH MEMORYHOW TO USE BASECHATMESSAGEHISTORY WITH LANGGRAPHMIGRATING OFF CONVERSATIONBUFFERMEMORY OR CONVERSATIONSTRINGBUFFERMEMORYMIGRATING OFF CONVERSATIONBUFFERWINDOWMEMORY OR CONVERSATIONTOKENBUFFERMEMORYMIGRATING OFF CONVERSATIONSUMMARYMEMORY OR CONVERSATIONSUMMARYBUFFERMEMORYA LONG-TERM MEMORY AGENTRELEASE POLICYSECURITY POLICYHOW-TO GUIDESHOW TO CHAIN RUNNABLESON THIS PAGEHOW TO CHAIN RUNNABLES\n",
      "PREREQUISITESTHIS GUIDE ASSUMES FAMILIARITY WITH THE FOLLOWING CONCEPTS:\n",
      "LANGCHAIN EXPRESSION LANGUAGE (LCEL)\n",
      "PROMPT TEMPLATES\n",
      "CHAT MODELS\n",
      "OUTPUT PARSER\n",
      "\n",
      "ONE POINT ABOUT LANGCHAIN EXPRESSION LANGUAGE IS THAT ANY TWO RUNNABLES CAN BE \"CHAINED\" TOGETHER INTO SEQUENCES. THE OUTPUT OF THE PREVIOUS RUNNABLE'S .INVOKE() CALL IS PASSED AS INPUT TO THE NEXT RUNNABLE. THIS CAN BE DONE USING THE PIPE OPERATOR (|), OR THE MORE EXPLICIT .PIPE() METHOD, WHICH DOES THE SAME THING.\n",
      "THE RESULTING RUNNABLESEQUENCE IS ITSELF A RUNNABLE, WHICH MEANS IT CAN BE INVOKED, STREAMED, OR FURTHER CHAINED JUST LIKE ANY OTHER RUNNABLE. ADVANTAGES OF CHAINING RUNNABLES IN THIS WAY ARE EFFICIENT STREAMING (THE SEQUENCE WILL STREAM OUTPUT AS SOON AS IT IS AVAILABLE), AND DEBUGGING AND TRACING WITH TOOLS LIKE LANGSMITH.\n",
      "THE PIPE OPERATOR: |​\n",
      "TO SHOW OFF HOW THIS WORKS, LET'S GO THROUGH AN EXAMPLE. WE'LL WALK THROUGH A COMMON PATTERN IN LANGCHAIN: USING A PROMPT TEMPLATE TO FORMAT INPUT INTO A CHAT MODEL, AND FINALLY CONVERTING THE CHAT MESSAGE OUTPUT INTO A STRING WITH AN OUTPUT PARSER.\n",
      "\n",
      "SELECT CHAT MODEL:GROQ▾GROQOPENAIANTHROPICAZUREGOOGLE VERTEXAWSCOHERENVIDIAFIREWORKS AIMISTRAL AITOGETHER AIIBM WATSONXDATABRICKSXAIPIP INSTALL -QU \"LANGCHAIN[GROQ]\"IMPORT GETPASSIMPORT OSIF NOT OS.ENVIRON.GET(\"GROQ_API_KEY\"):  OS.ENVIRON[\"GROQ_API_KEY\"] = GETPASS.GETPASS(\"ENTER API KEY FOR GROQ: \")FROM LANGCHAIN.CHAT_MODELS IMPORT INIT_CHAT_MODELMODEL = INIT_CHAT_MODEL(\"LLAMA3-8B-8192\", MODEL_PROVIDER=\"GROQ\")\n",
      "FROM LANGCHAIN_CORE.OUTPUT_PARSERS IMPORT STROUTPUTPARSERFROM LANGCHAIN_CORE.PROMPTS IMPORT CHATPROMPTTEMPLATEPROMPT = CHATPROMPTTEMPLATE.FROM_TEMPLATE(\"TELL ME A JOKE ABOUT {TOPIC}\")CHAIN = PROMPT | MODEL | STROUTPUTPARSER()API REFERENCE:STROUTPUTPARSER | CHATPROMPTTEMPLATE\n",
      "PROMPTS AND MODELS ARE BOTH RUNNABLE, AND THE OUTPUT TYPE FROM THE PROMPT CALL IS THE SAME AS THE INPUT TYPE OF THE CHAT MODEL, SO WE CAN CHAIN THEM TOGETHER. WE CAN THEN INVOKE THE RESULTING SEQUENCE LIKE ANY OTHER RUNNABLE:\n",
      "CHAIN.INVOKE({\"TOPIC\": \"BEARS\"})\n",
      "\"HERE'S A BEAR JOKE FOR YOU:\\N\\NWHY DID THE BEAR DISSOLVE IN WATER?\\NBECAUSE IT WAS A POLAR BEAR!\"\n",
      "COERCION​\n",
      "WE CAN EVEN COMBINE THIS CHAIN WITH MORE RUNNABLES TO CREATE ANOTHER CHAIN. THIS MAY INVOLVE SOME INPUT/OUTPUT FORMATTING USING OTHER TYPES OF RUNNABLES, DEPENDING ON THE REQUIRED INPUTS AND OUTPUTS OF THE CHAIN COMPONENTS.\n",
      "FOR EXAMPLE, LET'S SAY WE WANTED TO COMPOSE THE JOKE GENERATING CHAIN WITH ANOTHER CHAIN THAT EVALUATES WHETHER OR NOT THE GENERATED JOKE WAS FUNNY.\n",
      "WE WOULD NEED TO BE CAREFUL WITH HOW WE FORMAT THE INPUT INTO THE NEXT CHAIN. IN THE BELOW EXAMPLE, THE DICT IN THE CHAIN IS AUTOMATICALLY PARSED AND CONVERTED INTO A RUNNABLEPARALLEL, WHICH RUNS ALL OF ITS VALUES IN PARALLEL AND RETURNS A DICT WITH THE RESULTS.\n",
      "THIS HAPPENS TO BE THE SAME FORMAT THE NEXT PROMPT TEMPLATE EXPECTS. HERE IT IS IN ACTION:\n",
      "FROM LANGCHAIN_CORE.OUTPUT_PARSERS IMPORT STROUTPUTPARSERANALYSIS_PROMPT = CHATPROMPTTEMPLATE.FROM_TEMPLATE(\"IS THIS A FUNNY JOKE? {JOKE}\")COMPOSED_CHAIN = {\"JOKE\": CHAIN} | ANALYSIS_PROMPT | MODEL | STROUTPUTPARSER()COMPOSED_CHAIN.INVOKE({\"TOPIC\": \"BEARS\"})API REFERENCE:STROUTPUTPARSER\n",
      "'HAHA, THAT\\'S A CLEVER PLAY ON WORDS! USING \"POLAR\" TO IMPLY THE BEAR DISSOLVED OR BECAME POLAR/POLARIZED WHEN PUT IN WATER. NOT THE MOST HILARIOUS JOKE EVER, BUT IT HAS A CUTE, GROAN-WORTHY PUN THAT MAKES IT MILDLY AMUSING. I APPRECIATE A GOOD PUN OR WORDPLAY JOKE.'\n",
      "FUNCTIONS WILL ALSO BE COERCED INTO RUNNABLES, SO YOU CAN ADD CUSTOM LOGIC TO YOUR CHAINS TOO. THE BELOW CHAIN RESULTS IN THE SAME LOGICAL FLOW AS BEFORE:\n",
      "COMPOSED_CHAIN_WITH_LAMBDA = (    CHAIN    | (LAMBDA INPUT: {\"JOKE\": INPUT})    | ANALYSIS_PROMPT    | MODEL    | STROUTPUTPARSER())COMPOSED_CHAIN_WITH_LAMBDA.INVOKE({\"TOPIC\": \"BEETS\"})\n",
      "\"HAHA, THAT'S A CUTE AND PUNNY JOKE! I LIKE HOW IT PLAYS ON THE IDEA OF BEETS BLUSHING OR TURNING RED LIKE SOMEONE BLUSHING. FOOD PUNS CAN BE QUITE AMUSING. WHILE NOT A TOTAL KNEE-SLAPPER, IT'S A LIGHT-HEARTED, GROAN-WORTHY DAD JOKE THAT WOULD MAKE ME CHUCKLE AND SHAKE MY HEAD. SIMPLE VEGETABLE HUMOR!\"\n",
      "HOWEVER, KEEP IN MIND THAT USING FUNCTIONS LIKE THIS MAY INTERFERE WITH OPERATIONS LIKE STREAMING. SEE THIS SECTION FOR MORE INFORMATION.\n",
      "THE .PIPE() METHOD​\n",
      "WE COULD ALSO COMPOSE THE SAME SEQUENCE USING THE .PIPE() METHOD. HERE'S WHAT THAT LOOKS LIKE:\n",
      "FROM LANGCHAIN_CORE.RUNNABLES IMPORT RUNNABLEPARALLELCOMPOSED_CHAIN_WITH_PIPE = (    RUNNABLEPARALLEL({\"JOKE\": CHAIN})    .PIPE(ANALYSIS_PROMPT)    .PIPE(MODEL)    .PIPE(STROUTPUTPARSER()))COMPOSED_CHAIN_WITH_PIPE.INVOKE({\"TOPIC\": \"BATTLESTAR GALACTICA\"})API REFERENCE:RUNNABLEPARALLEL\n",
      "\"I CANNOT REPRODUCE ANY COPYRIGHTED MATERIAL VERBATIM, BUT I CAN TRY TO ANALYZE THE HUMOR IN THE JOKE YOU PROVIDED WITHOUT QUOTING IT DIRECTLY.\\N\\NTHE JOKE PLAYS ON THE IDEA THAT THE CYLON RAIDERS, WHO ARE THE ANTAGONISTS IN THE BATTLESTAR GALACTICA UNIVERSE, FAILED TO LOCATE THE HUMAN SURVIVORS AFTER ATTACKING THEIR HOME PLANETS (THE TWELVE COLONIES) DUE TO USING AN OUTDATED AND POORLY PERFORMING OPERATING SYSTEM (WINDOWS VISTA) FOR THEIR TARGETING SYSTEMS.\\N\\NTHE HUMOR STEMS FROM THE JUXTAPOSITION OF A FUTURISTIC SCIENCE FICTION SETTING WITH A RELATABLE REAL-WORLD FRUSTRATION – THE USE OF BUGGY, SLOW, OR UNRELIABLE SOFTWARE OR TECHNOLOGY. IT POKES FUN AT THE PERCEIVED INADEQUACIES OF WINDOWS VISTA, WHICH WAS WIDELY CRITICIZED FOR ITS PERFORMANCE ISSUES AND OTHER PROBLEMS WHEN IT WAS RELEASED.\\N\\NBY ATTRIBUTING THE CYLONS' FAILURE TO LOCATE THE HUMANS TO THEIR USE OF VISTA, THE JOKE CREATES AN AMUSING AND UNEXPECTED CONNECTION BETWEEN A FICTIONAL ADVANCED RACE OF ROBOTS AND A FAMILIAR TECHNOLOGICAL ANNOYANCE EXPERIENCED BY MANY PEOPLE IN THE REAL WORLD.\\N\\NOVERALL, THE JOKE RELIES ON INCONGRUITY AND RELATABILITY TO GENERATE HUMOR, BUT WITHOUT REPRODUCING ANY COPYRIGHTED MATERIAL DIRECTLY.\"\n",
      "OR THE ABBREVIATED:\n",
      "COMPOSED_CHAIN_WITH_PIPE = RUNNABLEPARALLEL({\"JOKE\": CHAIN}).PIPE(    ANALYSIS_PROMPT, MODEL, STROUTPUTPARSER())\n",
      "RELATED​\n",
      "\n",
      "STREAMING: CHECK OUT THE STREAMING GUIDE TO UNDERSTAND THE STREAMING BEHAVIOR OF A CHAIN\n",
      "EDIT THIS PAGEWAS THIS PAGE HELPFUL?PREVIOUSHOW TO SPLIT TEXT BASED ON SEMANTIC SIMILARITYNEXTHOW TO SAVE AND LOAD LANGCHAIN OBJECTSTHE PIPE OPERATOR: |COERCIONTHE .PIPE() METHODRELATEDCOMMUNITYTWITTERGITHUBORGANIZATIONPYTHONJS/TSMOREHOMEPAGEBLOGYOUTUBECOPYRIGHT © 2025 LANGCHAIN, INC.\n",
      "\n",
      "\n",
      "          -------\n",
      "\n",
      "          THE PREVIOUS CODE ATTEMPT FAILED WITH THE FOLLOWING ERROR:\n",
      "          CANNOT IMPORT NAME 'CONVERSATIONSUMMARYMEMORY' FROM 'LANGCHAIN_CORE.MEMORY' (/USERS/MJACK6/GSU_SPRING2025/MSA8700/VENV_AGENTICAI/LIB/PYTHON3.11/SITE-PACKAGES/LANGCHAIN_CORE/MEMORY.PY)\n",
      "\n",
      "          YOUR CODING TASK:\n",
      "          HOW CAN I ADD MEMORY TO AN ARBITRARY CHAIN USING LANGCHAIN?\n",
      "\n",
      "          PREVIOUS CODE ATTEMPT:\n",
      "          TO ADD MEMORY TO AN ARBITRARY CHAIN USING LANGCHAIN, IT'S IMPORTANT TO SWITCH TO COMPATIBLE MEMORY MODULES. THE ERROR INDICATES AN ISSUE WITH IMPORTING `CONVERSATIONBUFFERMEMORY` FROM `LANGCHAIN_CORE.MEMORY`, WHICH MIGHT HAVE BEEN DEPRECATED OR INCORRECTLY IMPORTED. BELOW IS A CORRECT APPROACH TO INTEGRATE MEMORY USING LANGCHAIN.\n",
      "          FROM LANGCHAIN_CORE.MEMORY IMPORT CONVERSATIONSUMMARYMEMORY\n",
      "FROM LANGCHAIN.CHAT_MODELS IMPORT INIT_CHAT_MODEL\n",
      "FROM LANGCHAIN_CORE.PROMPTS IMPORT CHATPROMPTTEMPLATE\n",
      "FROM LANGCHAIN_CORE.OUTPUT_PARSERS IMPORT STROUTPUTPARSER\n",
      "          MEMORY = CONVERSATIONSUMMARYMEMORY()\n",
      "MODEL = INIT_CHAT_MODEL('LLAMA3-8B-8192', MODEL_PROVIDER='GROQ')\n",
      "PROMPT = CHATPROMPTTEMPLATE.FROM_TEMPLATE('TELL ME A JOKE ABOUT {TOPIC}')\n",
      "CHAIN = PROMPT | MODEL | STROUTPUTPARSER()\n",
      "\n",
      "# EXAMPLE OF ADDING MEMORY TO THE CHAIN\n",
      "CHAIN_WITH_MEMORY = CHAIN.PIPE(MEMORY)\n",
      "\n",
      "# INVOKING THE CHAIN WITH MEMORY TO KEEP TRACK OF CONVERSATION HISTORY\n",
      "RESULT = CHAIN_WITH_MEMORY.INVOKE({'TOPIC': 'SPACE'})\n",
      "PRINT(RESULT)\n",
      "\n",
      "          ANSWER WITH A DESCRIPTION OF THE CODE SOLUTION, FOLLOWED BY THE IMPORTS, AND FINALLY THE FUNCTIONING CODE BLOCK.\n",
      "          ENSURE ALL IMPORTS ARE CORRECT AND THE CODE IS EXECUTABLE.]: 2025-03-13 15:37:12.136737\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:12][🤖 AGENT 'CODING ASSISTANT' STARTED TASK]: 2025-03-13 15:37:12.137420\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:12][🤖 LLM CALL STARTED]: 2025-03-13 15:37:12.137554\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:15][✅ LLM CALL COMPLETED]: 2025-03-13 15:37:15.464986\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:15][✅ AGENT 'CODING ASSISTANT' COMPLETED TASK]: 2025-03-13 15:37:15.466105\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:15][✅ TASK COMPLETED: YOU ARE A CODING ASSISTANT WITH EXPERTISE IN LCEL, LANGCHAIN EXPRESSION LANGUAGE.\n",
      "          HERE IS A FULL SET OF LCEL DOCUMENTATION:\n",
      "          -------\n",
      "          \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "HOW TO CHAIN RUNNABLES | 🦜️🔗 LANGCHAIN\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "SKIP TO MAIN CONTENTJOIN US AT  INTERRUPT: THE AGENT AI CONFERENCE BY LANGCHAIN ON MAY 13 & 14 IN SAN FRANCISCO!INTEGRATIONSAPI REFERENCEMORECONTRIBUTINGPEOPLEERROR REFERENCELANGSMITHLANGGRAPHLANGCHAIN HUBLANGCHAIN JS/TSV0.3V0.3V0.2V0.1💬SEARCHINTRODUCTIONTUTORIALSBUILD A QUESTION ANSWERING APPLICATION OVER A GRAPH DATABASETUTORIALSBUILD A SIMPLE LLM APPLICATION WITH CHAT MODELS AND PROMPT TEMPLATESBUILD A CHATBOTBUILD A RETRIEVAL AUGMENTED GENERATION (RAG) APP: PART 2BUILD AN EXTRACTION CHAINBUILD AN AGENTTAGGINGBUILD A RETRIEVAL AUGMENTED GENERATION (RAG) APP: PART 1BUILD A SEMANTIC SEARCH ENGINEBUILD A QUESTION/ANSWERING SYSTEM OVER SQL DATASUMMARIZE TEXTHOW-TO GUIDESHOW-TO GUIDESHOW TO USE TOOLS IN A CHAINHOW TO USE A VECTORSTORE AS A RETRIEVERHOW TO ADD MEMORY TO CHATBOTSHOW TO USE EXAMPLE SELECTORSHOW TO ADD A SEMANTIC LAYER OVER GRAPH DATABASEHOW TO INVOKE RUNNABLES IN PARALLELHOW TO STREAM CHAT MODEL RESPONSESHOW TO ADD DEFAULT INVOCATION ARGS TO A RUNNABLEHOW TO ADD RETRIEVAL TO CHATBOTSHOW TO USE FEW SHOT EXAMPLES IN CHAT MODELSHOW TO DO TOOL/FUNCTION CALLINGHOW TO INSTALL LANGCHAIN PACKAGESHOW TO ADD EXAMPLES TO THE PROMPT FOR QUERY ANALYSISHOW TO USE FEW SHOT EXAMPLESHOW TO RUN CUSTOM FUNCTIONSHOW TO USE OUTPUT PARSERS TO PARSE AN LLM RESPONSE INTO STRUCTURED FORMATHOW TO HANDLE CASES WHERE NO QUERIES ARE GENERATEDHOW TO ROUTE BETWEEN SUB-CHAINSHOW TO RETURN STRUCTURED DATA FROM A MODELHOW TO SUMMARIZE TEXT THROUGH PARALLELIZATIONHOW TO SUMMARIZE TEXT THROUGH ITERATIVE REFINEMENTHOW TO SUMMARIZE TEXT IN A SINGLE LLM CALLHOW TO USE TOOLKITSHOW TO ADD AD-HOC TOOL CALLING CAPABILITY TO LLMS AND CHAT MODELSBUILD AN AGENT WITH AGENTEXECUTOR (LEGACY)HOW TO CONSTRUCT KNOWLEDGE GRAPHSHOW TO PARTIALLY FORMAT PROMPT TEMPLATESHOW TO HANDLE MULTIPLE QUERIES WHEN DOING QUERY ANALYSISHOW TO USE BUILT-IN TOOLS AND TOOLKITSHOW TO PASS THROUGH ARGUMENTS FROM ONE STEP TO THE NEXTHOW TO COMPOSE PROMPTS TOGETHERHOW TO HANDLE MULTIPLE RETRIEVERS WHEN DOING QUERY ANALYSISHOW TO ADD VALUES TO A CHAIN'S STATEHOW TO CONSTRUCT FILTERS FOR QUERY ANALYSISHOW TO CONFIGURE RUNTIME CHAIN INTERNALSHOW DEAL WITH HIGH CARDINALITY CATEGORICALS WHEN DOING QUERY ANALYSISCUSTOM DOCUMENT LOADERHOW TO USE THE MULTIQUERYRETRIEVERHOW TO ADD SCORES TO RETRIEVER RESULTSCACHINGHOW TO USE CALLBACKS IN ASYNC ENVIRONMENTSHOW TO ATTACH CALLBACKS TO A RUNNABLEHOW TO PROPAGATE CALLBACKS  CONSTRUCTORHOW TO DISPATCH CUSTOM CALLBACK EVENTSHOW TO PASS CALLBACKS IN AT RUNTIMEHOW TO SPLIT BY CHARACTERHOW TO CACHE CHAT MODEL RESPONSESHOW TO HANDLE RATE LIMITSHOW TO INIT ANY MODEL IN ONE LINEHOW TO TRACK TOKEN USAGE IN CHATMODELSHOW TO ADD TOOLS TO CHATBOTSHOW TO SPLIT CODEHOW TO DO RETRIEVAL WITH CONTEXTUAL COMPRESSIONHOW TO CONVERT RUNNABLES TO TOOLSHOW TO CREATE CUSTOM CALLBACK HANDLERSHOW TO CREATE A CUSTOM CHAT MODEL CLASSCUSTOM EMBEDDINGSHOW TO CREATE A CUSTOM LLM CLASSCUSTOM RETRIEVERHOW TO CREATE TOOLSHOW TO DEBUG YOUR LLM APPSHOW TO LOAD CSVSHOW TO LOAD DOCUMENTS FROM A DIRECTORYHOW TO LOAD HTMLHOW TO LOAD JSONHOW TO LOAD MARKDOWNHOW TO LOAD MICROSOFT OFFICE FILESHOW TO LOAD PDFSHOW TO LOAD WEB PAGESHOW TO CREATE A DYNAMIC (SELF-CONSTRUCTING) CHAINTEXT EMBEDDING MODELSHOW TO COMBINE RESULTS FROM MULTIPLE RETRIEVERSHOW TO SELECT EXAMPLES FROM A LANGSMITH DATASETHOW TO SELECT EXAMPLES BY LENGTHHOW TO SELECT EXAMPLES BY MAXIMAL MARGINAL RELEVANCE (MMR)HOW TO SELECT EXAMPLES BY N-GRAM OVERLAPHOW TO SELECT EXAMPLES BY SIMILARITYHOW TO USE REFERENCE EXAMPLES WHEN DOING EXTRACTIONHOW TO HANDLE LONG TEXT WHEN DOING EXTRACTIONHOW TO USE PROMPTING ALONE (NO TOOL CALLING) TO DO EXTRACTIONHOW TO ADD FALLBACKS TO A RUNNABLEHOW TO FILTER MESSAGESHYBRID SEARCHHOW TO USE THE LANGCHAIN INDEXING APIHOW TO INSPECT RUNNABLESLANGCHAIN EXPRESSION LANGUAGE CHEATSHEETHOW TO CACHE LLM RESPONSESHOW TO TRACK TOKEN USAGE FOR LLMSRUN MODELS LOCALLYHOW TO GET LOG PROBABILITIESHOW TO REORDER RETRIEVED RESULTS TO MITIGATE THE \"LOST IN THE MIDDLE\" EFFECTHOW TO SPLIT MARKDOWN BY HEADERSHOW TO MERGE CONSECUTIVE MESSAGES OF THE SAME TYPEHOW TO ADD MESSAGE HISTORYHOW TO MIGRATE FROM LEGACY LANGCHAIN AGENTS TO LANGGRAPHHOW TO RETRIEVE USING MULTIPLE VECTORS PER DOCUMENTHOW TO PASS MULTIMODAL DATA DIRECTLY TO MODELSHOW TO USE MULTIMODAL PROMPTSHOW TO CREATE A CUSTOM OUTPUT PARSERHOW TO USE THE OUTPUT-FIXING PARSERHOW TO PARSE JSON OUTPUTHOW TO RETRY WHEN A PARSING ERROR OCCURSHOW TO PARSE TEXT FROM MESSAGE OBJECTSHOW TO PARSE XML OUTPUTHOW TO PARSE YAML OUTPUTHOW TO USE THE PARENT DOCUMENT RETRIEVERHOW TO USE LANGCHAIN WITH DIFFERENT PYDANTIC VERSIONSHOW TO ADD CHAT HISTORYHOW TO GET A RAG APPLICATION TO ADD CITATIONSHOW TO DO PER-USER RETRIEVALHOW TO GET YOUR RAG APPLICATION TO RETURN SOURCESHOW TO STREAM RESULTS FROM YOUR RAG APPLICATIONHOW TO SPLIT JSON DATAHOW TO RECURSIVELY SPLIT TEXT BY CHARACTERSRESPONSE METADATAHOW TO PASS RUNTIME SECRETS TO RUNNABLESHOW TO DO \"SELF-QUERYING\" RETRIEVALHOW TO SPLIT TEXT BASED ON SEMANTIC SIMILARITYHOW TO CHAIN RUNNABLESHOW TO SAVE AND LOAD LANGCHAIN OBJECTSHOW TO SPLIT TEXT BY TOKENSHOW TO SPLIT HTMLHOW TO DO QUESTION ANSWERING OVER CSVSHOW TO DEAL WITH LARGE DATABASES WHEN DOING SQL QUESTION-ANSWERINGHOW TO BETTER PROMPT WHEN DOING SQL QUESTION-ANSWERINGHOW TO DO QUERY VALIDATION AS PART OF SQL QUESTION-ANSWERINGHOW TO STREAM RUNNABLESHOW TO STREAM RESPONSES FROM AN LLMHOW TO USE A TIME-WEIGHTED VECTOR STORE RETRIEVERHOW TO RETURN ARTIFACTS FROM A TOOLHOW TO USE CHAT MODELS TO CALL TOOLSHOW TO DISABLE PARALLEL TOOL CALLINGHOW TO FORCE MODELS TO CALL A TOOLHOW TO ACCESS THE RUNNABLECONFIG FROM A TOOLHOW TO PASS TOOL OUTPUTS TO CHAT MODELSHOW TO PASS RUN TIME VALUES TO TOOLSHOW TO STREAM EVENTS FROM A TOOLHOW TO STREAM TOOL CALLSHOW TO CONVERT TOOLS TO OPENAI FUNCTIONSHOW TO HANDLE TOOL ERRORSHOW TO USE FEW-SHOT PROMPTING WITH TOOL CALLINGHOW TO ADD A HUMAN-IN-THE-LOOP FOR TOOLSHOW TO BIND MODEL-SPECIFIC TOOLSHOW TO TRIM MESSAGESHOW TO CREATE AND QUERY VECTOR STORESCONCEPTUAL GUIDEAGENTSARCHITECTUREASYNC PROGRAMMING WITH LANGCHAINCALLBACKSCHAT HISTORYCHAT MODELSDOCUMENT LOADERSEMBEDDING MODELSEVALUATIONEXAMPLE SELECTORSFEW-SHOT PROMPTINGCONCEPTUAL GUIDEKEY-VALUE STORESLANGCHAIN EXPRESSION LANGUAGE (LCEL)MESSAGESMULTIMODALITYOUTPUT PARSERSPROMPT TEMPLATESRETRIEVAL AUGMENTED GENERATION (RAG)RETRIEVALRETRIEVERSRUNNABLE INTERFACESTREAMINGSTRUCTURED OUTPUTSTESTINGSTRING-IN, STRING-OUT LLMSTEXT SPLITTERSTOKENSTOOL CALLINGTOOLSTRACINGVECTOR STORESWHY LANGCHAIN?ECOSYSTEM🦜🛠️ LANGSMITH🦜🕸️ LANGGRAPHVERSIONSV0.3V0.2PYDANTIC COMPATIBILITYMIGRATING FROM V0.0 CHAINSHOW TO MIGRATE FROM V0.0 CHAINSMIGRATING FROM CONSTITUTIONALCHAINMIGRATING FROM CONVERSATIONALCHAINMIGRATING FROM CONVERSATIONALRETRIEVALCHAINMIGRATING FROM LLMCHAINMIGRATING FROM LLMMATHCHAINMIGRATING FROM LLMROUTERCHAINMIGRATING FROM MAPREDUCEDOCUMENTSCHAINMIGRATING FROM MAPRERANKDOCUMENTSCHAINMIGRATING FROM MULTIPROMPTCHAINMIGRATING FROM REFINEDOCUMENTSCHAINMIGRATING FROM RETRIEVALQAMIGRATING FROM STUFFDOCUMENTSCHAINUPGRADING TO LANGGRAPH MEMORYHOW TO MIGRATE TO LANGGRAPH MEMORYHOW TO USE BASECHATMESSAGEHISTORY WITH LANGGRAPHMIGRATING OFF CONVERSATIONBUFFERMEMORY OR CONVERSATIONSTRINGBUFFERMEMORYMIGRATING OFF CONVERSATIONBUFFERWINDOWMEMORY OR CONVERSATIONTOKENBUFFERMEMORYMIGRATING OFF CONVERSATIONSUMMARYMEMORY OR CONVERSATIONSUMMARYBUFFERMEMORYA LONG-TERM MEMORY AGENTRELEASE POLICYSECURITY POLICYHOW-TO GUIDESHOW TO CHAIN RUNNABLESON THIS PAGEHOW TO CHAIN RUNNABLES\n",
      "PREREQUISITESTHIS GUIDE ASSUMES FAMILIARITY WITH THE FOLLOWING CONCEPTS:\n",
      "LANGCHAIN EXPRESSION LANGUAGE (LCEL)\n",
      "PROMPT TEMPLATES\n",
      "CHAT MODELS\n",
      "OUTPUT PARSER\n",
      "\n",
      "ONE POINT ABOUT LANGCHAIN EXPRESSION LANGUAGE IS THAT ANY TWO RUNNABLES CAN BE \"CHAINED\" TOGETHER INTO SEQUENCES. THE OUTPUT OF THE PREVIOUS RUNNABLE'S .INVOKE() CALL IS PASSED AS INPUT TO THE NEXT RUNNABLE. THIS CAN BE DONE USING THE PIPE OPERATOR (|), OR THE MORE EXPLICIT .PIPE() METHOD, WHICH DOES THE SAME THING.\n",
      "THE RESULTING RUNNABLESEQUENCE IS ITSELF A RUNNABLE, WHICH MEANS IT CAN BE INVOKED, STREAMED, OR FURTHER CHAINED JUST LIKE ANY OTHER RUNNABLE. ADVANTAGES OF CHAINING RUNNABLES IN THIS WAY ARE EFFICIENT STREAMING (THE SEQUENCE WILL STREAM OUTPUT AS SOON AS IT IS AVAILABLE), AND DEBUGGING AND TRACING WITH TOOLS LIKE LANGSMITH.\n",
      "THE PIPE OPERATOR: |​\n",
      "TO SHOW OFF HOW THIS WORKS, LET'S GO THROUGH AN EXAMPLE. WE'LL WALK THROUGH A COMMON PATTERN IN LANGCHAIN: USING A PROMPT TEMPLATE TO FORMAT INPUT INTO A CHAT MODEL, AND FINALLY CONVERTING THE CHAT MESSAGE OUTPUT INTO A STRING WITH AN OUTPUT PARSER.\n",
      "\n",
      "SELECT CHAT MODEL:GROQ▾GROQOPENAIANTHROPICAZUREGOOGLE VERTEXAWSCOHERENVIDIAFIREWORKS AIMISTRAL AITOGETHER AIIBM WATSONXDATABRICKSXAIPIP INSTALL -QU \"LANGCHAIN[GROQ]\"IMPORT GETPASSIMPORT OSIF NOT OS.ENVIRON.GET(\"GROQ_API_KEY\"):  OS.ENVIRON[\"GROQ_API_KEY\"] = GETPASS.GETPASS(\"ENTER API KEY FOR GROQ: \")FROM LANGCHAIN.CHAT_MODELS IMPORT INIT_CHAT_MODELMODEL = INIT_CHAT_MODEL(\"LLAMA3-8B-8192\", MODEL_PROVIDER=\"GROQ\")\n",
      "FROM LANGCHAIN_CORE.OUTPUT_PARSERS IMPORT STROUTPUTPARSERFROM LANGCHAIN_CORE.PROMPTS IMPORT CHATPROMPTTEMPLATEPROMPT = CHATPROMPTTEMPLATE.FROM_TEMPLATE(\"TELL ME A JOKE ABOUT {TOPIC}\")CHAIN = PROMPT | MODEL | STROUTPUTPARSER()API REFERENCE:STROUTPUTPARSER | CHATPROMPTTEMPLATE\n",
      "PROMPTS AND MODELS ARE BOTH RUNNABLE, AND THE OUTPUT TYPE FROM THE PROMPT CALL IS THE SAME AS THE INPUT TYPE OF THE CHAT MODEL, SO WE CAN CHAIN THEM TOGETHER. WE CAN THEN INVOKE THE RESULTING SEQUENCE LIKE ANY OTHER RUNNABLE:\n",
      "CHAIN.INVOKE({\"TOPIC\": \"BEARS\"})\n",
      "\"HERE'S A BEAR JOKE FOR YOU:\\N\\NWHY DID THE BEAR DISSOLVE IN WATER?\\NBECAUSE IT WAS A POLAR BEAR!\"\n",
      "COERCION​\n",
      "WE CAN EVEN COMBINE THIS CHAIN WITH MORE RUNNABLES TO CREATE ANOTHER CHAIN. THIS MAY INVOLVE SOME INPUT/OUTPUT FORMATTING USING OTHER TYPES OF RUNNABLES, DEPENDING ON THE REQUIRED INPUTS AND OUTPUTS OF THE CHAIN COMPONENTS.\n",
      "FOR EXAMPLE, LET'S SAY WE WANTED TO COMPOSE THE JOKE GENERATING CHAIN WITH ANOTHER CHAIN THAT EVALUATES WHETHER OR NOT THE GENERATED JOKE WAS FUNNY.\n",
      "WE WOULD NEED TO BE CAREFUL WITH HOW WE FORMAT THE INPUT INTO THE NEXT CHAIN. IN THE BELOW EXAMPLE, THE DICT IN THE CHAIN IS AUTOMATICALLY PARSED AND CONVERTED INTO A RUNNABLEPARALLEL, WHICH RUNS ALL OF ITS VALUES IN PARALLEL AND RETURNS A DICT WITH THE RESULTS.\n",
      "THIS HAPPENS TO BE THE SAME FORMAT THE NEXT PROMPT TEMPLATE EXPECTS. HERE IT IS IN ACTION:\n",
      "FROM LANGCHAIN_CORE.OUTPUT_PARSERS IMPORT STROUTPUTPARSERANALYSIS_PROMPT = CHATPROMPTTEMPLATE.FROM_TEMPLATE(\"IS THIS A FUNNY JOKE? {JOKE}\")COMPOSED_CHAIN = {\"JOKE\": CHAIN} | ANALYSIS_PROMPT | MODEL | STROUTPUTPARSER()COMPOSED_CHAIN.INVOKE({\"TOPIC\": \"BEARS\"})API REFERENCE:STROUTPUTPARSER\n",
      "'HAHA, THAT\\'S A CLEVER PLAY ON WORDS! USING \"POLAR\" TO IMPLY THE BEAR DISSOLVED OR BECAME POLAR/POLARIZED WHEN PUT IN WATER. NOT THE MOST HILARIOUS JOKE EVER, BUT IT HAS A CUTE, GROAN-WORTHY PUN THAT MAKES IT MILDLY AMUSING. I APPRECIATE A GOOD PUN OR WORDPLAY JOKE.'\n",
      "FUNCTIONS WILL ALSO BE COERCED INTO RUNNABLES, SO YOU CAN ADD CUSTOM LOGIC TO YOUR CHAINS TOO. THE BELOW CHAIN RESULTS IN THE SAME LOGICAL FLOW AS BEFORE:\n",
      "COMPOSED_CHAIN_WITH_LAMBDA = (    CHAIN    | (LAMBDA INPUT: {\"JOKE\": INPUT})    | ANALYSIS_PROMPT    | MODEL    | STROUTPUTPARSER())COMPOSED_CHAIN_WITH_LAMBDA.INVOKE({\"TOPIC\": \"BEETS\"})\n",
      "\"HAHA, THAT'S A CUTE AND PUNNY JOKE! I LIKE HOW IT PLAYS ON THE IDEA OF BEETS BLUSHING OR TURNING RED LIKE SOMEONE BLUSHING. FOOD PUNS CAN BE QUITE AMUSING. WHILE NOT A TOTAL KNEE-SLAPPER, IT'S A LIGHT-HEARTED, GROAN-WORTHY DAD JOKE THAT WOULD MAKE ME CHUCKLE AND SHAKE MY HEAD. SIMPLE VEGETABLE HUMOR!\"\n",
      "HOWEVER, KEEP IN MIND THAT USING FUNCTIONS LIKE THIS MAY INTERFERE WITH OPERATIONS LIKE STREAMING. SEE THIS SECTION FOR MORE INFORMATION.\n",
      "THE .PIPE() METHOD​\n",
      "WE COULD ALSO COMPOSE THE SAME SEQUENCE USING THE .PIPE() METHOD. HERE'S WHAT THAT LOOKS LIKE:\n",
      "FROM LANGCHAIN_CORE.RUNNABLES IMPORT RUNNABLEPARALLELCOMPOSED_CHAIN_WITH_PIPE = (    RUNNABLEPARALLEL({\"JOKE\": CHAIN})    .PIPE(ANALYSIS_PROMPT)    .PIPE(MODEL)    .PIPE(STROUTPUTPARSER()))COMPOSED_CHAIN_WITH_PIPE.INVOKE({\"TOPIC\": \"BATTLESTAR GALACTICA\"})API REFERENCE:RUNNABLEPARALLEL\n",
      "\"I CANNOT REPRODUCE ANY COPYRIGHTED MATERIAL VERBATIM, BUT I CAN TRY TO ANALYZE THE HUMOR IN THE JOKE YOU PROVIDED WITHOUT QUOTING IT DIRECTLY.\\N\\NTHE JOKE PLAYS ON THE IDEA THAT THE CYLON RAIDERS, WHO ARE THE ANTAGONISTS IN THE BATTLESTAR GALACTICA UNIVERSE, FAILED TO LOCATE THE HUMAN SURVIVORS AFTER ATTACKING THEIR HOME PLANETS (THE TWELVE COLONIES) DUE TO USING AN OUTDATED AND POORLY PERFORMING OPERATING SYSTEM (WINDOWS VISTA) FOR THEIR TARGETING SYSTEMS.\\N\\NTHE HUMOR STEMS FROM THE JUXTAPOSITION OF A FUTURISTIC SCIENCE FICTION SETTING WITH A RELATABLE REAL-WORLD FRUSTRATION – THE USE OF BUGGY, SLOW, OR UNRELIABLE SOFTWARE OR TECHNOLOGY. IT POKES FUN AT THE PERCEIVED INADEQUACIES OF WINDOWS VISTA, WHICH WAS WIDELY CRITICIZED FOR ITS PERFORMANCE ISSUES AND OTHER PROBLEMS WHEN IT WAS RELEASED.\\N\\NBY ATTRIBUTING THE CYLONS' FAILURE TO LOCATE THE HUMANS TO THEIR USE OF VISTA, THE JOKE CREATES AN AMUSING AND UNEXPECTED CONNECTION BETWEEN A FICTIONAL ADVANCED RACE OF ROBOTS AND A FAMILIAR TECHNOLOGICAL ANNOYANCE EXPERIENCED BY MANY PEOPLE IN THE REAL WORLD.\\N\\NOVERALL, THE JOKE RELIES ON INCONGRUITY AND RELATABILITY TO GENERATE HUMOR, BUT WITHOUT REPRODUCING ANY COPYRIGHTED MATERIAL DIRECTLY.\"\n",
      "OR THE ABBREVIATED:\n",
      "COMPOSED_CHAIN_WITH_PIPE = RUNNABLEPARALLEL({\"JOKE\": CHAIN}).PIPE(    ANALYSIS_PROMPT, MODEL, STROUTPUTPARSER())\n",
      "RELATED​\n",
      "\n",
      "STREAMING: CHECK OUT THE STREAMING GUIDE TO UNDERSTAND THE STREAMING BEHAVIOR OF A CHAIN\n",
      "EDIT THIS PAGEWAS THIS PAGE HELPFUL?PREVIOUSHOW TO SPLIT TEXT BASED ON SEMANTIC SIMILARITYNEXTHOW TO SAVE AND LOAD LANGCHAIN OBJECTSTHE PIPE OPERATOR: |COERCIONTHE .PIPE() METHODRELATEDCOMMUNITYTWITTERGITHUBORGANIZATIONPYTHONJS/TSMOREHOMEPAGEBLOGYOUTUBECOPYRIGHT © 2025 LANGCHAIN, INC.\n",
      "\n",
      "\n",
      "          -------\n",
      "\n",
      "          THE PREVIOUS CODE ATTEMPT FAILED WITH THE FOLLOWING ERROR:\n",
      "          CANNOT IMPORT NAME 'CONVERSATIONSUMMARYMEMORY' FROM 'LANGCHAIN_CORE.MEMORY' (/USERS/MJACK6/GSU_SPRING2025/MSA8700/VENV_AGENTICAI/LIB/PYTHON3.11/SITE-PACKAGES/LANGCHAIN_CORE/MEMORY.PY)\n",
      "\n",
      "          YOUR CODING TASK:\n",
      "          HOW CAN I ADD MEMORY TO AN ARBITRARY CHAIN USING LANGCHAIN?\n",
      "\n",
      "          PREVIOUS CODE ATTEMPT:\n",
      "          TO ADD MEMORY TO AN ARBITRARY CHAIN USING LANGCHAIN, IT'S IMPORTANT TO SWITCH TO COMPATIBLE MEMORY MODULES. THE ERROR INDICATES AN ISSUE WITH IMPORTING `CONVERSATIONBUFFERMEMORY` FROM `LANGCHAIN_CORE.MEMORY`, WHICH MIGHT HAVE BEEN DEPRECATED OR INCORRECTLY IMPORTED. BELOW IS A CORRECT APPROACH TO INTEGRATE MEMORY USING LANGCHAIN.\n",
      "          FROM LANGCHAIN_CORE.MEMORY IMPORT CONVERSATIONSUMMARYMEMORY\n",
      "FROM LANGCHAIN.CHAT_MODELS IMPORT INIT_CHAT_MODEL\n",
      "FROM LANGCHAIN_CORE.PROMPTS IMPORT CHATPROMPTTEMPLATE\n",
      "FROM LANGCHAIN_CORE.OUTPUT_PARSERS IMPORT STROUTPUTPARSER\n",
      "          MEMORY = CONVERSATIONSUMMARYMEMORY()\n",
      "MODEL = INIT_CHAT_MODEL('LLAMA3-8B-8192', MODEL_PROVIDER='GROQ')\n",
      "PROMPT = CHATPROMPTTEMPLATE.FROM_TEMPLATE('TELL ME A JOKE ABOUT {TOPIC}')\n",
      "CHAIN = PROMPT | MODEL | STROUTPUTPARSER()\n",
      "\n",
      "# EXAMPLE OF ADDING MEMORY TO THE CHAIN\n",
      "CHAIN_WITH_MEMORY = CHAIN.PIPE(MEMORY)\n",
      "\n",
      "# INVOKING THE CHAIN WITH MEMORY TO KEEP TRACK OF CONVERSATION HISTORY\n",
      "RESULT = CHAIN_WITH_MEMORY.INVOKE({'TOPIC': 'SPACE'})\n",
      "PRINT(RESULT)\n",
      "\n",
      "          ANSWER WITH A DESCRIPTION OF THE CODE SOLUTION, FOLLOWED BY THE IMPORTS, AND FINALLY THE FUNCTIONING CODE BLOCK.\n",
      "          ENSURE ALL IMPORTS ARE CORRECT AND THE CODE IS EXECUTABLE.]: 2025-03-13 15:37:15.466654\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:15][✅ CREW 'CREW' COMPLETED, 535D9A82-D305-456D-AB3A-AB6AA6934923]: 2025-03-13 15:37:15.471604\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:15][👍 FLOW METHOD FINISHED: 'RE_RUN_FIX']: 2025-03-13 15:37:15.472037\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:15][🤖 FLOW METHOD STARTED: 'RE_RE_RUN_CHECK']: 2025-03-13 15:37:15.472269\u001b[00m\n",
      "---CHECKING CODE---\n",
      "---CODE BLOCK CHECK: FAILED---\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:15][👍 FLOW METHOD FINISHED: 'RE_RE_RUN_CHECK']: 2025-03-13 15:37:15.536154\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:15][👍 FLOW FINISHED: 'CODEGENFLOW', A54275CB-541D-4A15-8031-37DF750CC696]: 2025-03-13 15:37:15.536356\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:15][🌊 FLOW CREATED: 'CODEGENFLOW']: 2025-03-13 15:37:15.546928\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:15][🤖 FLOW STARTED: 'CODEGENFLOW', FE9EFE2C-DED0-4836-A33C-AA9DD0FF3BE7]: 2025-03-13 15:37:15.547110\u001b[00m\n",
      "\u001b[1m\u001b[35m Flow started with ID: fe9efe2c-ded0-4836-a33c-aa9dd0ff3be7\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:15][🤖 FLOW METHOD STARTED: 'GENERATE_CODE']: 2025-03-13 15:37:15.547233\u001b[00m\n",
      "---GENERATING CODE SOLUTION---\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:15][🚀 CREW 'CREW' STARTED, 368F5772-413F-4BF5-BD01-847C2CD6098D]: 2025-03-13 15:37:15.547994\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:15][📋 TASK STARTED: ANSWER THE USER QUESTION BASED ON THE ABOVE PROVIDED DOCUMENTATION. ENSURE ANY CODE YOU PROVIDE CAN BE EXECUTED\n",
      "    WITH ALL REQUIRED IMPORTS AND VARIABLES DEFINED. STRUCTURE YOUR ANSWER:\n",
      "    1) A PREFIX DESCRIBING THE CODE SOLUTION\n",
      "    2) THE IMPORTS\n",
      "    3) THE FUNCTIONING CODE BLOCK\n",
      "\n",
      "    YOUR CODING TASK:\n",
      "    HOW CAN I MAKE THE OUTPUT OF MY LCEL CHAIN A STRING?\n",
      "    ]: 2025-03-13 15:37:15.549521\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:15][🤖 AGENT 'CODING ASSISTANT' STARTED TASK]: 2025-03-13 15:37:15.549800\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:15][🤖 LLM CALL STARTED]: 2025-03-13 15:37:15.549859\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:6: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:18][✅ LLM CALL COMPLETED]: 2025-03-13 15:37:18.435178\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:18][✅ AGENT 'CODING ASSISTANT' COMPLETED TASK]: 2025-03-13 15:37:18.436596\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:18][✅ TASK COMPLETED: ANSWER THE USER QUESTION BASED ON THE ABOVE PROVIDED DOCUMENTATION. ENSURE ANY CODE YOU PROVIDE CAN BE EXECUTED\n",
      "    WITH ALL REQUIRED IMPORTS AND VARIABLES DEFINED. STRUCTURE YOUR ANSWER:\n",
      "    1) A PREFIX DESCRIBING THE CODE SOLUTION\n",
      "    2) THE IMPORTS\n",
      "    3) THE FUNCTIONING CODE BLOCK\n",
      "\n",
      "    YOUR CODING TASK:\n",
      "    HOW CAN I MAKE THE OUTPUT OF MY LCEL CHAIN A STRING?\n",
      "    ]: 2025-03-13 15:37:18.436965\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:18][✅ CREW 'CREW' COMPLETED, 368F5772-413F-4BF5-BD01-847C2CD6098D]: 2025-03-13 15:37:18.441982\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:18][👍 FLOW METHOD FINISHED: 'GENERATE_CODE']: 2025-03-13 15:37:18.442236\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:18][🤖 FLOW METHOD STARTED: 'RUN_CHECK']: 2025-03-13 15:37:18.442413\u001b[00m\n",
      "---CHECKING CODE---\n",
      "Why did the bear go to the doctor?\n",
      "\n",
      "Because it had a grizzly cough!\n",
      "---NO CODE TEST FAILURES---\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:18][👍 FLOW METHOD FINISHED: 'RUN_CHECK']: 2025-03-13 15:37:18.799719\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:18][👍 FLOW FINISHED: 'CODEGENFLOW', FE9EFE2C-DED0-4836-A33C-AA9DD0FF3BE7]: 2025-03-13 15:37:18.802596\u001b[00m\n",
      "Why did the bear go to the doctor?\n",
      "\n",
      "Because it had a grizzly cough!\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:19][🌊 FLOW CREATED: 'CODEGENFLOW']: 2025-03-13 15:37:19.046657\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:19][🤖 FLOW STARTED: 'CODEGENFLOW', BCC5925E-33DA-4324-A7AD-F06502C58B18]: 2025-03-13 15:37:19.047150\u001b[00m\n",
      "\u001b[1m\u001b[35m Flow started with ID: bcc5925e-33da-4324-a7ad-f06502c58b18\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:19][🤖 FLOW METHOD STARTED: 'GENERATE_CODE']: 2025-03-13 15:37:19.047551\u001b[00m\n",
      "---GENERATING CODE SOLUTION---\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:19][🚀 CREW 'CREW' STARTED, 368F5772-413F-4BF5-BD01-847C2CD6098D]: 2025-03-13 15:37:19.047850\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:19][📋 TASK STARTED: ANSWER THE USER QUESTION BASED ON THE ABOVE PROVIDED DOCUMENTATION. ENSURE ANY CODE YOU PROVIDE CAN BE EXECUTED\n",
      "    WITH ALL REQUIRED IMPORTS AND VARIABLES DEFINED. STRUCTURE YOUR ANSWER:\n",
      "    1) A PREFIX DESCRIBING THE CODE SOLUTION\n",
      "    2) THE IMPORTS\n",
      "    3) THE FUNCTIONING CODE BLOCK\n",
      "\n",
      "    YOUR CODING TASK:\n",
      "    HOW CAN I APPLY A CUSTOM FUNCTION TO ONE OF THE CHAINS?\n",
      "    ]: 2025-03-13 15:37:19.052085\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:19][🤖 AGENT 'CODING ASSISTANT' STARTED TASK]: 2025-03-13 15:37:19.052725\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:19][🤖 LLM CALL STARTED]: 2025-03-13 15:37:19.052854\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:24][✅ LLM CALL COMPLETED]: 2025-03-13 15:37:24.239261\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:24][✅ AGENT 'CODING ASSISTANT' COMPLETED TASK]: 2025-03-13 15:37:24.240586\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:24][✅ TASK COMPLETED: ANSWER THE USER QUESTION BASED ON THE ABOVE PROVIDED DOCUMENTATION. ENSURE ANY CODE YOU PROVIDE CAN BE EXECUTED\n",
      "    WITH ALL REQUIRED IMPORTS AND VARIABLES DEFINED. STRUCTURE YOUR ANSWER:\n",
      "    1) A PREFIX DESCRIBING THE CODE SOLUTION\n",
      "    2) THE IMPORTS\n",
      "    3) THE FUNCTIONING CODE BLOCK\n",
      "\n",
      "    YOUR CODING TASK:\n",
      "    HOW CAN I APPLY A CUSTOM FUNCTION TO ONE OF THE CHAINS?\n",
      "    ]: 2025-03-13 15:37:24.240927\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:24][✅ CREW 'CREW' COMPLETED, 368F5772-413F-4BF5-BD01-847C2CD6098D]: 2025-03-13 15:37:24.245703\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:24][👍 FLOW METHOD FINISHED: 'GENERATE_CODE']: 2025-03-13 15:37:24.245964\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:24][🤖 FLOW METHOD STARTED: 'RUN_CHECK']: 2025-03-13 15:37:24.246138\u001b[00m\n",
      "---CHECKING CODE---\n",
      "I think it's a clever play on words! The pun on \"beet\" and \"beau\" (meaning a person or thing that is desirable or fashionable to be with) is quite creative and unexpected. It's the kind of joke that might elicit a chuckle or a smile from someone who appreciates wordplay.\n",
      "\n",
      "Well done to the person who came up with this beet-iful joke!\n",
      "---NO CODE TEST FAILURES---\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:25][👍 FLOW METHOD FINISHED: 'RUN_CHECK']: 2025-03-13 15:37:25.091821\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:25][👍 FLOW FINISHED: 'CODEGENFLOW', BCC5925E-33DA-4324-A7AD-F06502C58B18]: 2025-03-13 15:37:25.092696\u001b[00m\n",
      "Ahah! Yes, that is a funny joke! The pun on \"root\" is clever and unexpected, making it a great play on words. It's a simple joke, but the wordplay is quick and clever enough to elicit a chuckle. Well done! Would you like to share another one?\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:25][🌊 FLOW CREATED: 'CODEGENFLOW']: 2025-03-13 15:37:25.639855\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:25][🤖 FLOW STARTED: 'CODEGENFLOW', A52D58D7-28B5-4406-83E5-B65CDABE85E8]: 2025-03-13 15:37:25.640604\u001b[00m\n",
      "\u001b[1m\u001b[35m Flow started with ID: a52d58d7-28b5-4406-83e5-b65cdabe85e8\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:25][🤖 FLOW METHOD STARTED: 'GENERATE_CODE']: 2025-03-13 15:37:25.641406\u001b[00m\n",
      "---GENERATING CODE SOLUTION---\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:25][🚀 CREW 'CREW' STARTED, 368F5772-413F-4BF5-BD01-847C2CD6098D]: 2025-03-13 15:37:25.641854\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:25][📋 TASK STARTED: ANSWER THE USER QUESTION BASED ON THE ABOVE PROVIDED DOCUMENTATION. ENSURE ANY CODE YOU PROVIDE CAN BE EXECUTED\n",
      "    WITH ALL REQUIRED IMPORTS AND VARIABLES DEFINED. STRUCTURE YOUR ANSWER:\n",
      "    1) A PREFIX DESCRIBING THE CODE SOLUTION\n",
      "    2) THE IMPORTS\n",
      "    3) THE FUNCTIONING CODE BLOCK\n",
      "\n",
      "    YOUR CODING TASK:\n",
      "    WITH A RAG CHAIN IN LCEL, WHY ARE DOCUMENTS REQUIRED?\n",
      "    ]: 2025-03-13 15:37:25.646787\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:25][🤖 AGENT 'CODING ASSISTANT' STARTED TASK]: 2025-03-13 15:37:25.647416\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:25][🤖 LLM CALL STARTED]: 2025-03-13 15:37:25.647518\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:29][✅ LLM CALL COMPLETED]: 2025-03-13 15:37:29.158664\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:29][✅ AGENT 'CODING ASSISTANT' COMPLETED TASK]: 2025-03-13 15:37:29.159967\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:29][✅ TASK COMPLETED: ANSWER THE USER QUESTION BASED ON THE ABOVE PROVIDED DOCUMENTATION. ENSURE ANY CODE YOU PROVIDE CAN BE EXECUTED\n",
      "    WITH ALL REQUIRED IMPORTS AND VARIABLES DEFINED. STRUCTURE YOUR ANSWER:\n",
      "    1) A PREFIX DESCRIBING THE CODE SOLUTION\n",
      "    2) THE IMPORTS\n",
      "    3) THE FUNCTIONING CODE BLOCK\n",
      "\n",
      "    YOUR CODING TASK:\n",
      "    WITH A RAG CHAIN IN LCEL, WHY ARE DOCUMENTS REQUIRED?\n",
      "    ]: 2025-03-13 15:37:29.160363\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:29][✅ CREW 'CREW' COMPLETED, 368F5772-413F-4BF5-BD01-847C2CD6098D]: 2025-03-13 15:37:29.164870\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:29][👍 FLOW METHOD FINISHED: 'GENERATE_CODE']: 2025-03-13 15:37:29.165110\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:29][🤖 FLOW METHOD STARTED: 'RUN_CHECK']: 2025-03-13 15:37:29.165268\u001b[00m\n",
      "---CHECKING CODE---\n",
      "---NO CODE TEST FAILURES---\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:29][👍 FLOW METHOD FINISHED: 'RUN_CHECK']: 2025-03-13 15:37:29.500943\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:29][👍 FLOW FINISHED: 'CODEGENFLOW', A52D58D7-28B5-4406-83E5-B65CDABE85E8]: 2025-03-13 15:37:29.502076\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:29][🌊 FLOW CREATED: 'CODEGENFLOW']: 2025-03-13 15:37:29.766807\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:29][🤖 FLOW STARTED: 'CODEGENFLOW', 26FAE512-A786-44C8-AEAC-24410EF9C475]: 2025-03-13 15:37:29.769808\u001b[00m\n",
      "\u001b[1m\u001b[35m Flow started with ID: 26fae512-a786-44c8-aeac-24410ef9c475\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:29][🤖 FLOW METHOD STARTED: 'GENERATE_CODE']: 2025-03-13 15:37:29.770479\u001b[00m\n",
      "---GENERATING CODE SOLUTION---\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:29][🚀 CREW 'CREW' STARTED, 368F5772-413F-4BF5-BD01-847C2CD6098D]: 2025-03-13 15:37:29.770828\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:29][📋 TASK STARTED: ANSWER THE USER QUESTION BASED ON THE ABOVE PROVIDED DOCUMENTATION. ENSURE ANY CODE YOU PROVIDE CAN BE EXECUTED\n",
      "    WITH ALL REQUIRED IMPORTS AND VARIABLES DEFINED. STRUCTURE YOUR ANSWER:\n",
      "    1) A PREFIX DESCRIBING THE CODE SOLUTION\n",
      "    2) THE IMPORTS\n",
      "    3) THE FUNCTIONING CODE BLOCK\n",
      "\n",
      "    YOUR CODING TASK:\n",
      "    HOW CAN I CONFIGURE THE TEMPERATURE OF AN LLM?\n",
      "    ]: 2025-03-13 15:37:29.775055\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:29][🤖 AGENT 'CODING ASSISTANT' STARTED TASK]: 2025-03-13 15:37:29.775702\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:29][🤖 LLM CALL STARTED]: 2025-03-13 15:37:29.775821\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:31][✅ LLM CALL COMPLETED]: 2025-03-13 15:37:31.266501\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:31][✅ AGENT 'CODING ASSISTANT' COMPLETED TASK]: 2025-03-13 15:37:31.267707\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:31][✅ TASK COMPLETED: ANSWER THE USER QUESTION BASED ON THE ABOVE PROVIDED DOCUMENTATION. ENSURE ANY CODE YOU PROVIDE CAN BE EXECUTED\n",
      "    WITH ALL REQUIRED IMPORTS AND VARIABLES DEFINED. STRUCTURE YOUR ANSWER:\n",
      "    1) A PREFIX DESCRIBING THE CODE SOLUTION\n",
      "    2) THE IMPORTS\n",
      "    3) THE FUNCTIONING CODE BLOCK\n",
      "\n",
      "    YOUR CODING TASK:\n",
      "    HOW CAN I CONFIGURE THE TEMPERATURE OF AN LLM?\n",
      "    ]: 2025-03-13 15:37:31.268373\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:31][✅ CREW 'CREW' COMPLETED, 368F5772-413F-4BF5-BD01-847C2CD6098D]: 2025-03-13 15:37:31.271864\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:31][👍 FLOW METHOD FINISHED: 'GENERATE_CODE']: 2025-03-13 15:37:31.272105\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:31][🤖 FLOW METHOD STARTED: 'RUN_CHECK']: 2025-03-13 15:37:31.272277\u001b[00m\n",
      "---CHECKING CODE---\n",
      "---NO CODE TEST FAILURES---\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:31][👍 FLOW METHOD FINISHED: 'RUN_CHECK']: 2025-03-13 15:37:31.291644\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:31][👍 FLOW FINISHED: 'CODEGENFLOW', 26FAE512-A786-44C8-AEAC-24410EF9C475]: 2025-03-13 15:37:31.291775\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:31][🌊 FLOW CREATED: 'CODEGENFLOW']: 2025-03-13 15:37:31.307649\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:31][🤖 FLOW STARTED: 'CODEGENFLOW', 7A2B1053-9C1B-448C-9256-5BC0099D643D]: 2025-03-13 15:37:31.308646\u001b[00m\n",
      "\u001b[1m\u001b[35m Flow started with ID: 7a2b1053-9c1b-448c-9256-5bc0099d643d\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:31][🤖 FLOW METHOD STARTED: 'GENERATE_CODE']: 2025-03-13 15:37:31.308790\u001b[00m\n",
      "---GENERATING CODE SOLUTION---\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:31][🚀 CREW 'CREW' STARTED, 368F5772-413F-4BF5-BD01-847C2CD6098D]: 2025-03-13 15:37:31.308931\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:31][📋 TASK STARTED: ANSWER THE USER QUESTION BASED ON THE ABOVE PROVIDED DOCUMENTATION. ENSURE ANY CODE YOU PROVIDE CAN BE EXECUTED\n",
      "    WITH ALL REQUIRED IMPORTS AND VARIABLES DEFINED. STRUCTURE YOUR ANSWER:\n",
      "    1) A PREFIX DESCRIBING THE CODE SOLUTION\n",
      "    2) THE IMPORTS\n",
      "    3) THE FUNCTIONING CODE BLOCK\n",
      "\n",
      "    YOUR CODING TASK:\n",
      "    HOW CAN WE APPLY A FUNCTION CALL TO AN LLM IN A CHAIN?\n",
      "    ]: 2025-03-13 15:37:31.310816\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:31][🤖 AGENT 'CODING ASSISTANT' STARTED TASK]: 2025-03-13 15:37:31.311217\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:31][🤖 LLM CALL STARTED]: 2025-03-13 15:37:31.311290\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:35][✅ LLM CALL COMPLETED]: 2025-03-13 15:37:35.404536\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:35][✅ AGENT 'CODING ASSISTANT' COMPLETED TASK]: 2025-03-13 15:37:35.405662\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:35][✅ TASK COMPLETED: ANSWER THE USER QUESTION BASED ON THE ABOVE PROVIDED DOCUMENTATION. ENSURE ANY CODE YOU PROVIDE CAN BE EXECUTED\n",
      "    WITH ALL REQUIRED IMPORTS AND VARIABLES DEFINED. STRUCTURE YOUR ANSWER:\n",
      "    1) A PREFIX DESCRIBING THE CODE SOLUTION\n",
      "    2) THE IMPORTS\n",
      "    3) THE FUNCTIONING CODE BLOCK\n",
      "\n",
      "    YOUR CODING TASK:\n",
      "    HOW CAN WE APPLY A FUNCTION CALL TO AN LLM IN A CHAIN?\n",
      "    ]: 2025-03-13 15:37:35.405990\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:35][✅ CREW 'CREW' COMPLETED, 368F5772-413F-4BF5-BD01-847C2CD6098D]: 2025-03-13 15:37:35.410927\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:35][👍 FLOW METHOD FINISHED: 'GENERATE_CODE']: 2025-03-13 15:37:35.411181\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:35][🤖 FLOW METHOD STARTED: 'RUN_CHECK']: 2025-03-13 15:37:35.411351\u001b[00m\n",
      "---CHECKING CODE---\n",
      "A classic play on words!\n",
      "\n",
      "Yes, I think this joke is funny! The pun on \"beet-red\" (a reference to the beet root's characteristic color) and \"feeling a little red\" (as in, feeling unwell or flushed) is clever and unexpected. It's a quick and simple joke, but the wordplay creates a delightful surprise, making it likely to elicit a chuckle.\n",
      "\n",
      "Puns like this one often rely on a shared understanding of the words and their meanings, which can create a sense of shared joy and amusement. Well-crafted puns like this one can bring people together and add a dash of whimsy to our daily conversations!\n",
      "---NO CODE TEST FAILURES---\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:36][👍 FLOW METHOD FINISHED: 'RUN_CHECK']: 2025-03-13 15:37:36.147454\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:36][👍 FLOW FINISHED: 'CODEGENFLOW', 7A2B1053-9C1B-448C-9256-5BC0099D643D]: 2025-03-13 15:37:36.150139\u001b[00m\n",
      "Ahahah! Yes, I think that's a great joke! It's a clever play on words, using the phrase \"a beat to be there\" (meaning it's a must-attend event) and replacing \"beat\" with \"beet\" (the vegetable). The pun is unexpected and quick-witted, which makes it amusing. Well done!\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:36][🌊 FLOW CREATED: 'CODEGENFLOW']: 2025-03-13 15:37:36.660715\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:36][🤖 FLOW STARTED: 'CODEGENFLOW', 38DB8972-D295-4155-94E0-2DFEB4D62573]: 2025-03-13 15:37:36.661845\u001b[00m\n",
      "\u001b[1m\u001b[35m Flow started with ID: 38db8972-d295-4155-94e0-2dfeb4d62573\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:36][🤖 FLOW METHOD STARTED: 'GENERATE_CODE']: 2025-03-13 15:37:36.662381\u001b[00m\n",
      "---GENERATING CODE SOLUTION---\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:36][🚀 CREW 'CREW' STARTED, 368F5772-413F-4BF5-BD01-847C2CD6098D]: 2025-03-13 15:37:36.662958\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:36][📋 TASK STARTED: ANSWER THE USER QUESTION BASED ON THE ABOVE PROVIDED DOCUMENTATION. ENSURE ANY CODE YOU PROVIDE CAN BE EXECUTED\n",
      "    WITH ALL REQUIRED IMPORTS AND VARIABLES DEFINED. STRUCTURE YOUR ANSWER:\n",
      "    1) A PREFIX DESCRIBING THE CODE SOLUTION\n",
      "    2) THE IMPORTS\n",
      "    3) THE FUNCTIONING CODE BLOCK\n",
      "\n",
      "    YOUR CODING TASK:\n",
      "    HOW CAN I RUN TWO LCEL CHAINS IN PARALLEL AND SEQUENTIALLY?\n",
      "    ]: 2025-03-13 15:37:36.668881\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:36][🤖 AGENT 'CODING ASSISTANT' STARTED TASK]: 2025-03-13 15:37:36.669622\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:36][🤖 LLM CALL STARTED]: 2025-03-13 15:37:36.669751\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:43][✅ LLM CALL COMPLETED]: 2025-03-13 15:37:43.783444\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:43][✅ AGENT 'CODING ASSISTANT' COMPLETED TASK]: 2025-03-13 15:37:43.784985\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:43][✅ TASK COMPLETED: ANSWER THE USER QUESTION BASED ON THE ABOVE PROVIDED DOCUMENTATION. ENSURE ANY CODE YOU PROVIDE CAN BE EXECUTED\n",
      "    WITH ALL REQUIRED IMPORTS AND VARIABLES DEFINED. STRUCTURE YOUR ANSWER:\n",
      "    1) A PREFIX DESCRIBING THE CODE SOLUTION\n",
      "    2) THE IMPORTS\n",
      "    3) THE FUNCTIONING CODE BLOCK\n",
      "\n",
      "    YOUR CODING TASK:\n",
      "    HOW CAN I RUN TWO LCEL CHAINS IN PARALLEL AND SEQUENTIALLY?\n",
      "    ]: 2025-03-13 15:37:43.785654\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:43][✅ CREW 'CREW' COMPLETED, 368F5772-413F-4BF5-BD01-847C2CD6098D]: 2025-03-13 15:37:43.789504\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:43][👍 FLOW METHOD FINISHED: 'GENERATE_CODE']: 2025-03-13 15:37:43.789827\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:43][🤖 FLOW METHOD STARTED: 'RUN_CHECK']: 2025-03-13 15:37:43.789974\u001b[00m\n",
      "---CHECKING CODE---\n",
      "Sequential result: Ahaha! Yes, that's a funny joke! It's a play on words, using the idiomatic expression \"grizzly\" (meaning fierce or intimidating) and applying it to a bear's cough, which is a clever and unexpected twist. The punchline is quick and easy to understand, making it a great example of a lighthearted and humorous joke!\n",
      "---CODE BLOCK CHECK: FAILED---\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:44][👍 FLOW METHOD FINISHED: 'RUN_CHECK']: 2025-03-13 15:37:44.850367\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:44][🤖 FLOW METHOD STARTED: 'RUN_FIX']: 2025-03-13 15:37:44.857332\u001b[00m\n",
      "---FIXING CODE---\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:44][🚀 CREW 'CREW' STARTED, 1021A5ED-92FD-47E0-B207-775D392C7C9E]: 2025-03-13 15:37:44.858894\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:44][📋 TASK STARTED: YOU ARE A CODING ASSISTANT WITH EXPERTISE IN LCEL, LANGCHAIN EXPRESSION LANGUAGE.\n",
      "          HERE IS A FULL SET OF LCEL DOCUMENTATION:\n",
      "          -------\n",
      "          \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "HOW TO CHAIN RUNNABLES | 🦜️🔗 LANGCHAIN\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "SKIP TO MAIN CONTENTJOIN US AT  INTERRUPT: THE AGENT AI CONFERENCE BY LANGCHAIN ON MAY 13 & 14 IN SAN FRANCISCO!INTEGRATIONSAPI REFERENCEMORECONTRIBUTINGPEOPLEERROR REFERENCELANGSMITHLANGGRAPHLANGCHAIN HUBLANGCHAIN JS/TSV0.3V0.3V0.2V0.1💬SEARCHINTRODUCTIONTUTORIALSBUILD A QUESTION ANSWERING APPLICATION OVER A GRAPH DATABASETUTORIALSBUILD A SIMPLE LLM APPLICATION WITH CHAT MODELS AND PROMPT TEMPLATESBUILD A CHATBOTBUILD A RETRIEVAL AUGMENTED GENERATION (RAG) APP: PART 2BUILD AN EXTRACTION CHAINBUILD AN AGENTTAGGINGBUILD A RETRIEVAL AUGMENTED GENERATION (RAG) APP: PART 1BUILD A SEMANTIC SEARCH ENGINEBUILD A QUESTION/ANSWERING SYSTEM OVER SQL DATASUMMARIZE TEXTHOW-TO GUIDESHOW-TO GUIDESHOW TO USE TOOLS IN A CHAINHOW TO USE A VECTORSTORE AS A RETRIEVERHOW TO ADD MEMORY TO CHATBOTSHOW TO USE EXAMPLE SELECTORSHOW TO ADD A SEMANTIC LAYER OVER GRAPH DATABASEHOW TO INVOKE RUNNABLES IN PARALLELHOW TO STREAM CHAT MODEL RESPONSESHOW TO ADD DEFAULT INVOCATION ARGS TO A RUNNABLEHOW TO ADD RETRIEVAL TO CHATBOTSHOW TO USE FEW SHOT EXAMPLES IN CHAT MODELSHOW TO DO TOOL/FUNCTION CALLINGHOW TO INSTALL LANGCHAIN PACKAGESHOW TO ADD EXAMPLES TO THE PROMPT FOR QUERY ANALYSISHOW TO USE FEW SHOT EXAMPLESHOW TO RUN CUSTOM FUNCTIONSHOW TO USE OUTPUT PARSERS TO PARSE AN LLM RESPONSE INTO STRUCTURED FORMATHOW TO HANDLE CASES WHERE NO QUERIES ARE GENERATEDHOW TO ROUTE BETWEEN SUB-CHAINSHOW TO RETURN STRUCTURED DATA FROM A MODELHOW TO SUMMARIZE TEXT THROUGH PARALLELIZATIONHOW TO SUMMARIZE TEXT THROUGH ITERATIVE REFINEMENTHOW TO SUMMARIZE TEXT IN A SINGLE LLM CALLHOW TO USE TOOLKITSHOW TO ADD AD-HOC TOOL CALLING CAPABILITY TO LLMS AND CHAT MODELSBUILD AN AGENT WITH AGENTEXECUTOR (LEGACY)HOW TO CONSTRUCT KNOWLEDGE GRAPHSHOW TO PARTIALLY FORMAT PROMPT TEMPLATESHOW TO HANDLE MULTIPLE QUERIES WHEN DOING QUERY ANALYSISHOW TO USE BUILT-IN TOOLS AND TOOLKITSHOW TO PASS THROUGH ARGUMENTS FROM ONE STEP TO THE NEXTHOW TO COMPOSE PROMPTS TOGETHERHOW TO HANDLE MULTIPLE RETRIEVERS WHEN DOING QUERY ANALYSISHOW TO ADD VALUES TO A CHAIN'S STATEHOW TO CONSTRUCT FILTERS FOR QUERY ANALYSISHOW TO CONFIGURE RUNTIME CHAIN INTERNALSHOW DEAL WITH HIGH CARDINALITY CATEGORICALS WHEN DOING QUERY ANALYSISCUSTOM DOCUMENT LOADERHOW TO USE THE MULTIQUERYRETRIEVERHOW TO ADD SCORES TO RETRIEVER RESULTSCACHINGHOW TO USE CALLBACKS IN ASYNC ENVIRONMENTSHOW TO ATTACH CALLBACKS TO A RUNNABLEHOW TO PROPAGATE CALLBACKS  CONSTRUCTORHOW TO DISPATCH CUSTOM CALLBACK EVENTSHOW TO PASS CALLBACKS IN AT RUNTIMEHOW TO SPLIT BY CHARACTERHOW TO CACHE CHAT MODEL RESPONSESHOW TO HANDLE RATE LIMITSHOW TO INIT ANY MODEL IN ONE LINEHOW TO TRACK TOKEN USAGE IN CHATMODELSHOW TO ADD TOOLS TO CHATBOTSHOW TO SPLIT CODEHOW TO DO RETRIEVAL WITH CONTEXTUAL COMPRESSIONHOW TO CONVERT RUNNABLES TO TOOLSHOW TO CREATE CUSTOM CALLBACK HANDLERSHOW TO CREATE A CUSTOM CHAT MODEL CLASSCUSTOM EMBEDDINGSHOW TO CREATE A CUSTOM LLM CLASSCUSTOM RETRIEVERHOW TO CREATE TOOLSHOW TO DEBUG YOUR LLM APPSHOW TO LOAD CSVSHOW TO LOAD DOCUMENTS FROM A DIRECTORYHOW TO LOAD HTMLHOW TO LOAD JSONHOW TO LOAD MARKDOWNHOW TO LOAD MICROSOFT OFFICE FILESHOW TO LOAD PDFSHOW TO LOAD WEB PAGESHOW TO CREATE A DYNAMIC (SELF-CONSTRUCTING) CHAINTEXT EMBEDDING MODELSHOW TO COMBINE RESULTS FROM MULTIPLE RETRIEVERSHOW TO SELECT EXAMPLES FROM A LANGSMITH DATASETHOW TO SELECT EXAMPLES BY LENGTHHOW TO SELECT EXAMPLES BY MAXIMAL MARGINAL RELEVANCE (MMR)HOW TO SELECT EXAMPLES BY N-GRAM OVERLAPHOW TO SELECT EXAMPLES BY SIMILARITYHOW TO USE REFERENCE EXAMPLES WHEN DOING EXTRACTIONHOW TO HANDLE LONG TEXT WHEN DOING EXTRACTIONHOW TO USE PROMPTING ALONE (NO TOOL CALLING) TO DO EXTRACTIONHOW TO ADD FALLBACKS TO A RUNNABLEHOW TO FILTER MESSAGESHYBRID SEARCHHOW TO USE THE LANGCHAIN INDEXING APIHOW TO INSPECT RUNNABLESLANGCHAIN EXPRESSION LANGUAGE CHEATSHEETHOW TO CACHE LLM RESPONSESHOW TO TRACK TOKEN USAGE FOR LLMSRUN MODELS LOCALLYHOW TO GET LOG PROBABILITIESHOW TO REORDER RETRIEVED RESULTS TO MITIGATE THE \"LOST IN THE MIDDLE\" EFFECTHOW TO SPLIT MARKDOWN BY HEADERSHOW TO MERGE CONSECUTIVE MESSAGES OF THE SAME TYPEHOW TO ADD MESSAGE HISTORYHOW TO MIGRATE FROM LEGACY LANGCHAIN AGENTS TO LANGGRAPHHOW TO RETRIEVE USING MULTIPLE VECTORS PER DOCUMENTHOW TO PASS MULTIMODAL DATA DIRECTLY TO MODELSHOW TO USE MULTIMODAL PROMPTSHOW TO CREATE A CUSTOM OUTPUT PARSERHOW TO USE THE OUTPUT-FIXING PARSERHOW TO PARSE JSON OUTPUTHOW TO RETRY WHEN A PARSING ERROR OCCURSHOW TO PARSE TEXT FROM MESSAGE OBJECTSHOW TO PARSE XML OUTPUTHOW TO PARSE YAML OUTPUTHOW TO USE THE PARENT DOCUMENT RETRIEVERHOW TO USE LANGCHAIN WITH DIFFERENT PYDANTIC VERSIONSHOW TO ADD CHAT HISTORYHOW TO GET A RAG APPLICATION TO ADD CITATIONSHOW TO DO PER-USER RETRIEVALHOW TO GET YOUR RAG APPLICATION TO RETURN SOURCESHOW TO STREAM RESULTS FROM YOUR RAG APPLICATIONHOW TO SPLIT JSON DATAHOW TO RECURSIVELY SPLIT TEXT BY CHARACTERSRESPONSE METADATAHOW TO PASS RUNTIME SECRETS TO RUNNABLESHOW TO DO \"SELF-QUERYING\" RETRIEVALHOW TO SPLIT TEXT BASED ON SEMANTIC SIMILARITYHOW TO CHAIN RUNNABLESHOW TO SAVE AND LOAD LANGCHAIN OBJECTSHOW TO SPLIT TEXT BY TOKENSHOW TO SPLIT HTMLHOW TO DO QUESTION ANSWERING OVER CSVSHOW TO DEAL WITH LARGE DATABASES WHEN DOING SQL QUESTION-ANSWERINGHOW TO BETTER PROMPT WHEN DOING SQL QUESTION-ANSWERINGHOW TO DO QUERY VALIDATION AS PART OF SQL QUESTION-ANSWERINGHOW TO STREAM RUNNABLESHOW TO STREAM RESPONSES FROM AN LLMHOW TO USE A TIME-WEIGHTED VECTOR STORE RETRIEVERHOW TO RETURN ARTIFACTS FROM A TOOLHOW TO USE CHAT MODELS TO CALL TOOLSHOW TO DISABLE PARALLEL TOOL CALLINGHOW TO FORCE MODELS TO CALL A TOOLHOW TO ACCESS THE RUNNABLECONFIG FROM A TOOLHOW TO PASS TOOL OUTPUTS TO CHAT MODELSHOW TO PASS RUN TIME VALUES TO TOOLSHOW TO STREAM EVENTS FROM A TOOLHOW TO STREAM TOOL CALLSHOW TO CONVERT TOOLS TO OPENAI FUNCTIONSHOW TO HANDLE TOOL ERRORSHOW TO USE FEW-SHOT PROMPTING WITH TOOL CALLINGHOW TO ADD A HUMAN-IN-THE-LOOP FOR TOOLSHOW TO BIND MODEL-SPECIFIC TOOLSHOW TO TRIM MESSAGESHOW TO CREATE AND QUERY VECTOR STORESCONCEPTUAL GUIDEAGENTSARCHITECTUREASYNC PROGRAMMING WITH LANGCHAINCALLBACKSCHAT HISTORYCHAT MODELSDOCUMENT LOADERSEMBEDDING MODELSEVALUATIONEXAMPLE SELECTORSFEW-SHOT PROMPTINGCONCEPTUAL GUIDEKEY-VALUE STORESLANGCHAIN EXPRESSION LANGUAGE (LCEL)MESSAGESMULTIMODALITYOUTPUT PARSERSPROMPT TEMPLATESRETRIEVAL AUGMENTED GENERATION (RAG)RETRIEVALRETRIEVERSRUNNABLE INTERFACESTREAMINGSTRUCTURED OUTPUTSTESTINGSTRING-IN, STRING-OUT LLMSTEXT SPLITTERSTOKENSTOOL CALLINGTOOLSTRACINGVECTOR STORESWHY LANGCHAIN?ECOSYSTEM🦜🛠️ LANGSMITH🦜🕸️ LANGGRAPHVERSIONSV0.3V0.2PYDANTIC COMPATIBILITYMIGRATING FROM V0.0 CHAINSHOW TO MIGRATE FROM V0.0 CHAINSMIGRATING FROM CONSTITUTIONALCHAINMIGRATING FROM CONVERSATIONALCHAINMIGRATING FROM CONVERSATIONALRETRIEVALCHAINMIGRATING FROM LLMCHAINMIGRATING FROM LLMMATHCHAINMIGRATING FROM LLMROUTERCHAINMIGRATING FROM MAPREDUCEDOCUMENTSCHAINMIGRATING FROM MAPRERANKDOCUMENTSCHAINMIGRATING FROM MULTIPROMPTCHAINMIGRATING FROM REFINEDOCUMENTSCHAINMIGRATING FROM RETRIEVALQAMIGRATING FROM STUFFDOCUMENTSCHAINUPGRADING TO LANGGRAPH MEMORYHOW TO MIGRATE TO LANGGRAPH MEMORYHOW TO USE BASECHATMESSAGEHISTORY WITH LANGGRAPHMIGRATING OFF CONVERSATIONBUFFERMEMORY OR CONVERSATIONSTRINGBUFFERMEMORYMIGRATING OFF CONVERSATIONBUFFERWINDOWMEMORY OR CONVERSATIONTOKENBUFFERMEMORYMIGRATING OFF CONVERSATIONSUMMARYMEMORY OR CONVERSATIONSUMMARYBUFFERMEMORYA LONG-TERM MEMORY AGENTRELEASE POLICYSECURITY POLICYHOW-TO GUIDESHOW TO CHAIN RUNNABLESON THIS PAGEHOW TO CHAIN RUNNABLES\n",
      "PREREQUISITESTHIS GUIDE ASSUMES FAMILIARITY WITH THE FOLLOWING CONCEPTS:\n",
      "LANGCHAIN EXPRESSION LANGUAGE (LCEL)\n",
      "PROMPT TEMPLATES\n",
      "CHAT MODELS\n",
      "OUTPUT PARSER\n",
      "\n",
      "ONE POINT ABOUT LANGCHAIN EXPRESSION LANGUAGE IS THAT ANY TWO RUNNABLES CAN BE \"CHAINED\" TOGETHER INTO SEQUENCES. THE OUTPUT OF THE PREVIOUS RUNNABLE'S .INVOKE() CALL IS PASSED AS INPUT TO THE NEXT RUNNABLE. THIS CAN BE DONE USING THE PIPE OPERATOR (|), OR THE MORE EXPLICIT .PIPE() METHOD, WHICH DOES THE SAME THING.\n",
      "THE RESULTING RUNNABLESEQUENCE IS ITSELF A RUNNABLE, WHICH MEANS IT CAN BE INVOKED, STREAMED, OR FURTHER CHAINED JUST LIKE ANY OTHER RUNNABLE. ADVANTAGES OF CHAINING RUNNABLES IN THIS WAY ARE EFFICIENT STREAMING (THE SEQUENCE WILL STREAM OUTPUT AS SOON AS IT IS AVAILABLE), AND DEBUGGING AND TRACING WITH TOOLS LIKE LANGSMITH.\n",
      "THE PIPE OPERATOR: |​\n",
      "TO SHOW OFF HOW THIS WORKS, LET'S GO THROUGH AN EXAMPLE. WE'LL WALK THROUGH A COMMON PATTERN IN LANGCHAIN: USING A PROMPT TEMPLATE TO FORMAT INPUT INTO A CHAT MODEL, AND FINALLY CONVERTING THE CHAT MESSAGE OUTPUT INTO A STRING WITH AN OUTPUT PARSER.\n",
      "\n",
      "SELECT CHAT MODEL:GROQ▾GROQOPENAIANTHROPICAZUREGOOGLE VERTEXAWSCOHERENVIDIAFIREWORKS AIMISTRAL AITOGETHER AIIBM WATSONXDATABRICKSXAIPIP INSTALL -QU \"LANGCHAIN[GROQ]\"IMPORT GETPASSIMPORT OSIF NOT OS.ENVIRON.GET(\"GROQ_API_KEY\"):  OS.ENVIRON[\"GROQ_API_KEY\"] = GETPASS.GETPASS(\"ENTER API KEY FOR GROQ: \")FROM LANGCHAIN.CHAT_MODELS IMPORT INIT_CHAT_MODELMODEL = INIT_CHAT_MODEL(\"LLAMA3-8B-8192\", MODEL_PROVIDER=\"GROQ\")\n",
      "FROM LANGCHAIN_CORE.OUTPUT_PARSERS IMPORT STROUTPUTPARSERFROM LANGCHAIN_CORE.PROMPTS IMPORT CHATPROMPTTEMPLATEPROMPT = CHATPROMPTTEMPLATE.FROM_TEMPLATE(\"TELL ME A JOKE ABOUT {TOPIC}\")CHAIN = PROMPT | MODEL | STROUTPUTPARSER()API REFERENCE:STROUTPUTPARSER | CHATPROMPTTEMPLATE\n",
      "PROMPTS AND MODELS ARE BOTH RUNNABLE, AND THE OUTPUT TYPE FROM THE PROMPT CALL IS THE SAME AS THE INPUT TYPE OF THE CHAT MODEL, SO WE CAN CHAIN THEM TOGETHER. WE CAN THEN INVOKE THE RESULTING SEQUENCE LIKE ANY OTHER RUNNABLE:\n",
      "CHAIN.INVOKE({\"TOPIC\": \"BEARS\"})\n",
      "\"HERE'S A BEAR JOKE FOR YOU:\\N\\NWHY DID THE BEAR DISSOLVE IN WATER?\\NBECAUSE IT WAS A POLAR BEAR!\"\n",
      "COERCION​\n",
      "WE CAN EVEN COMBINE THIS CHAIN WITH MORE RUNNABLES TO CREATE ANOTHER CHAIN. THIS MAY INVOLVE SOME INPUT/OUTPUT FORMATTING USING OTHER TYPES OF RUNNABLES, DEPENDING ON THE REQUIRED INPUTS AND OUTPUTS OF THE CHAIN COMPONENTS.\n",
      "FOR EXAMPLE, LET'S SAY WE WANTED TO COMPOSE THE JOKE GENERATING CHAIN WITH ANOTHER CHAIN THAT EVALUATES WHETHER OR NOT THE GENERATED JOKE WAS FUNNY.\n",
      "WE WOULD NEED TO BE CAREFUL WITH HOW WE FORMAT THE INPUT INTO THE NEXT CHAIN. IN THE BELOW EXAMPLE, THE DICT IN THE CHAIN IS AUTOMATICALLY PARSED AND CONVERTED INTO A RUNNABLEPARALLEL, WHICH RUNS ALL OF ITS VALUES IN PARALLEL AND RETURNS A DICT WITH THE RESULTS.\n",
      "THIS HAPPENS TO BE THE SAME FORMAT THE NEXT PROMPT TEMPLATE EXPECTS. HERE IT IS IN ACTION:\n",
      "FROM LANGCHAIN_CORE.OUTPUT_PARSERS IMPORT STROUTPUTPARSERANALYSIS_PROMPT = CHATPROMPTTEMPLATE.FROM_TEMPLATE(\"IS THIS A FUNNY JOKE? {JOKE}\")COMPOSED_CHAIN = {\"JOKE\": CHAIN} | ANALYSIS_PROMPT | MODEL | STROUTPUTPARSER()COMPOSED_CHAIN.INVOKE({\"TOPIC\": \"BEARS\"})API REFERENCE:STROUTPUTPARSER\n",
      "'HAHA, THAT\\'S A CLEVER PLAY ON WORDS! USING \"POLAR\" TO IMPLY THE BEAR DISSOLVED OR BECAME POLAR/POLARIZED WHEN PUT IN WATER. NOT THE MOST HILARIOUS JOKE EVER, BUT IT HAS A CUTE, GROAN-WORTHY PUN THAT MAKES IT MILDLY AMUSING. I APPRECIATE A GOOD PUN OR WORDPLAY JOKE.'\n",
      "FUNCTIONS WILL ALSO BE COERCED INTO RUNNABLES, SO YOU CAN ADD CUSTOM LOGIC TO YOUR CHAINS TOO. THE BELOW CHAIN RESULTS IN THE SAME LOGICAL FLOW AS BEFORE:\n",
      "COMPOSED_CHAIN_WITH_LAMBDA = (    CHAIN    | (LAMBDA INPUT: {\"JOKE\": INPUT})    | ANALYSIS_PROMPT    | MODEL    | STROUTPUTPARSER())COMPOSED_CHAIN_WITH_LAMBDA.INVOKE({\"TOPIC\": \"BEETS\"})\n",
      "\"HAHA, THAT'S A CUTE AND PUNNY JOKE! I LIKE HOW IT PLAYS ON THE IDEA OF BEETS BLUSHING OR TURNING RED LIKE SOMEONE BLUSHING. FOOD PUNS CAN BE QUITE AMUSING. WHILE NOT A TOTAL KNEE-SLAPPER, IT'S A LIGHT-HEARTED, GROAN-WORTHY DAD JOKE THAT WOULD MAKE ME CHUCKLE AND SHAKE MY HEAD. SIMPLE VEGETABLE HUMOR!\"\n",
      "HOWEVER, KEEP IN MIND THAT USING FUNCTIONS LIKE THIS MAY INTERFERE WITH OPERATIONS LIKE STREAMING. SEE THIS SECTION FOR MORE INFORMATION.\n",
      "THE .PIPE() METHOD​\n",
      "WE COULD ALSO COMPOSE THE SAME SEQUENCE USING THE .PIPE() METHOD. HERE'S WHAT THAT LOOKS LIKE:\n",
      "FROM LANGCHAIN_CORE.RUNNABLES IMPORT RUNNABLEPARALLELCOMPOSED_CHAIN_WITH_PIPE = (    RUNNABLEPARALLEL({\"JOKE\": CHAIN})    .PIPE(ANALYSIS_PROMPT)    .PIPE(MODEL)    .PIPE(STROUTPUTPARSER()))COMPOSED_CHAIN_WITH_PIPE.INVOKE({\"TOPIC\": \"BATTLESTAR GALACTICA\"})API REFERENCE:RUNNABLEPARALLEL\n",
      "\"I CANNOT REPRODUCE ANY COPYRIGHTED MATERIAL VERBATIM, BUT I CAN TRY TO ANALYZE THE HUMOR IN THE JOKE YOU PROVIDED WITHOUT QUOTING IT DIRECTLY.\\N\\NTHE JOKE PLAYS ON THE IDEA THAT THE CYLON RAIDERS, WHO ARE THE ANTAGONISTS IN THE BATTLESTAR GALACTICA UNIVERSE, FAILED TO LOCATE THE HUMAN SURVIVORS AFTER ATTACKING THEIR HOME PLANETS (THE TWELVE COLONIES) DUE TO USING AN OUTDATED AND POORLY PERFORMING OPERATING SYSTEM (WINDOWS VISTA) FOR THEIR TARGETING SYSTEMS.\\N\\NTHE HUMOR STEMS FROM THE JUXTAPOSITION OF A FUTURISTIC SCIENCE FICTION SETTING WITH A RELATABLE REAL-WORLD FRUSTRATION – THE USE OF BUGGY, SLOW, OR UNRELIABLE SOFTWARE OR TECHNOLOGY. IT POKES FUN AT THE PERCEIVED INADEQUACIES OF WINDOWS VISTA, WHICH WAS WIDELY CRITICIZED FOR ITS PERFORMANCE ISSUES AND OTHER PROBLEMS WHEN IT WAS RELEASED.\\N\\NBY ATTRIBUTING THE CYLONS' FAILURE TO LOCATE THE HUMANS TO THEIR USE OF VISTA, THE JOKE CREATES AN AMUSING AND UNEXPECTED CONNECTION BETWEEN A FICTIONAL ADVANCED RACE OF ROBOTS AND A FAMILIAR TECHNOLOGICAL ANNOYANCE EXPERIENCED BY MANY PEOPLE IN THE REAL WORLD.\\N\\NOVERALL, THE JOKE RELIES ON INCONGRUITY AND RELATABILITY TO GENERATE HUMOR, BUT WITHOUT REPRODUCING ANY COPYRIGHTED MATERIAL DIRECTLY.\"\n",
      "OR THE ABBREVIATED:\n",
      "COMPOSED_CHAIN_WITH_PIPE = RUNNABLEPARALLEL({\"JOKE\": CHAIN}).PIPE(    ANALYSIS_PROMPT, MODEL, STROUTPUTPARSER())\n",
      "RELATED​\n",
      "\n",
      "STREAMING: CHECK OUT THE STREAMING GUIDE TO UNDERSTAND THE STREAMING BEHAVIOR OF A CHAIN\n",
      "EDIT THIS PAGEWAS THIS PAGE HELPFUL?PREVIOUSHOW TO SPLIT TEXT BASED ON SEMANTIC SIMILARITYNEXTHOW TO SAVE AND LOAD LANGCHAIN OBJECTSTHE PIPE OPERATOR: |COERCIONTHE .PIPE() METHODRELATEDCOMMUNITYTWITTERGITHUBORGANIZATIONPYTHONJS/TSMOREHOMEPAGEBLOGYOUTUBECOPYRIGHT © 2025 LANGCHAIN, INC.\n",
      "\n",
      "\n",
      "          -------\n",
      "\n",
      "          THE PREVIOUS CODE ATTEMPT FAILED WITH THE FOLLOWING ERROR:\n",
      "          \"INPUT TO CHATPROMPTTEMPLATE IS MISSING VARIABLES {'JOKE'}.  EXPECTED: ['JOKE'] RECEIVED: ['TOPIC']\\NNOTE: IF YOU INTENDED {JOKE} TO BE PART OF THE STRING AND NOT A VARIABLE, PLEASE ESCAPE IT WITH DOUBLE CURLY BRACES LIKE: '{{JOKE}}'.\\NFOR TROUBLESHOOTING, VISIT: HTTPS://PYTHON.LANGCHAIN.COM/DOCS/TROUBLESHOOTING/ERRORS/INVALID_PROMPT_INPUT \"\n",
      "\n",
      "          YOUR CODING TASK:\n",
      "          HOW CAN I RUN TWO LCEL CHAINS IN PARALLEL AND SEQUENTIALLY?\n",
      "\n",
      "          PREVIOUS CODE ATTEMPT:\n",
      "          HERE'S HOW TO RUN TWO LCEL CHAINS IN BOTH PARALLEL AND SEQUENTIALLY. FIRST, WE'LL DEFINE THE INDIVIDUAL CHAINS AND THEN COMBINE THEM FOR PARALLEL AND SEQUENTIAL EXECUTION.\n",
      "          FROM LANGCHAIN_CORE.OUTPUT_PARSERS IMPORT STROUTPUTPARSER\n",
      "FROM LANGCHAIN_CORE.PROMPTS IMPORT CHATPROMPTTEMPLATE\n",
      "FROM LANGCHAIN_CORE.RUNNABLES IMPORT RUNNABLEPARALLEL\n",
      "FROM LANGCHAIN.CHAT_MODELS IMPORT INIT_CHAT_MODEL\n",
      "IMPORT GETPASS\n",
      "IMPORT OS\n",
      "\n",
      "# SETUP API KEY FOR THE MODEL\n",
      "IF NOT OS.ENVIRON.GET('GROQ_API_KEY'):\n",
      "    OS.ENVIRON['GROQ_API_KEY'] = GETPASS.GETPASS('ENTER API KEY FOR GROQ: ')\n",
      "\n",
      "# INITIALIZE THE CHAT MODEL\n",
      "MODEL = INIT_CHAT_MODEL('LLAMA3-8B-8192', MODEL_PROVIDER='GROQ')\n",
      "          # DEFINE THE FIRST CHAIN: GENERATE A JOKE\n",
      "JOKE_PROMPT = CHATPROMPTTEMPLATE.FROM_TEMPLATE('TELL ME A JOKE ABOUT {TOPIC}')\n",
      "JOKE_CHAIN = JOKE_PROMPT | MODEL | STROUTPUTPARSER()\n",
      "\n",
      "# DEFINE THE SECOND CHAIN: ANALYZE IF THE JOKE IS FUNNY\n",
      "ANALYZE_PROMPT = CHATPROMPTTEMPLATE.FROM_TEMPLATE('IS THIS A FUNNY JOKE? {JOKE}')\n",
      "ANALYZE_CHAIN = ANALYZE_PROMPT | MODEL | STROUTPUTPARSER()\n",
      "\n",
      "# SEQUENTIAL EXECUTION: RUN JOKE_CHAIN AND THEN PASS ITS OUTPUT TO ANALYZE_CHAIN\n",
      "SEQUENTIAL_CHAIN = JOKE_CHAIN | (LAMBDA INPUT: {'JOKE': INPUT}) | ANALYZE_CHAIN\n",
      "\n",
      "# EXECUTE SEQUENTIAL CHAIN\n",
      "TOPIC = {'TOPIC': 'BEARS'}\n",
      "RESULT_SEQUENTIAL = SEQUENTIAL_CHAIN.INVOKE(TOPIC)\n",
      "PRINT('SEQUENTIAL RESULT:', RESULT_SEQUENTIAL)\n",
      "\n",
      "# PARALLEL EXECUTION: RUN BOTH CHAINS IN PARALLEL\n",
      "PARALLEL_RUNNABLE = RUNNABLEPARALLEL({'JOKE_RESULT': JOKE_CHAIN, 'ANALYSIS_RESULT': ANALYZE_CHAIN})\n",
      "\n",
      "# EXECUTE PARALLEL CHAINS\n",
      "RESULT_PARALLEL = PARALLEL_RUNNABLE.INVOKE({'TOPIC': 'BEARS'})\n",
      "PRINT('PARALLEL RESULT:', RESULT_PARALLEL)\n",
      "\n",
      "          ANSWER WITH A DESCRIPTION OF THE CODE SOLUTION, FOLLOWED BY THE IMPORTS, AND FINALLY THE FUNCTIONING CODE BLOCK.\n",
      "          ENSURE ALL IMPORTS ARE CORRECT AND THE CODE IS EXECUTABLE.]: 2025-03-13 15:37:44.862964\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:44][🤖 AGENT 'CODING ASSISTANT' STARTED TASK]: 2025-03-13 15:37:44.863809\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:44][🤖 LLM CALL STARTED]: 2025-03-13 15:37:44.863937\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:59][✅ LLM CALL COMPLETED]: 2025-03-13 15:37:59.803905\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:59][✅ AGENT 'CODING ASSISTANT' COMPLETED TASK]: 2025-03-13 15:37:59.805017\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:59][✅ TASK COMPLETED: YOU ARE A CODING ASSISTANT WITH EXPERTISE IN LCEL, LANGCHAIN EXPRESSION LANGUAGE.\n",
      "          HERE IS A FULL SET OF LCEL DOCUMENTATION:\n",
      "          -------\n",
      "          \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "HOW TO CHAIN RUNNABLES | 🦜️🔗 LANGCHAIN\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "SKIP TO MAIN CONTENTJOIN US AT  INTERRUPT: THE AGENT AI CONFERENCE BY LANGCHAIN ON MAY 13 & 14 IN SAN FRANCISCO!INTEGRATIONSAPI REFERENCEMORECONTRIBUTINGPEOPLEERROR REFERENCELANGSMITHLANGGRAPHLANGCHAIN HUBLANGCHAIN JS/TSV0.3V0.3V0.2V0.1💬SEARCHINTRODUCTIONTUTORIALSBUILD A QUESTION ANSWERING APPLICATION OVER A GRAPH DATABASETUTORIALSBUILD A SIMPLE LLM APPLICATION WITH CHAT MODELS AND PROMPT TEMPLATESBUILD A CHATBOTBUILD A RETRIEVAL AUGMENTED GENERATION (RAG) APP: PART 2BUILD AN EXTRACTION CHAINBUILD AN AGENTTAGGINGBUILD A RETRIEVAL AUGMENTED GENERATION (RAG) APP: PART 1BUILD A SEMANTIC SEARCH ENGINEBUILD A QUESTION/ANSWERING SYSTEM OVER SQL DATASUMMARIZE TEXTHOW-TO GUIDESHOW-TO GUIDESHOW TO USE TOOLS IN A CHAINHOW TO USE A VECTORSTORE AS A RETRIEVERHOW TO ADD MEMORY TO CHATBOTSHOW TO USE EXAMPLE SELECTORSHOW TO ADD A SEMANTIC LAYER OVER GRAPH DATABASEHOW TO INVOKE RUNNABLES IN PARALLELHOW TO STREAM CHAT MODEL RESPONSESHOW TO ADD DEFAULT INVOCATION ARGS TO A RUNNABLEHOW TO ADD RETRIEVAL TO CHATBOTSHOW TO USE FEW SHOT EXAMPLES IN CHAT MODELSHOW TO DO TOOL/FUNCTION CALLINGHOW TO INSTALL LANGCHAIN PACKAGESHOW TO ADD EXAMPLES TO THE PROMPT FOR QUERY ANALYSISHOW TO USE FEW SHOT EXAMPLESHOW TO RUN CUSTOM FUNCTIONSHOW TO USE OUTPUT PARSERS TO PARSE AN LLM RESPONSE INTO STRUCTURED FORMATHOW TO HANDLE CASES WHERE NO QUERIES ARE GENERATEDHOW TO ROUTE BETWEEN SUB-CHAINSHOW TO RETURN STRUCTURED DATA FROM A MODELHOW TO SUMMARIZE TEXT THROUGH PARALLELIZATIONHOW TO SUMMARIZE TEXT THROUGH ITERATIVE REFINEMENTHOW TO SUMMARIZE TEXT IN A SINGLE LLM CALLHOW TO USE TOOLKITSHOW TO ADD AD-HOC TOOL CALLING CAPABILITY TO LLMS AND CHAT MODELSBUILD AN AGENT WITH AGENTEXECUTOR (LEGACY)HOW TO CONSTRUCT KNOWLEDGE GRAPHSHOW TO PARTIALLY FORMAT PROMPT TEMPLATESHOW TO HANDLE MULTIPLE QUERIES WHEN DOING QUERY ANALYSISHOW TO USE BUILT-IN TOOLS AND TOOLKITSHOW TO PASS THROUGH ARGUMENTS FROM ONE STEP TO THE NEXTHOW TO COMPOSE PROMPTS TOGETHERHOW TO HANDLE MULTIPLE RETRIEVERS WHEN DOING QUERY ANALYSISHOW TO ADD VALUES TO A CHAIN'S STATEHOW TO CONSTRUCT FILTERS FOR QUERY ANALYSISHOW TO CONFIGURE RUNTIME CHAIN INTERNALSHOW DEAL WITH HIGH CARDINALITY CATEGORICALS WHEN DOING QUERY ANALYSISCUSTOM DOCUMENT LOADERHOW TO USE THE MULTIQUERYRETRIEVERHOW TO ADD SCORES TO RETRIEVER RESULTSCACHINGHOW TO USE CALLBACKS IN ASYNC ENVIRONMENTSHOW TO ATTACH CALLBACKS TO A RUNNABLEHOW TO PROPAGATE CALLBACKS  CONSTRUCTORHOW TO DISPATCH CUSTOM CALLBACK EVENTSHOW TO PASS CALLBACKS IN AT RUNTIMEHOW TO SPLIT BY CHARACTERHOW TO CACHE CHAT MODEL RESPONSESHOW TO HANDLE RATE LIMITSHOW TO INIT ANY MODEL IN ONE LINEHOW TO TRACK TOKEN USAGE IN CHATMODELSHOW TO ADD TOOLS TO CHATBOTSHOW TO SPLIT CODEHOW TO DO RETRIEVAL WITH CONTEXTUAL COMPRESSIONHOW TO CONVERT RUNNABLES TO TOOLSHOW TO CREATE CUSTOM CALLBACK HANDLERSHOW TO CREATE A CUSTOM CHAT MODEL CLASSCUSTOM EMBEDDINGSHOW TO CREATE A CUSTOM LLM CLASSCUSTOM RETRIEVERHOW TO CREATE TOOLSHOW TO DEBUG YOUR LLM APPSHOW TO LOAD CSVSHOW TO LOAD DOCUMENTS FROM A DIRECTORYHOW TO LOAD HTMLHOW TO LOAD JSONHOW TO LOAD MARKDOWNHOW TO LOAD MICROSOFT OFFICE FILESHOW TO LOAD PDFSHOW TO LOAD WEB PAGESHOW TO CREATE A DYNAMIC (SELF-CONSTRUCTING) CHAINTEXT EMBEDDING MODELSHOW TO COMBINE RESULTS FROM MULTIPLE RETRIEVERSHOW TO SELECT EXAMPLES FROM A LANGSMITH DATASETHOW TO SELECT EXAMPLES BY LENGTHHOW TO SELECT EXAMPLES BY MAXIMAL MARGINAL RELEVANCE (MMR)HOW TO SELECT EXAMPLES BY N-GRAM OVERLAPHOW TO SELECT EXAMPLES BY SIMILARITYHOW TO USE REFERENCE EXAMPLES WHEN DOING EXTRACTIONHOW TO HANDLE LONG TEXT WHEN DOING EXTRACTIONHOW TO USE PROMPTING ALONE (NO TOOL CALLING) TO DO EXTRACTIONHOW TO ADD FALLBACKS TO A RUNNABLEHOW TO FILTER MESSAGESHYBRID SEARCHHOW TO USE THE LANGCHAIN INDEXING APIHOW TO INSPECT RUNNABLESLANGCHAIN EXPRESSION LANGUAGE CHEATSHEETHOW TO CACHE LLM RESPONSESHOW TO TRACK TOKEN USAGE FOR LLMSRUN MODELS LOCALLYHOW TO GET LOG PROBABILITIESHOW TO REORDER RETRIEVED RESULTS TO MITIGATE THE \"LOST IN THE MIDDLE\" EFFECTHOW TO SPLIT MARKDOWN BY HEADERSHOW TO MERGE CONSECUTIVE MESSAGES OF THE SAME TYPEHOW TO ADD MESSAGE HISTORYHOW TO MIGRATE FROM LEGACY LANGCHAIN AGENTS TO LANGGRAPHHOW TO RETRIEVE USING MULTIPLE VECTORS PER DOCUMENTHOW TO PASS MULTIMODAL DATA DIRECTLY TO MODELSHOW TO USE MULTIMODAL PROMPTSHOW TO CREATE A CUSTOM OUTPUT PARSERHOW TO USE THE OUTPUT-FIXING PARSERHOW TO PARSE JSON OUTPUTHOW TO RETRY WHEN A PARSING ERROR OCCURSHOW TO PARSE TEXT FROM MESSAGE OBJECTSHOW TO PARSE XML OUTPUTHOW TO PARSE YAML OUTPUTHOW TO USE THE PARENT DOCUMENT RETRIEVERHOW TO USE LANGCHAIN WITH DIFFERENT PYDANTIC VERSIONSHOW TO ADD CHAT HISTORYHOW TO GET A RAG APPLICATION TO ADD CITATIONSHOW TO DO PER-USER RETRIEVALHOW TO GET YOUR RAG APPLICATION TO RETURN SOURCESHOW TO STREAM RESULTS FROM YOUR RAG APPLICATIONHOW TO SPLIT JSON DATAHOW TO RECURSIVELY SPLIT TEXT BY CHARACTERSRESPONSE METADATAHOW TO PASS RUNTIME SECRETS TO RUNNABLESHOW TO DO \"SELF-QUERYING\" RETRIEVALHOW TO SPLIT TEXT BASED ON SEMANTIC SIMILARITYHOW TO CHAIN RUNNABLESHOW TO SAVE AND LOAD LANGCHAIN OBJECTSHOW TO SPLIT TEXT BY TOKENSHOW TO SPLIT HTMLHOW TO DO QUESTION ANSWERING OVER CSVSHOW TO DEAL WITH LARGE DATABASES WHEN DOING SQL QUESTION-ANSWERINGHOW TO BETTER PROMPT WHEN DOING SQL QUESTION-ANSWERINGHOW TO DO QUERY VALIDATION AS PART OF SQL QUESTION-ANSWERINGHOW TO STREAM RUNNABLESHOW TO STREAM RESPONSES FROM AN LLMHOW TO USE A TIME-WEIGHTED VECTOR STORE RETRIEVERHOW TO RETURN ARTIFACTS FROM A TOOLHOW TO USE CHAT MODELS TO CALL TOOLSHOW TO DISABLE PARALLEL TOOL CALLINGHOW TO FORCE MODELS TO CALL A TOOLHOW TO ACCESS THE RUNNABLECONFIG FROM A TOOLHOW TO PASS TOOL OUTPUTS TO CHAT MODELSHOW TO PASS RUN TIME VALUES TO TOOLSHOW TO STREAM EVENTS FROM A TOOLHOW TO STREAM TOOL CALLSHOW TO CONVERT TOOLS TO OPENAI FUNCTIONSHOW TO HANDLE TOOL ERRORSHOW TO USE FEW-SHOT PROMPTING WITH TOOL CALLINGHOW TO ADD A HUMAN-IN-THE-LOOP FOR TOOLSHOW TO BIND MODEL-SPECIFIC TOOLSHOW TO TRIM MESSAGESHOW TO CREATE AND QUERY VECTOR STORESCONCEPTUAL GUIDEAGENTSARCHITECTUREASYNC PROGRAMMING WITH LANGCHAINCALLBACKSCHAT HISTORYCHAT MODELSDOCUMENT LOADERSEMBEDDING MODELSEVALUATIONEXAMPLE SELECTORSFEW-SHOT PROMPTINGCONCEPTUAL GUIDEKEY-VALUE STORESLANGCHAIN EXPRESSION LANGUAGE (LCEL)MESSAGESMULTIMODALITYOUTPUT PARSERSPROMPT TEMPLATESRETRIEVAL AUGMENTED GENERATION (RAG)RETRIEVALRETRIEVERSRUNNABLE INTERFACESTREAMINGSTRUCTURED OUTPUTSTESTINGSTRING-IN, STRING-OUT LLMSTEXT SPLITTERSTOKENSTOOL CALLINGTOOLSTRACINGVECTOR STORESWHY LANGCHAIN?ECOSYSTEM🦜🛠️ LANGSMITH🦜🕸️ LANGGRAPHVERSIONSV0.3V0.2PYDANTIC COMPATIBILITYMIGRATING FROM V0.0 CHAINSHOW TO MIGRATE FROM V0.0 CHAINSMIGRATING FROM CONSTITUTIONALCHAINMIGRATING FROM CONVERSATIONALCHAINMIGRATING FROM CONVERSATIONALRETRIEVALCHAINMIGRATING FROM LLMCHAINMIGRATING FROM LLMMATHCHAINMIGRATING FROM LLMROUTERCHAINMIGRATING FROM MAPREDUCEDOCUMENTSCHAINMIGRATING FROM MAPRERANKDOCUMENTSCHAINMIGRATING FROM MULTIPROMPTCHAINMIGRATING FROM REFINEDOCUMENTSCHAINMIGRATING FROM RETRIEVALQAMIGRATING FROM STUFFDOCUMENTSCHAINUPGRADING TO LANGGRAPH MEMORYHOW TO MIGRATE TO LANGGRAPH MEMORYHOW TO USE BASECHATMESSAGEHISTORY WITH LANGGRAPHMIGRATING OFF CONVERSATIONBUFFERMEMORY OR CONVERSATIONSTRINGBUFFERMEMORYMIGRATING OFF CONVERSATIONBUFFERWINDOWMEMORY OR CONVERSATIONTOKENBUFFERMEMORYMIGRATING OFF CONVERSATIONSUMMARYMEMORY OR CONVERSATIONSUMMARYBUFFERMEMORYA LONG-TERM MEMORY AGENTRELEASE POLICYSECURITY POLICYHOW-TO GUIDESHOW TO CHAIN RUNNABLESON THIS PAGEHOW TO CHAIN RUNNABLES\n",
      "PREREQUISITESTHIS GUIDE ASSUMES FAMILIARITY WITH THE FOLLOWING CONCEPTS:\n",
      "LANGCHAIN EXPRESSION LANGUAGE (LCEL)\n",
      "PROMPT TEMPLATES\n",
      "CHAT MODELS\n",
      "OUTPUT PARSER\n",
      "\n",
      "ONE POINT ABOUT LANGCHAIN EXPRESSION LANGUAGE IS THAT ANY TWO RUNNABLES CAN BE \"CHAINED\" TOGETHER INTO SEQUENCES. THE OUTPUT OF THE PREVIOUS RUNNABLE'S .INVOKE() CALL IS PASSED AS INPUT TO THE NEXT RUNNABLE. THIS CAN BE DONE USING THE PIPE OPERATOR (|), OR THE MORE EXPLICIT .PIPE() METHOD, WHICH DOES THE SAME THING.\n",
      "THE RESULTING RUNNABLESEQUENCE IS ITSELF A RUNNABLE, WHICH MEANS IT CAN BE INVOKED, STREAMED, OR FURTHER CHAINED JUST LIKE ANY OTHER RUNNABLE. ADVANTAGES OF CHAINING RUNNABLES IN THIS WAY ARE EFFICIENT STREAMING (THE SEQUENCE WILL STREAM OUTPUT AS SOON AS IT IS AVAILABLE), AND DEBUGGING AND TRACING WITH TOOLS LIKE LANGSMITH.\n",
      "THE PIPE OPERATOR: |​\n",
      "TO SHOW OFF HOW THIS WORKS, LET'S GO THROUGH AN EXAMPLE. WE'LL WALK THROUGH A COMMON PATTERN IN LANGCHAIN: USING A PROMPT TEMPLATE TO FORMAT INPUT INTO A CHAT MODEL, AND FINALLY CONVERTING THE CHAT MESSAGE OUTPUT INTO A STRING WITH AN OUTPUT PARSER.\n",
      "\n",
      "SELECT CHAT MODEL:GROQ▾GROQOPENAIANTHROPICAZUREGOOGLE VERTEXAWSCOHERENVIDIAFIREWORKS AIMISTRAL AITOGETHER AIIBM WATSONXDATABRICKSXAIPIP INSTALL -QU \"LANGCHAIN[GROQ]\"IMPORT GETPASSIMPORT OSIF NOT OS.ENVIRON.GET(\"GROQ_API_KEY\"):  OS.ENVIRON[\"GROQ_API_KEY\"] = GETPASS.GETPASS(\"ENTER API KEY FOR GROQ: \")FROM LANGCHAIN.CHAT_MODELS IMPORT INIT_CHAT_MODELMODEL = INIT_CHAT_MODEL(\"LLAMA3-8B-8192\", MODEL_PROVIDER=\"GROQ\")\n",
      "FROM LANGCHAIN_CORE.OUTPUT_PARSERS IMPORT STROUTPUTPARSERFROM LANGCHAIN_CORE.PROMPTS IMPORT CHATPROMPTTEMPLATEPROMPT = CHATPROMPTTEMPLATE.FROM_TEMPLATE(\"TELL ME A JOKE ABOUT {TOPIC}\")CHAIN = PROMPT | MODEL | STROUTPUTPARSER()API REFERENCE:STROUTPUTPARSER | CHATPROMPTTEMPLATE\n",
      "PROMPTS AND MODELS ARE BOTH RUNNABLE, AND THE OUTPUT TYPE FROM THE PROMPT CALL IS THE SAME AS THE INPUT TYPE OF THE CHAT MODEL, SO WE CAN CHAIN THEM TOGETHER. WE CAN THEN INVOKE THE RESULTING SEQUENCE LIKE ANY OTHER RUNNABLE:\n",
      "CHAIN.INVOKE({\"TOPIC\": \"BEARS\"})\n",
      "\"HERE'S A BEAR JOKE FOR YOU:\\N\\NWHY DID THE BEAR DISSOLVE IN WATER?\\NBECAUSE IT WAS A POLAR BEAR!\"\n",
      "COERCION​\n",
      "WE CAN EVEN COMBINE THIS CHAIN WITH MORE RUNNABLES TO CREATE ANOTHER CHAIN. THIS MAY INVOLVE SOME INPUT/OUTPUT FORMATTING USING OTHER TYPES OF RUNNABLES, DEPENDING ON THE REQUIRED INPUTS AND OUTPUTS OF THE CHAIN COMPONENTS.\n",
      "FOR EXAMPLE, LET'S SAY WE WANTED TO COMPOSE THE JOKE GENERATING CHAIN WITH ANOTHER CHAIN THAT EVALUATES WHETHER OR NOT THE GENERATED JOKE WAS FUNNY.\n",
      "WE WOULD NEED TO BE CAREFUL WITH HOW WE FORMAT THE INPUT INTO THE NEXT CHAIN. IN THE BELOW EXAMPLE, THE DICT IN THE CHAIN IS AUTOMATICALLY PARSED AND CONVERTED INTO A RUNNABLEPARALLEL, WHICH RUNS ALL OF ITS VALUES IN PARALLEL AND RETURNS A DICT WITH THE RESULTS.\n",
      "THIS HAPPENS TO BE THE SAME FORMAT THE NEXT PROMPT TEMPLATE EXPECTS. HERE IT IS IN ACTION:\n",
      "FROM LANGCHAIN_CORE.OUTPUT_PARSERS IMPORT STROUTPUTPARSERANALYSIS_PROMPT = CHATPROMPTTEMPLATE.FROM_TEMPLATE(\"IS THIS A FUNNY JOKE? {JOKE}\")COMPOSED_CHAIN = {\"JOKE\": CHAIN} | ANALYSIS_PROMPT | MODEL | STROUTPUTPARSER()COMPOSED_CHAIN.INVOKE({\"TOPIC\": \"BEARS\"})API REFERENCE:STROUTPUTPARSER\n",
      "'HAHA, THAT\\'S A CLEVER PLAY ON WORDS! USING \"POLAR\" TO IMPLY THE BEAR DISSOLVED OR BECAME POLAR/POLARIZED WHEN PUT IN WATER. NOT THE MOST HILARIOUS JOKE EVER, BUT IT HAS A CUTE, GROAN-WORTHY PUN THAT MAKES IT MILDLY AMUSING. I APPRECIATE A GOOD PUN OR WORDPLAY JOKE.'\n",
      "FUNCTIONS WILL ALSO BE COERCED INTO RUNNABLES, SO YOU CAN ADD CUSTOM LOGIC TO YOUR CHAINS TOO. THE BELOW CHAIN RESULTS IN THE SAME LOGICAL FLOW AS BEFORE:\n",
      "COMPOSED_CHAIN_WITH_LAMBDA = (    CHAIN    | (LAMBDA INPUT: {\"JOKE\": INPUT})    | ANALYSIS_PROMPT    | MODEL    | STROUTPUTPARSER())COMPOSED_CHAIN_WITH_LAMBDA.INVOKE({\"TOPIC\": \"BEETS\"})\n",
      "\"HAHA, THAT'S A CUTE AND PUNNY JOKE! I LIKE HOW IT PLAYS ON THE IDEA OF BEETS BLUSHING OR TURNING RED LIKE SOMEONE BLUSHING. FOOD PUNS CAN BE QUITE AMUSING. WHILE NOT A TOTAL KNEE-SLAPPER, IT'S A LIGHT-HEARTED, GROAN-WORTHY DAD JOKE THAT WOULD MAKE ME CHUCKLE AND SHAKE MY HEAD. SIMPLE VEGETABLE HUMOR!\"\n",
      "HOWEVER, KEEP IN MIND THAT USING FUNCTIONS LIKE THIS MAY INTERFERE WITH OPERATIONS LIKE STREAMING. SEE THIS SECTION FOR MORE INFORMATION.\n",
      "THE .PIPE() METHOD​\n",
      "WE COULD ALSO COMPOSE THE SAME SEQUENCE USING THE .PIPE() METHOD. HERE'S WHAT THAT LOOKS LIKE:\n",
      "FROM LANGCHAIN_CORE.RUNNABLES IMPORT RUNNABLEPARALLELCOMPOSED_CHAIN_WITH_PIPE = (    RUNNABLEPARALLEL({\"JOKE\": CHAIN})    .PIPE(ANALYSIS_PROMPT)    .PIPE(MODEL)    .PIPE(STROUTPUTPARSER()))COMPOSED_CHAIN_WITH_PIPE.INVOKE({\"TOPIC\": \"BATTLESTAR GALACTICA\"})API REFERENCE:RUNNABLEPARALLEL\n",
      "\"I CANNOT REPRODUCE ANY COPYRIGHTED MATERIAL VERBATIM, BUT I CAN TRY TO ANALYZE THE HUMOR IN THE JOKE YOU PROVIDED WITHOUT QUOTING IT DIRECTLY.\\N\\NTHE JOKE PLAYS ON THE IDEA THAT THE CYLON RAIDERS, WHO ARE THE ANTAGONISTS IN THE BATTLESTAR GALACTICA UNIVERSE, FAILED TO LOCATE THE HUMAN SURVIVORS AFTER ATTACKING THEIR HOME PLANETS (THE TWELVE COLONIES) DUE TO USING AN OUTDATED AND POORLY PERFORMING OPERATING SYSTEM (WINDOWS VISTA) FOR THEIR TARGETING SYSTEMS.\\N\\NTHE HUMOR STEMS FROM THE JUXTAPOSITION OF A FUTURISTIC SCIENCE FICTION SETTING WITH A RELATABLE REAL-WORLD FRUSTRATION – THE USE OF BUGGY, SLOW, OR UNRELIABLE SOFTWARE OR TECHNOLOGY. IT POKES FUN AT THE PERCEIVED INADEQUACIES OF WINDOWS VISTA, WHICH WAS WIDELY CRITICIZED FOR ITS PERFORMANCE ISSUES AND OTHER PROBLEMS WHEN IT WAS RELEASED.\\N\\NBY ATTRIBUTING THE CYLONS' FAILURE TO LOCATE THE HUMANS TO THEIR USE OF VISTA, THE JOKE CREATES AN AMUSING AND UNEXPECTED CONNECTION BETWEEN A FICTIONAL ADVANCED RACE OF ROBOTS AND A FAMILIAR TECHNOLOGICAL ANNOYANCE EXPERIENCED BY MANY PEOPLE IN THE REAL WORLD.\\N\\NOVERALL, THE JOKE RELIES ON INCONGRUITY AND RELATABILITY TO GENERATE HUMOR, BUT WITHOUT REPRODUCING ANY COPYRIGHTED MATERIAL DIRECTLY.\"\n",
      "OR THE ABBREVIATED:\n",
      "COMPOSED_CHAIN_WITH_PIPE = RUNNABLEPARALLEL({\"JOKE\": CHAIN}).PIPE(    ANALYSIS_PROMPT, MODEL, STROUTPUTPARSER())\n",
      "RELATED​\n",
      "\n",
      "STREAMING: CHECK OUT THE STREAMING GUIDE TO UNDERSTAND THE STREAMING BEHAVIOR OF A CHAIN\n",
      "EDIT THIS PAGEWAS THIS PAGE HELPFUL?PREVIOUSHOW TO SPLIT TEXT BASED ON SEMANTIC SIMILARITYNEXTHOW TO SAVE AND LOAD LANGCHAIN OBJECTSTHE PIPE OPERATOR: |COERCIONTHE .PIPE() METHODRELATEDCOMMUNITYTWITTERGITHUBORGANIZATIONPYTHONJS/TSMOREHOMEPAGEBLOGYOUTUBECOPYRIGHT © 2025 LANGCHAIN, INC.\n",
      "\n",
      "\n",
      "          -------\n",
      "\n",
      "          THE PREVIOUS CODE ATTEMPT FAILED WITH THE FOLLOWING ERROR:\n",
      "          \"INPUT TO CHATPROMPTTEMPLATE IS MISSING VARIABLES {'JOKE'}.  EXPECTED: ['JOKE'] RECEIVED: ['TOPIC']\\NNOTE: IF YOU INTENDED {JOKE} TO BE PART OF THE STRING AND NOT A VARIABLE, PLEASE ESCAPE IT WITH DOUBLE CURLY BRACES LIKE: '{{JOKE}}'.\\NFOR TROUBLESHOOTING, VISIT: HTTPS://PYTHON.LANGCHAIN.COM/DOCS/TROUBLESHOOTING/ERRORS/INVALID_PROMPT_INPUT \"\n",
      "\n",
      "          YOUR CODING TASK:\n",
      "          HOW CAN I RUN TWO LCEL CHAINS IN PARALLEL AND SEQUENTIALLY?\n",
      "\n",
      "          PREVIOUS CODE ATTEMPT:\n",
      "          HERE'S HOW TO RUN TWO LCEL CHAINS IN BOTH PARALLEL AND SEQUENTIALLY. FIRST, WE'LL DEFINE THE INDIVIDUAL CHAINS AND THEN COMBINE THEM FOR PARALLEL AND SEQUENTIAL EXECUTION.\n",
      "          FROM LANGCHAIN_CORE.OUTPUT_PARSERS IMPORT STROUTPUTPARSER\n",
      "FROM LANGCHAIN_CORE.PROMPTS IMPORT CHATPROMPTTEMPLATE\n",
      "FROM LANGCHAIN_CORE.RUNNABLES IMPORT RUNNABLEPARALLEL\n",
      "FROM LANGCHAIN.CHAT_MODELS IMPORT INIT_CHAT_MODEL\n",
      "IMPORT GETPASS\n",
      "IMPORT OS\n",
      "\n",
      "# SETUP API KEY FOR THE MODEL\n",
      "IF NOT OS.ENVIRON.GET('GROQ_API_KEY'):\n",
      "    OS.ENVIRON['GROQ_API_KEY'] = GETPASS.GETPASS('ENTER API KEY FOR GROQ: ')\n",
      "\n",
      "# INITIALIZE THE CHAT MODEL\n",
      "MODEL = INIT_CHAT_MODEL('LLAMA3-8B-8192', MODEL_PROVIDER='GROQ')\n",
      "          # DEFINE THE FIRST CHAIN: GENERATE A JOKE\n",
      "JOKE_PROMPT = CHATPROMPTTEMPLATE.FROM_TEMPLATE('TELL ME A JOKE ABOUT {TOPIC}')\n",
      "JOKE_CHAIN = JOKE_PROMPT | MODEL | STROUTPUTPARSER()\n",
      "\n",
      "# DEFINE THE SECOND CHAIN: ANALYZE IF THE JOKE IS FUNNY\n",
      "ANALYZE_PROMPT = CHATPROMPTTEMPLATE.FROM_TEMPLATE('IS THIS A FUNNY JOKE? {JOKE}')\n",
      "ANALYZE_CHAIN = ANALYZE_PROMPT | MODEL | STROUTPUTPARSER()\n",
      "\n",
      "# SEQUENTIAL EXECUTION: RUN JOKE_CHAIN AND THEN PASS ITS OUTPUT TO ANALYZE_CHAIN\n",
      "SEQUENTIAL_CHAIN = JOKE_CHAIN | (LAMBDA INPUT: {'JOKE': INPUT}) | ANALYZE_CHAIN\n",
      "\n",
      "# EXECUTE SEQUENTIAL CHAIN\n",
      "TOPIC = {'TOPIC': 'BEARS'}\n",
      "RESULT_SEQUENTIAL = SEQUENTIAL_CHAIN.INVOKE(TOPIC)\n",
      "PRINT('SEQUENTIAL RESULT:', RESULT_SEQUENTIAL)\n",
      "\n",
      "# PARALLEL EXECUTION: RUN BOTH CHAINS IN PARALLEL\n",
      "PARALLEL_RUNNABLE = RUNNABLEPARALLEL({'JOKE_RESULT': JOKE_CHAIN, 'ANALYSIS_RESULT': ANALYZE_CHAIN})\n",
      "\n",
      "# EXECUTE PARALLEL CHAINS\n",
      "RESULT_PARALLEL = PARALLEL_RUNNABLE.INVOKE({'TOPIC': 'BEARS'})\n",
      "PRINT('PARALLEL RESULT:', RESULT_PARALLEL)\n",
      "\n",
      "          ANSWER WITH A DESCRIPTION OF THE CODE SOLUTION, FOLLOWED BY THE IMPORTS, AND FINALLY THE FUNCTIONING CODE BLOCK.\n",
      "          ENSURE ALL IMPORTS ARE CORRECT AND THE CODE IS EXECUTABLE.]: 2025-03-13 15:37:59.805766\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:59][✅ CREW 'CREW' COMPLETED, 1021A5ED-92FD-47E0-B207-775D392C7C9E]: 2025-03-13 15:37:59.810923\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:59][👍 FLOW METHOD FINISHED: 'RUN_FIX']: 2025-03-13 15:37:59.811385\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:37:59][🤖 FLOW METHOD STARTED: 'RE_RUN_CHECK']: 2025-03-13 15:37:59.811516\u001b[00m\n",
      "---CHECKING CODE---\n",
      "Sequential result: Ahaha, yes! That's a classic play on words, and it's a great example of a pun! The use of \"grizzly\" (meaning both the bear's species and the severity of the cough) is clever and unexpected, making it a funny joke. Well done!\n",
      "Parallel result: {'joke_result': 'Ahaha! Yes, that\\'s a clever and funny joke! The pun on \"grizzly\" (meaning both a type of bear and a descriptive word for a rough or severe cough) is what makes it humorous. It\\'s a great example of a well-crafted pun, which can bring a smile to people\\'s faces. Well done, whoever came up with that joke!'}\n",
      "---NO CODE TEST FAILURES---\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:38:00][👍 FLOW METHOD FINISHED: 'RE_RUN_CHECK']: 2025-03-13 15:38:00.963359\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:38:00][👍 FLOW FINISHED: 'CODEGENFLOW', 38DB8972-D295-4155-94E0-2DFEB4D62573]: 2025-03-13 15:38:00.964227\u001b[00m\n",
      "Sequential result: That's a classic play on words! The joke is funny because it's a clever pun on the phrase \"grizzly bear\" (a type of bear) and the phrase \"grisly cough\" (a cough that's unpleasant or frightening). The unexpected twist creates a sense of surprise and delight, making it a clever and amusing joke!\n",
      "Parallel result: {'joke_result': 'I think it is a funny joke! It\\'s a play on words, using \"grizzly\" to refer to both the type of bear and the severity of the cough, which is a clever and unexpected pun. Well done!'}\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:38:02][🌊 FLOW CREATED: 'CODEGENFLOW']: 2025-03-13 15:38:02.263178\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:38:02][🤖 FLOW STARTED: 'CODEGENFLOW', 4A113966-B19C-4B68-A0E7-BB099E825108]: 2025-03-13 15:38:02.264384\u001b[00m\n",
      "\u001b[1m\u001b[35m Flow started with ID: 4a113966-b19c-4b68-a0e7-bb099e825108\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:38:02][🤖 FLOW METHOD STARTED: 'GENERATE_CODE']: 2025-03-13 15:38:02.264907\u001b[00m\n",
      "---GENERATING CODE SOLUTION---\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:38:02][🚀 CREW 'CREW' STARTED, 368F5772-413F-4BF5-BD01-847C2CD6098D]: 2025-03-13 15:38:02.265536\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:38:02][📋 TASK STARTED: ANSWER THE USER QUESTION BASED ON THE ABOVE PROVIDED DOCUMENTATION. ENSURE ANY CODE YOU PROVIDE CAN BE EXECUTED\n",
      "    WITH ALL REQUIRED IMPORTS AND VARIABLES DEFINED. STRUCTURE YOUR ANSWER:\n",
      "    1) A PREFIX DESCRIBING THE CODE SOLUTION\n",
      "    2) THE IMPORTS\n",
      "    3) THE FUNCTIONING CODE BLOCK\n",
      "\n",
      "    YOUR CODING TASK:\n",
      "    HOW CAN I DIRECTLY PASS A STRING TO A RUNNABLE CHAIN?\n",
      "    ]: 2025-03-13 15:38:02.272052\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:38:02][🤖 AGENT 'CODING ASSISTANT' STARTED TASK]: 2025-03-13 15:38:02.273024\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:38:02][🤖 LLM CALL STARTED]: 2025-03-13 15:38:02.273151\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:38:07][✅ LLM CALL COMPLETED]: 2025-03-13 15:38:07.280178\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:38:07][✅ AGENT 'CODING ASSISTANT' COMPLETED TASK]: 2025-03-13 15:38:07.281262\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:38:07][✅ TASK COMPLETED: ANSWER THE USER QUESTION BASED ON THE ABOVE PROVIDED DOCUMENTATION. ENSURE ANY CODE YOU PROVIDE CAN BE EXECUTED\n",
      "    WITH ALL REQUIRED IMPORTS AND VARIABLES DEFINED. STRUCTURE YOUR ANSWER:\n",
      "    1) A PREFIX DESCRIBING THE CODE SOLUTION\n",
      "    2) THE IMPORTS\n",
      "    3) THE FUNCTIONING CODE BLOCK\n",
      "\n",
      "    YOUR CODING TASK:\n",
      "    HOW CAN I DIRECTLY PASS A STRING TO A RUNNABLE CHAIN?\n",
      "    ]: 2025-03-13 15:38:07.281574\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:38:07][✅ CREW 'CREW' COMPLETED, 368F5772-413F-4BF5-BD01-847C2CD6098D]: 2025-03-13 15:38:07.285157\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:38:07][👍 FLOW METHOD FINISHED: 'GENERATE_CODE']: 2025-03-13 15:38:07.285504\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:38:07][🤖 FLOW METHOD STARTED: 'RUN_CHECK']: 2025-03-13 15:38:07.285654\u001b[00m\n",
      "---CHECKING CODE---\n",
      "Why did the bear go to the doctor?\n",
      "\n",
      "Because it had a grizzly cough!\n",
      "\n",
      "Hope that made you roar with laughter!\n",
      "---NO CODE TEST FAILURES---\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:38:07][👍 FLOW METHOD FINISHED: 'RUN_CHECK']: 2025-03-13 15:38:07.631667\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:38:07][👍 FLOW FINISHED: 'CODEGENFLOW', 4A113966-B19C-4B68-A0E7-BB099E825108]: 2025-03-13 15:38:07.632224\u001b[00m\n",
      "Why did the bear go to the doctor?\n",
      "\n",
      "Because it had a grizzly cough!\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:38:07][🌊 FLOW CREATED: 'CODEGENFLOW']: 2025-03-13 15:38:07.886588\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:38:07][🤖 FLOW STARTED: 'CODEGENFLOW', 9DCFE464-316B-4ECC-B42F-628919014791]: 2025-03-13 15:38:07.887171\u001b[00m\n",
      "\u001b[1m\u001b[35m Flow started with ID: 9dcfe464-316b-4ecc-b42f-628919014791\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:38:07][🤖 FLOW METHOD STARTED: 'GENERATE_CODE']: 2025-03-13 15:38:07.887410\u001b[00m\n",
      "---GENERATING CODE SOLUTION---\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:38:07][🚀 CREW 'CREW' STARTED, 368F5772-413F-4BF5-BD01-847C2CD6098D]: 2025-03-13 15:38:07.889183\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:38:07][📋 TASK STARTED: ANSWER THE USER QUESTION BASED ON THE ABOVE PROVIDED DOCUMENTATION. ENSURE ANY CODE YOU PROVIDE CAN BE EXECUTED\n",
      "    WITH ALL REQUIRED IMPORTS AND VARIABLES DEFINED. STRUCTURE YOUR ANSWER:\n",
      "    1) A PREFIX DESCRIBING THE CODE SOLUTION\n",
      "    2) THE IMPORTS\n",
      "    3) THE FUNCTIONING CODE BLOCK\n",
      "\n",
      "    YOUR CODING TASK:\n",
      "    HOW CAN I USE A CUSTOM FUNCTION TO ROUTE BETWEEN TWO CHAINS?\n",
      "    ]: 2025-03-13 15:38:07.892005\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:38:07][🤖 AGENT 'CODING ASSISTANT' STARTED TASK]: 2025-03-13 15:38:07.892470\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:38:07][🤖 LLM CALL STARTED]: 2025-03-13 15:38:07.892554\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:38:11][✅ LLM CALL COMPLETED]: 2025-03-13 15:38:11.173093\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:38:11][✅ AGENT 'CODING ASSISTANT' COMPLETED TASK]: 2025-03-13 15:38:11.174215\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:38:11][✅ TASK COMPLETED: ANSWER THE USER QUESTION BASED ON THE ABOVE PROVIDED DOCUMENTATION. ENSURE ANY CODE YOU PROVIDE CAN BE EXECUTED\n",
      "    WITH ALL REQUIRED IMPORTS AND VARIABLES DEFINED. STRUCTURE YOUR ANSWER:\n",
      "    1) A PREFIX DESCRIBING THE CODE SOLUTION\n",
      "    2) THE IMPORTS\n",
      "    3) THE FUNCTIONING CODE BLOCK\n",
      "\n",
      "    YOUR CODING TASK:\n",
      "    HOW CAN I USE A CUSTOM FUNCTION TO ROUTE BETWEEN TWO CHAINS?\n",
      "    ]: 2025-03-13 15:38:11.174570\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:38:11][✅ CREW 'CREW' COMPLETED, 368F5772-413F-4BF5-BD01-847C2CD6098D]: 2025-03-13 15:38:11.178758\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:38:11][👍 FLOW METHOD FINISHED: 'GENERATE_CODE']: 2025-03-13 15:38:11.179078\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:38:11][🤖 FLOW METHOD STARTED: 'RUN_CHECK']: 2025-03-13 15:38:11.179220\u001b[00m\n",
      "---CHECKING CODE---\n",
      "---CODE BLOCK CHECK: FAILED---\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:38:11][👍 FLOW METHOD FINISHED: 'RUN_CHECK']: 2025-03-13 15:38:11.405999\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:38:11][🤖 FLOW METHOD STARTED: 'RUN_FIX']: 2025-03-13 15:38:11.407747\u001b[00m\n",
      "---FIXING CODE---\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:38:11][🚀 CREW 'CREW' STARTED, 9FDEA3EB-0EC6-462B-BCA6-55FFCE1E6CD3]: 2025-03-13 15:38:11.409243\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:38:11][📋 TASK STARTED: YOU ARE A CODING ASSISTANT WITH EXPERTISE IN LCEL, LANGCHAIN EXPRESSION LANGUAGE.\n",
      "          HERE IS A FULL SET OF LCEL DOCUMENTATION:\n",
      "          -------\n",
      "          \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "HOW TO CHAIN RUNNABLES | 🦜️🔗 LANGCHAIN\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "SKIP TO MAIN CONTENTJOIN US AT  INTERRUPT: THE AGENT AI CONFERENCE BY LANGCHAIN ON MAY 13 & 14 IN SAN FRANCISCO!INTEGRATIONSAPI REFERENCEMORECONTRIBUTINGPEOPLEERROR REFERENCELANGSMITHLANGGRAPHLANGCHAIN HUBLANGCHAIN JS/TSV0.3V0.3V0.2V0.1💬SEARCHINTRODUCTIONTUTORIALSBUILD A QUESTION ANSWERING APPLICATION OVER A GRAPH DATABASETUTORIALSBUILD A SIMPLE LLM APPLICATION WITH CHAT MODELS AND PROMPT TEMPLATESBUILD A CHATBOTBUILD A RETRIEVAL AUGMENTED GENERATION (RAG) APP: PART 2BUILD AN EXTRACTION CHAINBUILD AN AGENTTAGGINGBUILD A RETRIEVAL AUGMENTED GENERATION (RAG) APP: PART 1BUILD A SEMANTIC SEARCH ENGINEBUILD A QUESTION/ANSWERING SYSTEM OVER SQL DATASUMMARIZE TEXTHOW-TO GUIDESHOW-TO GUIDESHOW TO USE TOOLS IN A CHAINHOW TO USE A VECTORSTORE AS A RETRIEVERHOW TO ADD MEMORY TO CHATBOTSHOW TO USE EXAMPLE SELECTORSHOW TO ADD A SEMANTIC LAYER OVER GRAPH DATABASEHOW TO INVOKE RUNNABLES IN PARALLELHOW TO STREAM CHAT MODEL RESPONSESHOW TO ADD DEFAULT INVOCATION ARGS TO A RUNNABLEHOW TO ADD RETRIEVAL TO CHATBOTSHOW TO USE FEW SHOT EXAMPLES IN CHAT MODELSHOW TO DO TOOL/FUNCTION CALLINGHOW TO INSTALL LANGCHAIN PACKAGESHOW TO ADD EXAMPLES TO THE PROMPT FOR QUERY ANALYSISHOW TO USE FEW SHOT EXAMPLESHOW TO RUN CUSTOM FUNCTIONSHOW TO USE OUTPUT PARSERS TO PARSE AN LLM RESPONSE INTO STRUCTURED FORMATHOW TO HANDLE CASES WHERE NO QUERIES ARE GENERATEDHOW TO ROUTE BETWEEN SUB-CHAINSHOW TO RETURN STRUCTURED DATA FROM A MODELHOW TO SUMMARIZE TEXT THROUGH PARALLELIZATIONHOW TO SUMMARIZE TEXT THROUGH ITERATIVE REFINEMENTHOW TO SUMMARIZE TEXT IN A SINGLE LLM CALLHOW TO USE TOOLKITSHOW TO ADD AD-HOC TOOL CALLING CAPABILITY TO LLMS AND CHAT MODELSBUILD AN AGENT WITH AGENTEXECUTOR (LEGACY)HOW TO CONSTRUCT KNOWLEDGE GRAPHSHOW TO PARTIALLY FORMAT PROMPT TEMPLATESHOW TO HANDLE MULTIPLE QUERIES WHEN DOING QUERY ANALYSISHOW TO USE BUILT-IN TOOLS AND TOOLKITSHOW TO PASS THROUGH ARGUMENTS FROM ONE STEP TO THE NEXTHOW TO COMPOSE PROMPTS TOGETHERHOW TO HANDLE MULTIPLE RETRIEVERS WHEN DOING QUERY ANALYSISHOW TO ADD VALUES TO A CHAIN'S STATEHOW TO CONSTRUCT FILTERS FOR QUERY ANALYSISHOW TO CONFIGURE RUNTIME CHAIN INTERNALSHOW DEAL WITH HIGH CARDINALITY CATEGORICALS WHEN DOING QUERY ANALYSISCUSTOM DOCUMENT LOADERHOW TO USE THE MULTIQUERYRETRIEVERHOW TO ADD SCORES TO RETRIEVER RESULTSCACHINGHOW TO USE CALLBACKS IN ASYNC ENVIRONMENTSHOW TO ATTACH CALLBACKS TO A RUNNABLEHOW TO PROPAGATE CALLBACKS  CONSTRUCTORHOW TO DISPATCH CUSTOM CALLBACK EVENTSHOW TO PASS CALLBACKS IN AT RUNTIMEHOW TO SPLIT BY CHARACTERHOW TO CACHE CHAT MODEL RESPONSESHOW TO HANDLE RATE LIMITSHOW TO INIT ANY MODEL IN ONE LINEHOW TO TRACK TOKEN USAGE IN CHATMODELSHOW TO ADD TOOLS TO CHATBOTSHOW TO SPLIT CODEHOW TO DO RETRIEVAL WITH CONTEXTUAL COMPRESSIONHOW TO CONVERT RUNNABLES TO TOOLSHOW TO CREATE CUSTOM CALLBACK HANDLERSHOW TO CREATE A CUSTOM CHAT MODEL CLASSCUSTOM EMBEDDINGSHOW TO CREATE A CUSTOM LLM CLASSCUSTOM RETRIEVERHOW TO CREATE TOOLSHOW TO DEBUG YOUR LLM APPSHOW TO LOAD CSVSHOW TO LOAD DOCUMENTS FROM A DIRECTORYHOW TO LOAD HTMLHOW TO LOAD JSONHOW TO LOAD MARKDOWNHOW TO LOAD MICROSOFT OFFICE FILESHOW TO LOAD PDFSHOW TO LOAD WEB PAGESHOW TO CREATE A DYNAMIC (SELF-CONSTRUCTING) CHAINTEXT EMBEDDING MODELSHOW TO COMBINE RESULTS FROM MULTIPLE RETRIEVERSHOW TO SELECT EXAMPLES FROM A LANGSMITH DATASETHOW TO SELECT EXAMPLES BY LENGTHHOW TO SELECT EXAMPLES BY MAXIMAL MARGINAL RELEVANCE (MMR)HOW TO SELECT EXAMPLES BY N-GRAM OVERLAPHOW TO SELECT EXAMPLES BY SIMILARITYHOW TO USE REFERENCE EXAMPLES WHEN DOING EXTRACTIONHOW TO HANDLE LONG TEXT WHEN DOING EXTRACTIONHOW TO USE PROMPTING ALONE (NO TOOL CALLING) TO DO EXTRACTIONHOW TO ADD FALLBACKS TO A RUNNABLEHOW TO FILTER MESSAGESHYBRID SEARCHHOW TO USE THE LANGCHAIN INDEXING APIHOW TO INSPECT RUNNABLESLANGCHAIN EXPRESSION LANGUAGE CHEATSHEETHOW TO CACHE LLM RESPONSESHOW TO TRACK TOKEN USAGE FOR LLMSRUN MODELS LOCALLYHOW TO GET LOG PROBABILITIESHOW TO REORDER RETRIEVED RESULTS TO MITIGATE THE \"LOST IN THE MIDDLE\" EFFECTHOW TO SPLIT MARKDOWN BY HEADERSHOW TO MERGE CONSECUTIVE MESSAGES OF THE SAME TYPEHOW TO ADD MESSAGE HISTORYHOW TO MIGRATE FROM LEGACY LANGCHAIN AGENTS TO LANGGRAPHHOW TO RETRIEVE USING MULTIPLE VECTORS PER DOCUMENTHOW TO PASS MULTIMODAL DATA DIRECTLY TO MODELSHOW TO USE MULTIMODAL PROMPTSHOW TO CREATE A CUSTOM OUTPUT PARSERHOW TO USE THE OUTPUT-FIXING PARSERHOW TO PARSE JSON OUTPUTHOW TO RETRY WHEN A PARSING ERROR OCCURSHOW TO PARSE TEXT FROM MESSAGE OBJECTSHOW TO PARSE XML OUTPUTHOW TO PARSE YAML OUTPUTHOW TO USE THE PARENT DOCUMENT RETRIEVERHOW TO USE LANGCHAIN WITH DIFFERENT PYDANTIC VERSIONSHOW TO ADD CHAT HISTORYHOW TO GET A RAG APPLICATION TO ADD CITATIONSHOW TO DO PER-USER RETRIEVALHOW TO GET YOUR RAG APPLICATION TO RETURN SOURCESHOW TO STREAM RESULTS FROM YOUR RAG APPLICATIONHOW TO SPLIT JSON DATAHOW TO RECURSIVELY SPLIT TEXT BY CHARACTERSRESPONSE METADATAHOW TO PASS RUNTIME SECRETS TO RUNNABLESHOW TO DO \"SELF-QUERYING\" RETRIEVALHOW TO SPLIT TEXT BASED ON SEMANTIC SIMILARITYHOW TO CHAIN RUNNABLESHOW TO SAVE AND LOAD LANGCHAIN OBJECTSHOW TO SPLIT TEXT BY TOKENSHOW TO SPLIT HTMLHOW TO DO QUESTION ANSWERING OVER CSVSHOW TO DEAL WITH LARGE DATABASES WHEN DOING SQL QUESTION-ANSWERINGHOW TO BETTER PROMPT WHEN DOING SQL QUESTION-ANSWERINGHOW TO DO QUERY VALIDATION AS PART OF SQL QUESTION-ANSWERINGHOW TO STREAM RUNNABLESHOW TO STREAM RESPONSES FROM AN LLMHOW TO USE A TIME-WEIGHTED VECTOR STORE RETRIEVERHOW TO RETURN ARTIFACTS FROM A TOOLHOW TO USE CHAT MODELS TO CALL TOOLSHOW TO DISABLE PARALLEL TOOL CALLINGHOW TO FORCE MODELS TO CALL A TOOLHOW TO ACCESS THE RUNNABLECONFIG FROM A TOOLHOW TO PASS TOOL OUTPUTS TO CHAT MODELSHOW TO PASS RUN TIME VALUES TO TOOLSHOW TO STREAM EVENTS FROM A TOOLHOW TO STREAM TOOL CALLSHOW TO CONVERT TOOLS TO OPENAI FUNCTIONSHOW TO HANDLE TOOL ERRORSHOW TO USE FEW-SHOT PROMPTING WITH TOOL CALLINGHOW TO ADD A HUMAN-IN-THE-LOOP FOR TOOLSHOW TO BIND MODEL-SPECIFIC TOOLSHOW TO TRIM MESSAGESHOW TO CREATE AND QUERY VECTOR STORESCONCEPTUAL GUIDEAGENTSARCHITECTUREASYNC PROGRAMMING WITH LANGCHAINCALLBACKSCHAT HISTORYCHAT MODELSDOCUMENT LOADERSEMBEDDING MODELSEVALUATIONEXAMPLE SELECTORSFEW-SHOT PROMPTINGCONCEPTUAL GUIDEKEY-VALUE STORESLANGCHAIN EXPRESSION LANGUAGE (LCEL)MESSAGESMULTIMODALITYOUTPUT PARSERSPROMPT TEMPLATESRETRIEVAL AUGMENTED GENERATION (RAG)RETRIEVALRETRIEVERSRUNNABLE INTERFACESTREAMINGSTRUCTURED OUTPUTSTESTINGSTRING-IN, STRING-OUT LLMSTEXT SPLITTERSTOKENSTOOL CALLINGTOOLSTRACINGVECTOR STORESWHY LANGCHAIN?ECOSYSTEM🦜🛠️ LANGSMITH🦜🕸️ LANGGRAPHVERSIONSV0.3V0.2PYDANTIC COMPATIBILITYMIGRATING FROM V0.0 CHAINSHOW TO MIGRATE FROM V0.0 CHAINSMIGRATING FROM CONSTITUTIONALCHAINMIGRATING FROM CONVERSATIONALCHAINMIGRATING FROM CONVERSATIONALRETRIEVALCHAINMIGRATING FROM LLMCHAINMIGRATING FROM LLMMATHCHAINMIGRATING FROM LLMROUTERCHAINMIGRATING FROM MAPREDUCEDOCUMENTSCHAINMIGRATING FROM MAPRERANKDOCUMENTSCHAINMIGRATING FROM MULTIPROMPTCHAINMIGRATING FROM REFINEDOCUMENTSCHAINMIGRATING FROM RETRIEVALQAMIGRATING FROM STUFFDOCUMENTSCHAINUPGRADING TO LANGGRAPH MEMORYHOW TO MIGRATE TO LANGGRAPH MEMORYHOW TO USE BASECHATMESSAGEHISTORY WITH LANGGRAPHMIGRATING OFF CONVERSATIONBUFFERMEMORY OR CONVERSATIONSTRINGBUFFERMEMORYMIGRATING OFF CONVERSATIONBUFFERWINDOWMEMORY OR CONVERSATIONTOKENBUFFERMEMORYMIGRATING OFF CONVERSATIONSUMMARYMEMORY OR CONVERSATIONSUMMARYBUFFERMEMORYA LONG-TERM MEMORY AGENTRELEASE POLICYSECURITY POLICYHOW-TO GUIDESHOW TO CHAIN RUNNABLESON THIS PAGEHOW TO CHAIN RUNNABLES\n",
      "PREREQUISITESTHIS GUIDE ASSUMES FAMILIARITY WITH THE FOLLOWING CONCEPTS:\n",
      "LANGCHAIN EXPRESSION LANGUAGE (LCEL)\n",
      "PROMPT TEMPLATES\n",
      "CHAT MODELS\n",
      "OUTPUT PARSER\n",
      "\n",
      "ONE POINT ABOUT LANGCHAIN EXPRESSION LANGUAGE IS THAT ANY TWO RUNNABLES CAN BE \"CHAINED\" TOGETHER INTO SEQUENCES. THE OUTPUT OF THE PREVIOUS RUNNABLE'S .INVOKE() CALL IS PASSED AS INPUT TO THE NEXT RUNNABLE. THIS CAN BE DONE USING THE PIPE OPERATOR (|), OR THE MORE EXPLICIT .PIPE() METHOD, WHICH DOES THE SAME THING.\n",
      "THE RESULTING RUNNABLESEQUENCE IS ITSELF A RUNNABLE, WHICH MEANS IT CAN BE INVOKED, STREAMED, OR FURTHER CHAINED JUST LIKE ANY OTHER RUNNABLE. ADVANTAGES OF CHAINING RUNNABLES IN THIS WAY ARE EFFICIENT STREAMING (THE SEQUENCE WILL STREAM OUTPUT AS SOON AS IT IS AVAILABLE), AND DEBUGGING AND TRACING WITH TOOLS LIKE LANGSMITH.\n",
      "THE PIPE OPERATOR: |​\n",
      "TO SHOW OFF HOW THIS WORKS, LET'S GO THROUGH AN EXAMPLE. WE'LL WALK THROUGH A COMMON PATTERN IN LANGCHAIN: USING A PROMPT TEMPLATE TO FORMAT INPUT INTO A CHAT MODEL, AND FINALLY CONVERTING THE CHAT MESSAGE OUTPUT INTO A STRING WITH AN OUTPUT PARSER.\n",
      "\n",
      "SELECT CHAT MODEL:GROQ▾GROQOPENAIANTHROPICAZUREGOOGLE VERTEXAWSCOHERENVIDIAFIREWORKS AIMISTRAL AITOGETHER AIIBM WATSONXDATABRICKSXAIPIP INSTALL -QU \"LANGCHAIN[GROQ]\"IMPORT GETPASSIMPORT OSIF NOT OS.ENVIRON.GET(\"GROQ_API_KEY\"):  OS.ENVIRON[\"GROQ_API_KEY\"] = GETPASS.GETPASS(\"ENTER API KEY FOR GROQ: \")FROM LANGCHAIN.CHAT_MODELS IMPORT INIT_CHAT_MODELMODEL = INIT_CHAT_MODEL(\"LLAMA3-8B-8192\", MODEL_PROVIDER=\"GROQ\")\n",
      "FROM LANGCHAIN_CORE.OUTPUT_PARSERS IMPORT STROUTPUTPARSERFROM LANGCHAIN_CORE.PROMPTS IMPORT CHATPROMPTTEMPLATEPROMPT = CHATPROMPTTEMPLATE.FROM_TEMPLATE(\"TELL ME A JOKE ABOUT {TOPIC}\")CHAIN = PROMPT | MODEL | STROUTPUTPARSER()API REFERENCE:STROUTPUTPARSER | CHATPROMPTTEMPLATE\n",
      "PROMPTS AND MODELS ARE BOTH RUNNABLE, AND THE OUTPUT TYPE FROM THE PROMPT CALL IS THE SAME AS THE INPUT TYPE OF THE CHAT MODEL, SO WE CAN CHAIN THEM TOGETHER. WE CAN THEN INVOKE THE RESULTING SEQUENCE LIKE ANY OTHER RUNNABLE:\n",
      "CHAIN.INVOKE({\"TOPIC\": \"BEARS\"})\n",
      "\"HERE'S A BEAR JOKE FOR YOU:\\N\\NWHY DID THE BEAR DISSOLVE IN WATER?\\NBECAUSE IT WAS A POLAR BEAR!\"\n",
      "COERCION​\n",
      "WE CAN EVEN COMBINE THIS CHAIN WITH MORE RUNNABLES TO CREATE ANOTHER CHAIN. THIS MAY INVOLVE SOME INPUT/OUTPUT FORMATTING USING OTHER TYPES OF RUNNABLES, DEPENDING ON THE REQUIRED INPUTS AND OUTPUTS OF THE CHAIN COMPONENTS.\n",
      "FOR EXAMPLE, LET'S SAY WE WANTED TO COMPOSE THE JOKE GENERATING CHAIN WITH ANOTHER CHAIN THAT EVALUATES WHETHER OR NOT THE GENERATED JOKE WAS FUNNY.\n",
      "WE WOULD NEED TO BE CAREFUL WITH HOW WE FORMAT THE INPUT INTO THE NEXT CHAIN. IN THE BELOW EXAMPLE, THE DICT IN THE CHAIN IS AUTOMATICALLY PARSED AND CONVERTED INTO A RUNNABLEPARALLEL, WHICH RUNS ALL OF ITS VALUES IN PARALLEL AND RETURNS A DICT WITH THE RESULTS.\n",
      "THIS HAPPENS TO BE THE SAME FORMAT THE NEXT PROMPT TEMPLATE EXPECTS. HERE IT IS IN ACTION:\n",
      "FROM LANGCHAIN_CORE.OUTPUT_PARSERS IMPORT STROUTPUTPARSERANALYSIS_PROMPT = CHATPROMPTTEMPLATE.FROM_TEMPLATE(\"IS THIS A FUNNY JOKE? {JOKE}\")COMPOSED_CHAIN = {\"JOKE\": CHAIN} | ANALYSIS_PROMPT | MODEL | STROUTPUTPARSER()COMPOSED_CHAIN.INVOKE({\"TOPIC\": \"BEARS\"})API REFERENCE:STROUTPUTPARSER\n",
      "'HAHA, THAT\\'S A CLEVER PLAY ON WORDS! USING \"POLAR\" TO IMPLY THE BEAR DISSOLVED OR BECAME POLAR/POLARIZED WHEN PUT IN WATER. NOT THE MOST HILARIOUS JOKE EVER, BUT IT HAS A CUTE, GROAN-WORTHY PUN THAT MAKES IT MILDLY AMUSING. I APPRECIATE A GOOD PUN OR WORDPLAY JOKE.'\n",
      "FUNCTIONS WILL ALSO BE COERCED INTO RUNNABLES, SO YOU CAN ADD CUSTOM LOGIC TO YOUR CHAINS TOO. THE BELOW CHAIN RESULTS IN THE SAME LOGICAL FLOW AS BEFORE:\n",
      "COMPOSED_CHAIN_WITH_LAMBDA = (    CHAIN    | (LAMBDA INPUT: {\"JOKE\": INPUT})    | ANALYSIS_PROMPT    | MODEL    | STROUTPUTPARSER())COMPOSED_CHAIN_WITH_LAMBDA.INVOKE({\"TOPIC\": \"BEETS\"})\n",
      "\"HAHA, THAT'S A CUTE AND PUNNY JOKE! I LIKE HOW IT PLAYS ON THE IDEA OF BEETS BLUSHING OR TURNING RED LIKE SOMEONE BLUSHING. FOOD PUNS CAN BE QUITE AMUSING. WHILE NOT A TOTAL KNEE-SLAPPER, IT'S A LIGHT-HEARTED, GROAN-WORTHY DAD JOKE THAT WOULD MAKE ME CHUCKLE AND SHAKE MY HEAD. SIMPLE VEGETABLE HUMOR!\"\n",
      "HOWEVER, KEEP IN MIND THAT USING FUNCTIONS LIKE THIS MAY INTERFERE WITH OPERATIONS LIKE STREAMING. SEE THIS SECTION FOR MORE INFORMATION.\n",
      "THE .PIPE() METHOD​\n",
      "WE COULD ALSO COMPOSE THE SAME SEQUENCE USING THE .PIPE() METHOD. HERE'S WHAT THAT LOOKS LIKE:\n",
      "FROM LANGCHAIN_CORE.RUNNABLES IMPORT RUNNABLEPARALLELCOMPOSED_CHAIN_WITH_PIPE = (    RUNNABLEPARALLEL({\"JOKE\": CHAIN})    .PIPE(ANALYSIS_PROMPT)    .PIPE(MODEL)    .PIPE(STROUTPUTPARSER()))COMPOSED_CHAIN_WITH_PIPE.INVOKE({\"TOPIC\": \"BATTLESTAR GALACTICA\"})API REFERENCE:RUNNABLEPARALLEL\n",
      "\"I CANNOT REPRODUCE ANY COPYRIGHTED MATERIAL VERBATIM, BUT I CAN TRY TO ANALYZE THE HUMOR IN THE JOKE YOU PROVIDED WITHOUT QUOTING IT DIRECTLY.\\N\\NTHE JOKE PLAYS ON THE IDEA THAT THE CYLON RAIDERS, WHO ARE THE ANTAGONISTS IN THE BATTLESTAR GALACTICA UNIVERSE, FAILED TO LOCATE THE HUMAN SURVIVORS AFTER ATTACKING THEIR HOME PLANETS (THE TWELVE COLONIES) DUE TO USING AN OUTDATED AND POORLY PERFORMING OPERATING SYSTEM (WINDOWS VISTA) FOR THEIR TARGETING SYSTEMS.\\N\\NTHE HUMOR STEMS FROM THE JUXTAPOSITION OF A FUTURISTIC SCIENCE FICTION SETTING WITH A RELATABLE REAL-WORLD FRUSTRATION – THE USE OF BUGGY, SLOW, OR UNRELIABLE SOFTWARE OR TECHNOLOGY. IT POKES FUN AT THE PERCEIVED INADEQUACIES OF WINDOWS VISTA, WHICH WAS WIDELY CRITICIZED FOR ITS PERFORMANCE ISSUES AND OTHER PROBLEMS WHEN IT WAS RELEASED.\\N\\NBY ATTRIBUTING THE CYLONS' FAILURE TO LOCATE THE HUMANS TO THEIR USE OF VISTA, THE JOKE CREATES AN AMUSING AND UNEXPECTED CONNECTION BETWEEN A FICTIONAL ADVANCED RACE OF ROBOTS AND A FAMILIAR TECHNOLOGICAL ANNOYANCE EXPERIENCED BY MANY PEOPLE IN THE REAL WORLD.\\N\\NOVERALL, THE JOKE RELIES ON INCONGRUITY AND RELATABILITY TO GENERATE HUMOR, BUT WITHOUT REPRODUCING ANY COPYRIGHTED MATERIAL DIRECTLY.\"\n",
      "OR THE ABBREVIATED:\n",
      "COMPOSED_CHAIN_WITH_PIPE = RUNNABLEPARALLEL({\"JOKE\": CHAIN}).PIPE(    ANALYSIS_PROMPT, MODEL, STROUTPUTPARSER())\n",
      "RELATED​\n",
      "\n",
      "STREAMING: CHECK OUT THE STREAMING GUIDE TO UNDERSTAND THE STREAMING BEHAVIOR OF A CHAIN\n",
      "EDIT THIS PAGEWAS THIS PAGE HELPFUL?PREVIOUSHOW TO SPLIT TEXT BASED ON SEMANTIC SIMILARITYNEXTHOW TO SAVE AND LOAD LANGCHAIN OBJECTSTHE PIPE OPERATOR: |COERCIONTHE .PIPE() METHODRELATEDCOMMUNITYTWITTERGITHUBORGANIZATIONPYTHONJS/TSMOREHOMEPAGEBLOGYOUTUBECOPYRIGHT © 2025 LANGCHAIN, INC.\n",
      "\n",
      "\n",
      "          -------\n",
      "\n",
      "          THE PREVIOUS CODE ATTEMPT FAILED WITH THE FOLLOWING ERROR:\n",
      "          NAME 'ROUTE_FUNCTION' IS NOT DEFINED\n",
      "\n",
      "          YOUR CODING TASK:\n",
      "          HOW CAN I USE A CUSTOM FUNCTION TO ROUTE BETWEEN TWO CHAINS?\n",
      "\n",
      "          PREVIOUS CODE ATTEMPT:\n",
      "          THE FOLLOWING CODE DEMONSTRATES HOW TO USE A CUSTOM FUNCTION TO ROUTE BETWEEN TWO CHAINS IN LANGCHAIN. THE CUSTOM FUNCTION IS UTILIZED AS A RUNNABLE TO TRANSFORM THE OUTPUT OF THE FIRST CHAIN BEFORE PASSING IT TO THE SECOND CHAIN.\n",
      "          FROM LANGCHAIN_CORE.PROMPTS IMPORT CHATPROMPTTEMPLATE\n",
      "FROM LANGCHAIN.CHAT_MODELS IMPORT INIT_CHAT_MODEL\n",
      "FROM LANGCHAIN_CORE.OUTPUT_PARSERS IMPORT STROUTPUTPARSER\n",
      "          PROMPT = CHATPROMPTTEMPLATE.FROM_TEMPLATE(\"TELL ME A JOKE ABOUT {TOPIC}\")\n",
      "MODEL = INIT_CHAT_MODEL(\"LLAMA3-8B-8192\", MODEL_PROVIDER=\"GROQ\")\n",
      "\n",
      "# DEFINE THE FIRST CHAIN TO GENERATE JOKES\n",
      "JOKE_CHAIN = PROMPT | MODEL | STROUTPUTPARSER()\n",
      "\n",
      "# DEFINE A CUSTOM FUNCTION TO ROUTE OUTPUT BETWEEN CHAINS\n",
      "DEF ROUTE_FUNCTION(OUTPUT):\n",
      "    # TRANSFORM THE OUTPUT OF THE FIRST CHAIN AS NEEDED FOR THE NEXT CHAIN\n",
      "    RETURN {\"JOKE\": OUTPUT}\n",
      "\n",
      "# DEFINE A SECOND CHAIN TO ANALYZE THE JOKE\n",
      "ANALYSIS_PROMPT = CHATPROMPTTEMPLATE.FROM_TEMPLATE(\"IS THIS A FUNNY JOKE? {JOKE}\")\n",
      "\n",
      "# COMPOSE A NEW CHAIN USING THE CUSTOM FUNCTION TO ROUTE THE OUTPUT\n",
      "COMPOSED_CHAIN = (\n",
      "    JOKE_CHAIN\n",
      "    | (LAMBDA INPUT: ROUTE_FUNCTION(INPUT))  # CUSTOM FUNCTION ROUTING\n",
      "    | ANALYSIS_PROMPT\n",
      "    | MODEL\n",
      "    | STROUTPUTPARSER()\n",
      ")\n",
      "\n",
      "# EXECUTE THE COMPOSED CHAIN\n",
      "RESULT = COMPOSED_CHAIN.INVOKE({\"TOPIC\": \"BEARS\"})\n",
      "PRINT(RESULT)\n",
      "\n",
      "          ANSWER WITH A DESCRIPTION OF THE CODE SOLUTION, FOLLOWED BY THE IMPORTS, AND FINALLY THE FUNCTIONING CODE BLOCK.\n",
      "          ENSURE ALL IMPORTS ARE CORRECT AND THE CODE IS EXECUTABLE.]: 2025-03-13 15:38:11.412289\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:38:11][🤖 AGENT 'CODING ASSISTANT' STARTED TASK]: 2025-03-13 15:38:11.412970\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:38:11][🤖 LLM CALL STARTED]: 2025-03-13 15:38:11.413100\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:38:27][✅ LLM CALL COMPLETED]: 2025-03-13 15:38:27.347402\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:38:27][✅ AGENT 'CODING ASSISTANT' COMPLETED TASK]: 2025-03-13 15:38:27.349294\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:38:27][✅ TASK COMPLETED: YOU ARE A CODING ASSISTANT WITH EXPERTISE IN LCEL, LANGCHAIN EXPRESSION LANGUAGE.\n",
      "          HERE IS A FULL SET OF LCEL DOCUMENTATION:\n",
      "          -------\n",
      "          \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "HOW TO CHAIN RUNNABLES | 🦜️🔗 LANGCHAIN\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "SKIP TO MAIN CONTENTJOIN US AT  INTERRUPT: THE AGENT AI CONFERENCE BY LANGCHAIN ON MAY 13 & 14 IN SAN FRANCISCO!INTEGRATIONSAPI REFERENCEMORECONTRIBUTINGPEOPLEERROR REFERENCELANGSMITHLANGGRAPHLANGCHAIN HUBLANGCHAIN JS/TSV0.3V0.3V0.2V0.1💬SEARCHINTRODUCTIONTUTORIALSBUILD A QUESTION ANSWERING APPLICATION OVER A GRAPH DATABASETUTORIALSBUILD A SIMPLE LLM APPLICATION WITH CHAT MODELS AND PROMPT TEMPLATESBUILD A CHATBOTBUILD A RETRIEVAL AUGMENTED GENERATION (RAG) APP: PART 2BUILD AN EXTRACTION CHAINBUILD AN AGENTTAGGINGBUILD A RETRIEVAL AUGMENTED GENERATION (RAG) APP: PART 1BUILD A SEMANTIC SEARCH ENGINEBUILD A QUESTION/ANSWERING SYSTEM OVER SQL DATASUMMARIZE TEXTHOW-TO GUIDESHOW-TO GUIDESHOW TO USE TOOLS IN A CHAINHOW TO USE A VECTORSTORE AS A RETRIEVERHOW TO ADD MEMORY TO CHATBOTSHOW TO USE EXAMPLE SELECTORSHOW TO ADD A SEMANTIC LAYER OVER GRAPH DATABASEHOW TO INVOKE RUNNABLES IN PARALLELHOW TO STREAM CHAT MODEL RESPONSESHOW TO ADD DEFAULT INVOCATION ARGS TO A RUNNABLEHOW TO ADD RETRIEVAL TO CHATBOTSHOW TO USE FEW SHOT EXAMPLES IN CHAT MODELSHOW TO DO TOOL/FUNCTION CALLINGHOW TO INSTALL LANGCHAIN PACKAGESHOW TO ADD EXAMPLES TO THE PROMPT FOR QUERY ANALYSISHOW TO USE FEW SHOT EXAMPLESHOW TO RUN CUSTOM FUNCTIONSHOW TO USE OUTPUT PARSERS TO PARSE AN LLM RESPONSE INTO STRUCTURED FORMATHOW TO HANDLE CASES WHERE NO QUERIES ARE GENERATEDHOW TO ROUTE BETWEEN SUB-CHAINSHOW TO RETURN STRUCTURED DATA FROM A MODELHOW TO SUMMARIZE TEXT THROUGH PARALLELIZATIONHOW TO SUMMARIZE TEXT THROUGH ITERATIVE REFINEMENTHOW TO SUMMARIZE TEXT IN A SINGLE LLM CALLHOW TO USE TOOLKITSHOW TO ADD AD-HOC TOOL CALLING CAPABILITY TO LLMS AND CHAT MODELSBUILD AN AGENT WITH AGENTEXECUTOR (LEGACY)HOW TO CONSTRUCT KNOWLEDGE GRAPHSHOW TO PARTIALLY FORMAT PROMPT TEMPLATESHOW TO HANDLE MULTIPLE QUERIES WHEN DOING QUERY ANALYSISHOW TO USE BUILT-IN TOOLS AND TOOLKITSHOW TO PASS THROUGH ARGUMENTS FROM ONE STEP TO THE NEXTHOW TO COMPOSE PROMPTS TOGETHERHOW TO HANDLE MULTIPLE RETRIEVERS WHEN DOING QUERY ANALYSISHOW TO ADD VALUES TO A CHAIN'S STATEHOW TO CONSTRUCT FILTERS FOR QUERY ANALYSISHOW TO CONFIGURE RUNTIME CHAIN INTERNALSHOW DEAL WITH HIGH CARDINALITY CATEGORICALS WHEN DOING QUERY ANALYSISCUSTOM DOCUMENT LOADERHOW TO USE THE MULTIQUERYRETRIEVERHOW TO ADD SCORES TO RETRIEVER RESULTSCACHINGHOW TO USE CALLBACKS IN ASYNC ENVIRONMENTSHOW TO ATTACH CALLBACKS TO A RUNNABLEHOW TO PROPAGATE CALLBACKS  CONSTRUCTORHOW TO DISPATCH CUSTOM CALLBACK EVENTSHOW TO PASS CALLBACKS IN AT RUNTIMEHOW TO SPLIT BY CHARACTERHOW TO CACHE CHAT MODEL RESPONSESHOW TO HANDLE RATE LIMITSHOW TO INIT ANY MODEL IN ONE LINEHOW TO TRACK TOKEN USAGE IN CHATMODELSHOW TO ADD TOOLS TO CHATBOTSHOW TO SPLIT CODEHOW TO DO RETRIEVAL WITH CONTEXTUAL COMPRESSIONHOW TO CONVERT RUNNABLES TO TOOLSHOW TO CREATE CUSTOM CALLBACK HANDLERSHOW TO CREATE A CUSTOM CHAT MODEL CLASSCUSTOM EMBEDDINGSHOW TO CREATE A CUSTOM LLM CLASSCUSTOM RETRIEVERHOW TO CREATE TOOLSHOW TO DEBUG YOUR LLM APPSHOW TO LOAD CSVSHOW TO LOAD DOCUMENTS FROM A DIRECTORYHOW TO LOAD HTMLHOW TO LOAD JSONHOW TO LOAD MARKDOWNHOW TO LOAD MICROSOFT OFFICE FILESHOW TO LOAD PDFSHOW TO LOAD WEB PAGESHOW TO CREATE A DYNAMIC (SELF-CONSTRUCTING) CHAINTEXT EMBEDDING MODELSHOW TO COMBINE RESULTS FROM MULTIPLE RETRIEVERSHOW TO SELECT EXAMPLES FROM A LANGSMITH DATASETHOW TO SELECT EXAMPLES BY LENGTHHOW TO SELECT EXAMPLES BY MAXIMAL MARGINAL RELEVANCE (MMR)HOW TO SELECT EXAMPLES BY N-GRAM OVERLAPHOW TO SELECT EXAMPLES BY SIMILARITYHOW TO USE REFERENCE EXAMPLES WHEN DOING EXTRACTIONHOW TO HANDLE LONG TEXT WHEN DOING EXTRACTIONHOW TO USE PROMPTING ALONE (NO TOOL CALLING) TO DO EXTRACTIONHOW TO ADD FALLBACKS TO A RUNNABLEHOW TO FILTER MESSAGESHYBRID SEARCHHOW TO USE THE LANGCHAIN INDEXING APIHOW TO INSPECT RUNNABLESLANGCHAIN EXPRESSION LANGUAGE CHEATSHEETHOW TO CACHE LLM RESPONSESHOW TO TRACK TOKEN USAGE FOR LLMSRUN MODELS LOCALLYHOW TO GET LOG PROBABILITIESHOW TO REORDER RETRIEVED RESULTS TO MITIGATE THE \"LOST IN THE MIDDLE\" EFFECTHOW TO SPLIT MARKDOWN BY HEADERSHOW TO MERGE CONSECUTIVE MESSAGES OF THE SAME TYPEHOW TO ADD MESSAGE HISTORYHOW TO MIGRATE FROM LEGACY LANGCHAIN AGENTS TO LANGGRAPHHOW TO RETRIEVE USING MULTIPLE VECTORS PER DOCUMENTHOW TO PASS MULTIMODAL DATA DIRECTLY TO MODELSHOW TO USE MULTIMODAL PROMPTSHOW TO CREATE A CUSTOM OUTPUT PARSERHOW TO USE THE OUTPUT-FIXING PARSERHOW TO PARSE JSON OUTPUTHOW TO RETRY WHEN A PARSING ERROR OCCURSHOW TO PARSE TEXT FROM MESSAGE OBJECTSHOW TO PARSE XML OUTPUTHOW TO PARSE YAML OUTPUTHOW TO USE THE PARENT DOCUMENT RETRIEVERHOW TO USE LANGCHAIN WITH DIFFERENT PYDANTIC VERSIONSHOW TO ADD CHAT HISTORYHOW TO GET A RAG APPLICATION TO ADD CITATIONSHOW TO DO PER-USER RETRIEVALHOW TO GET YOUR RAG APPLICATION TO RETURN SOURCESHOW TO STREAM RESULTS FROM YOUR RAG APPLICATIONHOW TO SPLIT JSON DATAHOW TO RECURSIVELY SPLIT TEXT BY CHARACTERSRESPONSE METADATAHOW TO PASS RUNTIME SECRETS TO RUNNABLESHOW TO DO \"SELF-QUERYING\" RETRIEVALHOW TO SPLIT TEXT BASED ON SEMANTIC SIMILARITYHOW TO CHAIN RUNNABLESHOW TO SAVE AND LOAD LANGCHAIN OBJECTSHOW TO SPLIT TEXT BY TOKENSHOW TO SPLIT HTMLHOW TO DO QUESTION ANSWERING OVER CSVSHOW TO DEAL WITH LARGE DATABASES WHEN DOING SQL QUESTION-ANSWERINGHOW TO BETTER PROMPT WHEN DOING SQL QUESTION-ANSWERINGHOW TO DO QUERY VALIDATION AS PART OF SQL QUESTION-ANSWERINGHOW TO STREAM RUNNABLESHOW TO STREAM RESPONSES FROM AN LLMHOW TO USE A TIME-WEIGHTED VECTOR STORE RETRIEVERHOW TO RETURN ARTIFACTS FROM A TOOLHOW TO USE CHAT MODELS TO CALL TOOLSHOW TO DISABLE PARALLEL TOOL CALLINGHOW TO FORCE MODELS TO CALL A TOOLHOW TO ACCESS THE RUNNABLECONFIG FROM A TOOLHOW TO PASS TOOL OUTPUTS TO CHAT MODELSHOW TO PASS RUN TIME VALUES TO TOOLSHOW TO STREAM EVENTS FROM A TOOLHOW TO STREAM TOOL CALLSHOW TO CONVERT TOOLS TO OPENAI FUNCTIONSHOW TO HANDLE TOOL ERRORSHOW TO USE FEW-SHOT PROMPTING WITH TOOL CALLINGHOW TO ADD A HUMAN-IN-THE-LOOP FOR TOOLSHOW TO BIND MODEL-SPECIFIC TOOLSHOW TO TRIM MESSAGESHOW TO CREATE AND QUERY VECTOR STORESCONCEPTUAL GUIDEAGENTSARCHITECTUREASYNC PROGRAMMING WITH LANGCHAINCALLBACKSCHAT HISTORYCHAT MODELSDOCUMENT LOADERSEMBEDDING MODELSEVALUATIONEXAMPLE SELECTORSFEW-SHOT PROMPTINGCONCEPTUAL GUIDEKEY-VALUE STORESLANGCHAIN EXPRESSION LANGUAGE (LCEL)MESSAGESMULTIMODALITYOUTPUT PARSERSPROMPT TEMPLATESRETRIEVAL AUGMENTED GENERATION (RAG)RETRIEVALRETRIEVERSRUNNABLE INTERFACESTREAMINGSTRUCTURED OUTPUTSTESTINGSTRING-IN, STRING-OUT LLMSTEXT SPLITTERSTOKENSTOOL CALLINGTOOLSTRACINGVECTOR STORESWHY LANGCHAIN?ECOSYSTEM🦜🛠️ LANGSMITH🦜🕸️ LANGGRAPHVERSIONSV0.3V0.2PYDANTIC COMPATIBILITYMIGRATING FROM V0.0 CHAINSHOW TO MIGRATE FROM V0.0 CHAINSMIGRATING FROM CONSTITUTIONALCHAINMIGRATING FROM CONVERSATIONALCHAINMIGRATING FROM CONVERSATIONALRETRIEVALCHAINMIGRATING FROM LLMCHAINMIGRATING FROM LLMMATHCHAINMIGRATING FROM LLMROUTERCHAINMIGRATING FROM MAPREDUCEDOCUMENTSCHAINMIGRATING FROM MAPRERANKDOCUMENTSCHAINMIGRATING FROM MULTIPROMPTCHAINMIGRATING FROM REFINEDOCUMENTSCHAINMIGRATING FROM RETRIEVALQAMIGRATING FROM STUFFDOCUMENTSCHAINUPGRADING TO LANGGRAPH MEMORYHOW TO MIGRATE TO LANGGRAPH MEMORYHOW TO USE BASECHATMESSAGEHISTORY WITH LANGGRAPHMIGRATING OFF CONVERSATIONBUFFERMEMORY OR CONVERSATIONSTRINGBUFFERMEMORYMIGRATING OFF CONVERSATIONBUFFERWINDOWMEMORY OR CONVERSATIONTOKENBUFFERMEMORYMIGRATING OFF CONVERSATIONSUMMARYMEMORY OR CONVERSATIONSUMMARYBUFFERMEMORYA LONG-TERM MEMORY AGENTRELEASE POLICYSECURITY POLICYHOW-TO GUIDESHOW TO CHAIN RUNNABLESON THIS PAGEHOW TO CHAIN RUNNABLES\n",
      "PREREQUISITESTHIS GUIDE ASSUMES FAMILIARITY WITH THE FOLLOWING CONCEPTS:\n",
      "LANGCHAIN EXPRESSION LANGUAGE (LCEL)\n",
      "PROMPT TEMPLATES\n",
      "CHAT MODELS\n",
      "OUTPUT PARSER\n",
      "\n",
      "ONE POINT ABOUT LANGCHAIN EXPRESSION LANGUAGE IS THAT ANY TWO RUNNABLES CAN BE \"CHAINED\" TOGETHER INTO SEQUENCES. THE OUTPUT OF THE PREVIOUS RUNNABLE'S .INVOKE() CALL IS PASSED AS INPUT TO THE NEXT RUNNABLE. THIS CAN BE DONE USING THE PIPE OPERATOR (|), OR THE MORE EXPLICIT .PIPE() METHOD, WHICH DOES THE SAME THING.\n",
      "THE RESULTING RUNNABLESEQUENCE IS ITSELF A RUNNABLE, WHICH MEANS IT CAN BE INVOKED, STREAMED, OR FURTHER CHAINED JUST LIKE ANY OTHER RUNNABLE. ADVANTAGES OF CHAINING RUNNABLES IN THIS WAY ARE EFFICIENT STREAMING (THE SEQUENCE WILL STREAM OUTPUT AS SOON AS IT IS AVAILABLE), AND DEBUGGING AND TRACING WITH TOOLS LIKE LANGSMITH.\n",
      "THE PIPE OPERATOR: |​\n",
      "TO SHOW OFF HOW THIS WORKS, LET'S GO THROUGH AN EXAMPLE. WE'LL WALK THROUGH A COMMON PATTERN IN LANGCHAIN: USING A PROMPT TEMPLATE TO FORMAT INPUT INTO A CHAT MODEL, AND FINALLY CONVERTING THE CHAT MESSAGE OUTPUT INTO A STRING WITH AN OUTPUT PARSER.\n",
      "\n",
      "SELECT CHAT MODEL:GROQ▾GROQOPENAIANTHROPICAZUREGOOGLE VERTEXAWSCOHERENVIDIAFIREWORKS AIMISTRAL AITOGETHER AIIBM WATSONXDATABRICKSXAIPIP INSTALL -QU \"LANGCHAIN[GROQ]\"IMPORT GETPASSIMPORT OSIF NOT OS.ENVIRON.GET(\"GROQ_API_KEY\"):  OS.ENVIRON[\"GROQ_API_KEY\"] = GETPASS.GETPASS(\"ENTER API KEY FOR GROQ: \")FROM LANGCHAIN.CHAT_MODELS IMPORT INIT_CHAT_MODELMODEL = INIT_CHAT_MODEL(\"LLAMA3-8B-8192\", MODEL_PROVIDER=\"GROQ\")\n",
      "FROM LANGCHAIN_CORE.OUTPUT_PARSERS IMPORT STROUTPUTPARSERFROM LANGCHAIN_CORE.PROMPTS IMPORT CHATPROMPTTEMPLATEPROMPT = CHATPROMPTTEMPLATE.FROM_TEMPLATE(\"TELL ME A JOKE ABOUT {TOPIC}\")CHAIN = PROMPT | MODEL | STROUTPUTPARSER()API REFERENCE:STROUTPUTPARSER | CHATPROMPTTEMPLATE\n",
      "PROMPTS AND MODELS ARE BOTH RUNNABLE, AND THE OUTPUT TYPE FROM THE PROMPT CALL IS THE SAME AS THE INPUT TYPE OF THE CHAT MODEL, SO WE CAN CHAIN THEM TOGETHER. WE CAN THEN INVOKE THE RESULTING SEQUENCE LIKE ANY OTHER RUNNABLE:\n",
      "CHAIN.INVOKE({\"TOPIC\": \"BEARS\"})\n",
      "\"HERE'S A BEAR JOKE FOR YOU:\\N\\NWHY DID THE BEAR DISSOLVE IN WATER?\\NBECAUSE IT WAS A POLAR BEAR!\"\n",
      "COERCION​\n",
      "WE CAN EVEN COMBINE THIS CHAIN WITH MORE RUNNABLES TO CREATE ANOTHER CHAIN. THIS MAY INVOLVE SOME INPUT/OUTPUT FORMATTING USING OTHER TYPES OF RUNNABLES, DEPENDING ON THE REQUIRED INPUTS AND OUTPUTS OF THE CHAIN COMPONENTS.\n",
      "FOR EXAMPLE, LET'S SAY WE WANTED TO COMPOSE THE JOKE GENERATING CHAIN WITH ANOTHER CHAIN THAT EVALUATES WHETHER OR NOT THE GENERATED JOKE WAS FUNNY.\n",
      "WE WOULD NEED TO BE CAREFUL WITH HOW WE FORMAT THE INPUT INTO THE NEXT CHAIN. IN THE BELOW EXAMPLE, THE DICT IN THE CHAIN IS AUTOMATICALLY PARSED AND CONVERTED INTO A RUNNABLEPARALLEL, WHICH RUNS ALL OF ITS VALUES IN PARALLEL AND RETURNS A DICT WITH THE RESULTS.\n",
      "THIS HAPPENS TO BE THE SAME FORMAT THE NEXT PROMPT TEMPLATE EXPECTS. HERE IT IS IN ACTION:\n",
      "FROM LANGCHAIN_CORE.OUTPUT_PARSERS IMPORT STROUTPUTPARSERANALYSIS_PROMPT = CHATPROMPTTEMPLATE.FROM_TEMPLATE(\"IS THIS A FUNNY JOKE? {JOKE}\")COMPOSED_CHAIN = {\"JOKE\": CHAIN} | ANALYSIS_PROMPT | MODEL | STROUTPUTPARSER()COMPOSED_CHAIN.INVOKE({\"TOPIC\": \"BEARS\"})API REFERENCE:STROUTPUTPARSER\n",
      "'HAHA, THAT\\'S A CLEVER PLAY ON WORDS! USING \"POLAR\" TO IMPLY THE BEAR DISSOLVED OR BECAME POLAR/POLARIZED WHEN PUT IN WATER. NOT THE MOST HILARIOUS JOKE EVER, BUT IT HAS A CUTE, GROAN-WORTHY PUN THAT MAKES IT MILDLY AMUSING. I APPRECIATE A GOOD PUN OR WORDPLAY JOKE.'\n",
      "FUNCTIONS WILL ALSO BE COERCED INTO RUNNABLES, SO YOU CAN ADD CUSTOM LOGIC TO YOUR CHAINS TOO. THE BELOW CHAIN RESULTS IN THE SAME LOGICAL FLOW AS BEFORE:\n",
      "COMPOSED_CHAIN_WITH_LAMBDA = (    CHAIN    | (LAMBDA INPUT: {\"JOKE\": INPUT})    | ANALYSIS_PROMPT    | MODEL    | STROUTPUTPARSER())COMPOSED_CHAIN_WITH_LAMBDA.INVOKE({\"TOPIC\": \"BEETS\"})\n",
      "\"HAHA, THAT'S A CUTE AND PUNNY JOKE! I LIKE HOW IT PLAYS ON THE IDEA OF BEETS BLUSHING OR TURNING RED LIKE SOMEONE BLUSHING. FOOD PUNS CAN BE QUITE AMUSING. WHILE NOT A TOTAL KNEE-SLAPPER, IT'S A LIGHT-HEARTED, GROAN-WORTHY DAD JOKE THAT WOULD MAKE ME CHUCKLE AND SHAKE MY HEAD. SIMPLE VEGETABLE HUMOR!\"\n",
      "HOWEVER, KEEP IN MIND THAT USING FUNCTIONS LIKE THIS MAY INTERFERE WITH OPERATIONS LIKE STREAMING. SEE THIS SECTION FOR MORE INFORMATION.\n",
      "THE .PIPE() METHOD​\n",
      "WE COULD ALSO COMPOSE THE SAME SEQUENCE USING THE .PIPE() METHOD. HERE'S WHAT THAT LOOKS LIKE:\n",
      "FROM LANGCHAIN_CORE.RUNNABLES IMPORT RUNNABLEPARALLELCOMPOSED_CHAIN_WITH_PIPE = (    RUNNABLEPARALLEL({\"JOKE\": CHAIN})    .PIPE(ANALYSIS_PROMPT)    .PIPE(MODEL)    .PIPE(STROUTPUTPARSER()))COMPOSED_CHAIN_WITH_PIPE.INVOKE({\"TOPIC\": \"BATTLESTAR GALACTICA\"})API REFERENCE:RUNNABLEPARALLEL\n",
      "\"I CANNOT REPRODUCE ANY COPYRIGHTED MATERIAL VERBATIM, BUT I CAN TRY TO ANALYZE THE HUMOR IN THE JOKE YOU PROVIDED WITHOUT QUOTING IT DIRECTLY.\\N\\NTHE JOKE PLAYS ON THE IDEA THAT THE CYLON RAIDERS, WHO ARE THE ANTAGONISTS IN THE BATTLESTAR GALACTICA UNIVERSE, FAILED TO LOCATE THE HUMAN SURVIVORS AFTER ATTACKING THEIR HOME PLANETS (THE TWELVE COLONIES) DUE TO USING AN OUTDATED AND POORLY PERFORMING OPERATING SYSTEM (WINDOWS VISTA) FOR THEIR TARGETING SYSTEMS.\\N\\NTHE HUMOR STEMS FROM THE JUXTAPOSITION OF A FUTURISTIC SCIENCE FICTION SETTING WITH A RELATABLE REAL-WORLD FRUSTRATION – THE USE OF BUGGY, SLOW, OR UNRELIABLE SOFTWARE OR TECHNOLOGY. IT POKES FUN AT THE PERCEIVED INADEQUACIES OF WINDOWS VISTA, WHICH WAS WIDELY CRITICIZED FOR ITS PERFORMANCE ISSUES AND OTHER PROBLEMS WHEN IT WAS RELEASED.\\N\\NBY ATTRIBUTING THE CYLONS' FAILURE TO LOCATE THE HUMANS TO THEIR USE OF VISTA, THE JOKE CREATES AN AMUSING AND UNEXPECTED CONNECTION BETWEEN A FICTIONAL ADVANCED RACE OF ROBOTS AND A FAMILIAR TECHNOLOGICAL ANNOYANCE EXPERIENCED BY MANY PEOPLE IN THE REAL WORLD.\\N\\NOVERALL, THE JOKE RELIES ON INCONGRUITY AND RELATABILITY TO GENERATE HUMOR, BUT WITHOUT REPRODUCING ANY COPYRIGHTED MATERIAL DIRECTLY.\"\n",
      "OR THE ABBREVIATED:\n",
      "COMPOSED_CHAIN_WITH_PIPE = RUNNABLEPARALLEL({\"JOKE\": CHAIN}).PIPE(    ANALYSIS_PROMPT, MODEL, STROUTPUTPARSER())\n",
      "RELATED​\n",
      "\n",
      "STREAMING: CHECK OUT THE STREAMING GUIDE TO UNDERSTAND THE STREAMING BEHAVIOR OF A CHAIN\n",
      "EDIT THIS PAGEWAS THIS PAGE HELPFUL?PREVIOUSHOW TO SPLIT TEXT BASED ON SEMANTIC SIMILARITYNEXTHOW TO SAVE AND LOAD LANGCHAIN OBJECTSTHE PIPE OPERATOR: |COERCIONTHE .PIPE() METHODRELATEDCOMMUNITYTWITTERGITHUBORGANIZATIONPYTHONJS/TSMOREHOMEPAGEBLOGYOUTUBECOPYRIGHT © 2025 LANGCHAIN, INC.\n",
      "\n",
      "\n",
      "          -------\n",
      "\n",
      "          THE PREVIOUS CODE ATTEMPT FAILED WITH THE FOLLOWING ERROR:\n",
      "          NAME 'ROUTE_FUNCTION' IS NOT DEFINED\n",
      "\n",
      "          YOUR CODING TASK:\n",
      "          HOW CAN I USE A CUSTOM FUNCTION TO ROUTE BETWEEN TWO CHAINS?\n",
      "\n",
      "          PREVIOUS CODE ATTEMPT:\n",
      "          THE FOLLOWING CODE DEMONSTRATES HOW TO USE A CUSTOM FUNCTION TO ROUTE BETWEEN TWO CHAINS IN LANGCHAIN. THE CUSTOM FUNCTION IS UTILIZED AS A RUNNABLE TO TRANSFORM THE OUTPUT OF THE FIRST CHAIN BEFORE PASSING IT TO THE SECOND CHAIN.\n",
      "          FROM LANGCHAIN_CORE.PROMPTS IMPORT CHATPROMPTTEMPLATE\n",
      "FROM LANGCHAIN.CHAT_MODELS IMPORT INIT_CHAT_MODEL\n",
      "FROM LANGCHAIN_CORE.OUTPUT_PARSERS IMPORT STROUTPUTPARSER\n",
      "          PROMPT = CHATPROMPTTEMPLATE.FROM_TEMPLATE(\"TELL ME A JOKE ABOUT {TOPIC}\")\n",
      "MODEL = INIT_CHAT_MODEL(\"LLAMA3-8B-8192\", MODEL_PROVIDER=\"GROQ\")\n",
      "\n",
      "# DEFINE THE FIRST CHAIN TO GENERATE JOKES\n",
      "JOKE_CHAIN = PROMPT | MODEL | STROUTPUTPARSER()\n",
      "\n",
      "# DEFINE A CUSTOM FUNCTION TO ROUTE OUTPUT BETWEEN CHAINS\n",
      "DEF ROUTE_FUNCTION(OUTPUT):\n",
      "    # TRANSFORM THE OUTPUT OF THE FIRST CHAIN AS NEEDED FOR THE NEXT CHAIN\n",
      "    RETURN {\"JOKE\": OUTPUT}\n",
      "\n",
      "# DEFINE A SECOND CHAIN TO ANALYZE THE JOKE\n",
      "ANALYSIS_PROMPT = CHATPROMPTTEMPLATE.FROM_TEMPLATE(\"IS THIS A FUNNY JOKE? {JOKE}\")\n",
      "\n",
      "# COMPOSE A NEW CHAIN USING THE CUSTOM FUNCTION TO ROUTE THE OUTPUT\n",
      "COMPOSED_CHAIN = (\n",
      "    JOKE_CHAIN\n",
      "    | (LAMBDA INPUT: ROUTE_FUNCTION(INPUT))  # CUSTOM FUNCTION ROUTING\n",
      "    | ANALYSIS_PROMPT\n",
      "    | MODEL\n",
      "    | STROUTPUTPARSER()\n",
      ")\n",
      "\n",
      "# EXECUTE THE COMPOSED CHAIN\n",
      "RESULT = COMPOSED_CHAIN.INVOKE({\"TOPIC\": \"BEARS\"})\n",
      "PRINT(RESULT)\n",
      "\n",
      "          ANSWER WITH A DESCRIPTION OF THE CODE SOLUTION, FOLLOWED BY THE IMPORTS, AND FINALLY THE FUNCTIONING CODE BLOCK.\n",
      "          ENSURE ALL IMPORTS ARE CORRECT AND THE CODE IS EXECUTABLE.]: 2025-03-13 15:38:27.349865\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:38:27][✅ CREW 'CREW' COMPLETED, 9FDEA3EB-0EC6-462B-BCA6-55FFCE1E6CD3]: 2025-03-13 15:38:27.354335\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:38:27][👍 FLOW METHOD FINISHED: 'RUN_FIX']: 2025-03-13 15:38:27.354755\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:38:27][🤖 FLOW METHOD STARTED: 'RE_RUN_CHECK']: 2025-03-13 15:38:27.354900\u001b[00m\n",
      "---CHECKING CODE---\n",
      "---CODE BLOCK CHECK: FAILED---\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:38:27][👍 FLOW METHOD FINISHED: 'RE_RUN_CHECK']: 2025-03-13 15:38:27.597859\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:38:27][🤖 FLOW METHOD STARTED: 'RE_RUN_FIX']: 2025-03-13 15:38:27.598306\u001b[00m\n",
      "---FIXING CODE---\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:38:27][🚀 CREW 'CREW' STARTED, 7FC85D97-019D-49A7-AB80-B4E23A0AF71F]: 2025-03-13 15:38:27.600571\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:38:27][📋 TASK STARTED: YOU ARE A CODING ASSISTANT WITH EXPERTISE IN LCEL, LANGCHAIN EXPRESSION LANGUAGE.\n",
      "          HERE IS A FULL SET OF LCEL DOCUMENTATION:\n",
      "          -------\n",
      "          \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "HOW TO CHAIN RUNNABLES | 🦜️🔗 LANGCHAIN\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "SKIP TO MAIN CONTENTJOIN US AT  INTERRUPT: THE AGENT AI CONFERENCE BY LANGCHAIN ON MAY 13 & 14 IN SAN FRANCISCO!INTEGRATIONSAPI REFERENCEMORECONTRIBUTINGPEOPLEERROR REFERENCELANGSMITHLANGGRAPHLANGCHAIN HUBLANGCHAIN JS/TSV0.3V0.3V0.2V0.1💬SEARCHINTRODUCTIONTUTORIALSBUILD A QUESTION ANSWERING APPLICATION OVER A GRAPH DATABASETUTORIALSBUILD A SIMPLE LLM APPLICATION WITH CHAT MODELS AND PROMPT TEMPLATESBUILD A CHATBOTBUILD A RETRIEVAL AUGMENTED GENERATION (RAG) APP: PART 2BUILD AN EXTRACTION CHAINBUILD AN AGENTTAGGINGBUILD A RETRIEVAL AUGMENTED GENERATION (RAG) APP: PART 1BUILD A SEMANTIC SEARCH ENGINEBUILD A QUESTION/ANSWERING SYSTEM OVER SQL DATASUMMARIZE TEXTHOW-TO GUIDESHOW-TO GUIDESHOW TO USE TOOLS IN A CHAINHOW TO USE A VECTORSTORE AS A RETRIEVERHOW TO ADD MEMORY TO CHATBOTSHOW TO USE EXAMPLE SELECTORSHOW TO ADD A SEMANTIC LAYER OVER GRAPH DATABASEHOW TO INVOKE RUNNABLES IN PARALLELHOW TO STREAM CHAT MODEL RESPONSESHOW TO ADD DEFAULT INVOCATION ARGS TO A RUNNABLEHOW TO ADD RETRIEVAL TO CHATBOTSHOW TO USE FEW SHOT EXAMPLES IN CHAT MODELSHOW TO DO TOOL/FUNCTION CALLINGHOW TO INSTALL LANGCHAIN PACKAGESHOW TO ADD EXAMPLES TO THE PROMPT FOR QUERY ANALYSISHOW TO USE FEW SHOT EXAMPLESHOW TO RUN CUSTOM FUNCTIONSHOW TO USE OUTPUT PARSERS TO PARSE AN LLM RESPONSE INTO STRUCTURED FORMATHOW TO HANDLE CASES WHERE NO QUERIES ARE GENERATEDHOW TO ROUTE BETWEEN SUB-CHAINSHOW TO RETURN STRUCTURED DATA FROM A MODELHOW TO SUMMARIZE TEXT THROUGH PARALLELIZATIONHOW TO SUMMARIZE TEXT THROUGH ITERATIVE REFINEMENTHOW TO SUMMARIZE TEXT IN A SINGLE LLM CALLHOW TO USE TOOLKITSHOW TO ADD AD-HOC TOOL CALLING CAPABILITY TO LLMS AND CHAT MODELSBUILD AN AGENT WITH AGENTEXECUTOR (LEGACY)HOW TO CONSTRUCT KNOWLEDGE GRAPHSHOW TO PARTIALLY FORMAT PROMPT TEMPLATESHOW TO HANDLE MULTIPLE QUERIES WHEN DOING QUERY ANALYSISHOW TO USE BUILT-IN TOOLS AND TOOLKITSHOW TO PASS THROUGH ARGUMENTS FROM ONE STEP TO THE NEXTHOW TO COMPOSE PROMPTS TOGETHERHOW TO HANDLE MULTIPLE RETRIEVERS WHEN DOING QUERY ANALYSISHOW TO ADD VALUES TO A CHAIN'S STATEHOW TO CONSTRUCT FILTERS FOR QUERY ANALYSISHOW TO CONFIGURE RUNTIME CHAIN INTERNALSHOW DEAL WITH HIGH CARDINALITY CATEGORICALS WHEN DOING QUERY ANALYSISCUSTOM DOCUMENT LOADERHOW TO USE THE MULTIQUERYRETRIEVERHOW TO ADD SCORES TO RETRIEVER RESULTSCACHINGHOW TO USE CALLBACKS IN ASYNC ENVIRONMENTSHOW TO ATTACH CALLBACKS TO A RUNNABLEHOW TO PROPAGATE CALLBACKS  CONSTRUCTORHOW TO DISPATCH CUSTOM CALLBACK EVENTSHOW TO PASS CALLBACKS IN AT RUNTIMEHOW TO SPLIT BY CHARACTERHOW TO CACHE CHAT MODEL RESPONSESHOW TO HANDLE RATE LIMITSHOW TO INIT ANY MODEL IN ONE LINEHOW TO TRACK TOKEN USAGE IN CHATMODELSHOW TO ADD TOOLS TO CHATBOTSHOW TO SPLIT CODEHOW TO DO RETRIEVAL WITH CONTEXTUAL COMPRESSIONHOW TO CONVERT RUNNABLES TO TOOLSHOW TO CREATE CUSTOM CALLBACK HANDLERSHOW TO CREATE A CUSTOM CHAT MODEL CLASSCUSTOM EMBEDDINGSHOW TO CREATE A CUSTOM LLM CLASSCUSTOM RETRIEVERHOW TO CREATE TOOLSHOW TO DEBUG YOUR LLM APPSHOW TO LOAD CSVSHOW TO LOAD DOCUMENTS FROM A DIRECTORYHOW TO LOAD HTMLHOW TO LOAD JSONHOW TO LOAD MARKDOWNHOW TO LOAD MICROSOFT OFFICE FILESHOW TO LOAD PDFSHOW TO LOAD WEB PAGESHOW TO CREATE A DYNAMIC (SELF-CONSTRUCTING) CHAINTEXT EMBEDDING MODELSHOW TO COMBINE RESULTS FROM MULTIPLE RETRIEVERSHOW TO SELECT EXAMPLES FROM A LANGSMITH DATASETHOW TO SELECT EXAMPLES BY LENGTHHOW TO SELECT EXAMPLES BY MAXIMAL MARGINAL RELEVANCE (MMR)HOW TO SELECT EXAMPLES BY N-GRAM OVERLAPHOW TO SELECT EXAMPLES BY SIMILARITYHOW TO USE REFERENCE EXAMPLES WHEN DOING EXTRACTIONHOW TO HANDLE LONG TEXT WHEN DOING EXTRACTIONHOW TO USE PROMPTING ALONE (NO TOOL CALLING) TO DO EXTRACTIONHOW TO ADD FALLBACKS TO A RUNNABLEHOW TO FILTER MESSAGESHYBRID SEARCHHOW TO USE THE LANGCHAIN INDEXING APIHOW TO INSPECT RUNNABLESLANGCHAIN EXPRESSION LANGUAGE CHEATSHEETHOW TO CACHE LLM RESPONSESHOW TO TRACK TOKEN USAGE FOR LLMSRUN MODELS LOCALLYHOW TO GET LOG PROBABILITIESHOW TO REORDER RETRIEVED RESULTS TO MITIGATE THE \"LOST IN THE MIDDLE\" EFFECTHOW TO SPLIT MARKDOWN BY HEADERSHOW TO MERGE CONSECUTIVE MESSAGES OF THE SAME TYPEHOW TO ADD MESSAGE HISTORYHOW TO MIGRATE FROM LEGACY LANGCHAIN AGENTS TO LANGGRAPHHOW TO RETRIEVE USING MULTIPLE VECTORS PER DOCUMENTHOW TO PASS MULTIMODAL DATA DIRECTLY TO MODELSHOW TO USE MULTIMODAL PROMPTSHOW TO CREATE A CUSTOM OUTPUT PARSERHOW TO USE THE OUTPUT-FIXING PARSERHOW TO PARSE JSON OUTPUTHOW TO RETRY WHEN A PARSING ERROR OCCURSHOW TO PARSE TEXT FROM MESSAGE OBJECTSHOW TO PARSE XML OUTPUTHOW TO PARSE YAML OUTPUTHOW TO USE THE PARENT DOCUMENT RETRIEVERHOW TO USE LANGCHAIN WITH DIFFERENT PYDANTIC VERSIONSHOW TO ADD CHAT HISTORYHOW TO GET A RAG APPLICATION TO ADD CITATIONSHOW TO DO PER-USER RETRIEVALHOW TO GET YOUR RAG APPLICATION TO RETURN SOURCESHOW TO STREAM RESULTS FROM YOUR RAG APPLICATIONHOW TO SPLIT JSON DATAHOW TO RECURSIVELY SPLIT TEXT BY CHARACTERSRESPONSE METADATAHOW TO PASS RUNTIME SECRETS TO RUNNABLESHOW TO DO \"SELF-QUERYING\" RETRIEVALHOW TO SPLIT TEXT BASED ON SEMANTIC SIMILARITYHOW TO CHAIN RUNNABLESHOW TO SAVE AND LOAD LANGCHAIN OBJECTSHOW TO SPLIT TEXT BY TOKENSHOW TO SPLIT HTMLHOW TO DO QUESTION ANSWERING OVER CSVSHOW TO DEAL WITH LARGE DATABASES WHEN DOING SQL QUESTION-ANSWERINGHOW TO BETTER PROMPT WHEN DOING SQL QUESTION-ANSWERINGHOW TO DO QUERY VALIDATION AS PART OF SQL QUESTION-ANSWERINGHOW TO STREAM RUNNABLESHOW TO STREAM RESPONSES FROM AN LLMHOW TO USE A TIME-WEIGHTED VECTOR STORE RETRIEVERHOW TO RETURN ARTIFACTS FROM A TOOLHOW TO USE CHAT MODELS TO CALL TOOLSHOW TO DISABLE PARALLEL TOOL CALLINGHOW TO FORCE MODELS TO CALL A TOOLHOW TO ACCESS THE RUNNABLECONFIG FROM A TOOLHOW TO PASS TOOL OUTPUTS TO CHAT MODELSHOW TO PASS RUN TIME VALUES TO TOOLSHOW TO STREAM EVENTS FROM A TOOLHOW TO STREAM TOOL CALLSHOW TO CONVERT TOOLS TO OPENAI FUNCTIONSHOW TO HANDLE TOOL ERRORSHOW TO USE FEW-SHOT PROMPTING WITH TOOL CALLINGHOW TO ADD A HUMAN-IN-THE-LOOP FOR TOOLSHOW TO BIND MODEL-SPECIFIC TOOLSHOW TO TRIM MESSAGESHOW TO CREATE AND QUERY VECTOR STORESCONCEPTUAL GUIDEAGENTSARCHITECTUREASYNC PROGRAMMING WITH LANGCHAINCALLBACKSCHAT HISTORYCHAT MODELSDOCUMENT LOADERSEMBEDDING MODELSEVALUATIONEXAMPLE SELECTORSFEW-SHOT PROMPTINGCONCEPTUAL GUIDEKEY-VALUE STORESLANGCHAIN EXPRESSION LANGUAGE (LCEL)MESSAGESMULTIMODALITYOUTPUT PARSERSPROMPT TEMPLATESRETRIEVAL AUGMENTED GENERATION (RAG)RETRIEVALRETRIEVERSRUNNABLE INTERFACESTREAMINGSTRUCTURED OUTPUTSTESTINGSTRING-IN, STRING-OUT LLMSTEXT SPLITTERSTOKENSTOOL CALLINGTOOLSTRACINGVECTOR STORESWHY LANGCHAIN?ECOSYSTEM🦜🛠️ LANGSMITH🦜🕸️ LANGGRAPHVERSIONSV0.3V0.2PYDANTIC COMPATIBILITYMIGRATING FROM V0.0 CHAINSHOW TO MIGRATE FROM V0.0 CHAINSMIGRATING FROM CONSTITUTIONALCHAINMIGRATING FROM CONVERSATIONALCHAINMIGRATING FROM CONVERSATIONALRETRIEVALCHAINMIGRATING FROM LLMCHAINMIGRATING FROM LLMMATHCHAINMIGRATING FROM LLMROUTERCHAINMIGRATING FROM MAPREDUCEDOCUMENTSCHAINMIGRATING FROM MAPRERANKDOCUMENTSCHAINMIGRATING FROM MULTIPROMPTCHAINMIGRATING FROM REFINEDOCUMENTSCHAINMIGRATING FROM RETRIEVALQAMIGRATING FROM STUFFDOCUMENTSCHAINUPGRADING TO LANGGRAPH MEMORYHOW TO MIGRATE TO LANGGRAPH MEMORYHOW TO USE BASECHATMESSAGEHISTORY WITH LANGGRAPHMIGRATING OFF CONVERSATIONBUFFERMEMORY OR CONVERSATIONSTRINGBUFFERMEMORYMIGRATING OFF CONVERSATIONBUFFERWINDOWMEMORY OR CONVERSATIONTOKENBUFFERMEMORYMIGRATING OFF CONVERSATIONSUMMARYMEMORY OR CONVERSATIONSUMMARYBUFFERMEMORYA LONG-TERM MEMORY AGENTRELEASE POLICYSECURITY POLICYHOW-TO GUIDESHOW TO CHAIN RUNNABLESON THIS PAGEHOW TO CHAIN RUNNABLES\n",
      "PREREQUISITESTHIS GUIDE ASSUMES FAMILIARITY WITH THE FOLLOWING CONCEPTS:\n",
      "LANGCHAIN EXPRESSION LANGUAGE (LCEL)\n",
      "PROMPT TEMPLATES\n",
      "CHAT MODELS\n",
      "OUTPUT PARSER\n",
      "\n",
      "ONE POINT ABOUT LANGCHAIN EXPRESSION LANGUAGE IS THAT ANY TWO RUNNABLES CAN BE \"CHAINED\" TOGETHER INTO SEQUENCES. THE OUTPUT OF THE PREVIOUS RUNNABLE'S .INVOKE() CALL IS PASSED AS INPUT TO THE NEXT RUNNABLE. THIS CAN BE DONE USING THE PIPE OPERATOR (|), OR THE MORE EXPLICIT .PIPE() METHOD, WHICH DOES THE SAME THING.\n",
      "THE RESULTING RUNNABLESEQUENCE IS ITSELF A RUNNABLE, WHICH MEANS IT CAN BE INVOKED, STREAMED, OR FURTHER CHAINED JUST LIKE ANY OTHER RUNNABLE. ADVANTAGES OF CHAINING RUNNABLES IN THIS WAY ARE EFFICIENT STREAMING (THE SEQUENCE WILL STREAM OUTPUT AS SOON AS IT IS AVAILABLE), AND DEBUGGING AND TRACING WITH TOOLS LIKE LANGSMITH.\n",
      "THE PIPE OPERATOR: |​\n",
      "TO SHOW OFF HOW THIS WORKS, LET'S GO THROUGH AN EXAMPLE. WE'LL WALK THROUGH A COMMON PATTERN IN LANGCHAIN: USING A PROMPT TEMPLATE TO FORMAT INPUT INTO A CHAT MODEL, AND FINALLY CONVERTING THE CHAT MESSAGE OUTPUT INTO A STRING WITH AN OUTPUT PARSER.\n",
      "\n",
      "SELECT CHAT MODEL:GROQ▾GROQOPENAIANTHROPICAZUREGOOGLE VERTEXAWSCOHERENVIDIAFIREWORKS AIMISTRAL AITOGETHER AIIBM WATSONXDATABRICKSXAIPIP INSTALL -QU \"LANGCHAIN[GROQ]\"IMPORT GETPASSIMPORT OSIF NOT OS.ENVIRON.GET(\"GROQ_API_KEY\"):  OS.ENVIRON[\"GROQ_API_KEY\"] = GETPASS.GETPASS(\"ENTER API KEY FOR GROQ: \")FROM LANGCHAIN.CHAT_MODELS IMPORT INIT_CHAT_MODELMODEL = INIT_CHAT_MODEL(\"LLAMA3-8B-8192\", MODEL_PROVIDER=\"GROQ\")\n",
      "FROM LANGCHAIN_CORE.OUTPUT_PARSERS IMPORT STROUTPUTPARSERFROM LANGCHAIN_CORE.PROMPTS IMPORT CHATPROMPTTEMPLATEPROMPT = CHATPROMPTTEMPLATE.FROM_TEMPLATE(\"TELL ME A JOKE ABOUT {TOPIC}\")CHAIN = PROMPT | MODEL | STROUTPUTPARSER()API REFERENCE:STROUTPUTPARSER | CHATPROMPTTEMPLATE\n",
      "PROMPTS AND MODELS ARE BOTH RUNNABLE, AND THE OUTPUT TYPE FROM THE PROMPT CALL IS THE SAME AS THE INPUT TYPE OF THE CHAT MODEL, SO WE CAN CHAIN THEM TOGETHER. WE CAN THEN INVOKE THE RESULTING SEQUENCE LIKE ANY OTHER RUNNABLE:\n",
      "CHAIN.INVOKE({\"TOPIC\": \"BEARS\"})\n",
      "\"HERE'S A BEAR JOKE FOR YOU:\\N\\NWHY DID THE BEAR DISSOLVE IN WATER?\\NBECAUSE IT WAS A POLAR BEAR!\"\n",
      "COERCION​\n",
      "WE CAN EVEN COMBINE THIS CHAIN WITH MORE RUNNABLES TO CREATE ANOTHER CHAIN. THIS MAY INVOLVE SOME INPUT/OUTPUT FORMATTING USING OTHER TYPES OF RUNNABLES, DEPENDING ON THE REQUIRED INPUTS AND OUTPUTS OF THE CHAIN COMPONENTS.\n",
      "FOR EXAMPLE, LET'S SAY WE WANTED TO COMPOSE THE JOKE GENERATING CHAIN WITH ANOTHER CHAIN THAT EVALUATES WHETHER OR NOT THE GENERATED JOKE WAS FUNNY.\n",
      "WE WOULD NEED TO BE CAREFUL WITH HOW WE FORMAT THE INPUT INTO THE NEXT CHAIN. IN THE BELOW EXAMPLE, THE DICT IN THE CHAIN IS AUTOMATICALLY PARSED AND CONVERTED INTO A RUNNABLEPARALLEL, WHICH RUNS ALL OF ITS VALUES IN PARALLEL AND RETURNS A DICT WITH THE RESULTS.\n",
      "THIS HAPPENS TO BE THE SAME FORMAT THE NEXT PROMPT TEMPLATE EXPECTS. HERE IT IS IN ACTION:\n",
      "FROM LANGCHAIN_CORE.OUTPUT_PARSERS IMPORT STROUTPUTPARSERANALYSIS_PROMPT = CHATPROMPTTEMPLATE.FROM_TEMPLATE(\"IS THIS A FUNNY JOKE? {JOKE}\")COMPOSED_CHAIN = {\"JOKE\": CHAIN} | ANALYSIS_PROMPT | MODEL | STROUTPUTPARSER()COMPOSED_CHAIN.INVOKE({\"TOPIC\": \"BEARS\"})API REFERENCE:STROUTPUTPARSER\n",
      "'HAHA, THAT\\'S A CLEVER PLAY ON WORDS! USING \"POLAR\" TO IMPLY THE BEAR DISSOLVED OR BECAME POLAR/POLARIZED WHEN PUT IN WATER. NOT THE MOST HILARIOUS JOKE EVER, BUT IT HAS A CUTE, GROAN-WORTHY PUN THAT MAKES IT MILDLY AMUSING. I APPRECIATE A GOOD PUN OR WORDPLAY JOKE.'\n",
      "FUNCTIONS WILL ALSO BE COERCED INTO RUNNABLES, SO YOU CAN ADD CUSTOM LOGIC TO YOUR CHAINS TOO. THE BELOW CHAIN RESULTS IN THE SAME LOGICAL FLOW AS BEFORE:\n",
      "COMPOSED_CHAIN_WITH_LAMBDA = (    CHAIN    | (LAMBDA INPUT: {\"JOKE\": INPUT})    | ANALYSIS_PROMPT    | MODEL    | STROUTPUTPARSER())COMPOSED_CHAIN_WITH_LAMBDA.INVOKE({\"TOPIC\": \"BEETS\"})\n",
      "\"HAHA, THAT'S A CUTE AND PUNNY JOKE! I LIKE HOW IT PLAYS ON THE IDEA OF BEETS BLUSHING OR TURNING RED LIKE SOMEONE BLUSHING. FOOD PUNS CAN BE QUITE AMUSING. WHILE NOT A TOTAL KNEE-SLAPPER, IT'S A LIGHT-HEARTED, GROAN-WORTHY DAD JOKE THAT WOULD MAKE ME CHUCKLE AND SHAKE MY HEAD. SIMPLE VEGETABLE HUMOR!\"\n",
      "HOWEVER, KEEP IN MIND THAT USING FUNCTIONS LIKE THIS MAY INTERFERE WITH OPERATIONS LIKE STREAMING. SEE THIS SECTION FOR MORE INFORMATION.\n",
      "THE .PIPE() METHOD​\n",
      "WE COULD ALSO COMPOSE THE SAME SEQUENCE USING THE .PIPE() METHOD. HERE'S WHAT THAT LOOKS LIKE:\n",
      "FROM LANGCHAIN_CORE.RUNNABLES IMPORT RUNNABLEPARALLELCOMPOSED_CHAIN_WITH_PIPE = (    RUNNABLEPARALLEL({\"JOKE\": CHAIN})    .PIPE(ANALYSIS_PROMPT)    .PIPE(MODEL)    .PIPE(STROUTPUTPARSER()))COMPOSED_CHAIN_WITH_PIPE.INVOKE({\"TOPIC\": \"BATTLESTAR GALACTICA\"})API REFERENCE:RUNNABLEPARALLEL\n",
      "\"I CANNOT REPRODUCE ANY COPYRIGHTED MATERIAL VERBATIM, BUT I CAN TRY TO ANALYZE THE HUMOR IN THE JOKE YOU PROVIDED WITHOUT QUOTING IT DIRECTLY.\\N\\NTHE JOKE PLAYS ON THE IDEA THAT THE CYLON RAIDERS, WHO ARE THE ANTAGONISTS IN THE BATTLESTAR GALACTICA UNIVERSE, FAILED TO LOCATE THE HUMAN SURVIVORS AFTER ATTACKING THEIR HOME PLANETS (THE TWELVE COLONIES) DUE TO USING AN OUTDATED AND POORLY PERFORMING OPERATING SYSTEM (WINDOWS VISTA) FOR THEIR TARGETING SYSTEMS.\\N\\NTHE HUMOR STEMS FROM THE JUXTAPOSITION OF A FUTURISTIC SCIENCE FICTION SETTING WITH A RELATABLE REAL-WORLD FRUSTRATION – THE USE OF BUGGY, SLOW, OR UNRELIABLE SOFTWARE OR TECHNOLOGY. IT POKES FUN AT THE PERCEIVED INADEQUACIES OF WINDOWS VISTA, WHICH WAS WIDELY CRITICIZED FOR ITS PERFORMANCE ISSUES AND OTHER PROBLEMS WHEN IT WAS RELEASED.\\N\\NBY ATTRIBUTING THE CYLONS' FAILURE TO LOCATE THE HUMANS TO THEIR USE OF VISTA, THE JOKE CREATES AN AMUSING AND UNEXPECTED CONNECTION BETWEEN A FICTIONAL ADVANCED RACE OF ROBOTS AND A FAMILIAR TECHNOLOGICAL ANNOYANCE EXPERIENCED BY MANY PEOPLE IN THE REAL WORLD.\\N\\NOVERALL, THE JOKE RELIES ON INCONGRUITY AND RELATABILITY TO GENERATE HUMOR, BUT WITHOUT REPRODUCING ANY COPYRIGHTED MATERIAL DIRECTLY.\"\n",
      "OR THE ABBREVIATED:\n",
      "COMPOSED_CHAIN_WITH_PIPE = RUNNABLEPARALLEL({\"JOKE\": CHAIN}).PIPE(    ANALYSIS_PROMPT, MODEL, STROUTPUTPARSER())\n",
      "RELATED​\n",
      "\n",
      "STREAMING: CHECK OUT THE STREAMING GUIDE TO UNDERSTAND THE STREAMING BEHAVIOR OF A CHAIN\n",
      "EDIT THIS PAGEWAS THIS PAGE HELPFUL?PREVIOUSHOW TO SPLIT TEXT BASED ON SEMANTIC SIMILARITYNEXTHOW TO SAVE AND LOAD LANGCHAIN OBJECTSTHE PIPE OPERATOR: |COERCIONTHE .PIPE() METHODRELATEDCOMMUNITYTWITTERGITHUBORGANIZATIONPYTHONJS/TSMOREHOMEPAGEBLOGYOUTUBECOPYRIGHT © 2025 LANGCHAIN, INC.\n",
      "\n",
      "\n",
      "          -------\n",
      "\n",
      "          THE PREVIOUS CODE ATTEMPT FAILED WITH THE FOLLOWING ERROR:\n",
      "          NAME 'ROUTE_FUNCTION' IS NOT DEFINED\n",
      "\n",
      "          YOUR CODING TASK:\n",
      "          HOW CAN I USE A CUSTOM FUNCTION TO ROUTE BETWEEN TWO CHAINS?\n",
      "\n",
      "          PREVIOUS CODE ATTEMPT:\n",
      "          TO USE A CUSTOM FUNCTION TO ROUTE BETWEEN TWO CHAINS, YOU CAN DEFINE THE FUNCTION AND USE IT AS A RUNNABLE. BELOW, THE CODE DEMONSTRATES HOW TO CORRECTLY USE A CUSTOM FUNCTION TO ROUTE THE OUTPUT FROM ONE CHAIN TO ANOTHER. ENSURE THAT ALL NECESSARY IMPORTS ARE DEFINED PROPERLY.\n",
      "          FROM LANGCHAIN_CORE.PROMPTS IMPORT CHATPROMPTTEMPLATE\n",
      "FROM LANGCHAIN.CHAT_MODELS IMPORT INIT_CHAT_MODEL\n",
      "FROM LANGCHAIN_CORE.OUTPUT_PARSERS IMPORT STROUTPUTPARSER\n",
      "          PROMPT = CHATPROMPTTEMPLATE.FROM_TEMPLATE(\"TELL ME A JOKE ABOUT {TOPIC}\")\n",
      "MODEL = INIT_CHAT_MODEL(\"LLAMA3-8B-8192\", MODEL_PROVIDER=\"GROQ\")\n",
      "\n",
      "# DEFINE THE FIRST CHAIN TO GENERATE JOKES\n",
      "JOKE_CHAIN = PROMPT | MODEL | STROUTPUTPARSER()\n",
      "\n",
      "# DEFINE A CUSTOM FUNCTION TO ROUTE OUTPUT BETWEEN CHAINS\n",
      "DEF ROUTE_FUNCTION(OUTPUT):\n",
      "    # TRANSFORM THE OUTPUT OF THE FIRST CHAIN AS NEEDED FOR THE NEXT CHAIN\n",
      "    RETURN {\"JOKE\": OUTPUT[\"TEXT\"]}  # ADJUSTED TO EXTRACT TEXT PROPERLY\n",
      "\n",
      "# DEFINE A SECOND CHAIN TO ANALYZE THE JOKE\n",
      "ANALYSIS_PROMPT = CHATPROMPTTEMPLATE.FROM_TEMPLATE(\"IS THIS A FUNNY JOKE? {JOKE}\")\n",
      "\n",
      "# COMPOSE A NEW CHAIN USING THE CUSTOM FUNCTION TO ROUTE THE OUTPUT\n",
      "COMPOSED_CHAIN = (\n",
      "    JOKE_CHAIN\n",
      "    | (LAMBDA INPUT: ROUTE_FUNCTION(INPUT))  # CUSTOM FUNCTION ROUTING\n",
      "    | ANALYSIS_PROMPT\n",
      "    | MODEL\n",
      "    | STROUTPUTPARSER()\n",
      ")\n",
      "\n",
      "# EXECUTE THE COMPOSED CHAIN\n",
      "RESULT = COMPOSED_CHAIN.INVOKE({\"TOPIC\": \"BEARS\"})\n",
      "PRINT(RESULT)\n",
      "\n",
      "          ANSWER WITH A DESCRIPTION OF THE CODE SOLUTION, FOLLOWED BY THE IMPORTS, AND FINALLY THE FUNCTIONING CODE BLOCK.\n",
      "          ENSURE ALL IMPORTS ARE CORRECT AND THE CODE IS EXECUTABLE.]: 2025-03-13 15:38:27.603497\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:38:27][🤖 AGENT 'CODING ASSISTANT' STARTED TASK]: 2025-03-13 15:38:27.604075\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:38:27][🤖 LLM CALL STARTED]: 2025-03-13 15:38:27.604177\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:38:40][✅ LLM CALL COMPLETED]: 2025-03-13 15:38:40.582222\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:38:40][✅ AGENT 'CODING ASSISTANT' COMPLETED TASK]: 2025-03-13 15:38:40.583401\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:38:40][✅ TASK COMPLETED: YOU ARE A CODING ASSISTANT WITH EXPERTISE IN LCEL, LANGCHAIN EXPRESSION LANGUAGE.\n",
      "          HERE IS A FULL SET OF LCEL DOCUMENTATION:\n",
      "          -------\n",
      "          \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "HOW TO CHAIN RUNNABLES | 🦜️🔗 LANGCHAIN\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "SKIP TO MAIN CONTENTJOIN US AT  INTERRUPT: THE AGENT AI CONFERENCE BY LANGCHAIN ON MAY 13 & 14 IN SAN FRANCISCO!INTEGRATIONSAPI REFERENCEMORECONTRIBUTINGPEOPLEERROR REFERENCELANGSMITHLANGGRAPHLANGCHAIN HUBLANGCHAIN JS/TSV0.3V0.3V0.2V0.1💬SEARCHINTRODUCTIONTUTORIALSBUILD A QUESTION ANSWERING APPLICATION OVER A GRAPH DATABASETUTORIALSBUILD A SIMPLE LLM APPLICATION WITH CHAT MODELS AND PROMPT TEMPLATESBUILD A CHATBOTBUILD A RETRIEVAL AUGMENTED GENERATION (RAG) APP: PART 2BUILD AN EXTRACTION CHAINBUILD AN AGENTTAGGINGBUILD A RETRIEVAL AUGMENTED GENERATION (RAG) APP: PART 1BUILD A SEMANTIC SEARCH ENGINEBUILD A QUESTION/ANSWERING SYSTEM OVER SQL DATASUMMARIZE TEXTHOW-TO GUIDESHOW-TO GUIDESHOW TO USE TOOLS IN A CHAINHOW TO USE A VECTORSTORE AS A RETRIEVERHOW TO ADD MEMORY TO CHATBOTSHOW TO USE EXAMPLE SELECTORSHOW TO ADD A SEMANTIC LAYER OVER GRAPH DATABASEHOW TO INVOKE RUNNABLES IN PARALLELHOW TO STREAM CHAT MODEL RESPONSESHOW TO ADD DEFAULT INVOCATION ARGS TO A RUNNABLEHOW TO ADD RETRIEVAL TO CHATBOTSHOW TO USE FEW SHOT EXAMPLES IN CHAT MODELSHOW TO DO TOOL/FUNCTION CALLINGHOW TO INSTALL LANGCHAIN PACKAGESHOW TO ADD EXAMPLES TO THE PROMPT FOR QUERY ANALYSISHOW TO USE FEW SHOT EXAMPLESHOW TO RUN CUSTOM FUNCTIONSHOW TO USE OUTPUT PARSERS TO PARSE AN LLM RESPONSE INTO STRUCTURED FORMATHOW TO HANDLE CASES WHERE NO QUERIES ARE GENERATEDHOW TO ROUTE BETWEEN SUB-CHAINSHOW TO RETURN STRUCTURED DATA FROM A MODELHOW TO SUMMARIZE TEXT THROUGH PARALLELIZATIONHOW TO SUMMARIZE TEXT THROUGH ITERATIVE REFINEMENTHOW TO SUMMARIZE TEXT IN A SINGLE LLM CALLHOW TO USE TOOLKITSHOW TO ADD AD-HOC TOOL CALLING CAPABILITY TO LLMS AND CHAT MODELSBUILD AN AGENT WITH AGENTEXECUTOR (LEGACY)HOW TO CONSTRUCT KNOWLEDGE GRAPHSHOW TO PARTIALLY FORMAT PROMPT TEMPLATESHOW TO HANDLE MULTIPLE QUERIES WHEN DOING QUERY ANALYSISHOW TO USE BUILT-IN TOOLS AND TOOLKITSHOW TO PASS THROUGH ARGUMENTS FROM ONE STEP TO THE NEXTHOW TO COMPOSE PROMPTS TOGETHERHOW TO HANDLE MULTIPLE RETRIEVERS WHEN DOING QUERY ANALYSISHOW TO ADD VALUES TO A CHAIN'S STATEHOW TO CONSTRUCT FILTERS FOR QUERY ANALYSISHOW TO CONFIGURE RUNTIME CHAIN INTERNALSHOW DEAL WITH HIGH CARDINALITY CATEGORICALS WHEN DOING QUERY ANALYSISCUSTOM DOCUMENT LOADERHOW TO USE THE MULTIQUERYRETRIEVERHOW TO ADD SCORES TO RETRIEVER RESULTSCACHINGHOW TO USE CALLBACKS IN ASYNC ENVIRONMENTSHOW TO ATTACH CALLBACKS TO A RUNNABLEHOW TO PROPAGATE CALLBACKS  CONSTRUCTORHOW TO DISPATCH CUSTOM CALLBACK EVENTSHOW TO PASS CALLBACKS IN AT RUNTIMEHOW TO SPLIT BY CHARACTERHOW TO CACHE CHAT MODEL RESPONSESHOW TO HANDLE RATE LIMITSHOW TO INIT ANY MODEL IN ONE LINEHOW TO TRACK TOKEN USAGE IN CHATMODELSHOW TO ADD TOOLS TO CHATBOTSHOW TO SPLIT CODEHOW TO DO RETRIEVAL WITH CONTEXTUAL COMPRESSIONHOW TO CONVERT RUNNABLES TO TOOLSHOW TO CREATE CUSTOM CALLBACK HANDLERSHOW TO CREATE A CUSTOM CHAT MODEL CLASSCUSTOM EMBEDDINGSHOW TO CREATE A CUSTOM LLM CLASSCUSTOM RETRIEVERHOW TO CREATE TOOLSHOW TO DEBUG YOUR LLM APPSHOW TO LOAD CSVSHOW TO LOAD DOCUMENTS FROM A DIRECTORYHOW TO LOAD HTMLHOW TO LOAD JSONHOW TO LOAD MARKDOWNHOW TO LOAD MICROSOFT OFFICE FILESHOW TO LOAD PDFSHOW TO LOAD WEB PAGESHOW TO CREATE A DYNAMIC (SELF-CONSTRUCTING) CHAINTEXT EMBEDDING MODELSHOW TO COMBINE RESULTS FROM MULTIPLE RETRIEVERSHOW TO SELECT EXAMPLES FROM A LANGSMITH DATASETHOW TO SELECT EXAMPLES BY LENGTHHOW TO SELECT EXAMPLES BY MAXIMAL MARGINAL RELEVANCE (MMR)HOW TO SELECT EXAMPLES BY N-GRAM OVERLAPHOW TO SELECT EXAMPLES BY SIMILARITYHOW TO USE REFERENCE EXAMPLES WHEN DOING EXTRACTIONHOW TO HANDLE LONG TEXT WHEN DOING EXTRACTIONHOW TO USE PROMPTING ALONE (NO TOOL CALLING) TO DO EXTRACTIONHOW TO ADD FALLBACKS TO A RUNNABLEHOW TO FILTER MESSAGESHYBRID SEARCHHOW TO USE THE LANGCHAIN INDEXING APIHOW TO INSPECT RUNNABLESLANGCHAIN EXPRESSION LANGUAGE CHEATSHEETHOW TO CACHE LLM RESPONSESHOW TO TRACK TOKEN USAGE FOR LLMSRUN MODELS LOCALLYHOW TO GET LOG PROBABILITIESHOW TO REORDER RETRIEVED RESULTS TO MITIGATE THE \"LOST IN THE MIDDLE\" EFFECTHOW TO SPLIT MARKDOWN BY HEADERSHOW TO MERGE CONSECUTIVE MESSAGES OF THE SAME TYPEHOW TO ADD MESSAGE HISTORYHOW TO MIGRATE FROM LEGACY LANGCHAIN AGENTS TO LANGGRAPHHOW TO RETRIEVE USING MULTIPLE VECTORS PER DOCUMENTHOW TO PASS MULTIMODAL DATA DIRECTLY TO MODELSHOW TO USE MULTIMODAL PROMPTSHOW TO CREATE A CUSTOM OUTPUT PARSERHOW TO USE THE OUTPUT-FIXING PARSERHOW TO PARSE JSON OUTPUTHOW TO RETRY WHEN A PARSING ERROR OCCURSHOW TO PARSE TEXT FROM MESSAGE OBJECTSHOW TO PARSE XML OUTPUTHOW TO PARSE YAML OUTPUTHOW TO USE THE PARENT DOCUMENT RETRIEVERHOW TO USE LANGCHAIN WITH DIFFERENT PYDANTIC VERSIONSHOW TO ADD CHAT HISTORYHOW TO GET A RAG APPLICATION TO ADD CITATIONSHOW TO DO PER-USER RETRIEVALHOW TO GET YOUR RAG APPLICATION TO RETURN SOURCESHOW TO STREAM RESULTS FROM YOUR RAG APPLICATIONHOW TO SPLIT JSON DATAHOW TO RECURSIVELY SPLIT TEXT BY CHARACTERSRESPONSE METADATAHOW TO PASS RUNTIME SECRETS TO RUNNABLESHOW TO DO \"SELF-QUERYING\" RETRIEVALHOW TO SPLIT TEXT BASED ON SEMANTIC SIMILARITYHOW TO CHAIN RUNNABLESHOW TO SAVE AND LOAD LANGCHAIN OBJECTSHOW TO SPLIT TEXT BY TOKENSHOW TO SPLIT HTMLHOW TO DO QUESTION ANSWERING OVER CSVSHOW TO DEAL WITH LARGE DATABASES WHEN DOING SQL QUESTION-ANSWERINGHOW TO BETTER PROMPT WHEN DOING SQL QUESTION-ANSWERINGHOW TO DO QUERY VALIDATION AS PART OF SQL QUESTION-ANSWERINGHOW TO STREAM RUNNABLESHOW TO STREAM RESPONSES FROM AN LLMHOW TO USE A TIME-WEIGHTED VECTOR STORE RETRIEVERHOW TO RETURN ARTIFACTS FROM A TOOLHOW TO USE CHAT MODELS TO CALL TOOLSHOW TO DISABLE PARALLEL TOOL CALLINGHOW TO FORCE MODELS TO CALL A TOOLHOW TO ACCESS THE RUNNABLECONFIG FROM A TOOLHOW TO PASS TOOL OUTPUTS TO CHAT MODELSHOW TO PASS RUN TIME VALUES TO TOOLSHOW TO STREAM EVENTS FROM A TOOLHOW TO STREAM TOOL CALLSHOW TO CONVERT TOOLS TO OPENAI FUNCTIONSHOW TO HANDLE TOOL ERRORSHOW TO USE FEW-SHOT PROMPTING WITH TOOL CALLINGHOW TO ADD A HUMAN-IN-THE-LOOP FOR TOOLSHOW TO BIND MODEL-SPECIFIC TOOLSHOW TO TRIM MESSAGESHOW TO CREATE AND QUERY VECTOR STORESCONCEPTUAL GUIDEAGENTSARCHITECTUREASYNC PROGRAMMING WITH LANGCHAINCALLBACKSCHAT HISTORYCHAT MODELSDOCUMENT LOADERSEMBEDDING MODELSEVALUATIONEXAMPLE SELECTORSFEW-SHOT PROMPTINGCONCEPTUAL GUIDEKEY-VALUE STORESLANGCHAIN EXPRESSION LANGUAGE (LCEL)MESSAGESMULTIMODALITYOUTPUT PARSERSPROMPT TEMPLATESRETRIEVAL AUGMENTED GENERATION (RAG)RETRIEVALRETRIEVERSRUNNABLE INTERFACESTREAMINGSTRUCTURED OUTPUTSTESTINGSTRING-IN, STRING-OUT LLMSTEXT SPLITTERSTOKENSTOOL CALLINGTOOLSTRACINGVECTOR STORESWHY LANGCHAIN?ECOSYSTEM🦜🛠️ LANGSMITH🦜🕸️ LANGGRAPHVERSIONSV0.3V0.2PYDANTIC COMPATIBILITYMIGRATING FROM V0.0 CHAINSHOW TO MIGRATE FROM V0.0 CHAINSMIGRATING FROM CONSTITUTIONALCHAINMIGRATING FROM CONVERSATIONALCHAINMIGRATING FROM CONVERSATIONALRETRIEVALCHAINMIGRATING FROM LLMCHAINMIGRATING FROM LLMMATHCHAINMIGRATING FROM LLMROUTERCHAINMIGRATING FROM MAPREDUCEDOCUMENTSCHAINMIGRATING FROM MAPRERANKDOCUMENTSCHAINMIGRATING FROM MULTIPROMPTCHAINMIGRATING FROM REFINEDOCUMENTSCHAINMIGRATING FROM RETRIEVALQAMIGRATING FROM STUFFDOCUMENTSCHAINUPGRADING TO LANGGRAPH MEMORYHOW TO MIGRATE TO LANGGRAPH MEMORYHOW TO USE BASECHATMESSAGEHISTORY WITH LANGGRAPHMIGRATING OFF CONVERSATIONBUFFERMEMORY OR CONVERSATIONSTRINGBUFFERMEMORYMIGRATING OFF CONVERSATIONBUFFERWINDOWMEMORY OR CONVERSATIONTOKENBUFFERMEMORYMIGRATING OFF CONVERSATIONSUMMARYMEMORY OR CONVERSATIONSUMMARYBUFFERMEMORYA LONG-TERM MEMORY AGENTRELEASE POLICYSECURITY POLICYHOW-TO GUIDESHOW TO CHAIN RUNNABLESON THIS PAGEHOW TO CHAIN RUNNABLES\n",
      "PREREQUISITESTHIS GUIDE ASSUMES FAMILIARITY WITH THE FOLLOWING CONCEPTS:\n",
      "LANGCHAIN EXPRESSION LANGUAGE (LCEL)\n",
      "PROMPT TEMPLATES\n",
      "CHAT MODELS\n",
      "OUTPUT PARSER\n",
      "\n",
      "ONE POINT ABOUT LANGCHAIN EXPRESSION LANGUAGE IS THAT ANY TWO RUNNABLES CAN BE \"CHAINED\" TOGETHER INTO SEQUENCES. THE OUTPUT OF THE PREVIOUS RUNNABLE'S .INVOKE() CALL IS PASSED AS INPUT TO THE NEXT RUNNABLE. THIS CAN BE DONE USING THE PIPE OPERATOR (|), OR THE MORE EXPLICIT .PIPE() METHOD, WHICH DOES THE SAME THING.\n",
      "THE RESULTING RUNNABLESEQUENCE IS ITSELF A RUNNABLE, WHICH MEANS IT CAN BE INVOKED, STREAMED, OR FURTHER CHAINED JUST LIKE ANY OTHER RUNNABLE. ADVANTAGES OF CHAINING RUNNABLES IN THIS WAY ARE EFFICIENT STREAMING (THE SEQUENCE WILL STREAM OUTPUT AS SOON AS IT IS AVAILABLE), AND DEBUGGING AND TRACING WITH TOOLS LIKE LANGSMITH.\n",
      "THE PIPE OPERATOR: |​\n",
      "TO SHOW OFF HOW THIS WORKS, LET'S GO THROUGH AN EXAMPLE. WE'LL WALK THROUGH A COMMON PATTERN IN LANGCHAIN: USING A PROMPT TEMPLATE TO FORMAT INPUT INTO A CHAT MODEL, AND FINALLY CONVERTING THE CHAT MESSAGE OUTPUT INTO A STRING WITH AN OUTPUT PARSER.\n",
      "\n",
      "SELECT CHAT MODEL:GROQ▾GROQOPENAIANTHROPICAZUREGOOGLE VERTEXAWSCOHERENVIDIAFIREWORKS AIMISTRAL AITOGETHER AIIBM WATSONXDATABRICKSXAIPIP INSTALL -QU \"LANGCHAIN[GROQ]\"IMPORT GETPASSIMPORT OSIF NOT OS.ENVIRON.GET(\"GROQ_API_KEY\"):  OS.ENVIRON[\"GROQ_API_KEY\"] = GETPASS.GETPASS(\"ENTER API KEY FOR GROQ: \")FROM LANGCHAIN.CHAT_MODELS IMPORT INIT_CHAT_MODELMODEL = INIT_CHAT_MODEL(\"LLAMA3-8B-8192\", MODEL_PROVIDER=\"GROQ\")\n",
      "FROM LANGCHAIN_CORE.OUTPUT_PARSERS IMPORT STROUTPUTPARSERFROM LANGCHAIN_CORE.PROMPTS IMPORT CHATPROMPTTEMPLATEPROMPT = CHATPROMPTTEMPLATE.FROM_TEMPLATE(\"TELL ME A JOKE ABOUT {TOPIC}\")CHAIN = PROMPT | MODEL | STROUTPUTPARSER()API REFERENCE:STROUTPUTPARSER | CHATPROMPTTEMPLATE\n",
      "PROMPTS AND MODELS ARE BOTH RUNNABLE, AND THE OUTPUT TYPE FROM THE PROMPT CALL IS THE SAME AS THE INPUT TYPE OF THE CHAT MODEL, SO WE CAN CHAIN THEM TOGETHER. WE CAN THEN INVOKE THE RESULTING SEQUENCE LIKE ANY OTHER RUNNABLE:\n",
      "CHAIN.INVOKE({\"TOPIC\": \"BEARS\"})\n",
      "\"HERE'S A BEAR JOKE FOR YOU:\\N\\NWHY DID THE BEAR DISSOLVE IN WATER?\\NBECAUSE IT WAS A POLAR BEAR!\"\n",
      "COERCION​\n",
      "WE CAN EVEN COMBINE THIS CHAIN WITH MORE RUNNABLES TO CREATE ANOTHER CHAIN. THIS MAY INVOLVE SOME INPUT/OUTPUT FORMATTING USING OTHER TYPES OF RUNNABLES, DEPENDING ON THE REQUIRED INPUTS AND OUTPUTS OF THE CHAIN COMPONENTS.\n",
      "FOR EXAMPLE, LET'S SAY WE WANTED TO COMPOSE THE JOKE GENERATING CHAIN WITH ANOTHER CHAIN THAT EVALUATES WHETHER OR NOT THE GENERATED JOKE WAS FUNNY.\n",
      "WE WOULD NEED TO BE CAREFUL WITH HOW WE FORMAT THE INPUT INTO THE NEXT CHAIN. IN THE BELOW EXAMPLE, THE DICT IN THE CHAIN IS AUTOMATICALLY PARSED AND CONVERTED INTO A RUNNABLEPARALLEL, WHICH RUNS ALL OF ITS VALUES IN PARALLEL AND RETURNS A DICT WITH THE RESULTS.\n",
      "THIS HAPPENS TO BE THE SAME FORMAT THE NEXT PROMPT TEMPLATE EXPECTS. HERE IT IS IN ACTION:\n",
      "FROM LANGCHAIN_CORE.OUTPUT_PARSERS IMPORT STROUTPUTPARSERANALYSIS_PROMPT = CHATPROMPTTEMPLATE.FROM_TEMPLATE(\"IS THIS A FUNNY JOKE? {JOKE}\")COMPOSED_CHAIN = {\"JOKE\": CHAIN} | ANALYSIS_PROMPT | MODEL | STROUTPUTPARSER()COMPOSED_CHAIN.INVOKE({\"TOPIC\": \"BEARS\"})API REFERENCE:STROUTPUTPARSER\n",
      "'HAHA, THAT\\'S A CLEVER PLAY ON WORDS! USING \"POLAR\" TO IMPLY THE BEAR DISSOLVED OR BECAME POLAR/POLARIZED WHEN PUT IN WATER. NOT THE MOST HILARIOUS JOKE EVER, BUT IT HAS A CUTE, GROAN-WORTHY PUN THAT MAKES IT MILDLY AMUSING. I APPRECIATE A GOOD PUN OR WORDPLAY JOKE.'\n",
      "FUNCTIONS WILL ALSO BE COERCED INTO RUNNABLES, SO YOU CAN ADD CUSTOM LOGIC TO YOUR CHAINS TOO. THE BELOW CHAIN RESULTS IN THE SAME LOGICAL FLOW AS BEFORE:\n",
      "COMPOSED_CHAIN_WITH_LAMBDA = (    CHAIN    | (LAMBDA INPUT: {\"JOKE\": INPUT})    | ANALYSIS_PROMPT    | MODEL    | STROUTPUTPARSER())COMPOSED_CHAIN_WITH_LAMBDA.INVOKE({\"TOPIC\": \"BEETS\"})\n",
      "\"HAHA, THAT'S A CUTE AND PUNNY JOKE! I LIKE HOW IT PLAYS ON THE IDEA OF BEETS BLUSHING OR TURNING RED LIKE SOMEONE BLUSHING. FOOD PUNS CAN BE QUITE AMUSING. WHILE NOT A TOTAL KNEE-SLAPPER, IT'S A LIGHT-HEARTED, GROAN-WORTHY DAD JOKE THAT WOULD MAKE ME CHUCKLE AND SHAKE MY HEAD. SIMPLE VEGETABLE HUMOR!\"\n",
      "HOWEVER, KEEP IN MIND THAT USING FUNCTIONS LIKE THIS MAY INTERFERE WITH OPERATIONS LIKE STREAMING. SEE THIS SECTION FOR MORE INFORMATION.\n",
      "THE .PIPE() METHOD​\n",
      "WE COULD ALSO COMPOSE THE SAME SEQUENCE USING THE .PIPE() METHOD. HERE'S WHAT THAT LOOKS LIKE:\n",
      "FROM LANGCHAIN_CORE.RUNNABLES IMPORT RUNNABLEPARALLELCOMPOSED_CHAIN_WITH_PIPE = (    RUNNABLEPARALLEL({\"JOKE\": CHAIN})    .PIPE(ANALYSIS_PROMPT)    .PIPE(MODEL)    .PIPE(STROUTPUTPARSER()))COMPOSED_CHAIN_WITH_PIPE.INVOKE({\"TOPIC\": \"BATTLESTAR GALACTICA\"})API REFERENCE:RUNNABLEPARALLEL\n",
      "\"I CANNOT REPRODUCE ANY COPYRIGHTED MATERIAL VERBATIM, BUT I CAN TRY TO ANALYZE THE HUMOR IN THE JOKE YOU PROVIDED WITHOUT QUOTING IT DIRECTLY.\\N\\NTHE JOKE PLAYS ON THE IDEA THAT THE CYLON RAIDERS, WHO ARE THE ANTAGONISTS IN THE BATTLESTAR GALACTICA UNIVERSE, FAILED TO LOCATE THE HUMAN SURVIVORS AFTER ATTACKING THEIR HOME PLANETS (THE TWELVE COLONIES) DUE TO USING AN OUTDATED AND POORLY PERFORMING OPERATING SYSTEM (WINDOWS VISTA) FOR THEIR TARGETING SYSTEMS.\\N\\NTHE HUMOR STEMS FROM THE JUXTAPOSITION OF A FUTURISTIC SCIENCE FICTION SETTING WITH A RELATABLE REAL-WORLD FRUSTRATION – THE USE OF BUGGY, SLOW, OR UNRELIABLE SOFTWARE OR TECHNOLOGY. IT POKES FUN AT THE PERCEIVED INADEQUACIES OF WINDOWS VISTA, WHICH WAS WIDELY CRITICIZED FOR ITS PERFORMANCE ISSUES AND OTHER PROBLEMS WHEN IT WAS RELEASED.\\N\\NBY ATTRIBUTING THE CYLONS' FAILURE TO LOCATE THE HUMANS TO THEIR USE OF VISTA, THE JOKE CREATES AN AMUSING AND UNEXPECTED CONNECTION BETWEEN A FICTIONAL ADVANCED RACE OF ROBOTS AND A FAMILIAR TECHNOLOGICAL ANNOYANCE EXPERIENCED BY MANY PEOPLE IN THE REAL WORLD.\\N\\NOVERALL, THE JOKE RELIES ON INCONGRUITY AND RELATABILITY TO GENERATE HUMOR, BUT WITHOUT REPRODUCING ANY COPYRIGHTED MATERIAL DIRECTLY.\"\n",
      "OR THE ABBREVIATED:\n",
      "COMPOSED_CHAIN_WITH_PIPE = RUNNABLEPARALLEL({\"JOKE\": CHAIN}).PIPE(    ANALYSIS_PROMPT, MODEL, STROUTPUTPARSER())\n",
      "RELATED​\n",
      "\n",
      "STREAMING: CHECK OUT THE STREAMING GUIDE TO UNDERSTAND THE STREAMING BEHAVIOR OF A CHAIN\n",
      "EDIT THIS PAGEWAS THIS PAGE HELPFUL?PREVIOUSHOW TO SPLIT TEXT BASED ON SEMANTIC SIMILARITYNEXTHOW TO SAVE AND LOAD LANGCHAIN OBJECTSTHE PIPE OPERATOR: |COERCIONTHE .PIPE() METHODRELATEDCOMMUNITYTWITTERGITHUBORGANIZATIONPYTHONJS/TSMOREHOMEPAGEBLOGYOUTUBECOPYRIGHT © 2025 LANGCHAIN, INC.\n",
      "\n",
      "\n",
      "          -------\n",
      "\n",
      "          THE PREVIOUS CODE ATTEMPT FAILED WITH THE FOLLOWING ERROR:\n",
      "          NAME 'ROUTE_FUNCTION' IS NOT DEFINED\n",
      "\n",
      "          YOUR CODING TASK:\n",
      "          HOW CAN I USE A CUSTOM FUNCTION TO ROUTE BETWEEN TWO CHAINS?\n",
      "\n",
      "          PREVIOUS CODE ATTEMPT:\n",
      "          TO USE A CUSTOM FUNCTION TO ROUTE BETWEEN TWO CHAINS, YOU CAN DEFINE THE FUNCTION AND USE IT AS A RUNNABLE. BELOW, THE CODE DEMONSTRATES HOW TO CORRECTLY USE A CUSTOM FUNCTION TO ROUTE THE OUTPUT FROM ONE CHAIN TO ANOTHER. ENSURE THAT ALL NECESSARY IMPORTS ARE DEFINED PROPERLY.\n",
      "          FROM LANGCHAIN_CORE.PROMPTS IMPORT CHATPROMPTTEMPLATE\n",
      "FROM LANGCHAIN.CHAT_MODELS IMPORT INIT_CHAT_MODEL\n",
      "FROM LANGCHAIN_CORE.OUTPUT_PARSERS IMPORT STROUTPUTPARSER\n",
      "          PROMPT = CHATPROMPTTEMPLATE.FROM_TEMPLATE(\"TELL ME A JOKE ABOUT {TOPIC}\")\n",
      "MODEL = INIT_CHAT_MODEL(\"LLAMA3-8B-8192\", MODEL_PROVIDER=\"GROQ\")\n",
      "\n",
      "# DEFINE THE FIRST CHAIN TO GENERATE JOKES\n",
      "JOKE_CHAIN = PROMPT | MODEL | STROUTPUTPARSER()\n",
      "\n",
      "# DEFINE A CUSTOM FUNCTION TO ROUTE OUTPUT BETWEEN CHAINS\n",
      "DEF ROUTE_FUNCTION(OUTPUT):\n",
      "    # TRANSFORM THE OUTPUT OF THE FIRST CHAIN AS NEEDED FOR THE NEXT CHAIN\n",
      "    RETURN {\"JOKE\": OUTPUT[\"TEXT\"]}  # ADJUSTED TO EXTRACT TEXT PROPERLY\n",
      "\n",
      "# DEFINE A SECOND CHAIN TO ANALYZE THE JOKE\n",
      "ANALYSIS_PROMPT = CHATPROMPTTEMPLATE.FROM_TEMPLATE(\"IS THIS A FUNNY JOKE? {JOKE}\")\n",
      "\n",
      "# COMPOSE A NEW CHAIN USING THE CUSTOM FUNCTION TO ROUTE THE OUTPUT\n",
      "COMPOSED_CHAIN = (\n",
      "    JOKE_CHAIN\n",
      "    | (LAMBDA INPUT: ROUTE_FUNCTION(INPUT))  # CUSTOM FUNCTION ROUTING\n",
      "    | ANALYSIS_PROMPT\n",
      "    | MODEL\n",
      "    | STROUTPUTPARSER()\n",
      ")\n",
      "\n",
      "# EXECUTE THE COMPOSED CHAIN\n",
      "RESULT = COMPOSED_CHAIN.INVOKE({\"TOPIC\": \"BEARS\"})\n",
      "PRINT(RESULT)\n",
      "\n",
      "          ANSWER WITH A DESCRIPTION OF THE CODE SOLUTION, FOLLOWED BY THE IMPORTS, AND FINALLY THE FUNCTIONING CODE BLOCK.\n",
      "          ENSURE ALL IMPORTS ARE CORRECT AND THE CODE IS EXECUTABLE.]: 2025-03-13 15:38:40.583895\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:38:40][✅ CREW 'CREW' COMPLETED, 7FC85D97-019D-49A7-AB80-B4E23A0AF71F]: 2025-03-13 15:38:40.592311\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:38:40][👍 FLOW METHOD FINISHED: 'RE_RUN_FIX']: 2025-03-13 15:38:40.592692\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:38:40][🤖 FLOW METHOD STARTED: 'RE_RE_RUN_CHECK']: 2025-03-13 15:38:40.594645\u001b[00m\n",
      "---CHECKING CODE---\n",
      "---CODE BLOCK CHECK: FAILED---\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:38:40][👍 FLOW METHOD FINISHED: 'RE_RE_RUN_CHECK']: 2025-03-13 15:38:40.994544\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:38:40][👍 FLOW FINISHED: 'CODEGENFLOW', 9DCFE464-316B-4ECC-B42F-628919014791]: 2025-03-13 15:38:40.995522\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:38:41][🌊 FLOW CREATED: 'CODEGENFLOW']: 2025-03-13 15:38:41.382167\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:38:41][🤖 FLOW STARTED: 'CODEGENFLOW', F18112C0-4EB3-4279-85B4-6EE1A49E8BC3]: 2025-03-13 15:38:41.383176\u001b[00m\n",
      "\u001b[1m\u001b[35m Flow started with ID: f18112c0-4eb3-4279-85b4-6ee1a49e8bc3\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:38:41][🤖 FLOW METHOD STARTED: 'GENERATE_CODE']: 2025-03-13 15:38:41.383978\u001b[00m\n",
      "---GENERATING CODE SOLUTION---\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:38:41][🚀 CREW 'CREW' STARTED, 368F5772-413F-4BF5-BD01-847C2CD6098D]: 2025-03-13 15:38:41.399099\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:38:41][📋 TASK STARTED: ANSWER THE USER QUESTION BASED ON THE ABOVE PROVIDED DOCUMENTATION. ENSURE ANY CODE YOU PROVIDE CAN BE EXECUTED\n",
      "    WITH ALL REQUIRED IMPORTS AND VARIABLES DEFINED. STRUCTURE YOUR ANSWER:\n",
      "    1) A PREFIX DESCRIBING THE CODE SOLUTION\n",
      "    2) THE IMPORTS\n",
      "    3) THE FUNCTIONING CODE BLOCK\n",
      "\n",
      "    YOUR CODING TASK:\n",
      "    HOW DO I SET UP A RETRIEVAL-AUGMENTED GENERATION AGENT?\n",
      "    ]: 2025-03-13 15:38:41.402976\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:38:41][🤖 AGENT 'CODING ASSISTANT' STARTED TASK]: 2025-03-13 15:38:41.403494\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:38:41][🤖 LLM CALL STARTED]: 2025-03-13 15:38:41.403602\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:38:46][✅ LLM CALL COMPLETED]: 2025-03-13 15:38:46.878579\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:38:46][✅ AGENT 'CODING ASSISTANT' COMPLETED TASK]: 2025-03-13 15:38:46.879680\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:38:46][✅ TASK COMPLETED: ANSWER THE USER QUESTION BASED ON THE ABOVE PROVIDED DOCUMENTATION. ENSURE ANY CODE YOU PROVIDE CAN BE EXECUTED\n",
      "    WITH ALL REQUIRED IMPORTS AND VARIABLES DEFINED. STRUCTURE YOUR ANSWER:\n",
      "    1) A PREFIX DESCRIBING THE CODE SOLUTION\n",
      "    2) THE IMPORTS\n",
      "    3) THE FUNCTIONING CODE BLOCK\n",
      "\n",
      "    YOUR CODING TASK:\n",
      "    HOW DO I SET UP A RETRIEVAL-AUGMENTED GENERATION AGENT?\n",
      "    ]: 2025-03-13 15:38:46.880018\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:38:46][✅ CREW 'CREW' COMPLETED, 368F5772-413F-4BF5-BD01-847C2CD6098D]: 2025-03-13 15:38:46.884497\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:38:46][👍 FLOW METHOD FINISHED: 'GENERATE_CODE']: 2025-03-13 15:38:46.884727\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:38:46][🤖 FLOW METHOD STARTED: 'RUN_CHECK']: 2025-03-13 15:38:46.884884\u001b[00m\n",
      "---CHECKING CODE---\n",
      "---CODE IMPORT CHECK: FAILED---\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:38:46][👍 FLOW METHOD FINISHED: 'RUN_CHECK']: 2025-03-13 15:38:46.951732\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:38:46][🤖 FLOW METHOD STARTED: 'RUN_FIX']: 2025-03-13 15:38:46.956059\u001b[00m\n",
      "---FIXING CODE---\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:38:46][🚀 CREW 'CREW' STARTED, B34DCBC1-0E21-4881-A644-C6DB1DBA146F]: 2025-03-13 15:38:46.956737\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:38:46][📋 TASK STARTED: YOU ARE A CODING ASSISTANT WITH EXPERTISE IN LCEL, LANGCHAIN EXPRESSION LANGUAGE.\n",
      "          HERE IS A FULL SET OF LCEL DOCUMENTATION:\n",
      "          -------\n",
      "          \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "HOW TO CHAIN RUNNABLES | 🦜️🔗 LANGCHAIN\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "SKIP TO MAIN CONTENTJOIN US AT  INTERRUPT: THE AGENT AI CONFERENCE BY LANGCHAIN ON MAY 13 & 14 IN SAN FRANCISCO!INTEGRATIONSAPI REFERENCEMORECONTRIBUTINGPEOPLEERROR REFERENCELANGSMITHLANGGRAPHLANGCHAIN HUBLANGCHAIN JS/TSV0.3V0.3V0.2V0.1💬SEARCHINTRODUCTIONTUTORIALSBUILD A QUESTION ANSWERING APPLICATION OVER A GRAPH DATABASETUTORIALSBUILD A SIMPLE LLM APPLICATION WITH CHAT MODELS AND PROMPT TEMPLATESBUILD A CHATBOTBUILD A RETRIEVAL AUGMENTED GENERATION (RAG) APP: PART 2BUILD AN EXTRACTION CHAINBUILD AN AGENTTAGGINGBUILD A RETRIEVAL AUGMENTED GENERATION (RAG) APP: PART 1BUILD A SEMANTIC SEARCH ENGINEBUILD A QUESTION/ANSWERING SYSTEM OVER SQL DATASUMMARIZE TEXTHOW-TO GUIDESHOW-TO GUIDESHOW TO USE TOOLS IN A CHAINHOW TO USE A VECTORSTORE AS A RETRIEVERHOW TO ADD MEMORY TO CHATBOTSHOW TO USE EXAMPLE SELECTORSHOW TO ADD A SEMANTIC LAYER OVER GRAPH DATABASEHOW TO INVOKE RUNNABLES IN PARALLELHOW TO STREAM CHAT MODEL RESPONSESHOW TO ADD DEFAULT INVOCATION ARGS TO A RUNNABLEHOW TO ADD RETRIEVAL TO CHATBOTSHOW TO USE FEW SHOT EXAMPLES IN CHAT MODELSHOW TO DO TOOL/FUNCTION CALLINGHOW TO INSTALL LANGCHAIN PACKAGESHOW TO ADD EXAMPLES TO THE PROMPT FOR QUERY ANALYSISHOW TO USE FEW SHOT EXAMPLESHOW TO RUN CUSTOM FUNCTIONSHOW TO USE OUTPUT PARSERS TO PARSE AN LLM RESPONSE INTO STRUCTURED FORMATHOW TO HANDLE CASES WHERE NO QUERIES ARE GENERATEDHOW TO ROUTE BETWEEN SUB-CHAINSHOW TO RETURN STRUCTURED DATA FROM A MODELHOW TO SUMMARIZE TEXT THROUGH PARALLELIZATIONHOW TO SUMMARIZE TEXT THROUGH ITERATIVE REFINEMENTHOW TO SUMMARIZE TEXT IN A SINGLE LLM CALLHOW TO USE TOOLKITSHOW TO ADD AD-HOC TOOL CALLING CAPABILITY TO LLMS AND CHAT MODELSBUILD AN AGENT WITH AGENTEXECUTOR (LEGACY)HOW TO CONSTRUCT KNOWLEDGE GRAPHSHOW TO PARTIALLY FORMAT PROMPT TEMPLATESHOW TO HANDLE MULTIPLE QUERIES WHEN DOING QUERY ANALYSISHOW TO USE BUILT-IN TOOLS AND TOOLKITSHOW TO PASS THROUGH ARGUMENTS FROM ONE STEP TO THE NEXTHOW TO COMPOSE PROMPTS TOGETHERHOW TO HANDLE MULTIPLE RETRIEVERS WHEN DOING QUERY ANALYSISHOW TO ADD VALUES TO A CHAIN'S STATEHOW TO CONSTRUCT FILTERS FOR QUERY ANALYSISHOW TO CONFIGURE RUNTIME CHAIN INTERNALSHOW DEAL WITH HIGH CARDINALITY CATEGORICALS WHEN DOING QUERY ANALYSISCUSTOM DOCUMENT LOADERHOW TO USE THE MULTIQUERYRETRIEVERHOW TO ADD SCORES TO RETRIEVER RESULTSCACHINGHOW TO USE CALLBACKS IN ASYNC ENVIRONMENTSHOW TO ATTACH CALLBACKS TO A RUNNABLEHOW TO PROPAGATE CALLBACKS  CONSTRUCTORHOW TO DISPATCH CUSTOM CALLBACK EVENTSHOW TO PASS CALLBACKS IN AT RUNTIMEHOW TO SPLIT BY CHARACTERHOW TO CACHE CHAT MODEL RESPONSESHOW TO HANDLE RATE LIMITSHOW TO INIT ANY MODEL IN ONE LINEHOW TO TRACK TOKEN USAGE IN CHATMODELSHOW TO ADD TOOLS TO CHATBOTSHOW TO SPLIT CODEHOW TO DO RETRIEVAL WITH CONTEXTUAL COMPRESSIONHOW TO CONVERT RUNNABLES TO TOOLSHOW TO CREATE CUSTOM CALLBACK HANDLERSHOW TO CREATE A CUSTOM CHAT MODEL CLASSCUSTOM EMBEDDINGSHOW TO CREATE A CUSTOM LLM CLASSCUSTOM RETRIEVERHOW TO CREATE TOOLSHOW TO DEBUG YOUR LLM APPSHOW TO LOAD CSVSHOW TO LOAD DOCUMENTS FROM A DIRECTORYHOW TO LOAD HTMLHOW TO LOAD JSONHOW TO LOAD MARKDOWNHOW TO LOAD MICROSOFT OFFICE FILESHOW TO LOAD PDFSHOW TO LOAD WEB PAGESHOW TO CREATE A DYNAMIC (SELF-CONSTRUCTING) CHAINTEXT EMBEDDING MODELSHOW TO COMBINE RESULTS FROM MULTIPLE RETRIEVERSHOW TO SELECT EXAMPLES FROM A LANGSMITH DATASETHOW TO SELECT EXAMPLES BY LENGTHHOW TO SELECT EXAMPLES BY MAXIMAL MARGINAL RELEVANCE (MMR)HOW TO SELECT EXAMPLES BY N-GRAM OVERLAPHOW TO SELECT EXAMPLES BY SIMILARITYHOW TO USE REFERENCE EXAMPLES WHEN DOING EXTRACTIONHOW TO HANDLE LONG TEXT WHEN DOING EXTRACTIONHOW TO USE PROMPTING ALONE (NO TOOL CALLING) TO DO EXTRACTIONHOW TO ADD FALLBACKS TO A RUNNABLEHOW TO FILTER MESSAGESHYBRID SEARCHHOW TO USE THE LANGCHAIN INDEXING APIHOW TO INSPECT RUNNABLESLANGCHAIN EXPRESSION LANGUAGE CHEATSHEETHOW TO CACHE LLM RESPONSESHOW TO TRACK TOKEN USAGE FOR LLMSRUN MODELS LOCALLYHOW TO GET LOG PROBABILITIESHOW TO REORDER RETRIEVED RESULTS TO MITIGATE THE \"LOST IN THE MIDDLE\" EFFECTHOW TO SPLIT MARKDOWN BY HEADERSHOW TO MERGE CONSECUTIVE MESSAGES OF THE SAME TYPEHOW TO ADD MESSAGE HISTORYHOW TO MIGRATE FROM LEGACY LANGCHAIN AGENTS TO LANGGRAPHHOW TO RETRIEVE USING MULTIPLE VECTORS PER DOCUMENTHOW TO PASS MULTIMODAL DATA DIRECTLY TO MODELSHOW TO USE MULTIMODAL PROMPTSHOW TO CREATE A CUSTOM OUTPUT PARSERHOW TO USE THE OUTPUT-FIXING PARSERHOW TO PARSE JSON OUTPUTHOW TO RETRY WHEN A PARSING ERROR OCCURSHOW TO PARSE TEXT FROM MESSAGE OBJECTSHOW TO PARSE XML OUTPUTHOW TO PARSE YAML OUTPUTHOW TO USE THE PARENT DOCUMENT RETRIEVERHOW TO USE LANGCHAIN WITH DIFFERENT PYDANTIC VERSIONSHOW TO ADD CHAT HISTORYHOW TO GET A RAG APPLICATION TO ADD CITATIONSHOW TO DO PER-USER RETRIEVALHOW TO GET YOUR RAG APPLICATION TO RETURN SOURCESHOW TO STREAM RESULTS FROM YOUR RAG APPLICATIONHOW TO SPLIT JSON DATAHOW TO RECURSIVELY SPLIT TEXT BY CHARACTERSRESPONSE METADATAHOW TO PASS RUNTIME SECRETS TO RUNNABLESHOW TO DO \"SELF-QUERYING\" RETRIEVALHOW TO SPLIT TEXT BASED ON SEMANTIC SIMILARITYHOW TO CHAIN RUNNABLESHOW TO SAVE AND LOAD LANGCHAIN OBJECTSHOW TO SPLIT TEXT BY TOKENSHOW TO SPLIT HTMLHOW TO DO QUESTION ANSWERING OVER CSVSHOW TO DEAL WITH LARGE DATABASES WHEN DOING SQL QUESTION-ANSWERINGHOW TO BETTER PROMPT WHEN DOING SQL QUESTION-ANSWERINGHOW TO DO QUERY VALIDATION AS PART OF SQL QUESTION-ANSWERINGHOW TO STREAM RUNNABLESHOW TO STREAM RESPONSES FROM AN LLMHOW TO USE A TIME-WEIGHTED VECTOR STORE RETRIEVERHOW TO RETURN ARTIFACTS FROM A TOOLHOW TO USE CHAT MODELS TO CALL TOOLSHOW TO DISABLE PARALLEL TOOL CALLINGHOW TO FORCE MODELS TO CALL A TOOLHOW TO ACCESS THE RUNNABLECONFIG FROM A TOOLHOW TO PASS TOOL OUTPUTS TO CHAT MODELSHOW TO PASS RUN TIME VALUES TO TOOLSHOW TO STREAM EVENTS FROM A TOOLHOW TO STREAM TOOL CALLSHOW TO CONVERT TOOLS TO OPENAI FUNCTIONSHOW TO HANDLE TOOL ERRORSHOW TO USE FEW-SHOT PROMPTING WITH TOOL CALLINGHOW TO ADD A HUMAN-IN-THE-LOOP FOR TOOLSHOW TO BIND MODEL-SPECIFIC TOOLSHOW TO TRIM MESSAGESHOW TO CREATE AND QUERY VECTOR STORESCONCEPTUAL GUIDEAGENTSARCHITECTUREASYNC PROGRAMMING WITH LANGCHAINCALLBACKSCHAT HISTORYCHAT MODELSDOCUMENT LOADERSEMBEDDING MODELSEVALUATIONEXAMPLE SELECTORSFEW-SHOT PROMPTINGCONCEPTUAL GUIDEKEY-VALUE STORESLANGCHAIN EXPRESSION LANGUAGE (LCEL)MESSAGESMULTIMODALITYOUTPUT PARSERSPROMPT TEMPLATESRETRIEVAL AUGMENTED GENERATION (RAG)RETRIEVALRETRIEVERSRUNNABLE INTERFACESTREAMINGSTRUCTURED OUTPUTSTESTINGSTRING-IN, STRING-OUT LLMSTEXT SPLITTERSTOKENSTOOL CALLINGTOOLSTRACINGVECTOR STORESWHY LANGCHAIN?ECOSYSTEM🦜🛠️ LANGSMITH🦜🕸️ LANGGRAPHVERSIONSV0.3V0.2PYDANTIC COMPATIBILITYMIGRATING FROM V0.0 CHAINSHOW TO MIGRATE FROM V0.0 CHAINSMIGRATING FROM CONSTITUTIONALCHAINMIGRATING FROM CONVERSATIONALCHAINMIGRATING FROM CONVERSATIONALRETRIEVALCHAINMIGRATING FROM LLMCHAINMIGRATING FROM LLMMATHCHAINMIGRATING FROM LLMROUTERCHAINMIGRATING FROM MAPREDUCEDOCUMENTSCHAINMIGRATING FROM MAPRERANKDOCUMENTSCHAINMIGRATING FROM MULTIPROMPTCHAINMIGRATING FROM REFINEDOCUMENTSCHAINMIGRATING FROM RETRIEVALQAMIGRATING FROM STUFFDOCUMENTSCHAINUPGRADING TO LANGGRAPH MEMORYHOW TO MIGRATE TO LANGGRAPH MEMORYHOW TO USE BASECHATMESSAGEHISTORY WITH LANGGRAPHMIGRATING OFF CONVERSATIONBUFFERMEMORY OR CONVERSATIONSTRINGBUFFERMEMORYMIGRATING OFF CONVERSATIONBUFFERWINDOWMEMORY OR CONVERSATIONTOKENBUFFERMEMORYMIGRATING OFF CONVERSATIONSUMMARYMEMORY OR CONVERSATIONSUMMARYBUFFERMEMORYA LONG-TERM MEMORY AGENTRELEASE POLICYSECURITY POLICYHOW-TO GUIDESHOW TO CHAIN RUNNABLESON THIS PAGEHOW TO CHAIN RUNNABLES\n",
      "PREREQUISITESTHIS GUIDE ASSUMES FAMILIARITY WITH THE FOLLOWING CONCEPTS:\n",
      "LANGCHAIN EXPRESSION LANGUAGE (LCEL)\n",
      "PROMPT TEMPLATES\n",
      "CHAT MODELS\n",
      "OUTPUT PARSER\n",
      "\n",
      "ONE POINT ABOUT LANGCHAIN EXPRESSION LANGUAGE IS THAT ANY TWO RUNNABLES CAN BE \"CHAINED\" TOGETHER INTO SEQUENCES. THE OUTPUT OF THE PREVIOUS RUNNABLE'S .INVOKE() CALL IS PASSED AS INPUT TO THE NEXT RUNNABLE. THIS CAN BE DONE USING THE PIPE OPERATOR (|), OR THE MORE EXPLICIT .PIPE() METHOD, WHICH DOES THE SAME THING.\n",
      "THE RESULTING RUNNABLESEQUENCE IS ITSELF A RUNNABLE, WHICH MEANS IT CAN BE INVOKED, STREAMED, OR FURTHER CHAINED JUST LIKE ANY OTHER RUNNABLE. ADVANTAGES OF CHAINING RUNNABLES IN THIS WAY ARE EFFICIENT STREAMING (THE SEQUENCE WILL STREAM OUTPUT AS SOON AS IT IS AVAILABLE), AND DEBUGGING AND TRACING WITH TOOLS LIKE LANGSMITH.\n",
      "THE PIPE OPERATOR: |​\n",
      "TO SHOW OFF HOW THIS WORKS, LET'S GO THROUGH AN EXAMPLE. WE'LL WALK THROUGH A COMMON PATTERN IN LANGCHAIN: USING A PROMPT TEMPLATE TO FORMAT INPUT INTO A CHAT MODEL, AND FINALLY CONVERTING THE CHAT MESSAGE OUTPUT INTO A STRING WITH AN OUTPUT PARSER.\n",
      "\n",
      "SELECT CHAT MODEL:GROQ▾GROQOPENAIANTHROPICAZUREGOOGLE VERTEXAWSCOHERENVIDIAFIREWORKS AIMISTRAL AITOGETHER AIIBM WATSONXDATABRICKSXAIPIP INSTALL -QU \"LANGCHAIN[GROQ]\"IMPORT GETPASSIMPORT OSIF NOT OS.ENVIRON.GET(\"GROQ_API_KEY\"):  OS.ENVIRON[\"GROQ_API_KEY\"] = GETPASS.GETPASS(\"ENTER API KEY FOR GROQ: \")FROM LANGCHAIN.CHAT_MODELS IMPORT INIT_CHAT_MODELMODEL = INIT_CHAT_MODEL(\"LLAMA3-8B-8192\", MODEL_PROVIDER=\"GROQ\")\n",
      "FROM LANGCHAIN_CORE.OUTPUT_PARSERS IMPORT STROUTPUTPARSERFROM LANGCHAIN_CORE.PROMPTS IMPORT CHATPROMPTTEMPLATEPROMPT = CHATPROMPTTEMPLATE.FROM_TEMPLATE(\"TELL ME A JOKE ABOUT {TOPIC}\")CHAIN = PROMPT | MODEL | STROUTPUTPARSER()API REFERENCE:STROUTPUTPARSER | CHATPROMPTTEMPLATE\n",
      "PROMPTS AND MODELS ARE BOTH RUNNABLE, AND THE OUTPUT TYPE FROM THE PROMPT CALL IS THE SAME AS THE INPUT TYPE OF THE CHAT MODEL, SO WE CAN CHAIN THEM TOGETHER. WE CAN THEN INVOKE THE RESULTING SEQUENCE LIKE ANY OTHER RUNNABLE:\n",
      "CHAIN.INVOKE({\"TOPIC\": \"BEARS\"})\n",
      "\"HERE'S A BEAR JOKE FOR YOU:\\N\\NWHY DID THE BEAR DISSOLVE IN WATER?\\NBECAUSE IT WAS A POLAR BEAR!\"\n",
      "COERCION​\n",
      "WE CAN EVEN COMBINE THIS CHAIN WITH MORE RUNNABLES TO CREATE ANOTHER CHAIN. THIS MAY INVOLVE SOME INPUT/OUTPUT FORMATTING USING OTHER TYPES OF RUNNABLES, DEPENDING ON THE REQUIRED INPUTS AND OUTPUTS OF THE CHAIN COMPONENTS.\n",
      "FOR EXAMPLE, LET'S SAY WE WANTED TO COMPOSE THE JOKE GENERATING CHAIN WITH ANOTHER CHAIN THAT EVALUATES WHETHER OR NOT THE GENERATED JOKE WAS FUNNY.\n",
      "WE WOULD NEED TO BE CAREFUL WITH HOW WE FORMAT THE INPUT INTO THE NEXT CHAIN. IN THE BELOW EXAMPLE, THE DICT IN THE CHAIN IS AUTOMATICALLY PARSED AND CONVERTED INTO A RUNNABLEPARALLEL, WHICH RUNS ALL OF ITS VALUES IN PARALLEL AND RETURNS A DICT WITH THE RESULTS.\n",
      "THIS HAPPENS TO BE THE SAME FORMAT THE NEXT PROMPT TEMPLATE EXPECTS. HERE IT IS IN ACTION:\n",
      "FROM LANGCHAIN_CORE.OUTPUT_PARSERS IMPORT STROUTPUTPARSERANALYSIS_PROMPT = CHATPROMPTTEMPLATE.FROM_TEMPLATE(\"IS THIS A FUNNY JOKE? {JOKE}\")COMPOSED_CHAIN = {\"JOKE\": CHAIN} | ANALYSIS_PROMPT | MODEL | STROUTPUTPARSER()COMPOSED_CHAIN.INVOKE({\"TOPIC\": \"BEARS\"})API REFERENCE:STROUTPUTPARSER\n",
      "'HAHA, THAT\\'S A CLEVER PLAY ON WORDS! USING \"POLAR\" TO IMPLY THE BEAR DISSOLVED OR BECAME POLAR/POLARIZED WHEN PUT IN WATER. NOT THE MOST HILARIOUS JOKE EVER, BUT IT HAS A CUTE, GROAN-WORTHY PUN THAT MAKES IT MILDLY AMUSING. I APPRECIATE A GOOD PUN OR WORDPLAY JOKE.'\n",
      "FUNCTIONS WILL ALSO BE COERCED INTO RUNNABLES, SO YOU CAN ADD CUSTOM LOGIC TO YOUR CHAINS TOO. THE BELOW CHAIN RESULTS IN THE SAME LOGICAL FLOW AS BEFORE:\n",
      "COMPOSED_CHAIN_WITH_LAMBDA = (    CHAIN    | (LAMBDA INPUT: {\"JOKE\": INPUT})    | ANALYSIS_PROMPT    | MODEL    | STROUTPUTPARSER())COMPOSED_CHAIN_WITH_LAMBDA.INVOKE({\"TOPIC\": \"BEETS\"})\n",
      "\"HAHA, THAT'S A CUTE AND PUNNY JOKE! I LIKE HOW IT PLAYS ON THE IDEA OF BEETS BLUSHING OR TURNING RED LIKE SOMEONE BLUSHING. FOOD PUNS CAN BE QUITE AMUSING. WHILE NOT A TOTAL KNEE-SLAPPER, IT'S A LIGHT-HEARTED, GROAN-WORTHY DAD JOKE THAT WOULD MAKE ME CHUCKLE AND SHAKE MY HEAD. SIMPLE VEGETABLE HUMOR!\"\n",
      "HOWEVER, KEEP IN MIND THAT USING FUNCTIONS LIKE THIS MAY INTERFERE WITH OPERATIONS LIKE STREAMING. SEE THIS SECTION FOR MORE INFORMATION.\n",
      "THE .PIPE() METHOD​\n",
      "WE COULD ALSO COMPOSE THE SAME SEQUENCE USING THE .PIPE() METHOD. HERE'S WHAT THAT LOOKS LIKE:\n",
      "FROM LANGCHAIN_CORE.RUNNABLES IMPORT RUNNABLEPARALLELCOMPOSED_CHAIN_WITH_PIPE = (    RUNNABLEPARALLEL({\"JOKE\": CHAIN})    .PIPE(ANALYSIS_PROMPT)    .PIPE(MODEL)    .PIPE(STROUTPUTPARSER()))COMPOSED_CHAIN_WITH_PIPE.INVOKE({\"TOPIC\": \"BATTLESTAR GALACTICA\"})API REFERENCE:RUNNABLEPARALLEL\n",
      "\"I CANNOT REPRODUCE ANY COPYRIGHTED MATERIAL VERBATIM, BUT I CAN TRY TO ANALYZE THE HUMOR IN THE JOKE YOU PROVIDED WITHOUT QUOTING IT DIRECTLY.\\N\\NTHE JOKE PLAYS ON THE IDEA THAT THE CYLON RAIDERS, WHO ARE THE ANTAGONISTS IN THE BATTLESTAR GALACTICA UNIVERSE, FAILED TO LOCATE THE HUMAN SURVIVORS AFTER ATTACKING THEIR HOME PLANETS (THE TWELVE COLONIES) DUE TO USING AN OUTDATED AND POORLY PERFORMING OPERATING SYSTEM (WINDOWS VISTA) FOR THEIR TARGETING SYSTEMS.\\N\\NTHE HUMOR STEMS FROM THE JUXTAPOSITION OF A FUTURISTIC SCIENCE FICTION SETTING WITH A RELATABLE REAL-WORLD FRUSTRATION – THE USE OF BUGGY, SLOW, OR UNRELIABLE SOFTWARE OR TECHNOLOGY. IT POKES FUN AT THE PERCEIVED INADEQUACIES OF WINDOWS VISTA, WHICH WAS WIDELY CRITICIZED FOR ITS PERFORMANCE ISSUES AND OTHER PROBLEMS WHEN IT WAS RELEASED.\\N\\NBY ATTRIBUTING THE CYLONS' FAILURE TO LOCATE THE HUMANS TO THEIR USE OF VISTA, THE JOKE CREATES AN AMUSING AND UNEXPECTED CONNECTION BETWEEN A FICTIONAL ADVANCED RACE OF ROBOTS AND A FAMILIAR TECHNOLOGICAL ANNOYANCE EXPERIENCED BY MANY PEOPLE IN THE REAL WORLD.\\N\\NOVERALL, THE JOKE RELIES ON INCONGRUITY AND RELATABILITY TO GENERATE HUMOR, BUT WITHOUT REPRODUCING ANY COPYRIGHTED MATERIAL DIRECTLY.\"\n",
      "OR THE ABBREVIATED:\n",
      "COMPOSED_CHAIN_WITH_PIPE = RUNNABLEPARALLEL({\"JOKE\": CHAIN}).PIPE(    ANALYSIS_PROMPT, MODEL, STROUTPUTPARSER())\n",
      "RELATED​\n",
      "\n",
      "STREAMING: CHECK OUT THE STREAMING GUIDE TO UNDERSTAND THE STREAMING BEHAVIOR OF A CHAIN\n",
      "EDIT THIS PAGEWAS THIS PAGE HELPFUL?PREVIOUSHOW TO SPLIT TEXT BASED ON SEMANTIC SIMILARITYNEXTHOW TO SAVE AND LOAD LANGCHAIN OBJECTSTHE PIPE OPERATOR: |COERCIONTHE .PIPE() METHODRELATEDCOMMUNITYTWITTERGITHUBORGANIZATIONPYTHONJS/TSMOREHOMEPAGEBLOGYOUTUBECOPYRIGHT © 2025 LANGCHAIN, INC.\n",
      "\n",
      "\n",
      "          -------\n",
      "\n",
      "          THE PREVIOUS CODE ATTEMPT FAILED WITH THE FOLLOWING ERROR:\n",
      "          CANNOT IMPORT NAME 'VECTORSTORERETRIEVER' FROM 'LANGCHAIN.RETRIEVERS' (/USERS/MJACK6/GSU_SPRING2025/MSA8700/VENV_AGENTICAI/LIB/PYTHON3.11/SITE-PACKAGES/LANGCHAIN/RETRIEVERS/__INIT__.PY)\n",
      "\n",
      "          YOUR CODING TASK:\n",
      "          HOW DO I SET UP A RETRIEVAL-AUGMENTED GENERATION AGENT?\n",
      "\n",
      "          PREVIOUS CODE ATTEMPT:\n",
      "          TO SET UP A RETRIEVAL-AUGMENTED GENERATION (RAG) AGENT, YOU'LL NEED TO HAVE A RETRIEVAL MECHANISM IN PLACE TO FETCH RELEVANT DOCUMENTS AND THEN USE THAT INFORMATION TO GENERATE A RESPONSE. BELOW IS AN EXAMPLE CODE TO ILLUSTRATE THIS PROCESS USING A CHAT MODEL, A PROMPT TEMPLATE, AND OUTPUT PARSERS IN LANGCHAIN.\n",
      "          FROM LANGCHAIN.CHAT_MODELS IMPORT INIT_CHAT_MODEL\n",
      "FROM LANGCHAIN_CORE.OUTPUT_PARSERS IMPORT STROUTPUTPARSER\n",
      "FROM LANGCHAIN_CORE.PROMPTS IMPORT CHATPROMPTTEMPLATE\n",
      "FROM LANGCHAIN.RETRIEVERS IMPORT VECTORSTORERETRIEVER\n",
      "          IMPORT GETPASS\n",
      "IMPORT OS\n",
      "\n",
      "# SET UP THE ENVIRONMENT FOR THE CHAT MODEL\n",
      "IF NOT OS.ENVIRON.GET(\"GROQ_API_KEY\"):\n",
      "    OS.ENVIRON[\"GROQ_API_KEY\"] = GETPASS.GETPASS(\"ENTER API KEY FOR GROQ: \")\n",
      "\n",
      "# INITIALIZE THE CHAT MODEL\n",
      "MODEL = INIT_CHAT_MODEL(\"LLAMA3-8B-8192\", MODEL_PROVIDER=\"GROQ\")\n",
      "\n",
      "# DEFINE THE PROMPT TEMPLATE FOR RETRIEVAL AUGMENTED GENERATION\n",
      "PROMPT = CHATPROMPTTEMPLATE.FROM_TEMPLATE(\"USING THE FOLLOWING CONTEXT, ANSWER THE QUESTION: {CONTEXT}\n",
      "\n",
      "QUESTION: {QUERY}\")\n",
      "\n",
      "# INITIALIZE A HYPOTHETICAL VECTOR STORE RETRIEVER\n",
      "RETRIEVER = VECTORSTORERETRIEVER()\n",
      "\n",
      "# DEFINE A FUNCTION TO REPLACE RETRIEVAL LOGIC WITH REAL MECHANISM\n",
      "# THIS IS A PLACEHOLDER FOR WHERE YOU'D INTEGRATE A REAL VECTOR STORE LIKE PINECONE, WEAVIATE, ETC.\n",
      "DEF FETCH_DOCUMENTS(QUERY):\n",
      "    RETURN RETRIEVER.GET_RELEVANT_DOCUMENTS(QUERY)\n",
      "\n",
      "# CHAIN SETUP COMBINING RETRIEVAL WITH GENERATION\n",
      "RAG_CHAIN = (LAMBDA INPUT: {\n",
      "    \"CONTEXT\": FETCH_DOCUMENTS(INPUT['QUERY']),\n",
      "    \"QUERY\": INPUT['QUERY']\n",
      "}) | PROMPT | MODEL | STROUTPUTPARSER()\n",
      "\n",
      "# EXAMPLE USAGE\n",
      "RESPONSE = RAG_CHAIN.INVOKE({\"QUERY\": \"EXPLAIN QUANTUM COMPUTING IN SIMPLE TERMS.\"})\n",
      "PRINT(RESPONSE)\n",
      "\n",
      "          ANSWER WITH A DESCRIPTION OF THE CODE SOLUTION, FOLLOWED BY THE IMPORTS, AND FINALLY THE FUNCTIONING CODE BLOCK.\n",
      "          ENSURE ALL IMPORTS ARE CORRECT AND THE CODE IS EXECUTABLE.]: 2025-03-13 15:38:46.958090\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:38:46][🤖 AGENT 'CODING ASSISTANT' STARTED TASK]: 2025-03-13 15:38:46.958586\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:38:46][🤖 LLM CALL STARTED]: 2025-03-13 15:38:46.958654\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:39:01][✅ LLM CALL COMPLETED]: 2025-03-13 15:39:01.871175\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:39:01][✅ AGENT 'CODING ASSISTANT' COMPLETED TASK]: 2025-03-13 15:39:01.872304\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:39:01][✅ TASK COMPLETED: YOU ARE A CODING ASSISTANT WITH EXPERTISE IN LCEL, LANGCHAIN EXPRESSION LANGUAGE.\n",
      "          HERE IS A FULL SET OF LCEL DOCUMENTATION:\n",
      "          -------\n",
      "          \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "HOW TO CHAIN RUNNABLES | 🦜️🔗 LANGCHAIN\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "SKIP TO MAIN CONTENTJOIN US AT  INTERRUPT: THE AGENT AI CONFERENCE BY LANGCHAIN ON MAY 13 & 14 IN SAN FRANCISCO!INTEGRATIONSAPI REFERENCEMORECONTRIBUTINGPEOPLEERROR REFERENCELANGSMITHLANGGRAPHLANGCHAIN HUBLANGCHAIN JS/TSV0.3V0.3V0.2V0.1💬SEARCHINTRODUCTIONTUTORIALSBUILD A QUESTION ANSWERING APPLICATION OVER A GRAPH DATABASETUTORIALSBUILD A SIMPLE LLM APPLICATION WITH CHAT MODELS AND PROMPT TEMPLATESBUILD A CHATBOTBUILD A RETRIEVAL AUGMENTED GENERATION (RAG) APP: PART 2BUILD AN EXTRACTION CHAINBUILD AN AGENTTAGGINGBUILD A RETRIEVAL AUGMENTED GENERATION (RAG) APP: PART 1BUILD A SEMANTIC SEARCH ENGINEBUILD A QUESTION/ANSWERING SYSTEM OVER SQL DATASUMMARIZE TEXTHOW-TO GUIDESHOW-TO GUIDESHOW TO USE TOOLS IN A CHAINHOW TO USE A VECTORSTORE AS A RETRIEVERHOW TO ADD MEMORY TO CHATBOTSHOW TO USE EXAMPLE SELECTORSHOW TO ADD A SEMANTIC LAYER OVER GRAPH DATABASEHOW TO INVOKE RUNNABLES IN PARALLELHOW TO STREAM CHAT MODEL RESPONSESHOW TO ADD DEFAULT INVOCATION ARGS TO A RUNNABLEHOW TO ADD RETRIEVAL TO CHATBOTSHOW TO USE FEW SHOT EXAMPLES IN CHAT MODELSHOW TO DO TOOL/FUNCTION CALLINGHOW TO INSTALL LANGCHAIN PACKAGESHOW TO ADD EXAMPLES TO THE PROMPT FOR QUERY ANALYSISHOW TO USE FEW SHOT EXAMPLESHOW TO RUN CUSTOM FUNCTIONSHOW TO USE OUTPUT PARSERS TO PARSE AN LLM RESPONSE INTO STRUCTURED FORMATHOW TO HANDLE CASES WHERE NO QUERIES ARE GENERATEDHOW TO ROUTE BETWEEN SUB-CHAINSHOW TO RETURN STRUCTURED DATA FROM A MODELHOW TO SUMMARIZE TEXT THROUGH PARALLELIZATIONHOW TO SUMMARIZE TEXT THROUGH ITERATIVE REFINEMENTHOW TO SUMMARIZE TEXT IN A SINGLE LLM CALLHOW TO USE TOOLKITSHOW TO ADD AD-HOC TOOL CALLING CAPABILITY TO LLMS AND CHAT MODELSBUILD AN AGENT WITH AGENTEXECUTOR (LEGACY)HOW TO CONSTRUCT KNOWLEDGE GRAPHSHOW TO PARTIALLY FORMAT PROMPT TEMPLATESHOW TO HANDLE MULTIPLE QUERIES WHEN DOING QUERY ANALYSISHOW TO USE BUILT-IN TOOLS AND TOOLKITSHOW TO PASS THROUGH ARGUMENTS FROM ONE STEP TO THE NEXTHOW TO COMPOSE PROMPTS TOGETHERHOW TO HANDLE MULTIPLE RETRIEVERS WHEN DOING QUERY ANALYSISHOW TO ADD VALUES TO A CHAIN'S STATEHOW TO CONSTRUCT FILTERS FOR QUERY ANALYSISHOW TO CONFIGURE RUNTIME CHAIN INTERNALSHOW DEAL WITH HIGH CARDINALITY CATEGORICALS WHEN DOING QUERY ANALYSISCUSTOM DOCUMENT LOADERHOW TO USE THE MULTIQUERYRETRIEVERHOW TO ADD SCORES TO RETRIEVER RESULTSCACHINGHOW TO USE CALLBACKS IN ASYNC ENVIRONMENTSHOW TO ATTACH CALLBACKS TO A RUNNABLEHOW TO PROPAGATE CALLBACKS  CONSTRUCTORHOW TO DISPATCH CUSTOM CALLBACK EVENTSHOW TO PASS CALLBACKS IN AT RUNTIMEHOW TO SPLIT BY CHARACTERHOW TO CACHE CHAT MODEL RESPONSESHOW TO HANDLE RATE LIMITSHOW TO INIT ANY MODEL IN ONE LINEHOW TO TRACK TOKEN USAGE IN CHATMODELSHOW TO ADD TOOLS TO CHATBOTSHOW TO SPLIT CODEHOW TO DO RETRIEVAL WITH CONTEXTUAL COMPRESSIONHOW TO CONVERT RUNNABLES TO TOOLSHOW TO CREATE CUSTOM CALLBACK HANDLERSHOW TO CREATE A CUSTOM CHAT MODEL CLASSCUSTOM EMBEDDINGSHOW TO CREATE A CUSTOM LLM CLASSCUSTOM RETRIEVERHOW TO CREATE TOOLSHOW TO DEBUG YOUR LLM APPSHOW TO LOAD CSVSHOW TO LOAD DOCUMENTS FROM A DIRECTORYHOW TO LOAD HTMLHOW TO LOAD JSONHOW TO LOAD MARKDOWNHOW TO LOAD MICROSOFT OFFICE FILESHOW TO LOAD PDFSHOW TO LOAD WEB PAGESHOW TO CREATE A DYNAMIC (SELF-CONSTRUCTING) CHAINTEXT EMBEDDING MODELSHOW TO COMBINE RESULTS FROM MULTIPLE RETRIEVERSHOW TO SELECT EXAMPLES FROM A LANGSMITH DATASETHOW TO SELECT EXAMPLES BY LENGTHHOW TO SELECT EXAMPLES BY MAXIMAL MARGINAL RELEVANCE (MMR)HOW TO SELECT EXAMPLES BY N-GRAM OVERLAPHOW TO SELECT EXAMPLES BY SIMILARITYHOW TO USE REFERENCE EXAMPLES WHEN DOING EXTRACTIONHOW TO HANDLE LONG TEXT WHEN DOING EXTRACTIONHOW TO USE PROMPTING ALONE (NO TOOL CALLING) TO DO EXTRACTIONHOW TO ADD FALLBACKS TO A RUNNABLEHOW TO FILTER MESSAGESHYBRID SEARCHHOW TO USE THE LANGCHAIN INDEXING APIHOW TO INSPECT RUNNABLESLANGCHAIN EXPRESSION LANGUAGE CHEATSHEETHOW TO CACHE LLM RESPONSESHOW TO TRACK TOKEN USAGE FOR LLMSRUN MODELS LOCALLYHOW TO GET LOG PROBABILITIESHOW TO REORDER RETRIEVED RESULTS TO MITIGATE THE \"LOST IN THE MIDDLE\" EFFECTHOW TO SPLIT MARKDOWN BY HEADERSHOW TO MERGE CONSECUTIVE MESSAGES OF THE SAME TYPEHOW TO ADD MESSAGE HISTORYHOW TO MIGRATE FROM LEGACY LANGCHAIN AGENTS TO LANGGRAPHHOW TO RETRIEVE USING MULTIPLE VECTORS PER DOCUMENTHOW TO PASS MULTIMODAL DATA DIRECTLY TO MODELSHOW TO USE MULTIMODAL PROMPTSHOW TO CREATE A CUSTOM OUTPUT PARSERHOW TO USE THE OUTPUT-FIXING PARSERHOW TO PARSE JSON OUTPUTHOW TO RETRY WHEN A PARSING ERROR OCCURSHOW TO PARSE TEXT FROM MESSAGE OBJECTSHOW TO PARSE XML OUTPUTHOW TO PARSE YAML OUTPUTHOW TO USE THE PARENT DOCUMENT RETRIEVERHOW TO USE LANGCHAIN WITH DIFFERENT PYDANTIC VERSIONSHOW TO ADD CHAT HISTORYHOW TO GET A RAG APPLICATION TO ADD CITATIONSHOW TO DO PER-USER RETRIEVALHOW TO GET YOUR RAG APPLICATION TO RETURN SOURCESHOW TO STREAM RESULTS FROM YOUR RAG APPLICATIONHOW TO SPLIT JSON DATAHOW TO RECURSIVELY SPLIT TEXT BY CHARACTERSRESPONSE METADATAHOW TO PASS RUNTIME SECRETS TO RUNNABLESHOW TO DO \"SELF-QUERYING\" RETRIEVALHOW TO SPLIT TEXT BASED ON SEMANTIC SIMILARITYHOW TO CHAIN RUNNABLESHOW TO SAVE AND LOAD LANGCHAIN OBJECTSHOW TO SPLIT TEXT BY TOKENSHOW TO SPLIT HTMLHOW TO DO QUESTION ANSWERING OVER CSVSHOW TO DEAL WITH LARGE DATABASES WHEN DOING SQL QUESTION-ANSWERINGHOW TO BETTER PROMPT WHEN DOING SQL QUESTION-ANSWERINGHOW TO DO QUERY VALIDATION AS PART OF SQL QUESTION-ANSWERINGHOW TO STREAM RUNNABLESHOW TO STREAM RESPONSES FROM AN LLMHOW TO USE A TIME-WEIGHTED VECTOR STORE RETRIEVERHOW TO RETURN ARTIFACTS FROM A TOOLHOW TO USE CHAT MODELS TO CALL TOOLSHOW TO DISABLE PARALLEL TOOL CALLINGHOW TO FORCE MODELS TO CALL A TOOLHOW TO ACCESS THE RUNNABLECONFIG FROM A TOOLHOW TO PASS TOOL OUTPUTS TO CHAT MODELSHOW TO PASS RUN TIME VALUES TO TOOLSHOW TO STREAM EVENTS FROM A TOOLHOW TO STREAM TOOL CALLSHOW TO CONVERT TOOLS TO OPENAI FUNCTIONSHOW TO HANDLE TOOL ERRORSHOW TO USE FEW-SHOT PROMPTING WITH TOOL CALLINGHOW TO ADD A HUMAN-IN-THE-LOOP FOR TOOLSHOW TO BIND MODEL-SPECIFIC TOOLSHOW TO TRIM MESSAGESHOW TO CREATE AND QUERY VECTOR STORESCONCEPTUAL GUIDEAGENTSARCHITECTUREASYNC PROGRAMMING WITH LANGCHAINCALLBACKSCHAT HISTORYCHAT MODELSDOCUMENT LOADERSEMBEDDING MODELSEVALUATIONEXAMPLE SELECTORSFEW-SHOT PROMPTINGCONCEPTUAL GUIDEKEY-VALUE STORESLANGCHAIN EXPRESSION LANGUAGE (LCEL)MESSAGESMULTIMODALITYOUTPUT PARSERSPROMPT TEMPLATESRETRIEVAL AUGMENTED GENERATION (RAG)RETRIEVALRETRIEVERSRUNNABLE INTERFACESTREAMINGSTRUCTURED OUTPUTSTESTINGSTRING-IN, STRING-OUT LLMSTEXT SPLITTERSTOKENSTOOL CALLINGTOOLSTRACINGVECTOR STORESWHY LANGCHAIN?ECOSYSTEM🦜🛠️ LANGSMITH🦜🕸️ LANGGRAPHVERSIONSV0.3V0.2PYDANTIC COMPATIBILITYMIGRATING FROM V0.0 CHAINSHOW TO MIGRATE FROM V0.0 CHAINSMIGRATING FROM CONSTITUTIONALCHAINMIGRATING FROM CONVERSATIONALCHAINMIGRATING FROM CONVERSATIONALRETRIEVALCHAINMIGRATING FROM LLMCHAINMIGRATING FROM LLMMATHCHAINMIGRATING FROM LLMROUTERCHAINMIGRATING FROM MAPREDUCEDOCUMENTSCHAINMIGRATING FROM MAPRERANKDOCUMENTSCHAINMIGRATING FROM MULTIPROMPTCHAINMIGRATING FROM REFINEDOCUMENTSCHAINMIGRATING FROM RETRIEVALQAMIGRATING FROM STUFFDOCUMENTSCHAINUPGRADING TO LANGGRAPH MEMORYHOW TO MIGRATE TO LANGGRAPH MEMORYHOW TO USE BASECHATMESSAGEHISTORY WITH LANGGRAPHMIGRATING OFF CONVERSATIONBUFFERMEMORY OR CONVERSATIONSTRINGBUFFERMEMORYMIGRATING OFF CONVERSATIONBUFFERWINDOWMEMORY OR CONVERSATIONTOKENBUFFERMEMORYMIGRATING OFF CONVERSATIONSUMMARYMEMORY OR CONVERSATIONSUMMARYBUFFERMEMORYA LONG-TERM MEMORY AGENTRELEASE POLICYSECURITY POLICYHOW-TO GUIDESHOW TO CHAIN RUNNABLESON THIS PAGEHOW TO CHAIN RUNNABLES\n",
      "PREREQUISITESTHIS GUIDE ASSUMES FAMILIARITY WITH THE FOLLOWING CONCEPTS:\n",
      "LANGCHAIN EXPRESSION LANGUAGE (LCEL)\n",
      "PROMPT TEMPLATES\n",
      "CHAT MODELS\n",
      "OUTPUT PARSER\n",
      "\n",
      "ONE POINT ABOUT LANGCHAIN EXPRESSION LANGUAGE IS THAT ANY TWO RUNNABLES CAN BE \"CHAINED\" TOGETHER INTO SEQUENCES. THE OUTPUT OF THE PREVIOUS RUNNABLE'S .INVOKE() CALL IS PASSED AS INPUT TO THE NEXT RUNNABLE. THIS CAN BE DONE USING THE PIPE OPERATOR (|), OR THE MORE EXPLICIT .PIPE() METHOD, WHICH DOES THE SAME THING.\n",
      "THE RESULTING RUNNABLESEQUENCE IS ITSELF A RUNNABLE, WHICH MEANS IT CAN BE INVOKED, STREAMED, OR FURTHER CHAINED JUST LIKE ANY OTHER RUNNABLE. ADVANTAGES OF CHAINING RUNNABLES IN THIS WAY ARE EFFICIENT STREAMING (THE SEQUENCE WILL STREAM OUTPUT AS SOON AS IT IS AVAILABLE), AND DEBUGGING AND TRACING WITH TOOLS LIKE LANGSMITH.\n",
      "THE PIPE OPERATOR: |​\n",
      "TO SHOW OFF HOW THIS WORKS, LET'S GO THROUGH AN EXAMPLE. WE'LL WALK THROUGH A COMMON PATTERN IN LANGCHAIN: USING A PROMPT TEMPLATE TO FORMAT INPUT INTO A CHAT MODEL, AND FINALLY CONVERTING THE CHAT MESSAGE OUTPUT INTO A STRING WITH AN OUTPUT PARSER.\n",
      "\n",
      "SELECT CHAT MODEL:GROQ▾GROQOPENAIANTHROPICAZUREGOOGLE VERTEXAWSCOHERENVIDIAFIREWORKS AIMISTRAL AITOGETHER AIIBM WATSONXDATABRICKSXAIPIP INSTALL -QU \"LANGCHAIN[GROQ]\"IMPORT GETPASSIMPORT OSIF NOT OS.ENVIRON.GET(\"GROQ_API_KEY\"):  OS.ENVIRON[\"GROQ_API_KEY\"] = GETPASS.GETPASS(\"ENTER API KEY FOR GROQ: \")FROM LANGCHAIN.CHAT_MODELS IMPORT INIT_CHAT_MODELMODEL = INIT_CHAT_MODEL(\"LLAMA3-8B-8192\", MODEL_PROVIDER=\"GROQ\")\n",
      "FROM LANGCHAIN_CORE.OUTPUT_PARSERS IMPORT STROUTPUTPARSERFROM LANGCHAIN_CORE.PROMPTS IMPORT CHATPROMPTTEMPLATEPROMPT = CHATPROMPTTEMPLATE.FROM_TEMPLATE(\"TELL ME A JOKE ABOUT {TOPIC}\")CHAIN = PROMPT | MODEL | STROUTPUTPARSER()API REFERENCE:STROUTPUTPARSER | CHATPROMPTTEMPLATE\n",
      "PROMPTS AND MODELS ARE BOTH RUNNABLE, AND THE OUTPUT TYPE FROM THE PROMPT CALL IS THE SAME AS THE INPUT TYPE OF THE CHAT MODEL, SO WE CAN CHAIN THEM TOGETHER. WE CAN THEN INVOKE THE RESULTING SEQUENCE LIKE ANY OTHER RUNNABLE:\n",
      "CHAIN.INVOKE({\"TOPIC\": \"BEARS\"})\n",
      "\"HERE'S A BEAR JOKE FOR YOU:\\N\\NWHY DID THE BEAR DISSOLVE IN WATER?\\NBECAUSE IT WAS A POLAR BEAR!\"\n",
      "COERCION​\n",
      "WE CAN EVEN COMBINE THIS CHAIN WITH MORE RUNNABLES TO CREATE ANOTHER CHAIN. THIS MAY INVOLVE SOME INPUT/OUTPUT FORMATTING USING OTHER TYPES OF RUNNABLES, DEPENDING ON THE REQUIRED INPUTS AND OUTPUTS OF THE CHAIN COMPONENTS.\n",
      "FOR EXAMPLE, LET'S SAY WE WANTED TO COMPOSE THE JOKE GENERATING CHAIN WITH ANOTHER CHAIN THAT EVALUATES WHETHER OR NOT THE GENERATED JOKE WAS FUNNY.\n",
      "WE WOULD NEED TO BE CAREFUL WITH HOW WE FORMAT THE INPUT INTO THE NEXT CHAIN. IN THE BELOW EXAMPLE, THE DICT IN THE CHAIN IS AUTOMATICALLY PARSED AND CONVERTED INTO A RUNNABLEPARALLEL, WHICH RUNS ALL OF ITS VALUES IN PARALLEL AND RETURNS A DICT WITH THE RESULTS.\n",
      "THIS HAPPENS TO BE THE SAME FORMAT THE NEXT PROMPT TEMPLATE EXPECTS. HERE IT IS IN ACTION:\n",
      "FROM LANGCHAIN_CORE.OUTPUT_PARSERS IMPORT STROUTPUTPARSERANALYSIS_PROMPT = CHATPROMPTTEMPLATE.FROM_TEMPLATE(\"IS THIS A FUNNY JOKE? {JOKE}\")COMPOSED_CHAIN = {\"JOKE\": CHAIN} | ANALYSIS_PROMPT | MODEL | STROUTPUTPARSER()COMPOSED_CHAIN.INVOKE({\"TOPIC\": \"BEARS\"})API REFERENCE:STROUTPUTPARSER\n",
      "'HAHA, THAT\\'S A CLEVER PLAY ON WORDS! USING \"POLAR\" TO IMPLY THE BEAR DISSOLVED OR BECAME POLAR/POLARIZED WHEN PUT IN WATER. NOT THE MOST HILARIOUS JOKE EVER, BUT IT HAS A CUTE, GROAN-WORTHY PUN THAT MAKES IT MILDLY AMUSING. I APPRECIATE A GOOD PUN OR WORDPLAY JOKE.'\n",
      "FUNCTIONS WILL ALSO BE COERCED INTO RUNNABLES, SO YOU CAN ADD CUSTOM LOGIC TO YOUR CHAINS TOO. THE BELOW CHAIN RESULTS IN THE SAME LOGICAL FLOW AS BEFORE:\n",
      "COMPOSED_CHAIN_WITH_LAMBDA = (    CHAIN    | (LAMBDA INPUT: {\"JOKE\": INPUT})    | ANALYSIS_PROMPT    | MODEL    | STROUTPUTPARSER())COMPOSED_CHAIN_WITH_LAMBDA.INVOKE({\"TOPIC\": \"BEETS\"})\n",
      "\"HAHA, THAT'S A CUTE AND PUNNY JOKE! I LIKE HOW IT PLAYS ON THE IDEA OF BEETS BLUSHING OR TURNING RED LIKE SOMEONE BLUSHING. FOOD PUNS CAN BE QUITE AMUSING. WHILE NOT A TOTAL KNEE-SLAPPER, IT'S A LIGHT-HEARTED, GROAN-WORTHY DAD JOKE THAT WOULD MAKE ME CHUCKLE AND SHAKE MY HEAD. SIMPLE VEGETABLE HUMOR!\"\n",
      "HOWEVER, KEEP IN MIND THAT USING FUNCTIONS LIKE THIS MAY INTERFERE WITH OPERATIONS LIKE STREAMING. SEE THIS SECTION FOR MORE INFORMATION.\n",
      "THE .PIPE() METHOD​\n",
      "WE COULD ALSO COMPOSE THE SAME SEQUENCE USING THE .PIPE() METHOD. HERE'S WHAT THAT LOOKS LIKE:\n",
      "FROM LANGCHAIN_CORE.RUNNABLES IMPORT RUNNABLEPARALLELCOMPOSED_CHAIN_WITH_PIPE = (    RUNNABLEPARALLEL({\"JOKE\": CHAIN})    .PIPE(ANALYSIS_PROMPT)    .PIPE(MODEL)    .PIPE(STROUTPUTPARSER()))COMPOSED_CHAIN_WITH_PIPE.INVOKE({\"TOPIC\": \"BATTLESTAR GALACTICA\"})API REFERENCE:RUNNABLEPARALLEL\n",
      "\"I CANNOT REPRODUCE ANY COPYRIGHTED MATERIAL VERBATIM, BUT I CAN TRY TO ANALYZE THE HUMOR IN THE JOKE YOU PROVIDED WITHOUT QUOTING IT DIRECTLY.\\N\\NTHE JOKE PLAYS ON THE IDEA THAT THE CYLON RAIDERS, WHO ARE THE ANTAGONISTS IN THE BATTLESTAR GALACTICA UNIVERSE, FAILED TO LOCATE THE HUMAN SURVIVORS AFTER ATTACKING THEIR HOME PLANETS (THE TWELVE COLONIES) DUE TO USING AN OUTDATED AND POORLY PERFORMING OPERATING SYSTEM (WINDOWS VISTA) FOR THEIR TARGETING SYSTEMS.\\N\\NTHE HUMOR STEMS FROM THE JUXTAPOSITION OF A FUTURISTIC SCIENCE FICTION SETTING WITH A RELATABLE REAL-WORLD FRUSTRATION – THE USE OF BUGGY, SLOW, OR UNRELIABLE SOFTWARE OR TECHNOLOGY. IT POKES FUN AT THE PERCEIVED INADEQUACIES OF WINDOWS VISTA, WHICH WAS WIDELY CRITICIZED FOR ITS PERFORMANCE ISSUES AND OTHER PROBLEMS WHEN IT WAS RELEASED.\\N\\NBY ATTRIBUTING THE CYLONS' FAILURE TO LOCATE THE HUMANS TO THEIR USE OF VISTA, THE JOKE CREATES AN AMUSING AND UNEXPECTED CONNECTION BETWEEN A FICTIONAL ADVANCED RACE OF ROBOTS AND A FAMILIAR TECHNOLOGICAL ANNOYANCE EXPERIENCED BY MANY PEOPLE IN THE REAL WORLD.\\N\\NOVERALL, THE JOKE RELIES ON INCONGRUITY AND RELATABILITY TO GENERATE HUMOR, BUT WITHOUT REPRODUCING ANY COPYRIGHTED MATERIAL DIRECTLY.\"\n",
      "OR THE ABBREVIATED:\n",
      "COMPOSED_CHAIN_WITH_PIPE = RUNNABLEPARALLEL({\"JOKE\": CHAIN}).PIPE(    ANALYSIS_PROMPT, MODEL, STROUTPUTPARSER())\n",
      "RELATED​\n",
      "\n",
      "STREAMING: CHECK OUT THE STREAMING GUIDE TO UNDERSTAND THE STREAMING BEHAVIOR OF A CHAIN\n",
      "EDIT THIS PAGEWAS THIS PAGE HELPFUL?PREVIOUSHOW TO SPLIT TEXT BASED ON SEMANTIC SIMILARITYNEXTHOW TO SAVE AND LOAD LANGCHAIN OBJECTSTHE PIPE OPERATOR: |COERCIONTHE .PIPE() METHODRELATEDCOMMUNITYTWITTERGITHUBORGANIZATIONPYTHONJS/TSMOREHOMEPAGEBLOGYOUTUBECOPYRIGHT © 2025 LANGCHAIN, INC.\n",
      "\n",
      "\n",
      "          -------\n",
      "\n",
      "          THE PREVIOUS CODE ATTEMPT FAILED WITH THE FOLLOWING ERROR:\n",
      "          CANNOT IMPORT NAME 'VECTORSTORERETRIEVER' FROM 'LANGCHAIN.RETRIEVERS' (/USERS/MJACK6/GSU_SPRING2025/MSA8700/VENV_AGENTICAI/LIB/PYTHON3.11/SITE-PACKAGES/LANGCHAIN/RETRIEVERS/__INIT__.PY)\n",
      "\n",
      "          YOUR CODING TASK:\n",
      "          HOW DO I SET UP A RETRIEVAL-AUGMENTED GENERATION AGENT?\n",
      "\n",
      "          PREVIOUS CODE ATTEMPT:\n",
      "          TO SET UP A RETRIEVAL-AUGMENTED GENERATION (RAG) AGENT, YOU'LL NEED TO HAVE A RETRIEVAL MECHANISM IN PLACE TO FETCH RELEVANT DOCUMENTS AND THEN USE THAT INFORMATION TO GENERATE A RESPONSE. BELOW IS AN EXAMPLE CODE TO ILLUSTRATE THIS PROCESS USING A CHAT MODEL, A PROMPT TEMPLATE, AND OUTPUT PARSERS IN LANGCHAIN.\n",
      "          FROM LANGCHAIN.CHAT_MODELS IMPORT INIT_CHAT_MODEL\n",
      "FROM LANGCHAIN_CORE.OUTPUT_PARSERS IMPORT STROUTPUTPARSER\n",
      "FROM LANGCHAIN_CORE.PROMPTS IMPORT CHATPROMPTTEMPLATE\n",
      "FROM LANGCHAIN.RETRIEVERS IMPORT VECTORSTORERETRIEVER\n",
      "          IMPORT GETPASS\n",
      "IMPORT OS\n",
      "\n",
      "# SET UP THE ENVIRONMENT FOR THE CHAT MODEL\n",
      "IF NOT OS.ENVIRON.GET(\"GROQ_API_KEY\"):\n",
      "    OS.ENVIRON[\"GROQ_API_KEY\"] = GETPASS.GETPASS(\"ENTER API KEY FOR GROQ: \")\n",
      "\n",
      "# INITIALIZE THE CHAT MODEL\n",
      "MODEL = INIT_CHAT_MODEL(\"LLAMA3-8B-8192\", MODEL_PROVIDER=\"GROQ\")\n",
      "\n",
      "# DEFINE THE PROMPT TEMPLATE FOR RETRIEVAL AUGMENTED GENERATION\n",
      "PROMPT = CHATPROMPTTEMPLATE.FROM_TEMPLATE(\"USING THE FOLLOWING CONTEXT, ANSWER THE QUESTION: {CONTEXT}\n",
      "\n",
      "QUESTION: {QUERY}\")\n",
      "\n",
      "# INITIALIZE A HYPOTHETICAL VECTOR STORE RETRIEVER\n",
      "RETRIEVER = VECTORSTORERETRIEVER()\n",
      "\n",
      "# DEFINE A FUNCTION TO REPLACE RETRIEVAL LOGIC WITH REAL MECHANISM\n",
      "# THIS IS A PLACEHOLDER FOR WHERE YOU'D INTEGRATE A REAL VECTOR STORE LIKE PINECONE, WEAVIATE, ETC.\n",
      "DEF FETCH_DOCUMENTS(QUERY):\n",
      "    RETURN RETRIEVER.GET_RELEVANT_DOCUMENTS(QUERY)\n",
      "\n",
      "# CHAIN SETUP COMBINING RETRIEVAL WITH GENERATION\n",
      "RAG_CHAIN = (LAMBDA INPUT: {\n",
      "    \"CONTEXT\": FETCH_DOCUMENTS(INPUT['QUERY']),\n",
      "    \"QUERY\": INPUT['QUERY']\n",
      "}) | PROMPT | MODEL | STROUTPUTPARSER()\n",
      "\n",
      "# EXAMPLE USAGE\n",
      "RESPONSE = RAG_CHAIN.INVOKE({\"QUERY\": \"EXPLAIN QUANTUM COMPUTING IN SIMPLE TERMS.\"})\n",
      "PRINT(RESPONSE)\n",
      "\n",
      "          ANSWER WITH A DESCRIPTION OF THE CODE SOLUTION, FOLLOWED BY THE IMPORTS, AND FINALLY THE FUNCTIONING CODE BLOCK.\n",
      "          ENSURE ALL IMPORTS ARE CORRECT AND THE CODE IS EXECUTABLE.]: 2025-03-13 15:39:01.872930\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:39:01][✅ CREW 'CREW' COMPLETED, B34DCBC1-0E21-4881-A644-C6DB1DBA146F]: 2025-03-13 15:39:01.878254\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:39:01][👍 FLOW METHOD FINISHED: 'RUN_FIX']: 2025-03-13 15:39:01.878661\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:39:01][🤖 FLOW METHOD STARTED: 'RE_RUN_CHECK']: 2025-03-13 15:39:01.878791\u001b[00m\n",
      "---CHECKING CODE---\n",
      "---CODE BLOCK CHECK: FAILED---\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:39:01][👍 FLOW METHOD FINISHED: 'RE_RUN_CHECK']: 2025-03-13 15:39:01.897526\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:39:01][🤖 FLOW METHOD STARTED: 'RE_RUN_FIX']: 2025-03-13 15:39:01.897657\u001b[00m\n",
      "---FIXING CODE---\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:39:01][🚀 CREW 'CREW' STARTED, B6046CE6-092A-40BD-9AB3-75F71FA381A8]: 2025-03-13 15:39:01.898695\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:39:01][📋 TASK STARTED: YOU ARE A CODING ASSISTANT WITH EXPERTISE IN LCEL, LANGCHAIN EXPRESSION LANGUAGE.\n",
      "          HERE IS A FULL SET OF LCEL DOCUMENTATION:\n",
      "          -------\n",
      "          \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "HOW TO CHAIN RUNNABLES | 🦜️🔗 LANGCHAIN\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "SKIP TO MAIN CONTENTJOIN US AT  INTERRUPT: THE AGENT AI CONFERENCE BY LANGCHAIN ON MAY 13 & 14 IN SAN FRANCISCO!INTEGRATIONSAPI REFERENCEMORECONTRIBUTINGPEOPLEERROR REFERENCELANGSMITHLANGGRAPHLANGCHAIN HUBLANGCHAIN JS/TSV0.3V0.3V0.2V0.1💬SEARCHINTRODUCTIONTUTORIALSBUILD A QUESTION ANSWERING APPLICATION OVER A GRAPH DATABASETUTORIALSBUILD A SIMPLE LLM APPLICATION WITH CHAT MODELS AND PROMPT TEMPLATESBUILD A CHATBOTBUILD A RETRIEVAL AUGMENTED GENERATION (RAG) APP: PART 2BUILD AN EXTRACTION CHAINBUILD AN AGENTTAGGINGBUILD A RETRIEVAL AUGMENTED GENERATION (RAG) APP: PART 1BUILD A SEMANTIC SEARCH ENGINEBUILD A QUESTION/ANSWERING SYSTEM OVER SQL DATASUMMARIZE TEXTHOW-TO GUIDESHOW-TO GUIDESHOW TO USE TOOLS IN A CHAINHOW TO USE A VECTORSTORE AS A RETRIEVERHOW TO ADD MEMORY TO CHATBOTSHOW TO USE EXAMPLE SELECTORSHOW TO ADD A SEMANTIC LAYER OVER GRAPH DATABASEHOW TO INVOKE RUNNABLES IN PARALLELHOW TO STREAM CHAT MODEL RESPONSESHOW TO ADD DEFAULT INVOCATION ARGS TO A RUNNABLEHOW TO ADD RETRIEVAL TO CHATBOTSHOW TO USE FEW SHOT EXAMPLES IN CHAT MODELSHOW TO DO TOOL/FUNCTION CALLINGHOW TO INSTALL LANGCHAIN PACKAGESHOW TO ADD EXAMPLES TO THE PROMPT FOR QUERY ANALYSISHOW TO USE FEW SHOT EXAMPLESHOW TO RUN CUSTOM FUNCTIONSHOW TO USE OUTPUT PARSERS TO PARSE AN LLM RESPONSE INTO STRUCTURED FORMATHOW TO HANDLE CASES WHERE NO QUERIES ARE GENERATEDHOW TO ROUTE BETWEEN SUB-CHAINSHOW TO RETURN STRUCTURED DATA FROM A MODELHOW TO SUMMARIZE TEXT THROUGH PARALLELIZATIONHOW TO SUMMARIZE TEXT THROUGH ITERATIVE REFINEMENTHOW TO SUMMARIZE TEXT IN A SINGLE LLM CALLHOW TO USE TOOLKITSHOW TO ADD AD-HOC TOOL CALLING CAPABILITY TO LLMS AND CHAT MODELSBUILD AN AGENT WITH AGENTEXECUTOR (LEGACY)HOW TO CONSTRUCT KNOWLEDGE GRAPHSHOW TO PARTIALLY FORMAT PROMPT TEMPLATESHOW TO HANDLE MULTIPLE QUERIES WHEN DOING QUERY ANALYSISHOW TO USE BUILT-IN TOOLS AND TOOLKITSHOW TO PASS THROUGH ARGUMENTS FROM ONE STEP TO THE NEXTHOW TO COMPOSE PROMPTS TOGETHERHOW TO HANDLE MULTIPLE RETRIEVERS WHEN DOING QUERY ANALYSISHOW TO ADD VALUES TO A CHAIN'S STATEHOW TO CONSTRUCT FILTERS FOR QUERY ANALYSISHOW TO CONFIGURE RUNTIME CHAIN INTERNALSHOW DEAL WITH HIGH CARDINALITY CATEGORICALS WHEN DOING QUERY ANALYSISCUSTOM DOCUMENT LOADERHOW TO USE THE MULTIQUERYRETRIEVERHOW TO ADD SCORES TO RETRIEVER RESULTSCACHINGHOW TO USE CALLBACKS IN ASYNC ENVIRONMENTSHOW TO ATTACH CALLBACKS TO A RUNNABLEHOW TO PROPAGATE CALLBACKS  CONSTRUCTORHOW TO DISPATCH CUSTOM CALLBACK EVENTSHOW TO PASS CALLBACKS IN AT RUNTIMEHOW TO SPLIT BY CHARACTERHOW TO CACHE CHAT MODEL RESPONSESHOW TO HANDLE RATE LIMITSHOW TO INIT ANY MODEL IN ONE LINEHOW TO TRACK TOKEN USAGE IN CHATMODELSHOW TO ADD TOOLS TO CHATBOTSHOW TO SPLIT CODEHOW TO DO RETRIEVAL WITH CONTEXTUAL COMPRESSIONHOW TO CONVERT RUNNABLES TO TOOLSHOW TO CREATE CUSTOM CALLBACK HANDLERSHOW TO CREATE A CUSTOM CHAT MODEL CLASSCUSTOM EMBEDDINGSHOW TO CREATE A CUSTOM LLM CLASSCUSTOM RETRIEVERHOW TO CREATE TOOLSHOW TO DEBUG YOUR LLM APPSHOW TO LOAD CSVSHOW TO LOAD DOCUMENTS FROM A DIRECTORYHOW TO LOAD HTMLHOW TO LOAD JSONHOW TO LOAD MARKDOWNHOW TO LOAD MICROSOFT OFFICE FILESHOW TO LOAD PDFSHOW TO LOAD WEB PAGESHOW TO CREATE A DYNAMIC (SELF-CONSTRUCTING) CHAINTEXT EMBEDDING MODELSHOW TO COMBINE RESULTS FROM MULTIPLE RETRIEVERSHOW TO SELECT EXAMPLES FROM A LANGSMITH DATASETHOW TO SELECT EXAMPLES BY LENGTHHOW TO SELECT EXAMPLES BY MAXIMAL MARGINAL RELEVANCE (MMR)HOW TO SELECT EXAMPLES BY N-GRAM OVERLAPHOW TO SELECT EXAMPLES BY SIMILARITYHOW TO USE REFERENCE EXAMPLES WHEN DOING EXTRACTIONHOW TO HANDLE LONG TEXT WHEN DOING EXTRACTIONHOW TO USE PROMPTING ALONE (NO TOOL CALLING) TO DO EXTRACTIONHOW TO ADD FALLBACKS TO A RUNNABLEHOW TO FILTER MESSAGESHYBRID SEARCHHOW TO USE THE LANGCHAIN INDEXING APIHOW TO INSPECT RUNNABLESLANGCHAIN EXPRESSION LANGUAGE CHEATSHEETHOW TO CACHE LLM RESPONSESHOW TO TRACK TOKEN USAGE FOR LLMSRUN MODELS LOCALLYHOW TO GET LOG PROBABILITIESHOW TO REORDER RETRIEVED RESULTS TO MITIGATE THE \"LOST IN THE MIDDLE\" EFFECTHOW TO SPLIT MARKDOWN BY HEADERSHOW TO MERGE CONSECUTIVE MESSAGES OF THE SAME TYPEHOW TO ADD MESSAGE HISTORYHOW TO MIGRATE FROM LEGACY LANGCHAIN AGENTS TO LANGGRAPHHOW TO RETRIEVE USING MULTIPLE VECTORS PER DOCUMENTHOW TO PASS MULTIMODAL DATA DIRECTLY TO MODELSHOW TO USE MULTIMODAL PROMPTSHOW TO CREATE A CUSTOM OUTPUT PARSERHOW TO USE THE OUTPUT-FIXING PARSERHOW TO PARSE JSON OUTPUTHOW TO RETRY WHEN A PARSING ERROR OCCURSHOW TO PARSE TEXT FROM MESSAGE OBJECTSHOW TO PARSE XML OUTPUTHOW TO PARSE YAML OUTPUTHOW TO USE THE PARENT DOCUMENT RETRIEVERHOW TO USE LANGCHAIN WITH DIFFERENT PYDANTIC VERSIONSHOW TO ADD CHAT HISTORYHOW TO GET A RAG APPLICATION TO ADD CITATIONSHOW TO DO PER-USER RETRIEVALHOW TO GET YOUR RAG APPLICATION TO RETURN SOURCESHOW TO STREAM RESULTS FROM YOUR RAG APPLICATIONHOW TO SPLIT JSON DATAHOW TO RECURSIVELY SPLIT TEXT BY CHARACTERSRESPONSE METADATAHOW TO PASS RUNTIME SECRETS TO RUNNABLESHOW TO DO \"SELF-QUERYING\" RETRIEVALHOW TO SPLIT TEXT BASED ON SEMANTIC SIMILARITYHOW TO CHAIN RUNNABLESHOW TO SAVE AND LOAD LANGCHAIN OBJECTSHOW TO SPLIT TEXT BY TOKENSHOW TO SPLIT HTMLHOW TO DO QUESTION ANSWERING OVER CSVSHOW TO DEAL WITH LARGE DATABASES WHEN DOING SQL QUESTION-ANSWERINGHOW TO BETTER PROMPT WHEN DOING SQL QUESTION-ANSWERINGHOW TO DO QUERY VALIDATION AS PART OF SQL QUESTION-ANSWERINGHOW TO STREAM RUNNABLESHOW TO STREAM RESPONSES FROM AN LLMHOW TO USE A TIME-WEIGHTED VECTOR STORE RETRIEVERHOW TO RETURN ARTIFACTS FROM A TOOLHOW TO USE CHAT MODELS TO CALL TOOLSHOW TO DISABLE PARALLEL TOOL CALLINGHOW TO FORCE MODELS TO CALL A TOOLHOW TO ACCESS THE RUNNABLECONFIG FROM A TOOLHOW TO PASS TOOL OUTPUTS TO CHAT MODELSHOW TO PASS RUN TIME VALUES TO TOOLSHOW TO STREAM EVENTS FROM A TOOLHOW TO STREAM TOOL CALLSHOW TO CONVERT TOOLS TO OPENAI FUNCTIONSHOW TO HANDLE TOOL ERRORSHOW TO USE FEW-SHOT PROMPTING WITH TOOL CALLINGHOW TO ADD A HUMAN-IN-THE-LOOP FOR TOOLSHOW TO BIND MODEL-SPECIFIC TOOLSHOW TO TRIM MESSAGESHOW TO CREATE AND QUERY VECTOR STORESCONCEPTUAL GUIDEAGENTSARCHITECTUREASYNC PROGRAMMING WITH LANGCHAINCALLBACKSCHAT HISTORYCHAT MODELSDOCUMENT LOADERSEMBEDDING MODELSEVALUATIONEXAMPLE SELECTORSFEW-SHOT PROMPTINGCONCEPTUAL GUIDEKEY-VALUE STORESLANGCHAIN EXPRESSION LANGUAGE (LCEL)MESSAGESMULTIMODALITYOUTPUT PARSERSPROMPT TEMPLATESRETRIEVAL AUGMENTED GENERATION (RAG)RETRIEVALRETRIEVERSRUNNABLE INTERFACESTREAMINGSTRUCTURED OUTPUTSTESTINGSTRING-IN, STRING-OUT LLMSTEXT SPLITTERSTOKENSTOOL CALLINGTOOLSTRACINGVECTOR STORESWHY LANGCHAIN?ECOSYSTEM🦜🛠️ LANGSMITH🦜🕸️ LANGGRAPHVERSIONSV0.3V0.2PYDANTIC COMPATIBILITYMIGRATING FROM V0.0 CHAINSHOW TO MIGRATE FROM V0.0 CHAINSMIGRATING FROM CONSTITUTIONALCHAINMIGRATING FROM CONVERSATIONALCHAINMIGRATING FROM CONVERSATIONALRETRIEVALCHAINMIGRATING FROM LLMCHAINMIGRATING FROM LLMMATHCHAINMIGRATING FROM LLMROUTERCHAINMIGRATING FROM MAPREDUCEDOCUMENTSCHAINMIGRATING FROM MAPRERANKDOCUMENTSCHAINMIGRATING FROM MULTIPROMPTCHAINMIGRATING FROM REFINEDOCUMENTSCHAINMIGRATING FROM RETRIEVALQAMIGRATING FROM STUFFDOCUMENTSCHAINUPGRADING TO LANGGRAPH MEMORYHOW TO MIGRATE TO LANGGRAPH MEMORYHOW TO USE BASECHATMESSAGEHISTORY WITH LANGGRAPHMIGRATING OFF CONVERSATIONBUFFERMEMORY OR CONVERSATIONSTRINGBUFFERMEMORYMIGRATING OFF CONVERSATIONBUFFERWINDOWMEMORY OR CONVERSATIONTOKENBUFFERMEMORYMIGRATING OFF CONVERSATIONSUMMARYMEMORY OR CONVERSATIONSUMMARYBUFFERMEMORYA LONG-TERM MEMORY AGENTRELEASE POLICYSECURITY POLICYHOW-TO GUIDESHOW TO CHAIN RUNNABLESON THIS PAGEHOW TO CHAIN RUNNABLES\n",
      "PREREQUISITESTHIS GUIDE ASSUMES FAMILIARITY WITH THE FOLLOWING CONCEPTS:\n",
      "LANGCHAIN EXPRESSION LANGUAGE (LCEL)\n",
      "PROMPT TEMPLATES\n",
      "CHAT MODELS\n",
      "OUTPUT PARSER\n",
      "\n",
      "ONE POINT ABOUT LANGCHAIN EXPRESSION LANGUAGE IS THAT ANY TWO RUNNABLES CAN BE \"CHAINED\" TOGETHER INTO SEQUENCES. THE OUTPUT OF THE PREVIOUS RUNNABLE'S .INVOKE() CALL IS PASSED AS INPUT TO THE NEXT RUNNABLE. THIS CAN BE DONE USING THE PIPE OPERATOR (|), OR THE MORE EXPLICIT .PIPE() METHOD, WHICH DOES THE SAME THING.\n",
      "THE RESULTING RUNNABLESEQUENCE IS ITSELF A RUNNABLE, WHICH MEANS IT CAN BE INVOKED, STREAMED, OR FURTHER CHAINED JUST LIKE ANY OTHER RUNNABLE. ADVANTAGES OF CHAINING RUNNABLES IN THIS WAY ARE EFFICIENT STREAMING (THE SEQUENCE WILL STREAM OUTPUT AS SOON AS IT IS AVAILABLE), AND DEBUGGING AND TRACING WITH TOOLS LIKE LANGSMITH.\n",
      "THE PIPE OPERATOR: |​\n",
      "TO SHOW OFF HOW THIS WORKS, LET'S GO THROUGH AN EXAMPLE. WE'LL WALK THROUGH A COMMON PATTERN IN LANGCHAIN: USING A PROMPT TEMPLATE TO FORMAT INPUT INTO A CHAT MODEL, AND FINALLY CONVERTING THE CHAT MESSAGE OUTPUT INTO A STRING WITH AN OUTPUT PARSER.\n",
      "\n",
      "SELECT CHAT MODEL:GROQ▾GROQOPENAIANTHROPICAZUREGOOGLE VERTEXAWSCOHERENVIDIAFIREWORKS AIMISTRAL AITOGETHER AIIBM WATSONXDATABRICKSXAIPIP INSTALL -QU \"LANGCHAIN[GROQ]\"IMPORT GETPASSIMPORT OSIF NOT OS.ENVIRON.GET(\"GROQ_API_KEY\"):  OS.ENVIRON[\"GROQ_API_KEY\"] = GETPASS.GETPASS(\"ENTER API KEY FOR GROQ: \")FROM LANGCHAIN.CHAT_MODELS IMPORT INIT_CHAT_MODELMODEL = INIT_CHAT_MODEL(\"LLAMA3-8B-8192\", MODEL_PROVIDER=\"GROQ\")\n",
      "FROM LANGCHAIN_CORE.OUTPUT_PARSERS IMPORT STROUTPUTPARSERFROM LANGCHAIN_CORE.PROMPTS IMPORT CHATPROMPTTEMPLATEPROMPT = CHATPROMPTTEMPLATE.FROM_TEMPLATE(\"TELL ME A JOKE ABOUT {TOPIC}\")CHAIN = PROMPT | MODEL | STROUTPUTPARSER()API REFERENCE:STROUTPUTPARSER | CHATPROMPTTEMPLATE\n",
      "PROMPTS AND MODELS ARE BOTH RUNNABLE, AND THE OUTPUT TYPE FROM THE PROMPT CALL IS THE SAME AS THE INPUT TYPE OF THE CHAT MODEL, SO WE CAN CHAIN THEM TOGETHER. WE CAN THEN INVOKE THE RESULTING SEQUENCE LIKE ANY OTHER RUNNABLE:\n",
      "CHAIN.INVOKE({\"TOPIC\": \"BEARS\"})\n",
      "\"HERE'S A BEAR JOKE FOR YOU:\\N\\NWHY DID THE BEAR DISSOLVE IN WATER?\\NBECAUSE IT WAS A POLAR BEAR!\"\n",
      "COERCION​\n",
      "WE CAN EVEN COMBINE THIS CHAIN WITH MORE RUNNABLES TO CREATE ANOTHER CHAIN. THIS MAY INVOLVE SOME INPUT/OUTPUT FORMATTING USING OTHER TYPES OF RUNNABLES, DEPENDING ON THE REQUIRED INPUTS AND OUTPUTS OF THE CHAIN COMPONENTS.\n",
      "FOR EXAMPLE, LET'S SAY WE WANTED TO COMPOSE THE JOKE GENERATING CHAIN WITH ANOTHER CHAIN THAT EVALUATES WHETHER OR NOT THE GENERATED JOKE WAS FUNNY.\n",
      "WE WOULD NEED TO BE CAREFUL WITH HOW WE FORMAT THE INPUT INTO THE NEXT CHAIN. IN THE BELOW EXAMPLE, THE DICT IN THE CHAIN IS AUTOMATICALLY PARSED AND CONVERTED INTO A RUNNABLEPARALLEL, WHICH RUNS ALL OF ITS VALUES IN PARALLEL AND RETURNS A DICT WITH THE RESULTS.\n",
      "THIS HAPPENS TO BE THE SAME FORMAT THE NEXT PROMPT TEMPLATE EXPECTS. HERE IT IS IN ACTION:\n",
      "FROM LANGCHAIN_CORE.OUTPUT_PARSERS IMPORT STROUTPUTPARSERANALYSIS_PROMPT = CHATPROMPTTEMPLATE.FROM_TEMPLATE(\"IS THIS A FUNNY JOKE? {JOKE}\")COMPOSED_CHAIN = {\"JOKE\": CHAIN} | ANALYSIS_PROMPT | MODEL | STROUTPUTPARSER()COMPOSED_CHAIN.INVOKE({\"TOPIC\": \"BEARS\"})API REFERENCE:STROUTPUTPARSER\n",
      "'HAHA, THAT\\'S A CLEVER PLAY ON WORDS! USING \"POLAR\" TO IMPLY THE BEAR DISSOLVED OR BECAME POLAR/POLARIZED WHEN PUT IN WATER. NOT THE MOST HILARIOUS JOKE EVER, BUT IT HAS A CUTE, GROAN-WORTHY PUN THAT MAKES IT MILDLY AMUSING. I APPRECIATE A GOOD PUN OR WORDPLAY JOKE.'\n",
      "FUNCTIONS WILL ALSO BE COERCED INTO RUNNABLES, SO YOU CAN ADD CUSTOM LOGIC TO YOUR CHAINS TOO. THE BELOW CHAIN RESULTS IN THE SAME LOGICAL FLOW AS BEFORE:\n",
      "COMPOSED_CHAIN_WITH_LAMBDA = (    CHAIN    | (LAMBDA INPUT: {\"JOKE\": INPUT})    | ANALYSIS_PROMPT    | MODEL    | STROUTPUTPARSER())COMPOSED_CHAIN_WITH_LAMBDA.INVOKE({\"TOPIC\": \"BEETS\"})\n",
      "\"HAHA, THAT'S A CUTE AND PUNNY JOKE! I LIKE HOW IT PLAYS ON THE IDEA OF BEETS BLUSHING OR TURNING RED LIKE SOMEONE BLUSHING. FOOD PUNS CAN BE QUITE AMUSING. WHILE NOT A TOTAL KNEE-SLAPPER, IT'S A LIGHT-HEARTED, GROAN-WORTHY DAD JOKE THAT WOULD MAKE ME CHUCKLE AND SHAKE MY HEAD. SIMPLE VEGETABLE HUMOR!\"\n",
      "HOWEVER, KEEP IN MIND THAT USING FUNCTIONS LIKE THIS MAY INTERFERE WITH OPERATIONS LIKE STREAMING. SEE THIS SECTION FOR MORE INFORMATION.\n",
      "THE .PIPE() METHOD​\n",
      "WE COULD ALSO COMPOSE THE SAME SEQUENCE USING THE .PIPE() METHOD. HERE'S WHAT THAT LOOKS LIKE:\n",
      "FROM LANGCHAIN_CORE.RUNNABLES IMPORT RUNNABLEPARALLELCOMPOSED_CHAIN_WITH_PIPE = (    RUNNABLEPARALLEL({\"JOKE\": CHAIN})    .PIPE(ANALYSIS_PROMPT)    .PIPE(MODEL)    .PIPE(STROUTPUTPARSER()))COMPOSED_CHAIN_WITH_PIPE.INVOKE({\"TOPIC\": \"BATTLESTAR GALACTICA\"})API REFERENCE:RUNNABLEPARALLEL\n",
      "\"I CANNOT REPRODUCE ANY COPYRIGHTED MATERIAL VERBATIM, BUT I CAN TRY TO ANALYZE THE HUMOR IN THE JOKE YOU PROVIDED WITHOUT QUOTING IT DIRECTLY.\\N\\NTHE JOKE PLAYS ON THE IDEA THAT THE CYLON RAIDERS, WHO ARE THE ANTAGONISTS IN THE BATTLESTAR GALACTICA UNIVERSE, FAILED TO LOCATE THE HUMAN SURVIVORS AFTER ATTACKING THEIR HOME PLANETS (THE TWELVE COLONIES) DUE TO USING AN OUTDATED AND POORLY PERFORMING OPERATING SYSTEM (WINDOWS VISTA) FOR THEIR TARGETING SYSTEMS.\\N\\NTHE HUMOR STEMS FROM THE JUXTAPOSITION OF A FUTURISTIC SCIENCE FICTION SETTING WITH A RELATABLE REAL-WORLD FRUSTRATION – THE USE OF BUGGY, SLOW, OR UNRELIABLE SOFTWARE OR TECHNOLOGY. IT POKES FUN AT THE PERCEIVED INADEQUACIES OF WINDOWS VISTA, WHICH WAS WIDELY CRITICIZED FOR ITS PERFORMANCE ISSUES AND OTHER PROBLEMS WHEN IT WAS RELEASED.\\N\\NBY ATTRIBUTING THE CYLONS' FAILURE TO LOCATE THE HUMANS TO THEIR USE OF VISTA, THE JOKE CREATES AN AMUSING AND UNEXPECTED CONNECTION BETWEEN A FICTIONAL ADVANCED RACE OF ROBOTS AND A FAMILIAR TECHNOLOGICAL ANNOYANCE EXPERIENCED BY MANY PEOPLE IN THE REAL WORLD.\\N\\NOVERALL, THE JOKE RELIES ON INCONGRUITY AND RELATABILITY TO GENERATE HUMOR, BUT WITHOUT REPRODUCING ANY COPYRIGHTED MATERIAL DIRECTLY.\"\n",
      "OR THE ABBREVIATED:\n",
      "COMPOSED_CHAIN_WITH_PIPE = RUNNABLEPARALLEL({\"JOKE\": CHAIN}).PIPE(    ANALYSIS_PROMPT, MODEL, STROUTPUTPARSER())\n",
      "RELATED​\n",
      "\n",
      "STREAMING: CHECK OUT THE STREAMING GUIDE TO UNDERSTAND THE STREAMING BEHAVIOR OF A CHAIN\n",
      "EDIT THIS PAGEWAS THIS PAGE HELPFUL?PREVIOUSHOW TO SPLIT TEXT BASED ON SEMANTIC SIMILARITYNEXTHOW TO SAVE AND LOAD LANGCHAIN OBJECTSTHE PIPE OPERATOR: |COERCIONTHE .PIPE() METHODRELATEDCOMMUNITYTWITTERGITHUBORGANIZATIONPYTHONJS/TSMOREHOMEPAGEBLOGYOUTUBECOPYRIGHT © 2025 LANGCHAIN, INC.\n",
      "\n",
      "\n",
      "          -------\n",
      "\n",
      "          THE PREVIOUS CODE ATTEMPT FAILED WITH THE FOLLOWING ERROR:\n",
      "          NAME 'FETCH_DOCUMENTS' IS NOT DEFINED\n",
      "\n",
      "          YOUR CODING TASK:\n",
      "          HOW DO I SET UP A RETRIEVAL-AUGMENTED GENERATION AGENT?\n",
      "\n",
      "          PREVIOUS CODE ATTEMPT:\n",
      "          TO SET UP A RETRIEVAL-AUGMENTED GENERATION (RAG) AGENT USING LANGCHAIN, THE PROCESS INVOLVES COMBINING RETRIEVAL AND GENERATION STEPS IN A SINGLE CHAIN. THE RETRIEVAL MECHANISM FETCHES RELEVANT DOCUMENTS BASED ON A QUERY, AND THESE DOCUMENTS ARE THEN USED AS CONTEXT IN THE GENERATION PHASE TO PROVIDE A MORE INFORMED RESPONSE. SINCE THE `VECTORSTORERETRIEVER` IMPORT FAILED, I WILL PROVIDE A CORRECTED VERSION ASSUMING THAT A PLACEHOLDER FUNCTION SIMULATES DOCUMENT RETRIEVAL. TO ENSURE THAT THE CODE WORKS, YOU MIGHT NEED TO INTEGRATE IT WITH A REAL VECTOR STORE SYSTEM LIKE PINECONE OR WEAVIATE.\n",
      "          IMPORT GETPASS\n",
      "IMPORT OS\n",
      "FROM LANGCHAIN.CHAT_MODELS IMPORT INIT_CHAT_MODEL\n",
      "FROM LANGCHAIN_CORE.PROMPTS IMPORT CHATPROMPTTEMPLATE\n",
      "FROM LANGCHAIN_CORE.OUTPUT_PARSERS IMPORT STROUTPUTPARSER\n",
      "          IF NOT OS.ENVIRON.GET(\"GROQ_API_KEY\"):\n",
      "    OS.ENVIRON[\"GROQ_API_KEY\"] = GETPASS.GETPASS(\"ENTER API KEY FOR GROQ: \")\n",
      "\n",
      "MODEL = INIT_CHAT_MODEL(\"LLAMA3-8B-8192\", MODEL_PROVIDER=\"GROQ\")\n",
      "\n",
      "PROMPT = CHATPROMPTTEMPLATE.FROM_TEMPLATE(\"USING THE FOLLOWING CONTEXT, ANSWER THE QUESTION: {CONTEXT}\\N\\NQUESTION: {QUERY}\")\n",
      "\n",
      "DEF FETCH_DOCUMENTS(QUERY):\n",
      "    # PLACEHOLDER FUNCTION FOR FETCHING DOCUMENTS\n",
      "    RETURN \"RELEVANT CONTEXT FOR: \" + QUERY\n",
      "\n",
      "RAG_CHAIN = (LAMBDA INPUT: {\n",
      "    \"CONTEXT\": FETCH_DOCUMENTS(INPUT['QUERY']),\n",
      "    \"QUERY\": INPUT['QUERY']\n",
      "}) | PROMPT | MODEL | STROUTPUTPARSER()\n",
      "\n",
      "RESPONSE = RAG_CHAIN.INVOKE({\"QUERY\": \"EXPLAIN QUANTUM COMPUTING IN SIMPLE TERMS.\"})\n",
      "PRINT(RESPONSE)\n",
      "\n",
      "          ANSWER WITH A DESCRIPTION OF THE CODE SOLUTION, FOLLOWED BY THE IMPORTS, AND FINALLY THE FUNCTIONING CODE BLOCK.\n",
      "          ENSURE ALL IMPORTS ARE CORRECT AND THE CODE IS EXECUTABLE.]: 2025-03-13 15:39:01.900725\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:39:01][🤖 AGENT 'CODING ASSISTANT' STARTED TASK]: 2025-03-13 15:39:01.901258\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:39:01][🤖 LLM CALL STARTED]: 2025-03-13 15:39:01.901358\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:39:15][✅ LLM CALL COMPLETED]: 2025-03-13 15:39:15.679888\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:39:15][✅ AGENT 'CODING ASSISTANT' COMPLETED TASK]: 2025-03-13 15:39:15.680812\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:39:15][✅ TASK COMPLETED: YOU ARE A CODING ASSISTANT WITH EXPERTISE IN LCEL, LANGCHAIN EXPRESSION LANGUAGE.\n",
      "          HERE IS A FULL SET OF LCEL DOCUMENTATION:\n",
      "          -------\n",
      "          \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "HOW TO CHAIN RUNNABLES | 🦜️🔗 LANGCHAIN\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "SKIP TO MAIN CONTENTJOIN US AT  INTERRUPT: THE AGENT AI CONFERENCE BY LANGCHAIN ON MAY 13 & 14 IN SAN FRANCISCO!INTEGRATIONSAPI REFERENCEMORECONTRIBUTINGPEOPLEERROR REFERENCELANGSMITHLANGGRAPHLANGCHAIN HUBLANGCHAIN JS/TSV0.3V0.3V0.2V0.1💬SEARCHINTRODUCTIONTUTORIALSBUILD A QUESTION ANSWERING APPLICATION OVER A GRAPH DATABASETUTORIALSBUILD A SIMPLE LLM APPLICATION WITH CHAT MODELS AND PROMPT TEMPLATESBUILD A CHATBOTBUILD A RETRIEVAL AUGMENTED GENERATION (RAG) APP: PART 2BUILD AN EXTRACTION CHAINBUILD AN AGENTTAGGINGBUILD A RETRIEVAL AUGMENTED GENERATION (RAG) APP: PART 1BUILD A SEMANTIC SEARCH ENGINEBUILD A QUESTION/ANSWERING SYSTEM OVER SQL DATASUMMARIZE TEXTHOW-TO GUIDESHOW-TO GUIDESHOW TO USE TOOLS IN A CHAINHOW TO USE A VECTORSTORE AS A RETRIEVERHOW TO ADD MEMORY TO CHATBOTSHOW TO USE EXAMPLE SELECTORSHOW TO ADD A SEMANTIC LAYER OVER GRAPH DATABASEHOW TO INVOKE RUNNABLES IN PARALLELHOW TO STREAM CHAT MODEL RESPONSESHOW TO ADD DEFAULT INVOCATION ARGS TO A RUNNABLEHOW TO ADD RETRIEVAL TO CHATBOTSHOW TO USE FEW SHOT EXAMPLES IN CHAT MODELSHOW TO DO TOOL/FUNCTION CALLINGHOW TO INSTALL LANGCHAIN PACKAGESHOW TO ADD EXAMPLES TO THE PROMPT FOR QUERY ANALYSISHOW TO USE FEW SHOT EXAMPLESHOW TO RUN CUSTOM FUNCTIONSHOW TO USE OUTPUT PARSERS TO PARSE AN LLM RESPONSE INTO STRUCTURED FORMATHOW TO HANDLE CASES WHERE NO QUERIES ARE GENERATEDHOW TO ROUTE BETWEEN SUB-CHAINSHOW TO RETURN STRUCTURED DATA FROM A MODELHOW TO SUMMARIZE TEXT THROUGH PARALLELIZATIONHOW TO SUMMARIZE TEXT THROUGH ITERATIVE REFINEMENTHOW TO SUMMARIZE TEXT IN A SINGLE LLM CALLHOW TO USE TOOLKITSHOW TO ADD AD-HOC TOOL CALLING CAPABILITY TO LLMS AND CHAT MODELSBUILD AN AGENT WITH AGENTEXECUTOR (LEGACY)HOW TO CONSTRUCT KNOWLEDGE GRAPHSHOW TO PARTIALLY FORMAT PROMPT TEMPLATESHOW TO HANDLE MULTIPLE QUERIES WHEN DOING QUERY ANALYSISHOW TO USE BUILT-IN TOOLS AND TOOLKITSHOW TO PASS THROUGH ARGUMENTS FROM ONE STEP TO THE NEXTHOW TO COMPOSE PROMPTS TOGETHERHOW TO HANDLE MULTIPLE RETRIEVERS WHEN DOING QUERY ANALYSISHOW TO ADD VALUES TO A CHAIN'S STATEHOW TO CONSTRUCT FILTERS FOR QUERY ANALYSISHOW TO CONFIGURE RUNTIME CHAIN INTERNALSHOW DEAL WITH HIGH CARDINALITY CATEGORICALS WHEN DOING QUERY ANALYSISCUSTOM DOCUMENT LOADERHOW TO USE THE MULTIQUERYRETRIEVERHOW TO ADD SCORES TO RETRIEVER RESULTSCACHINGHOW TO USE CALLBACKS IN ASYNC ENVIRONMENTSHOW TO ATTACH CALLBACKS TO A RUNNABLEHOW TO PROPAGATE CALLBACKS  CONSTRUCTORHOW TO DISPATCH CUSTOM CALLBACK EVENTSHOW TO PASS CALLBACKS IN AT RUNTIMEHOW TO SPLIT BY CHARACTERHOW TO CACHE CHAT MODEL RESPONSESHOW TO HANDLE RATE LIMITSHOW TO INIT ANY MODEL IN ONE LINEHOW TO TRACK TOKEN USAGE IN CHATMODELSHOW TO ADD TOOLS TO CHATBOTSHOW TO SPLIT CODEHOW TO DO RETRIEVAL WITH CONTEXTUAL COMPRESSIONHOW TO CONVERT RUNNABLES TO TOOLSHOW TO CREATE CUSTOM CALLBACK HANDLERSHOW TO CREATE A CUSTOM CHAT MODEL CLASSCUSTOM EMBEDDINGSHOW TO CREATE A CUSTOM LLM CLASSCUSTOM RETRIEVERHOW TO CREATE TOOLSHOW TO DEBUG YOUR LLM APPSHOW TO LOAD CSVSHOW TO LOAD DOCUMENTS FROM A DIRECTORYHOW TO LOAD HTMLHOW TO LOAD JSONHOW TO LOAD MARKDOWNHOW TO LOAD MICROSOFT OFFICE FILESHOW TO LOAD PDFSHOW TO LOAD WEB PAGESHOW TO CREATE A DYNAMIC (SELF-CONSTRUCTING) CHAINTEXT EMBEDDING MODELSHOW TO COMBINE RESULTS FROM MULTIPLE RETRIEVERSHOW TO SELECT EXAMPLES FROM A LANGSMITH DATASETHOW TO SELECT EXAMPLES BY LENGTHHOW TO SELECT EXAMPLES BY MAXIMAL MARGINAL RELEVANCE (MMR)HOW TO SELECT EXAMPLES BY N-GRAM OVERLAPHOW TO SELECT EXAMPLES BY SIMILARITYHOW TO USE REFERENCE EXAMPLES WHEN DOING EXTRACTIONHOW TO HANDLE LONG TEXT WHEN DOING EXTRACTIONHOW TO USE PROMPTING ALONE (NO TOOL CALLING) TO DO EXTRACTIONHOW TO ADD FALLBACKS TO A RUNNABLEHOW TO FILTER MESSAGESHYBRID SEARCHHOW TO USE THE LANGCHAIN INDEXING APIHOW TO INSPECT RUNNABLESLANGCHAIN EXPRESSION LANGUAGE CHEATSHEETHOW TO CACHE LLM RESPONSESHOW TO TRACK TOKEN USAGE FOR LLMSRUN MODELS LOCALLYHOW TO GET LOG PROBABILITIESHOW TO REORDER RETRIEVED RESULTS TO MITIGATE THE \"LOST IN THE MIDDLE\" EFFECTHOW TO SPLIT MARKDOWN BY HEADERSHOW TO MERGE CONSECUTIVE MESSAGES OF THE SAME TYPEHOW TO ADD MESSAGE HISTORYHOW TO MIGRATE FROM LEGACY LANGCHAIN AGENTS TO LANGGRAPHHOW TO RETRIEVE USING MULTIPLE VECTORS PER DOCUMENTHOW TO PASS MULTIMODAL DATA DIRECTLY TO MODELSHOW TO USE MULTIMODAL PROMPTSHOW TO CREATE A CUSTOM OUTPUT PARSERHOW TO USE THE OUTPUT-FIXING PARSERHOW TO PARSE JSON OUTPUTHOW TO RETRY WHEN A PARSING ERROR OCCURSHOW TO PARSE TEXT FROM MESSAGE OBJECTSHOW TO PARSE XML OUTPUTHOW TO PARSE YAML OUTPUTHOW TO USE THE PARENT DOCUMENT RETRIEVERHOW TO USE LANGCHAIN WITH DIFFERENT PYDANTIC VERSIONSHOW TO ADD CHAT HISTORYHOW TO GET A RAG APPLICATION TO ADD CITATIONSHOW TO DO PER-USER RETRIEVALHOW TO GET YOUR RAG APPLICATION TO RETURN SOURCESHOW TO STREAM RESULTS FROM YOUR RAG APPLICATIONHOW TO SPLIT JSON DATAHOW TO RECURSIVELY SPLIT TEXT BY CHARACTERSRESPONSE METADATAHOW TO PASS RUNTIME SECRETS TO RUNNABLESHOW TO DO \"SELF-QUERYING\" RETRIEVALHOW TO SPLIT TEXT BASED ON SEMANTIC SIMILARITYHOW TO CHAIN RUNNABLESHOW TO SAVE AND LOAD LANGCHAIN OBJECTSHOW TO SPLIT TEXT BY TOKENSHOW TO SPLIT HTMLHOW TO DO QUESTION ANSWERING OVER CSVSHOW TO DEAL WITH LARGE DATABASES WHEN DOING SQL QUESTION-ANSWERINGHOW TO BETTER PROMPT WHEN DOING SQL QUESTION-ANSWERINGHOW TO DO QUERY VALIDATION AS PART OF SQL QUESTION-ANSWERINGHOW TO STREAM RUNNABLESHOW TO STREAM RESPONSES FROM AN LLMHOW TO USE A TIME-WEIGHTED VECTOR STORE RETRIEVERHOW TO RETURN ARTIFACTS FROM A TOOLHOW TO USE CHAT MODELS TO CALL TOOLSHOW TO DISABLE PARALLEL TOOL CALLINGHOW TO FORCE MODELS TO CALL A TOOLHOW TO ACCESS THE RUNNABLECONFIG FROM A TOOLHOW TO PASS TOOL OUTPUTS TO CHAT MODELSHOW TO PASS RUN TIME VALUES TO TOOLSHOW TO STREAM EVENTS FROM A TOOLHOW TO STREAM TOOL CALLSHOW TO CONVERT TOOLS TO OPENAI FUNCTIONSHOW TO HANDLE TOOL ERRORSHOW TO USE FEW-SHOT PROMPTING WITH TOOL CALLINGHOW TO ADD A HUMAN-IN-THE-LOOP FOR TOOLSHOW TO BIND MODEL-SPECIFIC TOOLSHOW TO TRIM MESSAGESHOW TO CREATE AND QUERY VECTOR STORESCONCEPTUAL GUIDEAGENTSARCHITECTUREASYNC PROGRAMMING WITH LANGCHAINCALLBACKSCHAT HISTORYCHAT MODELSDOCUMENT LOADERSEMBEDDING MODELSEVALUATIONEXAMPLE SELECTORSFEW-SHOT PROMPTINGCONCEPTUAL GUIDEKEY-VALUE STORESLANGCHAIN EXPRESSION LANGUAGE (LCEL)MESSAGESMULTIMODALITYOUTPUT PARSERSPROMPT TEMPLATESRETRIEVAL AUGMENTED GENERATION (RAG)RETRIEVALRETRIEVERSRUNNABLE INTERFACESTREAMINGSTRUCTURED OUTPUTSTESTINGSTRING-IN, STRING-OUT LLMSTEXT SPLITTERSTOKENSTOOL CALLINGTOOLSTRACINGVECTOR STORESWHY LANGCHAIN?ECOSYSTEM🦜🛠️ LANGSMITH🦜🕸️ LANGGRAPHVERSIONSV0.3V0.2PYDANTIC COMPATIBILITYMIGRATING FROM V0.0 CHAINSHOW TO MIGRATE FROM V0.0 CHAINSMIGRATING FROM CONSTITUTIONALCHAINMIGRATING FROM CONVERSATIONALCHAINMIGRATING FROM CONVERSATIONALRETRIEVALCHAINMIGRATING FROM LLMCHAINMIGRATING FROM LLMMATHCHAINMIGRATING FROM LLMROUTERCHAINMIGRATING FROM MAPREDUCEDOCUMENTSCHAINMIGRATING FROM MAPRERANKDOCUMENTSCHAINMIGRATING FROM MULTIPROMPTCHAINMIGRATING FROM REFINEDOCUMENTSCHAINMIGRATING FROM RETRIEVALQAMIGRATING FROM STUFFDOCUMENTSCHAINUPGRADING TO LANGGRAPH MEMORYHOW TO MIGRATE TO LANGGRAPH MEMORYHOW TO USE BASECHATMESSAGEHISTORY WITH LANGGRAPHMIGRATING OFF CONVERSATIONBUFFERMEMORY OR CONVERSATIONSTRINGBUFFERMEMORYMIGRATING OFF CONVERSATIONBUFFERWINDOWMEMORY OR CONVERSATIONTOKENBUFFERMEMORYMIGRATING OFF CONVERSATIONSUMMARYMEMORY OR CONVERSATIONSUMMARYBUFFERMEMORYA LONG-TERM MEMORY AGENTRELEASE POLICYSECURITY POLICYHOW-TO GUIDESHOW TO CHAIN RUNNABLESON THIS PAGEHOW TO CHAIN RUNNABLES\n",
      "PREREQUISITESTHIS GUIDE ASSUMES FAMILIARITY WITH THE FOLLOWING CONCEPTS:\n",
      "LANGCHAIN EXPRESSION LANGUAGE (LCEL)\n",
      "PROMPT TEMPLATES\n",
      "CHAT MODELS\n",
      "OUTPUT PARSER\n",
      "\n",
      "ONE POINT ABOUT LANGCHAIN EXPRESSION LANGUAGE IS THAT ANY TWO RUNNABLES CAN BE \"CHAINED\" TOGETHER INTO SEQUENCES. THE OUTPUT OF THE PREVIOUS RUNNABLE'S .INVOKE() CALL IS PASSED AS INPUT TO THE NEXT RUNNABLE. THIS CAN BE DONE USING THE PIPE OPERATOR (|), OR THE MORE EXPLICIT .PIPE() METHOD, WHICH DOES THE SAME THING.\n",
      "THE RESULTING RUNNABLESEQUENCE IS ITSELF A RUNNABLE, WHICH MEANS IT CAN BE INVOKED, STREAMED, OR FURTHER CHAINED JUST LIKE ANY OTHER RUNNABLE. ADVANTAGES OF CHAINING RUNNABLES IN THIS WAY ARE EFFICIENT STREAMING (THE SEQUENCE WILL STREAM OUTPUT AS SOON AS IT IS AVAILABLE), AND DEBUGGING AND TRACING WITH TOOLS LIKE LANGSMITH.\n",
      "THE PIPE OPERATOR: |​\n",
      "TO SHOW OFF HOW THIS WORKS, LET'S GO THROUGH AN EXAMPLE. WE'LL WALK THROUGH A COMMON PATTERN IN LANGCHAIN: USING A PROMPT TEMPLATE TO FORMAT INPUT INTO A CHAT MODEL, AND FINALLY CONVERTING THE CHAT MESSAGE OUTPUT INTO A STRING WITH AN OUTPUT PARSER.\n",
      "\n",
      "SELECT CHAT MODEL:GROQ▾GROQOPENAIANTHROPICAZUREGOOGLE VERTEXAWSCOHERENVIDIAFIREWORKS AIMISTRAL AITOGETHER AIIBM WATSONXDATABRICKSXAIPIP INSTALL -QU \"LANGCHAIN[GROQ]\"IMPORT GETPASSIMPORT OSIF NOT OS.ENVIRON.GET(\"GROQ_API_KEY\"):  OS.ENVIRON[\"GROQ_API_KEY\"] = GETPASS.GETPASS(\"ENTER API KEY FOR GROQ: \")FROM LANGCHAIN.CHAT_MODELS IMPORT INIT_CHAT_MODELMODEL = INIT_CHAT_MODEL(\"LLAMA3-8B-8192\", MODEL_PROVIDER=\"GROQ\")\n",
      "FROM LANGCHAIN_CORE.OUTPUT_PARSERS IMPORT STROUTPUTPARSERFROM LANGCHAIN_CORE.PROMPTS IMPORT CHATPROMPTTEMPLATEPROMPT = CHATPROMPTTEMPLATE.FROM_TEMPLATE(\"TELL ME A JOKE ABOUT {TOPIC}\")CHAIN = PROMPT | MODEL | STROUTPUTPARSER()API REFERENCE:STROUTPUTPARSER | CHATPROMPTTEMPLATE\n",
      "PROMPTS AND MODELS ARE BOTH RUNNABLE, AND THE OUTPUT TYPE FROM THE PROMPT CALL IS THE SAME AS THE INPUT TYPE OF THE CHAT MODEL, SO WE CAN CHAIN THEM TOGETHER. WE CAN THEN INVOKE THE RESULTING SEQUENCE LIKE ANY OTHER RUNNABLE:\n",
      "CHAIN.INVOKE({\"TOPIC\": \"BEARS\"})\n",
      "\"HERE'S A BEAR JOKE FOR YOU:\\N\\NWHY DID THE BEAR DISSOLVE IN WATER?\\NBECAUSE IT WAS A POLAR BEAR!\"\n",
      "COERCION​\n",
      "WE CAN EVEN COMBINE THIS CHAIN WITH MORE RUNNABLES TO CREATE ANOTHER CHAIN. THIS MAY INVOLVE SOME INPUT/OUTPUT FORMATTING USING OTHER TYPES OF RUNNABLES, DEPENDING ON THE REQUIRED INPUTS AND OUTPUTS OF THE CHAIN COMPONENTS.\n",
      "FOR EXAMPLE, LET'S SAY WE WANTED TO COMPOSE THE JOKE GENERATING CHAIN WITH ANOTHER CHAIN THAT EVALUATES WHETHER OR NOT THE GENERATED JOKE WAS FUNNY.\n",
      "WE WOULD NEED TO BE CAREFUL WITH HOW WE FORMAT THE INPUT INTO THE NEXT CHAIN. IN THE BELOW EXAMPLE, THE DICT IN THE CHAIN IS AUTOMATICALLY PARSED AND CONVERTED INTO A RUNNABLEPARALLEL, WHICH RUNS ALL OF ITS VALUES IN PARALLEL AND RETURNS A DICT WITH THE RESULTS.\n",
      "THIS HAPPENS TO BE THE SAME FORMAT THE NEXT PROMPT TEMPLATE EXPECTS. HERE IT IS IN ACTION:\n",
      "FROM LANGCHAIN_CORE.OUTPUT_PARSERS IMPORT STROUTPUTPARSERANALYSIS_PROMPT = CHATPROMPTTEMPLATE.FROM_TEMPLATE(\"IS THIS A FUNNY JOKE? {JOKE}\")COMPOSED_CHAIN = {\"JOKE\": CHAIN} | ANALYSIS_PROMPT | MODEL | STROUTPUTPARSER()COMPOSED_CHAIN.INVOKE({\"TOPIC\": \"BEARS\"})API REFERENCE:STROUTPUTPARSER\n",
      "'HAHA, THAT\\'S A CLEVER PLAY ON WORDS! USING \"POLAR\" TO IMPLY THE BEAR DISSOLVED OR BECAME POLAR/POLARIZED WHEN PUT IN WATER. NOT THE MOST HILARIOUS JOKE EVER, BUT IT HAS A CUTE, GROAN-WORTHY PUN THAT MAKES IT MILDLY AMUSING. I APPRECIATE A GOOD PUN OR WORDPLAY JOKE.'\n",
      "FUNCTIONS WILL ALSO BE COERCED INTO RUNNABLES, SO YOU CAN ADD CUSTOM LOGIC TO YOUR CHAINS TOO. THE BELOW CHAIN RESULTS IN THE SAME LOGICAL FLOW AS BEFORE:\n",
      "COMPOSED_CHAIN_WITH_LAMBDA = (    CHAIN    | (LAMBDA INPUT: {\"JOKE\": INPUT})    | ANALYSIS_PROMPT    | MODEL    | STROUTPUTPARSER())COMPOSED_CHAIN_WITH_LAMBDA.INVOKE({\"TOPIC\": \"BEETS\"})\n",
      "\"HAHA, THAT'S A CUTE AND PUNNY JOKE! I LIKE HOW IT PLAYS ON THE IDEA OF BEETS BLUSHING OR TURNING RED LIKE SOMEONE BLUSHING. FOOD PUNS CAN BE QUITE AMUSING. WHILE NOT A TOTAL KNEE-SLAPPER, IT'S A LIGHT-HEARTED, GROAN-WORTHY DAD JOKE THAT WOULD MAKE ME CHUCKLE AND SHAKE MY HEAD. SIMPLE VEGETABLE HUMOR!\"\n",
      "HOWEVER, KEEP IN MIND THAT USING FUNCTIONS LIKE THIS MAY INTERFERE WITH OPERATIONS LIKE STREAMING. SEE THIS SECTION FOR MORE INFORMATION.\n",
      "THE .PIPE() METHOD​\n",
      "WE COULD ALSO COMPOSE THE SAME SEQUENCE USING THE .PIPE() METHOD. HERE'S WHAT THAT LOOKS LIKE:\n",
      "FROM LANGCHAIN_CORE.RUNNABLES IMPORT RUNNABLEPARALLELCOMPOSED_CHAIN_WITH_PIPE = (    RUNNABLEPARALLEL({\"JOKE\": CHAIN})    .PIPE(ANALYSIS_PROMPT)    .PIPE(MODEL)    .PIPE(STROUTPUTPARSER()))COMPOSED_CHAIN_WITH_PIPE.INVOKE({\"TOPIC\": \"BATTLESTAR GALACTICA\"})API REFERENCE:RUNNABLEPARALLEL\n",
      "\"I CANNOT REPRODUCE ANY COPYRIGHTED MATERIAL VERBATIM, BUT I CAN TRY TO ANALYZE THE HUMOR IN THE JOKE YOU PROVIDED WITHOUT QUOTING IT DIRECTLY.\\N\\NTHE JOKE PLAYS ON THE IDEA THAT THE CYLON RAIDERS, WHO ARE THE ANTAGONISTS IN THE BATTLESTAR GALACTICA UNIVERSE, FAILED TO LOCATE THE HUMAN SURVIVORS AFTER ATTACKING THEIR HOME PLANETS (THE TWELVE COLONIES) DUE TO USING AN OUTDATED AND POORLY PERFORMING OPERATING SYSTEM (WINDOWS VISTA) FOR THEIR TARGETING SYSTEMS.\\N\\NTHE HUMOR STEMS FROM THE JUXTAPOSITION OF A FUTURISTIC SCIENCE FICTION SETTING WITH A RELATABLE REAL-WORLD FRUSTRATION – THE USE OF BUGGY, SLOW, OR UNRELIABLE SOFTWARE OR TECHNOLOGY. IT POKES FUN AT THE PERCEIVED INADEQUACIES OF WINDOWS VISTA, WHICH WAS WIDELY CRITICIZED FOR ITS PERFORMANCE ISSUES AND OTHER PROBLEMS WHEN IT WAS RELEASED.\\N\\NBY ATTRIBUTING THE CYLONS' FAILURE TO LOCATE THE HUMANS TO THEIR USE OF VISTA, THE JOKE CREATES AN AMUSING AND UNEXPECTED CONNECTION BETWEEN A FICTIONAL ADVANCED RACE OF ROBOTS AND A FAMILIAR TECHNOLOGICAL ANNOYANCE EXPERIENCED BY MANY PEOPLE IN THE REAL WORLD.\\N\\NOVERALL, THE JOKE RELIES ON INCONGRUITY AND RELATABILITY TO GENERATE HUMOR, BUT WITHOUT REPRODUCING ANY COPYRIGHTED MATERIAL DIRECTLY.\"\n",
      "OR THE ABBREVIATED:\n",
      "COMPOSED_CHAIN_WITH_PIPE = RUNNABLEPARALLEL({\"JOKE\": CHAIN}).PIPE(    ANALYSIS_PROMPT, MODEL, STROUTPUTPARSER())\n",
      "RELATED​\n",
      "\n",
      "STREAMING: CHECK OUT THE STREAMING GUIDE TO UNDERSTAND THE STREAMING BEHAVIOR OF A CHAIN\n",
      "EDIT THIS PAGEWAS THIS PAGE HELPFUL?PREVIOUSHOW TO SPLIT TEXT BASED ON SEMANTIC SIMILARITYNEXTHOW TO SAVE AND LOAD LANGCHAIN OBJECTSTHE PIPE OPERATOR: |COERCIONTHE .PIPE() METHODRELATEDCOMMUNITYTWITTERGITHUBORGANIZATIONPYTHONJS/TSMOREHOMEPAGEBLOGYOUTUBECOPYRIGHT © 2025 LANGCHAIN, INC.\n",
      "\n",
      "\n",
      "          -------\n",
      "\n",
      "          THE PREVIOUS CODE ATTEMPT FAILED WITH THE FOLLOWING ERROR:\n",
      "          NAME 'FETCH_DOCUMENTS' IS NOT DEFINED\n",
      "\n",
      "          YOUR CODING TASK:\n",
      "          HOW DO I SET UP A RETRIEVAL-AUGMENTED GENERATION AGENT?\n",
      "\n",
      "          PREVIOUS CODE ATTEMPT:\n",
      "          TO SET UP A RETRIEVAL-AUGMENTED GENERATION (RAG) AGENT USING LANGCHAIN, THE PROCESS INVOLVES COMBINING RETRIEVAL AND GENERATION STEPS IN A SINGLE CHAIN. THE RETRIEVAL MECHANISM FETCHES RELEVANT DOCUMENTS BASED ON A QUERY, AND THESE DOCUMENTS ARE THEN USED AS CONTEXT IN THE GENERATION PHASE TO PROVIDE A MORE INFORMED RESPONSE. SINCE THE `VECTORSTORERETRIEVER` IMPORT FAILED, I WILL PROVIDE A CORRECTED VERSION ASSUMING THAT A PLACEHOLDER FUNCTION SIMULATES DOCUMENT RETRIEVAL. TO ENSURE THAT THE CODE WORKS, YOU MIGHT NEED TO INTEGRATE IT WITH A REAL VECTOR STORE SYSTEM LIKE PINECONE OR WEAVIATE.\n",
      "          IMPORT GETPASS\n",
      "IMPORT OS\n",
      "FROM LANGCHAIN.CHAT_MODELS IMPORT INIT_CHAT_MODEL\n",
      "FROM LANGCHAIN_CORE.PROMPTS IMPORT CHATPROMPTTEMPLATE\n",
      "FROM LANGCHAIN_CORE.OUTPUT_PARSERS IMPORT STROUTPUTPARSER\n",
      "          IF NOT OS.ENVIRON.GET(\"GROQ_API_KEY\"):\n",
      "    OS.ENVIRON[\"GROQ_API_KEY\"] = GETPASS.GETPASS(\"ENTER API KEY FOR GROQ: \")\n",
      "\n",
      "MODEL = INIT_CHAT_MODEL(\"LLAMA3-8B-8192\", MODEL_PROVIDER=\"GROQ\")\n",
      "\n",
      "PROMPT = CHATPROMPTTEMPLATE.FROM_TEMPLATE(\"USING THE FOLLOWING CONTEXT, ANSWER THE QUESTION: {CONTEXT}\\N\\NQUESTION: {QUERY}\")\n",
      "\n",
      "DEF FETCH_DOCUMENTS(QUERY):\n",
      "    # PLACEHOLDER FUNCTION FOR FETCHING DOCUMENTS\n",
      "    RETURN \"RELEVANT CONTEXT FOR: \" + QUERY\n",
      "\n",
      "RAG_CHAIN = (LAMBDA INPUT: {\n",
      "    \"CONTEXT\": FETCH_DOCUMENTS(INPUT['QUERY']),\n",
      "    \"QUERY\": INPUT['QUERY']\n",
      "}) | PROMPT | MODEL | STROUTPUTPARSER()\n",
      "\n",
      "RESPONSE = RAG_CHAIN.INVOKE({\"QUERY\": \"EXPLAIN QUANTUM COMPUTING IN SIMPLE TERMS.\"})\n",
      "PRINT(RESPONSE)\n",
      "\n",
      "          ANSWER WITH A DESCRIPTION OF THE CODE SOLUTION, FOLLOWED BY THE IMPORTS, AND FINALLY THE FUNCTIONING CODE BLOCK.\n",
      "          ENSURE ALL IMPORTS ARE CORRECT AND THE CODE IS EXECUTABLE.]: 2025-03-13 15:39:15.681290\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:39:15][✅ CREW 'CREW' COMPLETED, B6046CE6-092A-40BD-9AB3-75F71FA381A8]: 2025-03-13 15:39:15.684107\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:39:15][👍 FLOW METHOD FINISHED: 'RE_RUN_FIX']: 2025-03-13 15:39:15.684418\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:39:15][🤖 FLOW METHOD STARTED: 'RE_RE_RUN_CHECK']: 2025-03-13 15:39:15.686231\u001b[00m\n",
      "---CHECKING CODE---\n",
      "---CODE BLOCK CHECK: FAILED---\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:39:15][👍 FLOW METHOD FINISHED: 'RE_RE_RUN_CHECK']: 2025-03-13 15:39:15.705983\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:39:15][👍 FLOW FINISHED: 'CODEGENFLOW', F18112C0-4EB3-4279-85B4-6EE1A49E8BC3]: 2025-03-13 15:39:15.706214\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:39:15][🌊 FLOW CREATED: 'CODEGENFLOW']: 2025-03-13 15:39:15.723881\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:39:15][🤖 FLOW STARTED: 'CODEGENFLOW', 7179E483-D6ED-4FA5-B747-E1979B2D008B]: 2025-03-13 15:39:15.725170\u001b[00m\n",
      "\u001b[1m\u001b[35m Flow started with ID: 7179e483-d6ed-4fa5-b747-e1979b2d008b\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:39:15][🤖 FLOW METHOD STARTED: 'GENERATE_CODE']: 2025-03-13 15:39:15.725457\u001b[00m\n",
      "---GENERATING CODE SOLUTION---\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:39:15][🚀 CREW 'CREW' STARTED, 368F5772-413F-4BF5-BD01-847C2CD6098D]: 2025-03-13 15:39:15.725750\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:39:15][📋 TASK STARTED: ANSWER THE USER QUESTION BASED ON THE ABOVE PROVIDED DOCUMENTATION. ENSURE ANY CODE YOU PROVIDE CAN BE EXECUTED\n",
      "    WITH ALL REQUIRED IMPORTS AND VARIABLES DEFINED. STRUCTURE YOUR ANSWER:\n",
      "    1) A PREFIX DESCRIBING THE CODE SOLUTION\n",
      "    2) THE IMPORTS\n",
      "    3) THE FUNCTIONING CODE BLOCK\n",
      "\n",
      "    YOUR CODING TASK:\n",
      "    HOW CAN I CREATE A LCEL CHAIN THAT QUERIES A SQL DATABASE?\n",
      "    ]: 2025-03-13 15:39:15.728172\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:39:15][🤖 AGENT 'CODING ASSISTANT' STARTED TASK]: 2025-03-13 15:39:15.728590\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:39:15][🤖 LLM CALL STARTED]: 2025-03-13 15:39:15.728673\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:39:20][✅ LLM CALL COMPLETED]: 2025-03-13 15:39:20.315133\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:39:20][✅ AGENT 'CODING ASSISTANT' COMPLETED TASK]: 2025-03-13 15:39:20.315863\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:39:20][✅ TASK COMPLETED: ANSWER THE USER QUESTION BASED ON THE ABOVE PROVIDED DOCUMENTATION. ENSURE ANY CODE YOU PROVIDE CAN BE EXECUTED\n",
      "    WITH ALL REQUIRED IMPORTS AND VARIABLES DEFINED. STRUCTURE YOUR ANSWER:\n",
      "    1) A PREFIX DESCRIBING THE CODE SOLUTION\n",
      "    2) THE IMPORTS\n",
      "    3) THE FUNCTIONING CODE BLOCK\n",
      "\n",
      "    YOUR CODING TASK:\n",
      "    HOW CAN I CREATE A LCEL CHAIN THAT QUERIES A SQL DATABASE?\n",
      "    ]: 2025-03-13 15:39:20.316084\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:39:20][✅ CREW 'CREW' COMPLETED, 368F5772-413F-4BF5-BD01-847C2CD6098D]: 2025-03-13 15:39:20.318777\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:39:20][👍 FLOW METHOD FINISHED: 'GENERATE_CODE']: 2025-03-13 15:39:20.318945\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:39:20][🤖 FLOW METHOD STARTED: 'RUN_CHECK']: 2025-03-13 15:39:20.319052\u001b[00m\n",
      "---CHECKING CODE---\n",
      "---CODE IMPORT CHECK: FAILED---\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:39:20][👍 FLOW METHOD FINISHED: 'RUN_CHECK']: 2025-03-13 15:39:20.319348\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:39:20][🤖 FLOW METHOD STARTED: 'RUN_FIX']: 2025-03-13 15:39:20.319503\u001b[00m\n",
      "---FIXING CODE---\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:39:20][🚀 CREW 'CREW' STARTED, 2612229F-71F2-4D41-B162-D29FA5C8825C]: 2025-03-13 15:39:20.320988\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:39:20][📋 TASK STARTED: YOU ARE A CODING ASSISTANT WITH EXPERTISE IN LCEL, LANGCHAIN EXPRESSION LANGUAGE.\n",
      "          HERE IS A FULL SET OF LCEL DOCUMENTATION:\n",
      "          -------\n",
      "          \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "HOW TO CHAIN RUNNABLES | 🦜️🔗 LANGCHAIN\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "SKIP TO MAIN CONTENTJOIN US AT  INTERRUPT: THE AGENT AI CONFERENCE BY LANGCHAIN ON MAY 13 & 14 IN SAN FRANCISCO!INTEGRATIONSAPI REFERENCEMORECONTRIBUTINGPEOPLEERROR REFERENCELANGSMITHLANGGRAPHLANGCHAIN HUBLANGCHAIN JS/TSV0.3V0.3V0.2V0.1💬SEARCHINTRODUCTIONTUTORIALSBUILD A QUESTION ANSWERING APPLICATION OVER A GRAPH DATABASETUTORIALSBUILD A SIMPLE LLM APPLICATION WITH CHAT MODELS AND PROMPT TEMPLATESBUILD A CHATBOTBUILD A RETRIEVAL AUGMENTED GENERATION (RAG) APP: PART 2BUILD AN EXTRACTION CHAINBUILD AN AGENTTAGGINGBUILD A RETRIEVAL AUGMENTED GENERATION (RAG) APP: PART 1BUILD A SEMANTIC SEARCH ENGINEBUILD A QUESTION/ANSWERING SYSTEM OVER SQL DATASUMMARIZE TEXTHOW-TO GUIDESHOW-TO GUIDESHOW TO USE TOOLS IN A CHAINHOW TO USE A VECTORSTORE AS A RETRIEVERHOW TO ADD MEMORY TO CHATBOTSHOW TO USE EXAMPLE SELECTORSHOW TO ADD A SEMANTIC LAYER OVER GRAPH DATABASEHOW TO INVOKE RUNNABLES IN PARALLELHOW TO STREAM CHAT MODEL RESPONSESHOW TO ADD DEFAULT INVOCATION ARGS TO A RUNNABLEHOW TO ADD RETRIEVAL TO CHATBOTSHOW TO USE FEW SHOT EXAMPLES IN CHAT MODELSHOW TO DO TOOL/FUNCTION CALLINGHOW TO INSTALL LANGCHAIN PACKAGESHOW TO ADD EXAMPLES TO THE PROMPT FOR QUERY ANALYSISHOW TO USE FEW SHOT EXAMPLESHOW TO RUN CUSTOM FUNCTIONSHOW TO USE OUTPUT PARSERS TO PARSE AN LLM RESPONSE INTO STRUCTURED FORMATHOW TO HANDLE CASES WHERE NO QUERIES ARE GENERATEDHOW TO ROUTE BETWEEN SUB-CHAINSHOW TO RETURN STRUCTURED DATA FROM A MODELHOW TO SUMMARIZE TEXT THROUGH PARALLELIZATIONHOW TO SUMMARIZE TEXT THROUGH ITERATIVE REFINEMENTHOW TO SUMMARIZE TEXT IN A SINGLE LLM CALLHOW TO USE TOOLKITSHOW TO ADD AD-HOC TOOL CALLING CAPABILITY TO LLMS AND CHAT MODELSBUILD AN AGENT WITH AGENTEXECUTOR (LEGACY)HOW TO CONSTRUCT KNOWLEDGE GRAPHSHOW TO PARTIALLY FORMAT PROMPT TEMPLATESHOW TO HANDLE MULTIPLE QUERIES WHEN DOING QUERY ANALYSISHOW TO USE BUILT-IN TOOLS AND TOOLKITSHOW TO PASS THROUGH ARGUMENTS FROM ONE STEP TO THE NEXTHOW TO COMPOSE PROMPTS TOGETHERHOW TO HANDLE MULTIPLE RETRIEVERS WHEN DOING QUERY ANALYSISHOW TO ADD VALUES TO A CHAIN'S STATEHOW TO CONSTRUCT FILTERS FOR QUERY ANALYSISHOW TO CONFIGURE RUNTIME CHAIN INTERNALSHOW DEAL WITH HIGH CARDINALITY CATEGORICALS WHEN DOING QUERY ANALYSISCUSTOM DOCUMENT LOADERHOW TO USE THE MULTIQUERYRETRIEVERHOW TO ADD SCORES TO RETRIEVER RESULTSCACHINGHOW TO USE CALLBACKS IN ASYNC ENVIRONMENTSHOW TO ATTACH CALLBACKS TO A RUNNABLEHOW TO PROPAGATE CALLBACKS  CONSTRUCTORHOW TO DISPATCH CUSTOM CALLBACK EVENTSHOW TO PASS CALLBACKS IN AT RUNTIMEHOW TO SPLIT BY CHARACTERHOW TO CACHE CHAT MODEL RESPONSESHOW TO HANDLE RATE LIMITSHOW TO INIT ANY MODEL IN ONE LINEHOW TO TRACK TOKEN USAGE IN CHATMODELSHOW TO ADD TOOLS TO CHATBOTSHOW TO SPLIT CODEHOW TO DO RETRIEVAL WITH CONTEXTUAL COMPRESSIONHOW TO CONVERT RUNNABLES TO TOOLSHOW TO CREATE CUSTOM CALLBACK HANDLERSHOW TO CREATE A CUSTOM CHAT MODEL CLASSCUSTOM EMBEDDINGSHOW TO CREATE A CUSTOM LLM CLASSCUSTOM RETRIEVERHOW TO CREATE TOOLSHOW TO DEBUG YOUR LLM APPSHOW TO LOAD CSVSHOW TO LOAD DOCUMENTS FROM A DIRECTORYHOW TO LOAD HTMLHOW TO LOAD JSONHOW TO LOAD MARKDOWNHOW TO LOAD MICROSOFT OFFICE FILESHOW TO LOAD PDFSHOW TO LOAD WEB PAGESHOW TO CREATE A DYNAMIC (SELF-CONSTRUCTING) CHAINTEXT EMBEDDING MODELSHOW TO COMBINE RESULTS FROM MULTIPLE RETRIEVERSHOW TO SELECT EXAMPLES FROM A LANGSMITH DATASETHOW TO SELECT EXAMPLES BY LENGTHHOW TO SELECT EXAMPLES BY MAXIMAL MARGINAL RELEVANCE (MMR)HOW TO SELECT EXAMPLES BY N-GRAM OVERLAPHOW TO SELECT EXAMPLES BY SIMILARITYHOW TO USE REFERENCE EXAMPLES WHEN DOING EXTRACTIONHOW TO HANDLE LONG TEXT WHEN DOING EXTRACTIONHOW TO USE PROMPTING ALONE (NO TOOL CALLING) TO DO EXTRACTIONHOW TO ADD FALLBACKS TO A RUNNABLEHOW TO FILTER MESSAGESHYBRID SEARCHHOW TO USE THE LANGCHAIN INDEXING APIHOW TO INSPECT RUNNABLESLANGCHAIN EXPRESSION LANGUAGE CHEATSHEETHOW TO CACHE LLM RESPONSESHOW TO TRACK TOKEN USAGE FOR LLMSRUN MODELS LOCALLYHOW TO GET LOG PROBABILITIESHOW TO REORDER RETRIEVED RESULTS TO MITIGATE THE \"LOST IN THE MIDDLE\" EFFECTHOW TO SPLIT MARKDOWN BY HEADERSHOW TO MERGE CONSECUTIVE MESSAGES OF THE SAME TYPEHOW TO ADD MESSAGE HISTORYHOW TO MIGRATE FROM LEGACY LANGCHAIN AGENTS TO LANGGRAPHHOW TO RETRIEVE USING MULTIPLE VECTORS PER DOCUMENTHOW TO PASS MULTIMODAL DATA DIRECTLY TO MODELSHOW TO USE MULTIMODAL PROMPTSHOW TO CREATE A CUSTOM OUTPUT PARSERHOW TO USE THE OUTPUT-FIXING PARSERHOW TO PARSE JSON OUTPUTHOW TO RETRY WHEN A PARSING ERROR OCCURSHOW TO PARSE TEXT FROM MESSAGE OBJECTSHOW TO PARSE XML OUTPUTHOW TO PARSE YAML OUTPUTHOW TO USE THE PARENT DOCUMENT RETRIEVERHOW TO USE LANGCHAIN WITH DIFFERENT PYDANTIC VERSIONSHOW TO ADD CHAT HISTORYHOW TO GET A RAG APPLICATION TO ADD CITATIONSHOW TO DO PER-USER RETRIEVALHOW TO GET YOUR RAG APPLICATION TO RETURN SOURCESHOW TO STREAM RESULTS FROM YOUR RAG APPLICATIONHOW TO SPLIT JSON DATAHOW TO RECURSIVELY SPLIT TEXT BY CHARACTERSRESPONSE METADATAHOW TO PASS RUNTIME SECRETS TO RUNNABLESHOW TO DO \"SELF-QUERYING\" RETRIEVALHOW TO SPLIT TEXT BASED ON SEMANTIC SIMILARITYHOW TO CHAIN RUNNABLESHOW TO SAVE AND LOAD LANGCHAIN OBJECTSHOW TO SPLIT TEXT BY TOKENSHOW TO SPLIT HTMLHOW TO DO QUESTION ANSWERING OVER CSVSHOW TO DEAL WITH LARGE DATABASES WHEN DOING SQL QUESTION-ANSWERINGHOW TO BETTER PROMPT WHEN DOING SQL QUESTION-ANSWERINGHOW TO DO QUERY VALIDATION AS PART OF SQL QUESTION-ANSWERINGHOW TO STREAM RUNNABLESHOW TO STREAM RESPONSES FROM AN LLMHOW TO USE A TIME-WEIGHTED VECTOR STORE RETRIEVERHOW TO RETURN ARTIFACTS FROM A TOOLHOW TO USE CHAT MODELS TO CALL TOOLSHOW TO DISABLE PARALLEL TOOL CALLINGHOW TO FORCE MODELS TO CALL A TOOLHOW TO ACCESS THE RUNNABLECONFIG FROM A TOOLHOW TO PASS TOOL OUTPUTS TO CHAT MODELSHOW TO PASS RUN TIME VALUES TO TOOLSHOW TO STREAM EVENTS FROM A TOOLHOW TO STREAM TOOL CALLSHOW TO CONVERT TOOLS TO OPENAI FUNCTIONSHOW TO HANDLE TOOL ERRORSHOW TO USE FEW-SHOT PROMPTING WITH TOOL CALLINGHOW TO ADD A HUMAN-IN-THE-LOOP FOR TOOLSHOW TO BIND MODEL-SPECIFIC TOOLSHOW TO TRIM MESSAGESHOW TO CREATE AND QUERY VECTOR STORESCONCEPTUAL GUIDEAGENTSARCHITECTUREASYNC PROGRAMMING WITH LANGCHAINCALLBACKSCHAT HISTORYCHAT MODELSDOCUMENT LOADERSEMBEDDING MODELSEVALUATIONEXAMPLE SELECTORSFEW-SHOT PROMPTINGCONCEPTUAL GUIDEKEY-VALUE STORESLANGCHAIN EXPRESSION LANGUAGE (LCEL)MESSAGESMULTIMODALITYOUTPUT PARSERSPROMPT TEMPLATESRETRIEVAL AUGMENTED GENERATION (RAG)RETRIEVALRETRIEVERSRUNNABLE INTERFACESTREAMINGSTRUCTURED OUTPUTSTESTINGSTRING-IN, STRING-OUT LLMSTEXT SPLITTERSTOKENSTOOL CALLINGTOOLSTRACINGVECTOR STORESWHY LANGCHAIN?ECOSYSTEM🦜🛠️ LANGSMITH🦜🕸️ LANGGRAPHVERSIONSV0.3V0.2PYDANTIC COMPATIBILITYMIGRATING FROM V0.0 CHAINSHOW TO MIGRATE FROM V0.0 CHAINSMIGRATING FROM CONSTITUTIONALCHAINMIGRATING FROM CONVERSATIONALCHAINMIGRATING FROM CONVERSATIONALRETRIEVALCHAINMIGRATING FROM LLMCHAINMIGRATING FROM LLMMATHCHAINMIGRATING FROM LLMROUTERCHAINMIGRATING FROM MAPREDUCEDOCUMENTSCHAINMIGRATING FROM MAPRERANKDOCUMENTSCHAINMIGRATING FROM MULTIPROMPTCHAINMIGRATING FROM REFINEDOCUMENTSCHAINMIGRATING FROM RETRIEVALQAMIGRATING FROM STUFFDOCUMENTSCHAINUPGRADING TO LANGGRAPH MEMORYHOW TO MIGRATE TO LANGGRAPH MEMORYHOW TO USE BASECHATMESSAGEHISTORY WITH LANGGRAPHMIGRATING OFF CONVERSATIONBUFFERMEMORY OR CONVERSATIONSTRINGBUFFERMEMORYMIGRATING OFF CONVERSATIONBUFFERWINDOWMEMORY OR CONVERSATIONTOKENBUFFERMEMORYMIGRATING OFF CONVERSATIONSUMMARYMEMORY OR CONVERSATIONSUMMARYBUFFERMEMORYA LONG-TERM MEMORY AGENTRELEASE POLICYSECURITY POLICYHOW-TO GUIDESHOW TO CHAIN RUNNABLESON THIS PAGEHOW TO CHAIN RUNNABLES\n",
      "PREREQUISITESTHIS GUIDE ASSUMES FAMILIARITY WITH THE FOLLOWING CONCEPTS:\n",
      "LANGCHAIN EXPRESSION LANGUAGE (LCEL)\n",
      "PROMPT TEMPLATES\n",
      "CHAT MODELS\n",
      "OUTPUT PARSER\n",
      "\n",
      "ONE POINT ABOUT LANGCHAIN EXPRESSION LANGUAGE IS THAT ANY TWO RUNNABLES CAN BE \"CHAINED\" TOGETHER INTO SEQUENCES. THE OUTPUT OF THE PREVIOUS RUNNABLE'S .INVOKE() CALL IS PASSED AS INPUT TO THE NEXT RUNNABLE. THIS CAN BE DONE USING THE PIPE OPERATOR (|), OR THE MORE EXPLICIT .PIPE() METHOD, WHICH DOES THE SAME THING.\n",
      "THE RESULTING RUNNABLESEQUENCE IS ITSELF A RUNNABLE, WHICH MEANS IT CAN BE INVOKED, STREAMED, OR FURTHER CHAINED JUST LIKE ANY OTHER RUNNABLE. ADVANTAGES OF CHAINING RUNNABLES IN THIS WAY ARE EFFICIENT STREAMING (THE SEQUENCE WILL STREAM OUTPUT AS SOON AS IT IS AVAILABLE), AND DEBUGGING AND TRACING WITH TOOLS LIKE LANGSMITH.\n",
      "THE PIPE OPERATOR: |​\n",
      "TO SHOW OFF HOW THIS WORKS, LET'S GO THROUGH AN EXAMPLE. WE'LL WALK THROUGH A COMMON PATTERN IN LANGCHAIN: USING A PROMPT TEMPLATE TO FORMAT INPUT INTO A CHAT MODEL, AND FINALLY CONVERTING THE CHAT MESSAGE OUTPUT INTO A STRING WITH AN OUTPUT PARSER.\n",
      "\n",
      "SELECT CHAT MODEL:GROQ▾GROQOPENAIANTHROPICAZUREGOOGLE VERTEXAWSCOHERENVIDIAFIREWORKS AIMISTRAL AITOGETHER AIIBM WATSONXDATABRICKSXAIPIP INSTALL -QU \"LANGCHAIN[GROQ]\"IMPORT GETPASSIMPORT OSIF NOT OS.ENVIRON.GET(\"GROQ_API_KEY\"):  OS.ENVIRON[\"GROQ_API_KEY\"] = GETPASS.GETPASS(\"ENTER API KEY FOR GROQ: \")FROM LANGCHAIN.CHAT_MODELS IMPORT INIT_CHAT_MODELMODEL = INIT_CHAT_MODEL(\"LLAMA3-8B-8192\", MODEL_PROVIDER=\"GROQ\")\n",
      "FROM LANGCHAIN_CORE.OUTPUT_PARSERS IMPORT STROUTPUTPARSERFROM LANGCHAIN_CORE.PROMPTS IMPORT CHATPROMPTTEMPLATEPROMPT = CHATPROMPTTEMPLATE.FROM_TEMPLATE(\"TELL ME A JOKE ABOUT {TOPIC}\")CHAIN = PROMPT | MODEL | STROUTPUTPARSER()API REFERENCE:STROUTPUTPARSER | CHATPROMPTTEMPLATE\n",
      "PROMPTS AND MODELS ARE BOTH RUNNABLE, AND THE OUTPUT TYPE FROM THE PROMPT CALL IS THE SAME AS THE INPUT TYPE OF THE CHAT MODEL, SO WE CAN CHAIN THEM TOGETHER. WE CAN THEN INVOKE THE RESULTING SEQUENCE LIKE ANY OTHER RUNNABLE:\n",
      "CHAIN.INVOKE({\"TOPIC\": \"BEARS\"})\n",
      "\"HERE'S A BEAR JOKE FOR YOU:\\N\\NWHY DID THE BEAR DISSOLVE IN WATER?\\NBECAUSE IT WAS A POLAR BEAR!\"\n",
      "COERCION​\n",
      "WE CAN EVEN COMBINE THIS CHAIN WITH MORE RUNNABLES TO CREATE ANOTHER CHAIN. THIS MAY INVOLVE SOME INPUT/OUTPUT FORMATTING USING OTHER TYPES OF RUNNABLES, DEPENDING ON THE REQUIRED INPUTS AND OUTPUTS OF THE CHAIN COMPONENTS.\n",
      "FOR EXAMPLE, LET'S SAY WE WANTED TO COMPOSE THE JOKE GENERATING CHAIN WITH ANOTHER CHAIN THAT EVALUATES WHETHER OR NOT THE GENERATED JOKE WAS FUNNY.\n",
      "WE WOULD NEED TO BE CAREFUL WITH HOW WE FORMAT THE INPUT INTO THE NEXT CHAIN. IN THE BELOW EXAMPLE, THE DICT IN THE CHAIN IS AUTOMATICALLY PARSED AND CONVERTED INTO A RUNNABLEPARALLEL, WHICH RUNS ALL OF ITS VALUES IN PARALLEL AND RETURNS A DICT WITH THE RESULTS.\n",
      "THIS HAPPENS TO BE THE SAME FORMAT THE NEXT PROMPT TEMPLATE EXPECTS. HERE IT IS IN ACTION:\n",
      "FROM LANGCHAIN_CORE.OUTPUT_PARSERS IMPORT STROUTPUTPARSERANALYSIS_PROMPT = CHATPROMPTTEMPLATE.FROM_TEMPLATE(\"IS THIS A FUNNY JOKE? {JOKE}\")COMPOSED_CHAIN = {\"JOKE\": CHAIN} | ANALYSIS_PROMPT | MODEL | STROUTPUTPARSER()COMPOSED_CHAIN.INVOKE({\"TOPIC\": \"BEARS\"})API REFERENCE:STROUTPUTPARSER\n",
      "'HAHA, THAT\\'S A CLEVER PLAY ON WORDS! USING \"POLAR\" TO IMPLY THE BEAR DISSOLVED OR BECAME POLAR/POLARIZED WHEN PUT IN WATER. NOT THE MOST HILARIOUS JOKE EVER, BUT IT HAS A CUTE, GROAN-WORTHY PUN THAT MAKES IT MILDLY AMUSING. I APPRECIATE A GOOD PUN OR WORDPLAY JOKE.'\n",
      "FUNCTIONS WILL ALSO BE COERCED INTO RUNNABLES, SO YOU CAN ADD CUSTOM LOGIC TO YOUR CHAINS TOO. THE BELOW CHAIN RESULTS IN THE SAME LOGICAL FLOW AS BEFORE:\n",
      "COMPOSED_CHAIN_WITH_LAMBDA = (    CHAIN    | (LAMBDA INPUT: {\"JOKE\": INPUT})    | ANALYSIS_PROMPT    | MODEL    | STROUTPUTPARSER())COMPOSED_CHAIN_WITH_LAMBDA.INVOKE({\"TOPIC\": \"BEETS\"})\n",
      "\"HAHA, THAT'S A CUTE AND PUNNY JOKE! I LIKE HOW IT PLAYS ON THE IDEA OF BEETS BLUSHING OR TURNING RED LIKE SOMEONE BLUSHING. FOOD PUNS CAN BE QUITE AMUSING. WHILE NOT A TOTAL KNEE-SLAPPER, IT'S A LIGHT-HEARTED, GROAN-WORTHY DAD JOKE THAT WOULD MAKE ME CHUCKLE AND SHAKE MY HEAD. SIMPLE VEGETABLE HUMOR!\"\n",
      "HOWEVER, KEEP IN MIND THAT USING FUNCTIONS LIKE THIS MAY INTERFERE WITH OPERATIONS LIKE STREAMING. SEE THIS SECTION FOR MORE INFORMATION.\n",
      "THE .PIPE() METHOD​\n",
      "WE COULD ALSO COMPOSE THE SAME SEQUENCE USING THE .PIPE() METHOD. HERE'S WHAT THAT LOOKS LIKE:\n",
      "FROM LANGCHAIN_CORE.RUNNABLES IMPORT RUNNABLEPARALLELCOMPOSED_CHAIN_WITH_PIPE = (    RUNNABLEPARALLEL({\"JOKE\": CHAIN})    .PIPE(ANALYSIS_PROMPT)    .PIPE(MODEL)    .PIPE(STROUTPUTPARSER()))COMPOSED_CHAIN_WITH_PIPE.INVOKE({\"TOPIC\": \"BATTLESTAR GALACTICA\"})API REFERENCE:RUNNABLEPARALLEL\n",
      "\"I CANNOT REPRODUCE ANY COPYRIGHTED MATERIAL VERBATIM, BUT I CAN TRY TO ANALYZE THE HUMOR IN THE JOKE YOU PROVIDED WITHOUT QUOTING IT DIRECTLY.\\N\\NTHE JOKE PLAYS ON THE IDEA THAT THE CYLON RAIDERS, WHO ARE THE ANTAGONISTS IN THE BATTLESTAR GALACTICA UNIVERSE, FAILED TO LOCATE THE HUMAN SURVIVORS AFTER ATTACKING THEIR HOME PLANETS (THE TWELVE COLONIES) DUE TO USING AN OUTDATED AND POORLY PERFORMING OPERATING SYSTEM (WINDOWS VISTA) FOR THEIR TARGETING SYSTEMS.\\N\\NTHE HUMOR STEMS FROM THE JUXTAPOSITION OF A FUTURISTIC SCIENCE FICTION SETTING WITH A RELATABLE REAL-WORLD FRUSTRATION – THE USE OF BUGGY, SLOW, OR UNRELIABLE SOFTWARE OR TECHNOLOGY. IT POKES FUN AT THE PERCEIVED INADEQUACIES OF WINDOWS VISTA, WHICH WAS WIDELY CRITICIZED FOR ITS PERFORMANCE ISSUES AND OTHER PROBLEMS WHEN IT WAS RELEASED.\\N\\NBY ATTRIBUTING THE CYLONS' FAILURE TO LOCATE THE HUMANS TO THEIR USE OF VISTA, THE JOKE CREATES AN AMUSING AND UNEXPECTED CONNECTION BETWEEN A FICTIONAL ADVANCED RACE OF ROBOTS AND A FAMILIAR TECHNOLOGICAL ANNOYANCE EXPERIENCED BY MANY PEOPLE IN THE REAL WORLD.\\N\\NOVERALL, THE JOKE RELIES ON INCONGRUITY AND RELATABILITY TO GENERATE HUMOR, BUT WITHOUT REPRODUCING ANY COPYRIGHTED MATERIAL DIRECTLY.\"\n",
      "OR THE ABBREVIATED:\n",
      "COMPOSED_CHAIN_WITH_PIPE = RUNNABLEPARALLEL({\"JOKE\": CHAIN}).PIPE(    ANALYSIS_PROMPT, MODEL, STROUTPUTPARSER())\n",
      "RELATED​\n",
      "\n",
      "STREAMING: CHECK OUT THE STREAMING GUIDE TO UNDERSTAND THE STREAMING BEHAVIOR OF A CHAIN\n",
      "EDIT THIS PAGEWAS THIS PAGE HELPFUL?PREVIOUSHOW TO SPLIT TEXT BASED ON SEMANTIC SIMILARITYNEXTHOW TO SAVE AND LOAD LANGCHAIN OBJECTSTHE PIPE OPERATOR: |COERCIONTHE .PIPE() METHODRELATEDCOMMUNITYTWITTERGITHUBORGANIZATIONPYTHONJS/TSMOREHOMEPAGEBLOGYOUTUBECOPYRIGHT © 2025 LANGCHAIN, INC.\n",
      "\n",
      "\n",
      "          -------\n",
      "\n",
      "          THE PREVIOUS CODE ATTEMPT FAILED WITH THE FOLLOWING ERROR:\n",
      "          CANNOT IMPORT NAME 'SQLDATABASECHAIN' FROM 'LANGCHAIN.CHAINS' (/USERS/MJACK6/GSU_SPRING2025/MSA8700/VENV_AGENTICAI/LIB/PYTHON3.11/SITE-PACKAGES/LANGCHAIN/CHAINS/__INIT__.PY)\n",
      "\n",
      "          YOUR CODING TASK:\n",
      "          HOW CAN I CREATE A LCEL CHAIN THAT QUERIES A SQL DATABASE?\n",
      "\n",
      "          PREVIOUS CODE ATTEMPT:\n",
      "          THIS CODE DEMONSTRATES HOW TO CREATE A LCEL CHAIN THAT QUERIES A SQL DATABASE. THE CHAIN IS CREATED BY INITIALIZING A SQLDATABASECHAIN WITH A CONNECTION STRING SPECIFIED FOR YOUR DATABASE. A CHAT MODEL AND PROMPT ARE USED TO PROCESS THE QUERY REQUEST, PASSING THROUGH VARIOUS PARSING AND ANALYZING LAYERS.\n",
      "          FROM LANGCHAIN.CHAINS IMPORT SQLDATABASECHAIN\n",
      "FROM LANGCHAIN_CORE.PROMPTS IMPORT CHATPROMPTTEMPLATE\n",
      "FROM LANGCHAIN_CORE.OUTPUT_PARSERS IMPORT STROUTPUTPARSER\n",
      "FROM LANGCHAIN.CHAT_MODELS IMPORT INIT_CHAT_MODEL\n",
      "          CONNECTION_STRING = \"SQLITE:///EXAMPLE.DB\"  # MODIFY THIS CONNECTION STRING TO MATCH YOUR SQL DATABASE\n",
      "\n",
      "DB_CHAIN = SQLDATABASECHAIN(DATABASE_URL=CONNECTION_STRING)\n",
      "\n",
      "PROMPT = CHATPROMPTTEMPLATE.FROM_TEMPLATE(\"WHAT DATA DO YOU NEED FROM THE DATABASE?\")\n",
      "MODEL = INIT_CHAT_MODEL(\"LLAMA3-8B-8192\", MODEL_PROVIDER=\"GROQ\")\n",
      "OUTPUT_PARSER = STROUTPUTPARSER()\n",
      "\n",
      "CHAIN = PROMPT | MODEL | DB_CHAIN | OUTPUT_PARSER\n",
      "\n",
      "RESULT = CHAIN.INVOKE({\"QUERY\": \"SELECT * FROM USERS WHERE AGE > 30;\"})\n",
      "PRINT(RESULT)\n",
      "\n",
      "          ANSWER WITH A DESCRIPTION OF THE CODE SOLUTION, FOLLOWED BY THE IMPORTS, AND FINALLY THE FUNCTIONING CODE BLOCK.\n",
      "          ENSURE ALL IMPORTS ARE CORRECT AND THE CODE IS EXECUTABLE.]: 2025-03-13 15:39:20.323447\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:39:20][🤖 AGENT 'CODING ASSISTANT' STARTED TASK]: 2025-03-13 15:39:20.324074\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:39:20][🤖 LLM CALL STARTED]: 2025-03-13 15:39:20.324199\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:39:35][✅ LLM CALL COMPLETED]: 2025-03-13 15:39:35.991222\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:39:35][✅ AGENT 'CODING ASSISTANT' COMPLETED TASK]: 2025-03-13 15:39:35.992525\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:39:35][✅ TASK COMPLETED: YOU ARE A CODING ASSISTANT WITH EXPERTISE IN LCEL, LANGCHAIN EXPRESSION LANGUAGE.\n",
      "          HERE IS A FULL SET OF LCEL DOCUMENTATION:\n",
      "          -------\n",
      "          \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "HOW TO CHAIN RUNNABLES | 🦜️🔗 LANGCHAIN\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "SKIP TO MAIN CONTENTJOIN US AT  INTERRUPT: THE AGENT AI CONFERENCE BY LANGCHAIN ON MAY 13 & 14 IN SAN FRANCISCO!INTEGRATIONSAPI REFERENCEMORECONTRIBUTINGPEOPLEERROR REFERENCELANGSMITHLANGGRAPHLANGCHAIN HUBLANGCHAIN JS/TSV0.3V0.3V0.2V0.1💬SEARCHINTRODUCTIONTUTORIALSBUILD A QUESTION ANSWERING APPLICATION OVER A GRAPH DATABASETUTORIALSBUILD A SIMPLE LLM APPLICATION WITH CHAT MODELS AND PROMPT TEMPLATESBUILD A CHATBOTBUILD A RETRIEVAL AUGMENTED GENERATION (RAG) APP: PART 2BUILD AN EXTRACTION CHAINBUILD AN AGENTTAGGINGBUILD A RETRIEVAL AUGMENTED GENERATION (RAG) APP: PART 1BUILD A SEMANTIC SEARCH ENGINEBUILD A QUESTION/ANSWERING SYSTEM OVER SQL DATASUMMARIZE TEXTHOW-TO GUIDESHOW-TO GUIDESHOW TO USE TOOLS IN A CHAINHOW TO USE A VECTORSTORE AS A RETRIEVERHOW TO ADD MEMORY TO CHATBOTSHOW TO USE EXAMPLE SELECTORSHOW TO ADD A SEMANTIC LAYER OVER GRAPH DATABASEHOW TO INVOKE RUNNABLES IN PARALLELHOW TO STREAM CHAT MODEL RESPONSESHOW TO ADD DEFAULT INVOCATION ARGS TO A RUNNABLEHOW TO ADD RETRIEVAL TO CHATBOTSHOW TO USE FEW SHOT EXAMPLES IN CHAT MODELSHOW TO DO TOOL/FUNCTION CALLINGHOW TO INSTALL LANGCHAIN PACKAGESHOW TO ADD EXAMPLES TO THE PROMPT FOR QUERY ANALYSISHOW TO USE FEW SHOT EXAMPLESHOW TO RUN CUSTOM FUNCTIONSHOW TO USE OUTPUT PARSERS TO PARSE AN LLM RESPONSE INTO STRUCTURED FORMATHOW TO HANDLE CASES WHERE NO QUERIES ARE GENERATEDHOW TO ROUTE BETWEEN SUB-CHAINSHOW TO RETURN STRUCTURED DATA FROM A MODELHOW TO SUMMARIZE TEXT THROUGH PARALLELIZATIONHOW TO SUMMARIZE TEXT THROUGH ITERATIVE REFINEMENTHOW TO SUMMARIZE TEXT IN A SINGLE LLM CALLHOW TO USE TOOLKITSHOW TO ADD AD-HOC TOOL CALLING CAPABILITY TO LLMS AND CHAT MODELSBUILD AN AGENT WITH AGENTEXECUTOR (LEGACY)HOW TO CONSTRUCT KNOWLEDGE GRAPHSHOW TO PARTIALLY FORMAT PROMPT TEMPLATESHOW TO HANDLE MULTIPLE QUERIES WHEN DOING QUERY ANALYSISHOW TO USE BUILT-IN TOOLS AND TOOLKITSHOW TO PASS THROUGH ARGUMENTS FROM ONE STEP TO THE NEXTHOW TO COMPOSE PROMPTS TOGETHERHOW TO HANDLE MULTIPLE RETRIEVERS WHEN DOING QUERY ANALYSISHOW TO ADD VALUES TO A CHAIN'S STATEHOW TO CONSTRUCT FILTERS FOR QUERY ANALYSISHOW TO CONFIGURE RUNTIME CHAIN INTERNALSHOW DEAL WITH HIGH CARDINALITY CATEGORICALS WHEN DOING QUERY ANALYSISCUSTOM DOCUMENT LOADERHOW TO USE THE MULTIQUERYRETRIEVERHOW TO ADD SCORES TO RETRIEVER RESULTSCACHINGHOW TO USE CALLBACKS IN ASYNC ENVIRONMENTSHOW TO ATTACH CALLBACKS TO A RUNNABLEHOW TO PROPAGATE CALLBACKS  CONSTRUCTORHOW TO DISPATCH CUSTOM CALLBACK EVENTSHOW TO PASS CALLBACKS IN AT RUNTIMEHOW TO SPLIT BY CHARACTERHOW TO CACHE CHAT MODEL RESPONSESHOW TO HANDLE RATE LIMITSHOW TO INIT ANY MODEL IN ONE LINEHOW TO TRACK TOKEN USAGE IN CHATMODELSHOW TO ADD TOOLS TO CHATBOTSHOW TO SPLIT CODEHOW TO DO RETRIEVAL WITH CONTEXTUAL COMPRESSIONHOW TO CONVERT RUNNABLES TO TOOLSHOW TO CREATE CUSTOM CALLBACK HANDLERSHOW TO CREATE A CUSTOM CHAT MODEL CLASSCUSTOM EMBEDDINGSHOW TO CREATE A CUSTOM LLM CLASSCUSTOM RETRIEVERHOW TO CREATE TOOLSHOW TO DEBUG YOUR LLM APPSHOW TO LOAD CSVSHOW TO LOAD DOCUMENTS FROM A DIRECTORYHOW TO LOAD HTMLHOW TO LOAD JSONHOW TO LOAD MARKDOWNHOW TO LOAD MICROSOFT OFFICE FILESHOW TO LOAD PDFSHOW TO LOAD WEB PAGESHOW TO CREATE A DYNAMIC (SELF-CONSTRUCTING) CHAINTEXT EMBEDDING MODELSHOW TO COMBINE RESULTS FROM MULTIPLE RETRIEVERSHOW TO SELECT EXAMPLES FROM A LANGSMITH DATASETHOW TO SELECT EXAMPLES BY LENGTHHOW TO SELECT EXAMPLES BY MAXIMAL MARGINAL RELEVANCE (MMR)HOW TO SELECT EXAMPLES BY N-GRAM OVERLAPHOW TO SELECT EXAMPLES BY SIMILARITYHOW TO USE REFERENCE EXAMPLES WHEN DOING EXTRACTIONHOW TO HANDLE LONG TEXT WHEN DOING EXTRACTIONHOW TO USE PROMPTING ALONE (NO TOOL CALLING) TO DO EXTRACTIONHOW TO ADD FALLBACKS TO A RUNNABLEHOW TO FILTER MESSAGESHYBRID SEARCHHOW TO USE THE LANGCHAIN INDEXING APIHOW TO INSPECT RUNNABLESLANGCHAIN EXPRESSION LANGUAGE CHEATSHEETHOW TO CACHE LLM RESPONSESHOW TO TRACK TOKEN USAGE FOR LLMSRUN MODELS LOCALLYHOW TO GET LOG PROBABILITIESHOW TO REORDER RETRIEVED RESULTS TO MITIGATE THE \"LOST IN THE MIDDLE\" EFFECTHOW TO SPLIT MARKDOWN BY HEADERSHOW TO MERGE CONSECUTIVE MESSAGES OF THE SAME TYPEHOW TO ADD MESSAGE HISTORYHOW TO MIGRATE FROM LEGACY LANGCHAIN AGENTS TO LANGGRAPHHOW TO RETRIEVE USING MULTIPLE VECTORS PER DOCUMENTHOW TO PASS MULTIMODAL DATA DIRECTLY TO MODELSHOW TO USE MULTIMODAL PROMPTSHOW TO CREATE A CUSTOM OUTPUT PARSERHOW TO USE THE OUTPUT-FIXING PARSERHOW TO PARSE JSON OUTPUTHOW TO RETRY WHEN A PARSING ERROR OCCURSHOW TO PARSE TEXT FROM MESSAGE OBJECTSHOW TO PARSE XML OUTPUTHOW TO PARSE YAML OUTPUTHOW TO USE THE PARENT DOCUMENT RETRIEVERHOW TO USE LANGCHAIN WITH DIFFERENT PYDANTIC VERSIONSHOW TO ADD CHAT HISTORYHOW TO GET A RAG APPLICATION TO ADD CITATIONSHOW TO DO PER-USER RETRIEVALHOW TO GET YOUR RAG APPLICATION TO RETURN SOURCESHOW TO STREAM RESULTS FROM YOUR RAG APPLICATIONHOW TO SPLIT JSON DATAHOW TO RECURSIVELY SPLIT TEXT BY CHARACTERSRESPONSE METADATAHOW TO PASS RUNTIME SECRETS TO RUNNABLESHOW TO DO \"SELF-QUERYING\" RETRIEVALHOW TO SPLIT TEXT BASED ON SEMANTIC SIMILARITYHOW TO CHAIN RUNNABLESHOW TO SAVE AND LOAD LANGCHAIN OBJECTSHOW TO SPLIT TEXT BY TOKENSHOW TO SPLIT HTMLHOW TO DO QUESTION ANSWERING OVER CSVSHOW TO DEAL WITH LARGE DATABASES WHEN DOING SQL QUESTION-ANSWERINGHOW TO BETTER PROMPT WHEN DOING SQL QUESTION-ANSWERINGHOW TO DO QUERY VALIDATION AS PART OF SQL QUESTION-ANSWERINGHOW TO STREAM RUNNABLESHOW TO STREAM RESPONSES FROM AN LLMHOW TO USE A TIME-WEIGHTED VECTOR STORE RETRIEVERHOW TO RETURN ARTIFACTS FROM A TOOLHOW TO USE CHAT MODELS TO CALL TOOLSHOW TO DISABLE PARALLEL TOOL CALLINGHOW TO FORCE MODELS TO CALL A TOOLHOW TO ACCESS THE RUNNABLECONFIG FROM A TOOLHOW TO PASS TOOL OUTPUTS TO CHAT MODELSHOW TO PASS RUN TIME VALUES TO TOOLSHOW TO STREAM EVENTS FROM A TOOLHOW TO STREAM TOOL CALLSHOW TO CONVERT TOOLS TO OPENAI FUNCTIONSHOW TO HANDLE TOOL ERRORSHOW TO USE FEW-SHOT PROMPTING WITH TOOL CALLINGHOW TO ADD A HUMAN-IN-THE-LOOP FOR TOOLSHOW TO BIND MODEL-SPECIFIC TOOLSHOW TO TRIM MESSAGESHOW TO CREATE AND QUERY VECTOR STORESCONCEPTUAL GUIDEAGENTSARCHITECTUREASYNC PROGRAMMING WITH LANGCHAINCALLBACKSCHAT HISTORYCHAT MODELSDOCUMENT LOADERSEMBEDDING MODELSEVALUATIONEXAMPLE SELECTORSFEW-SHOT PROMPTINGCONCEPTUAL GUIDEKEY-VALUE STORESLANGCHAIN EXPRESSION LANGUAGE (LCEL)MESSAGESMULTIMODALITYOUTPUT PARSERSPROMPT TEMPLATESRETRIEVAL AUGMENTED GENERATION (RAG)RETRIEVALRETRIEVERSRUNNABLE INTERFACESTREAMINGSTRUCTURED OUTPUTSTESTINGSTRING-IN, STRING-OUT LLMSTEXT SPLITTERSTOKENSTOOL CALLINGTOOLSTRACINGVECTOR STORESWHY LANGCHAIN?ECOSYSTEM🦜🛠️ LANGSMITH🦜🕸️ LANGGRAPHVERSIONSV0.3V0.2PYDANTIC COMPATIBILITYMIGRATING FROM V0.0 CHAINSHOW TO MIGRATE FROM V0.0 CHAINSMIGRATING FROM CONSTITUTIONALCHAINMIGRATING FROM CONVERSATIONALCHAINMIGRATING FROM CONVERSATIONALRETRIEVALCHAINMIGRATING FROM LLMCHAINMIGRATING FROM LLMMATHCHAINMIGRATING FROM LLMROUTERCHAINMIGRATING FROM MAPREDUCEDOCUMENTSCHAINMIGRATING FROM MAPRERANKDOCUMENTSCHAINMIGRATING FROM MULTIPROMPTCHAINMIGRATING FROM REFINEDOCUMENTSCHAINMIGRATING FROM RETRIEVALQAMIGRATING FROM STUFFDOCUMENTSCHAINUPGRADING TO LANGGRAPH MEMORYHOW TO MIGRATE TO LANGGRAPH MEMORYHOW TO USE BASECHATMESSAGEHISTORY WITH LANGGRAPHMIGRATING OFF CONVERSATIONBUFFERMEMORY OR CONVERSATIONSTRINGBUFFERMEMORYMIGRATING OFF CONVERSATIONBUFFERWINDOWMEMORY OR CONVERSATIONTOKENBUFFERMEMORYMIGRATING OFF CONVERSATIONSUMMARYMEMORY OR CONVERSATIONSUMMARYBUFFERMEMORYA LONG-TERM MEMORY AGENTRELEASE POLICYSECURITY POLICYHOW-TO GUIDESHOW TO CHAIN RUNNABLESON THIS PAGEHOW TO CHAIN RUNNABLES\n",
      "PREREQUISITESTHIS GUIDE ASSUMES FAMILIARITY WITH THE FOLLOWING CONCEPTS:\n",
      "LANGCHAIN EXPRESSION LANGUAGE (LCEL)\n",
      "PROMPT TEMPLATES\n",
      "CHAT MODELS\n",
      "OUTPUT PARSER\n",
      "\n",
      "ONE POINT ABOUT LANGCHAIN EXPRESSION LANGUAGE IS THAT ANY TWO RUNNABLES CAN BE \"CHAINED\" TOGETHER INTO SEQUENCES. THE OUTPUT OF THE PREVIOUS RUNNABLE'S .INVOKE() CALL IS PASSED AS INPUT TO THE NEXT RUNNABLE. THIS CAN BE DONE USING THE PIPE OPERATOR (|), OR THE MORE EXPLICIT .PIPE() METHOD, WHICH DOES THE SAME THING.\n",
      "THE RESULTING RUNNABLESEQUENCE IS ITSELF A RUNNABLE, WHICH MEANS IT CAN BE INVOKED, STREAMED, OR FURTHER CHAINED JUST LIKE ANY OTHER RUNNABLE. ADVANTAGES OF CHAINING RUNNABLES IN THIS WAY ARE EFFICIENT STREAMING (THE SEQUENCE WILL STREAM OUTPUT AS SOON AS IT IS AVAILABLE), AND DEBUGGING AND TRACING WITH TOOLS LIKE LANGSMITH.\n",
      "THE PIPE OPERATOR: |​\n",
      "TO SHOW OFF HOW THIS WORKS, LET'S GO THROUGH AN EXAMPLE. WE'LL WALK THROUGH A COMMON PATTERN IN LANGCHAIN: USING A PROMPT TEMPLATE TO FORMAT INPUT INTO A CHAT MODEL, AND FINALLY CONVERTING THE CHAT MESSAGE OUTPUT INTO A STRING WITH AN OUTPUT PARSER.\n",
      "\n",
      "SELECT CHAT MODEL:GROQ▾GROQOPENAIANTHROPICAZUREGOOGLE VERTEXAWSCOHERENVIDIAFIREWORKS AIMISTRAL AITOGETHER AIIBM WATSONXDATABRICKSXAIPIP INSTALL -QU \"LANGCHAIN[GROQ]\"IMPORT GETPASSIMPORT OSIF NOT OS.ENVIRON.GET(\"GROQ_API_KEY\"):  OS.ENVIRON[\"GROQ_API_KEY\"] = GETPASS.GETPASS(\"ENTER API KEY FOR GROQ: \")FROM LANGCHAIN.CHAT_MODELS IMPORT INIT_CHAT_MODELMODEL = INIT_CHAT_MODEL(\"LLAMA3-8B-8192\", MODEL_PROVIDER=\"GROQ\")\n",
      "FROM LANGCHAIN_CORE.OUTPUT_PARSERS IMPORT STROUTPUTPARSERFROM LANGCHAIN_CORE.PROMPTS IMPORT CHATPROMPTTEMPLATEPROMPT = CHATPROMPTTEMPLATE.FROM_TEMPLATE(\"TELL ME A JOKE ABOUT {TOPIC}\")CHAIN = PROMPT | MODEL | STROUTPUTPARSER()API REFERENCE:STROUTPUTPARSER | CHATPROMPTTEMPLATE\n",
      "PROMPTS AND MODELS ARE BOTH RUNNABLE, AND THE OUTPUT TYPE FROM THE PROMPT CALL IS THE SAME AS THE INPUT TYPE OF THE CHAT MODEL, SO WE CAN CHAIN THEM TOGETHER. WE CAN THEN INVOKE THE RESULTING SEQUENCE LIKE ANY OTHER RUNNABLE:\n",
      "CHAIN.INVOKE({\"TOPIC\": \"BEARS\"})\n",
      "\"HERE'S A BEAR JOKE FOR YOU:\\N\\NWHY DID THE BEAR DISSOLVE IN WATER?\\NBECAUSE IT WAS A POLAR BEAR!\"\n",
      "COERCION​\n",
      "WE CAN EVEN COMBINE THIS CHAIN WITH MORE RUNNABLES TO CREATE ANOTHER CHAIN. THIS MAY INVOLVE SOME INPUT/OUTPUT FORMATTING USING OTHER TYPES OF RUNNABLES, DEPENDING ON THE REQUIRED INPUTS AND OUTPUTS OF THE CHAIN COMPONENTS.\n",
      "FOR EXAMPLE, LET'S SAY WE WANTED TO COMPOSE THE JOKE GENERATING CHAIN WITH ANOTHER CHAIN THAT EVALUATES WHETHER OR NOT THE GENERATED JOKE WAS FUNNY.\n",
      "WE WOULD NEED TO BE CAREFUL WITH HOW WE FORMAT THE INPUT INTO THE NEXT CHAIN. IN THE BELOW EXAMPLE, THE DICT IN THE CHAIN IS AUTOMATICALLY PARSED AND CONVERTED INTO A RUNNABLEPARALLEL, WHICH RUNS ALL OF ITS VALUES IN PARALLEL AND RETURNS A DICT WITH THE RESULTS.\n",
      "THIS HAPPENS TO BE THE SAME FORMAT THE NEXT PROMPT TEMPLATE EXPECTS. HERE IT IS IN ACTION:\n",
      "FROM LANGCHAIN_CORE.OUTPUT_PARSERS IMPORT STROUTPUTPARSERANALYSIS_PROMPT = CHATPROMPTTEMPLATE.FROM_TEMPLATE(\"IS THIS A FUNNY JOKE? {JOKE}\")COMPOSED_CHAIN = {\"JOKE\": CHAIN} | ANALYSIS_PROMPT | MODEL | STROUTPUTPARSER()COMPOSED_CHAIN.INVOKE({\"TOPIC\": \"BEARS\"})API REFERENCE:STROUTPUTPARSER\n",
      "'HAHA, THAT\\'S A CLEVER PLAY ON WORDS! USING \"POLAR\" TO IMPLY THE BEAR DISSOLVED OR BECAME POLAR/POLARIZED WHEN PUT IN WATER. NOT THE MOST HILARIOUS JOKE EVER, BUT IT HAS A CUTE, GROAN-WORTHY PUN THAT MAKES IT MILDLY AMUSING. I APPRECIATE A GOOD PUN OR WORDPLAY JOKE.'\n",
      "FUNCTIONS WILL ALSO BE COERCED INTO RUNNABLES, SO YOU CAN ADD CUSTOM LOGIC TO YOUR CHAINS TOO. THE BELOW CHAIN RESULTS IN THE SAME LOGICAL FLOW AS BEFORE:\n",
      "COMPOSED_CHAIN_WITH_LAMBDA = (    CHAIN    | (LAMBDA INPUT: {\"JOKE\": INPUT})    | ANALYSIS_PROMPT    | MODEL    | STROUTPUTPARSER())COMPOSED_CHAIN_WITH_LAMBDA.INVOKE({\"TOPIC\": \"BEETS\"})\n",
      "\"HAHA, THAT'S A CUTE AND PUNNY JOKE! I LIKE HOW IT PLAYS ON THE IDEA OF BEETS BLUSHING OR TURNING RED LIKE SOMEONE BLUSHING. FOOD PUNS CAN BE QUITE AMUSING. WHILE NOT A TOTAL KNEE-SLAPPER, IT'S A LIGHT-HEARTED, GROAN-WORTHY DAD JOKE THAT WOULD MAKE ME CHUCKLE AND SHAKE MY HEAD. SIMPLE VEGETABLE HUMOR!\"\n",
      "HOWEVER, KEEP IN MIND THAT USING FUNCTIONS LIKE THIS MAY INTERFERE WITH OPERATIONS LIKE STREAMING. SEE THIS SECTION FOR MORE INFORMATION.\n",
      "THE .PIPE() METHOD​\n",
      "WE COULD ALSO COMPOSE THE SAME SEQUENCE USING THE .PIPE() METHOD. HERE'S WHAT THAT LOOKS LIKE:\n",
      "FROM LANGCHAIN_CORE.RUNNABLES IMPORT RUNNABLEPARALLELCOMPOSED_CHAIN_WITH_PIPE = (    RUNNABLEPARALLEL({\"JOKE\": CHAIN})    .PIPE(ANALYSIS_PROMPT)    .PIPE(MODEL)    .PIPE(STROUTPUTPARSER()))COMPOSED_CHAIN_WITH_PIPE.INVOKE({\"TOPIC\": \"BATTLESTAR GALACTICA\"})API REFERENCE:RUNNABLEPARALLEL\n",
      "\"I CANNOT REPRODUCE ANY COPYRIGHTED MATERIAL VERBATIM, BUT I CAN TRY TO ANALYZE THE HUMOR IN THE JOKE YOU PROVIDED WITHOUT QUOTING IT DIRECTLY.\\N\\NTHE JOKE PLAYS ON THE IDEA THAT THE CYLON RAIDERS, WHO ARE THE ANTAGONISTS IN THE BATTLESTAR GALACTICA UNIVERSE, FAILED TO LOCATE THE HUMAN SURVIVORS AFTER ATTACKING THEIR HOME PLANETS (THE TWELVE COLONIES) DUE TO USING AN OUTDATED AND POORLY PERFORMING OPERATING SYSTEM (WINDOWS VISTA) FOR THEIR TARGETING SYSTEMS.\\N\\NTHE HUMOR STEMS FROM THE JUXTAPOSITION OF A FUTURISTIC SCIENCE FICTION SETTING WITH A RELATABLE REAL-WORLD FRUSTRATION – THE USE OF BUGGY, SLOW, OR UNRELIABLE SOFTWARE OR TECHNOLOGY. IT POKES FUN AT THE PERCEIVED INADEQUACIES OF WINDOWS VISTA, WHICH WAS WIDELY CRITICIZED FOR ITS PERFORMANCE ISSUES AND OTHER PROBLEMS WHEN IT WAS RELEASED.\\N\\NBY ATTRIBUTING THE CYLONS' FAILURE TO LOCATE THE HUMANS TO THEIR USE OF VISTA, THE JOKE CREATES AN AMUSING AND UNEXPECTED CONNECTION BETWEEN A FICTIONAL ADVANCED RACE OF ROBOTS AND A FAMILIAR TECHNOLOGICAL ANNOYANCE EXPERIENCED BY MANY PEOPLE IN THE REAL WORLD.\\N\\NOVERALL, THE JOKE RELIES ON INCONGRUITY AND RELATABILITY TO GENERATE HUMOR, BUT WITHOUT REPRODUCING ANY COPYRIGHTED MATERIAL DIRECTLY.\"\n",
      "OR THE ABBREVIATED:\n",
      "COMPOSED_CHAIN_WITH_PIPE = RUNNABLEPARALLEL({\"JOKE\": CHAIN}).PIPE(    ANALYSIS_PROMPT, MODEL, STROUTPUTPARSER())\n",
      "RELATED​\n",
      "\n",
      "STREAMING: CHECK OUT THE STREAMING GUIDE TO UNDERSTAND THE STREAMING BEHAVIOR OF A CHAIN\n",
      "EDIT THIS PAGEWAS THIS PAGE HELPFUL?PREVIOUSHOW TO SPLIT TEXT BASED ON SEMANTIC SIMILARITYNEXTHOW TO SAVE AND LOAD LANGCHAIN OBJECTSTHE PIPE OPERATOR: |COERCIONTHE .PIPE() METHODRELATEDCOMMUNITYTWITTERGITHUBORGANIZATIONPYTHONJS/TSMOREHOMEPAGEBLOGYOUTUBECOPYRIGHT © 2025 LANGCHAIN, INC.\n",
      "\n",
      "\n",
      "          -------\n",
      "\n",
      "          THE PREVIOUS CODE ATTEMPT FAILED WITH THE FOLLOWING ERROR:\n",
      "          CANNOT IMPORT NAME 'SQLDATABASECHAIN' FROM 'LANGCHAIN.CHAINS' (/USERS/MJACK6/GSU_SPRING2025/MSA8700/VENV_AGENTICAI/LIB/PYTHON3.11/SITE-PACKAGES/LANGCHAIN/CHAINS/__INIT__.PY)\n",
      "\n",
      "          YOUR CODING TASK:\n",
      "          HOW CAN I CREATE A LCEL CHAIN THAT QUERIES A SQL DATABASE?\n",
      "\n",
      "          PREVIOUS CODE ATTEMPT:\n",
      "          THIS CODE DEMONSTRATES HOW TO CREATE A LCEL CHAIN THAT QUERIES A SQL DATABASE. THE CHAIN IS CREATED BY INITIALIZING A SQLDATABASECHAIN WITH A CONNECTION STRING SPECIFIED FOR YOUR DATABASE. A CHAT MODEL AND PROMPT ARE USED TO PROCESS THE QUERY REQUEST, PASSING THROUGH VARIOUS PARSING AND ANALYZING LAYERS.\n",
      "          FROM LANGCHAIN.CHAINS IMPORT SQLDATABASECHAIN\n",
      "FROM LANGCHAIN_CORE.PROMPTS IMPORT CHATPROMPTTEMPLATE\n",
      "FROM LANGCHAIN_CORE.OUTPUT_PARSERS IMPORT STROUTPUTPARSER\n",
      "FROM LANGCHAIN.CHAT_MODELS IMPORT INIT_CHAT_MODEL\n",
      "          CONNECTION_STRING = \"SQLITE:///EXAMPLE.DB\"  # MODIFY THIS CONNECTION STRING TO MATCH YOUR SQL DATABASE\n",
      "\n",
      "DB_CHAIN = SQLDATABASECHAIN(DATABASE_URL=CONNECTION_STRING)\n",
      "\n",
      "PROMPT = CHATPROMPTTEMPLATE.FROM_TEMPLATE(\"WHAT DATA DO YOU NEED FROM THE DATABASE?\")\n",
      "MODEL = INIT_CHAT_MODEL(\"LLAMA3-8B-8192\", MODEL_PROVIDER=\"GROQ\")\n",
      "OUTPUT_PARSER = STROUTPUTPARSER()\n",
      "\n",
      "CHAIN = PROMPT | MODEL | DB_CHAIN | OUTPUT_PARSER\n",
      "\n",
      "RESULT = CHAIN.INVOKE({\"QUERY\": \"SELECT * FROM USERS WHERE AGE > 30;\"})\n",
      "PRINT(RESULT)\n",
      "\n",
      "          ANSWER WITH A DESCRIPTION OF THE CODE SOLUTION, FOLLOWED BY THE IMPORTS, AND FINALLY THE FUNCTIONING CODE BLOCK.\n",
      "          ENSURE ALL IMPORTS ARE CORRECT AND THE CODE IS EXECUTABLE.]: 2025-03-13 15:39:35.992948\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:39:35][✅ CREW 'CREW' COMPLETED, 2612229F-71F2-4D41-B162-D29FA5C8825C]: 2025-03-13 15:39:35.999108\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:39:35][👍 FLOW METHOD FINISHED: 'RUN_FIX']: 2025-03-13 15:39:35.999502\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:39:35][🤖 FLOW METHOD STARTED: 'RE_RUN_CHECK']: 2025-03-13 15:39:35.999687\u001b[00m\n",
      "---CHECKING CODE---\n",
      "---CODE BLOCK CHECK: FAILED---\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:39:36][👍 FLOW METHOD FINISHED: 'RE_RUN_CHECK']: 2025-03-13 15:39:36.403567\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:39:36][🤖 FLOW METHOD STARTED: 'RE_RUN_FIX']: 2025-03-13 15:39:36.404400\u001b[00m\n",
      "---FIXING CODE---\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:39:36][🚀 CREW 'CREW' STARTED, DCFAFFC0-E2D0-47E1-B5A8-134571F8CE0D]: 2025-03-13 15:39:36.407373\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:39:36][📋 TASK STARTED: YOU ARE A CODING ASSISTANT WITH EXPERTISE IN LCEL, LANGCHAIN EXPRESSION LANGUAGE.\n",
      "          HERE IS A FULL SET OF LCEL DOCUMENTATION:\n",
      "          -------\n",
      "          \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "HOW TO CHAIN RUNNABLES | 🦜️🔗 LANGCHAIN\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "SKIP TO MAIN CONTENTJOIN US AT  INTERRUPT: THE AGENT AI CONFERENCE BY LANGCHAIN ON MAY 13 & 14 IN SAN FRANCISCO!INTEGRATIONSAPI REFERENCEMORECONTRIBUTINGPEOPLEERROR REFERENCELANGSMITHLANGGRAPHLANGCHAIN HUBLANGCHAIN JS/TSV0.3V0.3V0.2V0.1💬SEARCHINTRODUCTIONTUTORIALSBUILD A QUESTION ANSWERING APPLICATION OVER A GRAPH DATABASETUTORIALSBUILD A SIMPLE LLM APPLICATION WITH CHAT MODELS AND PROMPT TEMPLATESBUILD A CHATBOTBUILD A RETRIEVAL AUGMENTED GENERATION (RAG) APP: PART 2BUILD AN EXTRACTION CHAINBUILD AN AGENTTAGGINGBUILD A RETRIEVAL AUGMENTED GENERATION (RAG) APP: PART 1BUILD A SEMANTIC SEARCH ENGINEBUILD A QUESTION/ANSWERING SYSTEM OVER SQL DATASUMMARIZE TEXTHOW-TO GUIDESHOW-TO GUIDESHOW TO USE TOOLS IN A CHAINHOW TO USE A VECTORSTORE AS A RETRIEVERHOW TO ADD MEMORY TO CHATBOTSHOW TO USE EXAMPLE SELECTORSHOW TO ADD A SEMANTIC LAYER OVER GRAPH DATABASEHOW TO INVOKE RUNNABLES IN PARALLELHOW TO STREAM CHAT MODEL RESPONSESHOW TO ADD DEFAULT INVOCATION ARGS TO A RUNNABLEHOW TO ADD RETRIEVAL TO CHATBOTSHOW TO USE FEW SHOT EXAMPLES IN CHAT MODELSHOW TO DO TOOL/FUNCTION CALLINGHOW TO INSTALL LANGCHAIN PACKAGESHOW TO ADD EXAMPLES TO THE PROMPT FOR QUERY ANALYSISHOW TO USE FEW SHOT EXAMPLESHOW TO RUN CUSTOM FUNCTIONSHOW TO USE OUTPUT PARSERS TO PARSE AN LLM RESPONSE INTO STRUCTURED FORMATHOW TO HANDLE CASES WHERE NO QUERIES ARE GENERATEDHOW TO ROUTE BETWEEN SUB-CHAINSHOW TO RETURN STRUCTURED DATA FROM A MODELHOW TO SUMMARIZE TEXT THROUGH PARALLELIZATIONHOW TO SUMMARIZE TEXT THROUGH ITERATIVE REFINEMENTHOW TO SUMMARIZE TEXT IN A SINGLE LLM CALLHOW TO USE TOOLKITSHOW TO ADD AD-HOC TOOL CALLING CAPABILITY TO LLMS AND CHAT MODELSBUILD AN AGENT WITH AGENTEXECUTOR (LEGACY)HOW TO CONSTRUCT KNOWLEDGE GRAPHSHOW TO PARTIALLY FORMAT PROMPT TEMPLATESHOW TO HANDLE MULTIPLE QUERIES WHEN DOING QUERY ANALYSISHOW TO USE BUILT-IN TOOLS AND TOOLKITSHOW TO PASS THROUGH ARGUMENTS FROM ONE STEP TO THE NEXTHOW TO COMPOSE PROMPTS TOGETHERHOW TO HANDLE MULTIPLE RETRIEVERS WHEN DOING QUERY ANALYSISHOW TO ADD VALUES TO A CHAIN'S STATEHOW TO CONSTRUCT FILTERS FOR QUERY ANALYSISHOW TO CONFIGURE RUNTIME CHAIN INTERNALSHOW DEAL WITH HIGH CARDINALITY CATEGORICALS WHEN DOING QUERY ANALYSISCUSTOM DOCUMENT LOADERHOW TO USE THE MULTIQUERYRETRIEVERHOW TO ADD SCORES TO RETRIEVER RESULTSCACHINGHOW TO USE CALLBACKS IN ASYNC ENVIRONMENTSHOW TO ATTACH CALLBACKS TO A RUNNABLEHOW TO PROPAGATE CALLBACKS  CONSTRUCTORHOW TO DISPATCH CUSTOM CALLBACK EVENTSHOW TO PASS CALLBACKS IN AT RUNTIMEHOW TO SPLIT BY CHARACTERHOW TO CACHE CHAT MODEL RESPONSESHOW TO HANDLE RATE LIMITSHOW TO INIT ANY MODEL IN ONE LINEHOW TO TRACK TOKEN USAGE IN CHATMODELSHOW TO ADD TOOLS TO CHATBOTSHOW TO SPLIT CODEHOW TO DO RETRIEVAL WITH CONTEXTUAL COMPRESSIONHOW TO CONVERT RUNNABLES TO TOOLSHOW TO CREATE CUSTOM CALLBACK HANDLERSHOW TO CREATE A CUSTOM CHAT MODEL CLASSCUSTOM EMBEDDINGSHOW TO CREATE A CUSTOM LLM CLASSCUSTOM RETRIEVERHOW TO CREATE TOOLSHOW TO DEBUG YOUR LLM APPSHOW TO LOAD CSVSHOW TO LOAD DOCUMENTS FROM A DIRECTORYHOW TO LOAD HTMLHOW TO LOAD JSONHOW TO LOAD MARKDOWNHOW TO LOAD MICROSOFT OFFICE FILESHOW TO LOAD PDFSHOW TO LOAD WEB PAGESHOW TO CREATE A DYNAMIC (SELF-CONSTRUCTING) CHAINTEXT EMBEDDING MODELSHOW TO COMBINE RESULTS FROM MULTIPLE RETRIEVERSHOW TO SELECT EXAMPLES FROM A LANGSMITH DATASETHOW TO SELECT EXAMPLES BY LENGTHHOW TO SELECT EXAMPLES BY MAXIMAL MARGINAL RELEVANCE (MMR)HOW TO SELECT EXAMPLES BY N-GRAM OVERLAPHOW TO SELECT EXAMPLES BY SIMILARITYHOW TO USE REFERENCE EXAMPLES WHEN DOING EXTRACTIONHOW TO HANDLE LONG TEXT WHEN DOING EXTRACTIONHOW TO USE PROMPTING ALONE (NO TOOL CALLING) TO DO EXTRACTIONHOW TO ADD FALLBACKS TO A RUNNABLEHOW TO FILTER MESSAGESHYBRID SEARCHHOW TO USE THE LANGCHAIN INDEXING APIHOW TO INSPECT RUNNABLESLANGCHAIN EXPRESSION LANGUAGE CHEATSHEETHOW TO CACHE LLM RESPONSESHOW TO TRACK TOKEN USAGE FOR LLMSRUN MODELS LOCALLYHOW TO GET LOG PROBABILITIESHOW TO REORDER RETRIEVED RESULTS TO MITIGATE THE \"LOST IN THE MIDDLE\" EFFECTHOW TO SPLIT MARKDOWN BY HEADERSHOW TO MERGE CONSECUTIVE MESSAGES OF THE SAME TYPEHOW TO ADD MESSAGE HISTORYHOW TO MIGRATE FROM LEGACY LANGCHAIN AGENTS TO LANGGRAPHHOW TO RETRIEVE USING MULTIPLE VECTORS PER DOCUMENTHOW TO PASS MULTIMODAL DATA DIRECTLY TO MODELSHOW TO USE MULTIMODAL PROMPTSHOW TO CREATE A CUSTOM OUTPUT PARSERHOW TO USE THE OUTPUT-FIXING PARSERHOW TO PARSE JSON OUTPUTHOW TO RETRY WHEN A PARSING ERROR OCCURSHOW TO PARSE TEXT FROM MESSAGE OBJECTSHOW TO PARSE XML OUTPUTHOW TO PARSE YAML OUTPUTHOW TO USE THE PARENT DOCUMENT RETRIEVERHOW TO USE LANGCHAIN WITH DIFFERENT PYDANTIC VERSIONSHOW TO ADD CHAT HISTORYHOW TO GET A RAG APPLICATION TO ADD CITATIONSHOW TO DO PER-USER RETRIEVALHOW TO GET YOUR RAG APPLICATION TO RETURN SOURCESHOW TO STREAM RESULTS FROM YOUR RAG APPLICATIONHOW TO SPLIT JSON DATAHOW TO RECURSIVELY SPLIT TEXT BY CHARACTERSRESPONSE METADATAHOW TO PASS RUNTIME SECRETS TO RUNNABLESHOW TO DO \"SELF-QUERYING\" RETRIEVALHOW TO SPLIT TEXT BASED ON SEMANTIC SIMILARITYHOW TO CHAIN RUNNABLESHOW TO SAVE AND LOAD LANGCHAIN OBJECTSHOW TO SPLIT TEXT BY TOKENSHOW TO SPLIT HTMLHOW TO DO QUESTION ANSWERING OVER CSVSHOW TO DEAL WITH LARGE DATABASES WHEN DOING SQL QUESTION-ANSWERINGHOW TO BETTER PROMPT WHEN DOING SQL QUESTION-ANSWERINGHOW TO DO QUERY VALIDATION AS PART OF SQL QUESTION-ANSWERINGHOW TO STREAM RUNNABLESHOW TO STREAM RESPONSES FROM AN LLMHOW TO USE A TIME-WEIGHTED VECTOR STORE RETRIEVERHOW TO RETURN ARTIFACTS FROM A TOOLHOW TO USE CHAT MODELS TO CALL TOOLSHOW TO DISABLE PARALLEL TOOL CALLINGHOW TO FORCE MODELS TO CALL A TOOLHOW TO ACCESS THE RUNNABLECONFIG FROM A TOOLHOW TO PASS TOOL OUTPUTS TO CHAT MODELSHOW TO PASS RUN TIME VALUES TO TOOLSHOW TO STREAM EVENTS FROM A TOOLHOW TO STREAM TOOL CALLSHOW TO CONVERT TOOLS TO OPENAI FUNCTIONSHOW TO HANDLE TOOL ERRORSHOW TO USE FEW-SHOT PROMPTING WITH TOOL CALLINGHOW TO ADD A HUMAN-IN-THE-LOOP FOR TOOLSHOW TO BIND MODEL-SPECIFIC TOOLSHOW TO TRIM MESSAGESHOW TO CREATE AND QUERY VECTOR STORESCONCEPTUAL GUIDEAGENTSARCHITECTUREASYNC PROGRAMMING WITH LANGCHAINCALLBACKSCHAT HISTORYCHAT MODELSDOCUMENT LOADERSEMBEDDING MODELSEVALUATIONEXAMPLE SELECTORSFEW-SHOT PROMPTINGCONCEPTUAL GUIDEKEY-VALUE STORESLANGCHAIN EXPRESSION LANGUAGE (LCEL)MESSAGESMULTIMODALITYOUTPUT PARSERSPROMPT TEMPLATESRETRIEVAL AUGMENTED GENERATION (RAG)RETRIEVALRETRIEVERSRUNNABLE INTERFACESTREAMINGSTRUCTURED OUTPUTSTESTINGSTRING-IN, STRING-OUT LLMSTEXT SPLITTERSTOKENSTOOL CALLINGTOOLSTRACINGVECTOR STORESWHY LANGCHAIN?ECOSYSTEM🦜🛠️ LANGSMITH🦜🕸️ LANGGRAPHVERSIONSV0.3V0.2PYDANTIC COMPATIBILITYMIGRATING FROM V0.0 CHAINSHOW TO MIGRATE FROM V0.0 CHAINSMIGRATING FROM CONSTITUTIONALCHAINMIGRATING FROM CONVERSATIONALCHAINMIGRATING FROM CONVERSATIONALRETRIEVALCHAINMIGRATING FROM LLMCHAINMIGRATING FROM LLMMATHCHAINMIGRATING FROM LLMROUTERCHAINMIGRATING FROM MAPREDUCEDOCUMENTSCHAINMIGRATING FROM MAPRERANKDOCUMENTSCHAINMIGRATING FROM MULTIPROMPTCHAINMIGRATING FROM REFINEDOCUMENTSCHAINMIGRATING FROM RETRIEVALQAMIGRATING FROM STUFFDOCUMENTSCHAINUPGRADING TO LANGGRAPH MEMORYHOW TO MIGRATE TO LANGGRAPH MEMORYHOW TO USE BASECHATMESSAGEHISTORY WITH LANGGRAPHMIGRATING OFF CONVERSATIONBUFFERMEMORY OR CONVERSATIONSTRINGBUFFERMEMORYMIGRATING OFF CONVERSATIONBUFFERWINDOWMEMORY OR CONVERSATIONTOKENBUFFERMEMORYMIGRATING OFF CONVERSATIONSUMMARYMEMORY OR CONVERSATIONSUMMARYBUFFERMEMORYA LONG-TERM MEMORY AGENTRELEASE POLICYSECURITY POLICYHOW-TO GUIDESHOW TO CHAIN RUNNABLESON THIS PAGEHOW TO CHAIN RUNNABLES\n",
      "PREREQUISITESTHIS GUIDE ASSUMES FAMILIARITY WITH THE FOLLOWING CONCEPTS:\n",
      "LANGCHAIN EXPRESSION LANGUAGE (LCEL)\n",
      "PROMPT TEMPLATES\n",
      "CHAT MODELS\n",
      "OUTPUT PARSER\n",
      "\n",
      "ONE POINT ABOUT LANGCHAIN EXPRESSION LANGUAGE IS THAT ANY TWO RUNNABLES CAN BE \"CHAINED\" TOGETHER INTO SEQUENCES. THE OUTPUT OF THE PREVIOUS RUNNABLE'S .INVOKE() CALL IS PASSED AS INPUT TO THE NEXT RUNNABLE. THIS CAN BE DONE USING THE PIPE OPERATOR (|), OR THE MORE EXPLICIT .PIPE() METHOD, WHICH DOES THE SAME THING.\n",
      "THE RESULTING RUNNABLESEQUENCE IS ITSELF A RUNNABLE, WHICH MEANS IT CAN BE INVOKED, STREAMED, OR FURTHER CHAINED JUST LIKE ANY OTHER RUNNABLE. ADVANTAGES OF CHAINING RUNNABLES IN THIS WAY ARE EFFICIENT STREAMING (THE SEQUENCE WILL STREAM OUTPUT AS SOON AS IT IS AVAILABLE), AND DEBUGGING AND TRACING WITH TOOLS LIKE LANGSMITH.\n",
      "THE PIPE OPERATOR: |​\n",
      "TO SHOW OFF HOW THIS WORKS, LET'S GO THROUGH AN EXAMPLE. WE'LL WALK THROUGH A COMMON PATTERN IN LANGCHAIN: USING A PROMPT TEMPLATE TO FORMAT INPUT INTO A CHAT MODEL, AND FINALLY CONVERTING THE CHAT MESSAGE OUTPUT INTO A STRING WITH AN OUTPUT PARSER.\n",
      "\n",
      "SELECT CHAT MODEL:GROQ▾GROQOPENAIANTHROPICAZUREGOOGLE VERTEXAWSCOHERENVIDIAFIREWORKS AIMISTRAL AITOGETHER AIIBM WATSONXDATABRICKSXAIPIP INSTALL -QU \"LANGCHAIN[GROQ]\"IMPORT GETPASSIMPORT OSIF NOT OS.ENVIRON.GET(\"GROQ_API_KEY\"):  OS.ENVIRON[\"GROQ_API_KEY\"] = GETPASS.GETPASS(\"ENTER API KEY FOR GROQ: \")FROM LANGCHAIN.CHAT_MODELS IMPORT INIT_CHAT_MODELMODEL = INIT_CHAT_MODEL(\"LLAMA3-8B-8192\", MODEL_PROVIDER=\"GROQ\")\n",
      "FROM LANGCHAIN_CORE.OUTPUT_PARSERS IMPORT STROUTPUTPARSERFROM LANGCHAIN_CORE.PROMPTS IMPORT CHATPROMPTTEMPLATEPROMPT = CHATPROMPTTEMPLATE.FROM_TEMPLATE(\"TELL ME A JOKE ABOUT {TOPIC}\")CHAIN = PROMPT | MODEL | STROUTPUTPARSER()API REFERENCE:STROUTPUTPARSER | CHATPROMPTTEMPLATE\n",
      "PROMPTS AND MODELS ARE BOTH RUNNABLE, AND THE OUTPUT TYPE FROM THE PROMPT CALL IS THE SAME AS THE INPUT TYPE OF THE CHAT MODEL, SO WE CAN CHAIN THEM TOGETHER. WE CAN THEN INVOKE THE RESULTING SEQUENCE LIKE ANY OTHER RUNNABLE:\n",
      "CHAIN.INVOKE({\"TOPIC\": \"BEARS\"})\n",
      "\"HERE'S A BEAR JOKE FOR YOU:\\N\\NWHY DID THE BEAR DISSOLVE IN WATER?\\NBECAUSE IT WAS A POLAR BEAR!\"\n",
      "COERCION​\n",
      "WE CAN EVEN COMBINE THIS CHAIN WITH MORE RUNNABLES TO CREATE ANOTHER CHAIN. THIS MAY INVOLVE SOME INPUT/OUTPUT FORMATTING USING OTHER TYPES OF RUNNABLES, DEPENDING ON THE REQUIRED INPUTS AND OUTPUTS OF THE CHAIN COMPONENTS.\n",
      "FOR EXAMPLE, LET'S SAY WE WANTED TO COMPOSE THE JOKE GENERATING CHAIN WITH ANOTHER CHAIN THAT EVALUATES WHETHER OR NOT THE GENERATED JOKE WAS FUNNY.\n",
      "WE WOULD NEED TO BE CAREFUL WITH HOW WE FORMAT THE INPUT INTO THE NEXT CHAIN. IN THE BELOW EXAMPLE, THE DICT IN THE CHAIN IS AUTOMATICALLY PARSED AND CONVERTED INTO A RUNNABLEPARALLEL, WHICH RUNS ALL OF ITS VALUES IN PARALLEL AND RETURNS A DICT WITH THE RESULTS.\n",
      "THIS HAPPENS TO BE THE SAME FORMAT THE NEXT PROMPT TEMPLATE EXPECTS. HERE IT IS IN ACTION:\n",
      "FROM LANGCHAIN_CORE.OUTPUT_PARSERS IMPORT STROUTPUTPARSERANALYSIS_PROMPT = CHATPROMPTTEMPLATE.FROM_TEMPLATE(\"IS THIS A FUNNY JOKE? {JOKE}\")COMPOSED_CHAIN = {\"JOKE\": CHAIN} | ANALYSIS_PROMPT | MODEL | STROUTPUTPARSER()COMPOSED_CHAIN.INVOKE({\"TOPIC\": \"BEARS\"})API REFERENCE:STROUTPUTPARSER\n",
      "'HAHA, THAT\\'S A CLEVER PLAY ON WORDS! USING \"POLAR\" TO IMPLY THE BEAR DISSOLVED OR BECAME POLAR/POLARIZED WHEN PUT IN WATER. NOT THE MOST HILARIOUS JOKE EVER, BUT IT HAS A CUTE, GROAN-WORTHY PUN THAT MAKES IT MILDLY AMUSING. I APPRECIATE A GOOD PUN OR WORDPLAY JOKE.'\n",
      "FUNCTIONS WILL ALSO BE COERCED INTO RUNNABLES, SO YOU CAN ADD CUSTOM LOGIC TO YOUR CHAINS TOO. THE BELOW CHAIN RESULTS IN THE SAME LOGICAL FLOW AS BEFORE:\n",
      "COMPOSED_CHAIN_WITH_LAMBDA = (    CHAIN    | (LAMBDA INPUT: {\"JOKE\": INPUT})    | ANALYSIS_PROMPT    | MODEL    | STROUTPUTPARSER())COMPOSED_CHAIN_WITH_LAMBDA.INVOKE({\"TOPIC\": \"BEETS\"})\n",
      "\"HAHA, THAT'S A CUTE AND PUNNY JOKE! I LIKE HOW IT PLAYS ON THE IDEA OF BEETS BLUSHING OR TURNING RED LIKE SOMEONE BLUSHING. FOOD PUNS CAN BE QUITE AMUSING. WHILE NOT A TOTAL KNEE-SLAPPER, IT'S A LIGHT-HEARTED, GROAN-WORTHY DAD JOKE THAT WOULD MAKE ME CHUCKLE AND SHAKE MY HEAD. SIMPLE VEGETABLE HUMOR!\"\n",
      "HOWEVER, KEEP IN MIND THAT USING FUNCTIONS LIKE THIS MAY INTERFERE WITH OPERATIONS LIKE STREAMING. SEE THIS SECTION FOR MORE INFORMATION.\n",
      "THE .PIPE() METHOD​\n",
      "WE COULD ALSO COMPOSE THE SAME SEQUENCE USING THE .PIPE() METHOD. HERE'S WHAT THAT LOOKS LIKE:\n",
      "FROM LANGCHAIN_CORE.RUNNABLES IMPORT RUNNABLEPARALLELCOMPOSED_CHAIN_WITH_PIPE = (    RUNNABLEPARALLEL({\"JOKE\": CHAIN})    .PIPE(ANALYSIS_PROMPT)    .PIPE(MODEL)    .PIPE(STROUTPUTPARSER()))COMPOSED_CHAIN_WITH_PIPE.INVOKE({\"TOPIC\": \"BATTLESTAR GALACTICA\"})API REFERENCE:RUNNABLEPARALLEL\n",
      "\"I CANNOT REPRODUCE ANY COPYRIGHTED MATERIAL VERBATIM, BUT I CAN TRY TO ANALYZE THE HUMOR IN THE JOKE YOU PROVIDED WITHOUT QUOTING IT DIRECTLY.\\N\\NTHE JOKE PLAYS ON THE IDEA THAT THE CYLON RAIDERS, WHO ARE THE ANTAGONISTS IN THE BATTLESTAR GALACTICA UNIVERSE, FAILED TO LOCATE THE HUMAN SURVIVORS AFTER ATTACKING THEIR HOME PLANETS (THE TWELVE COLONIES) DUE TO USING AN OUTDATED AND POORLY PERFORMING OPERATING SYSTEM (WINDOWS VISTA) FOR THEIR TARGETING SYSTEMS.\\N\\NTHE HUMOR STEMS FROM THE JUXTAPOSITION OF A FUTURISTIC SCIENCE FICTION SETTING WITH A RELATABLE REAL-WORLD FRUSTRATION – THE USE OF BUGGY, SLOW, OR UNRELIABLE SOFTWARE OR TECHNOLOGY. IT POKES FUN AT THE PERCEIVED INADEQUACIES OF WINDOWS VISTA, WHICH WAS WIDELY CRITICIZED FOR ITS PERFORMANCE ISSUES AND OTHER PROBLEMS WHEN IT WAS RELEASED.\\N\\NBY ATTRIBUTING THE CYLONS' FAILURE TO LOCATE THE HUMANS TO THEIR USE OF VISTA, THE JOKE CREATES AN AMUSING AND UNEXPECTED CONNECTION BETWEEN A FICTIONAL ADVANCED RACE OF ROBOTS AND A FAMILIAR TECHNOLOGICAL ANNOYANCE EXPERIENCED BY MANY PEOPLE IN THE REAL WORLD.\\N\\NOVERALL, THE JOKE RELIES ON INCONGRUITY AND RELATABILITY TO GENERATE HUMOR, BUT WITHOUT REPRODUCING ANY COPYRIGHTED MATERIAL DIRECTLY.\"\n",
      "OR THE ABBREVIATED:\n",
      "COMPOSED_CHAIN_WITH_PIPE = RUNNABLEPARALLEL({\"JOKE\": CHAIN}).PIPE(    ANALYSIS_PROMPT, MODEL, STROUTPUTPARSER())\n",
      "RELATED​\n",
      "\n",
      "STREAMING: CHECK OUT THE STREAMING GUIDE TO UNDERSTAND THE STREAMING BEHAVIOR OF A CHAIN\n",
      "EDIT THIS PAGEWAS THIS PAGE HELPFUL?PREVIOUSHOW TO SPLIT TEXT BASED ON SEMANTIC SIMILARITYNEXTHOW TO SAVE AND LOAD LANGCHAIN OBJECTSTHE PIPE OPERATOR: |COERCIONTHE .PIPE() METHODRELATEDCOMMUNITYTWITTERGITHUBORGANIZATIONPYTHONJS/TSMOREHOMEPAGEBLOGYOUTUBECOPYRIGHT © 2025 LANGCHAIN, INC.\n",
      "\n",
      "\n",
      "          -------\n",
      "\n",
      "          THE PREVIOUS CODE ATTEMPT FAILED WITH THE FOLLOWING ERROR:\n",
      "          NAME 'QUERY_DATABASE' IS NOT DEFINED\n",
      "\n",
      "          YOUR CODING TASK:\n",
      "          HOW CAN I CREATE A LCEL CHAIN THAT QUERIES A SQL DATABASE?\n",
      "\n",
      "          PREVIOUS CODE ATTEMPT:\n",
      "          HERE IS A WORKING EXAMPLE OF HOW TO CREATE A LCEL CHAIN THAT QUERIES A SQL DATABASE USING LANGCHAIN. PLEASE NOTE THAT THE PREVIOUS ATTEMPT'S ERROR IS DUE TO SQLDATABASECHAIN NOT BEING AVAILABLE. SINCE LCEL ALLOWS FOR CHAINING BETWEEN VARIOUS COMPONENTS LIKE PROMPTS, MODELS, AND OUTPUT PARSERS, WE CAN USE AN ALTERNATIVE WAY TO EXECUTE SQL QUERIES WITHIN A LANGCHAIN PIPELINE.\n",
      "          FROM LANGCHAIN_CORE.PROMPTS IMPORT CHATPROMPTTEMPLATE\n",
      "FROM LANGCHAIN_CORE.OUTPUT_PARSERS IMPORT STROUTPUTPARSER\n",
      "FROM LANGCHAIN.CHAT_MODELS IMPORT INIT_CHAT_MODEL\n",
      "FROM SQLALCHEMY IMPORT CREATE_ENGINE, TEXT\n",
      "\n",
      "          CONNECTION_STRING = 'SQLITE:///EXAMPLE.DB'  # MODIFY THIS CONNECTION STRING TO MATCH YOUR SQL DATABASE\n",
      "DEF QUERY_DATABASE(QUERY):\n",
      "    ENGINE = CREATE_ENGINE(CONNECTION_STRING)\n",
      "    WITH ENGINE.CONNECT() AS CONNECTION:\n",
      "        RESULT = CONNECTION.EXECUTE(TEXT(QUERY))\n",
      "        RETURN STR([ROW FOR ROW IN RESULT])\n",
      "\n",
      "PROMPT = CHATPROMPTTEMPLATE.FROM_TEMPLATE('WHAT DATA DO YOU NEED FROM THE DATABASE?')\n",
      "MODEL = INIT_CHAT_MODEL('LLAMA3-8B-8192', MODEL_PROVIDER='GROQ')\n",
      "OUTPUT_PARSER = STROUTPUTPARSER()\n",
      "\n",
      "CHAIN = PROMPT | MODEL | (LAMBDA INPUT: QUERY_DATABASE(INPUT.GET('QUERY'))) | OUTPUT_PARSER\n",
      "\n",
      "RESULT = CHAIN.INVOKE({'QUERY': 'SELECT * FROM USERS WHERE AGE > 30;'})\n",
      "PRINT(RESULT)\n",
      "\n",
      "          ANSWER WITH A DESCRIPTION OF THE CODE SOLUTION, FOLLOWED BY THE IMPORTS, AND FINALLY THE FUNCTIONING CODE BLOCK.\n",
      "          ENSURE ALL IMPORTS ARE CORRECT AND THE CODE IS EXECUTABLE.]: 2025-03-13 15:39:36.413390\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:39:36][🤖 AGENT 'CODING ASSISTANT' STARTED TASK]: 2025-03-13 15:39:36.414344\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:39:36][🤖 LLM CALL STARTED]: 2025-03-13 15:39:36.414503\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:39:49][✅ LLM CALL COMPLETED]: 2025-03-13 15:39:49.473445\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:39:49][✅ AGENT 'CODING ASSISTANT' COMPLETED TASK]: 2025-03-13 15:39:49.474566\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:39:49][✅ TASK COMPLETED: YOU ARE A CODING ASSISTANT WITH EXPERTISE IN LCEL, LANGCHAIN EXPRESSION LANGUAGE.\n",
      "          HERE IS A FULL SET OF LCEL DOCUMENTATION:\n",
      "          -------\n",
      "          \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "HOW TO CHAIN RUNNABLES | 🦜️🔗 LANGCHAIN\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "SKIP TO MAIN CONTENTJOIN US AT  INTERRUPT: THE AGENT AI CONFERENCE BY LANGCHAIN ON MAY 13 & 14 IN SAN FRANCISCO!INTEGRATIONSAPI REFERENCEMORECONTRIBUTINGPEOPLEERROR REFERENCELANGSMITHLANGGRAPHLANGCHAIN HUBLANGCHAIN JS/TSV0.3V0.3V0.2V0.1💬SEARCHINTRODUCTIONTUTORIALSBUILD A QUESTION ANSWERING APPLICATION OVER A GRAPH DATABASETUTORIALSBUILD A SIMPLE LLM APPLICATION WITH CHAT MODELS AND PROMPT TEMPLATESBUILD A CHATBOTBUILD A RETRIEVAL AUGMENTED GENERATION (RAG) APP: PART 2BUILD AN EXTRACTION CHAINBUILD AN AGENTTAGGINGBUILD A RETRIEVAL AUGMENTED GENERATION (RAG) APP: PART 1BUILD A SEMANTIC SEARCH ENGINEBUILD A QUESTION/ANSWERING SYSTEM OVER SQL DATASUMMARIZE TEXTHOW-TO GUIDESHOW-TO GUIDESHOW TO USE TOOLS IN A CHAINHOW TO USE A VECTORSTORE AS A RETRIEVERHOW TO ADD MEMORY TO CHATBOTSHOW TO USE EXAMPLE SELECTORSHOW TO ADD A SEMANTIC LAYER OVER GRAPH DATABASEHOW TO INVOKE RUNNABLES IN PARALLELHOW TO STREAM CHAT MODEL RESPONSESHOW TO ADD DEFAULT INVOCATION ARGS TO A RUNNABLEHOW TO ADD RETRIEVAL TO CHATBOTSHOW TO USE FEW SHOT EXAMPLES IN CHAT MODELSHOW TO DO TOOL/FUNCTION CALLINGHOW TO INSTALL LANGCHAIN PACKAGESHOW TO ADD EXAMPLES TO THE PROMPT FOR QUERY ANALYSISHOW TO USE FEW SHOT EXAMPLESHOW TO RUN CUSTOM FUNCTIONSHOW TO USE OUTPUT PARSERS TO PARSE AN LLM RESPONSE INTO STRUCTURED FORMATHOW TO HANDLE CASES WHERE NO QUERIES ARE GENERATEDHOW TO ROUTE BETWEEN SUB-CHAINSHOW TO RETURN STRUCTURED DATA FROM A MODELHOW TO SUMMARIZE TEXT THROUGH PARALLELIZATIONHOW TO SUMMARIZE TEXT THROUGH ITERATIVE REFINEMENTHOW TO SUMMARIZE TEXT IN A SINGLE LLM CALLHOW TO USE TOOLKITSHOW TO ADD AD-HOC TOOL CALLING CAPABILITY TO LLMS AND CHAT MODELSBUILD AN AGENT WITH AGENTEXECUTOR (LEGACY)HOW TO CONSTRUCT KNOWLEDGE GRAPHSHOW TO PARTIALLY FORMAT PROMPT TEMPLATESHOW TO HANDLE MULTIPLE QUERIES WHEN DOING QUERY ANALYSISHOW TO USE BUILT-IN TOOLS AND TOOLKITSHOW TO PASS THROUGH ARGUMENTS FROM ONE STEP TO THE NEXTHOW TO COMPOSE PROMPTS TOGETHERHOW TO HANDLE MULTIPLE RETRIEVERS WHEN DOING QUERY ANALYSISHOW TO ADD VALUES TO A CHAIN'S STATEHOW TO CONSTRUCT FILTERS FOR QUERY ANALYSISHOW TO CONFIGURE RUNTIME CHAIN INTERNALSHOW DEAL WITH HIGH CARDINALITY CATEGORICALS WHEN DOING QUERY ANALYSISCUSTOM DOCUMENT LOADERHOW TO USE THE MULTIQUERYRETRIEVERHOW TO ADD SCORES TO RETRIEVER RESULTSCACHINGHOW TO USE CALLBACKS IN ASYNC ENVIRONMENTSHOW TO ATTACH CALLBACKS TO A RUNNABLEHOW TO PROPAGATE CALLBACKS  CONSTRUCTORHOW TO DISPATCH CUSTOM CALLBACK EVENTSHOW TO PASS CALLBACKS IN AT RUNTIMEHOW TO SPLIT BY CHARACTERHOW TO CACHE CHAT MODEL RESPONSESHOW TO HANDLE RATE LIMITSHOW TO INIT ANY MODEL IN ONE LINEHOW TO TRACK TOKEN USAGE IN CHATMODELSHOW TO ADD TOOLS TO CHATBOTSHOW TO SPLIT CODEHOW TO DO RETRIEVAL WITH CONTEXTUAL COMPRESSIONHOW TO CONVERT RUNNABLES TO TOOLSHOW TO CREATE CUSTOM CALLBACK HANDLERSHOW TO CREATE A CUSTOM CHAT MODEL CLASSCUSTOM EMBEDDINGSHOW TO CREATE A CUSTOM LLM CLASSCUSTOM RETRIEVERHOW TO CREATE TOOLSHOW TO DEBUG YOUR LLM APPSHOW TO LOAD CSVSHOW TO LOAD DOCUMENTS FROM A DIRECTORYHOW TO LOAD HTMLHOW TO LOAD JSONHOW TO LOAD MARKDOWNHOW TO LOAD MICROSOFT OFFICE FILESHOW TO LOAD PDFSHOW TO LOAD WEB PAGESHOW TO CREATE A DYNAMIC (SELF-CONSTRUCTING) CHAINTEXT EMBEDDING MODELSHOW TO COMBINE RESULTS FROM MULTIPLE RETRIEVERSHOW TO SELECT EXAMPLES FROM A LANGSMITH DATASETHOW TO SELECT EXAMPLES BY LENGTHHOW TO SELECT EXAMPLES BY MAXIMAL MARGINAL RELEVANCE (MMR)HOW TO SELECT EXAMPLES BY N-GRAM OVERLAPHOW TO SELECT EXAMPLES BY SIMILARITYHOW TO USE REFERENCE EXAMPLES WHEN DOING EXTRACTIONHOW TO HANDLE LONG TEXT WHEN DOING EXTRACTIONHOW TO USE PROMPTING ALONE (NO TOOL CALLING) TO DO EXTRACTIONHOW TO ADD FALLBACKS TO A RUNNABLEHOW TO FILTER MESSAGESHYBRID SEARCHHOW TO USE THE LANGCHAIN INDEXING APIHOW TO INSPECT RUNNABLESLANGCHAIN EXPRESSION LANGUAGE CHEATSHEETHOW TO CACHE LLM RESPONSESHOW TO TRACK TOKEN USAGE FOR LLMSRUN MODELS LOCALLYHOW TO GET LOG PROBABILITIESHOW TO REORDER RETRIEVED RESULTS TO MITIGATE THE \"LOST IN THE MIDDLE\" EFFECTHOW TO SPLIT MARKDOWN BY HEADERSHOW TO MERGE CONSECUTIVE MESSAGES OF THE SAME TYPEHOW TO ADD MESSAGE HISTORYHOW TO MIGRATE FROM LEGACY LANGCHAIN AGENTS TO LANGGRAPHHOW TO RETRIEVE USING MULTIPLE VECTORS PER DOCUMENTHOW TO PASS MULTIMODAL DATA DIRECTLY TO MODELSHOW TO USE MULTIMODAL PROMPTSHOW TO CREATE A CUSTOM OUTPUT PARSERHOW TO USE THE OUTPUT-FIXING PARSERHOW TO PARSE JSON OUTPUTHOW TO RETRY WHEN A PARSING ERROR OCCURSHOW TO PARSE TEXT FROM MESSAGE OBJECTSHOW TO PARSE XML OUTPUTHOW TO PARSE YAML OUTPUTHOW TO USE THE PARENT DOCUMENT RETRIEVERHOW TO USE LANGCHAIN WITH DIFFERENT PYDANTIC VERSIONSHOW TO ADD CHAT HISTORYHOW TO GET A RAG APPLICATION TO ADD CITATIONSHOW TO DO PER-USER RETRIEVALHOW TO GET YOUR RAG APPLICATION TO RETURN SOURCESHOW TO STREAM RESULTS FROM YOUR RAG APPLICATIONHOW TO SPLIT JSON DATAHOW TO RECURSIVELY SPLIT TEXT BY CHARACTERSRESPONSE METADATAHOW TO PASS RUNTIME SECRETS TO RUNNABLESHOW TO DO \"SELF-QUERYING\" RETRIEVALHOW TO SPLIT TEXT BASED ON SEMANTIC SIMILARITYHOW TO CHAIN RUNNABLESHOW TO SAVE AND LOAD LANGCHAIN OBJECTSHOW TO SPLIT TEXT BY TOKENSHOW TO SPLIT HTMLHOW TO DO QUESTION ANSWERING OVER CSVSHOW TO DEAL WITH LARGE DATABASES WHEN DOING SQL QUESTION-ANSWERINGHOW TO BETTER PROMPT WHEN DOING SQL QUESTION-ANSWERINGHOW TO DO QUERY VALIDATION AS PART OF SQL QUESTION-ANSWERINGHOW TO STREAM RUNNABLESHOW TO STREAM RESPONSES FROM AN LLMHOW TO USE A TIME-WEIGHTED VECTOR STORE RETRIEVERHOW TO RETURN ARTIFACTS FROM A TOOLHOW TO USE CHAT MODELS TO CALL TOOLSHOW TO DISABLE PARALLEL TOOL CALLINGHOW TO FORCE MODELS TO CALL A TOOLHOW TO ACCESS THE RUNNABLECONFIG FROM A TOOLHOW TO PASS TOOL OUTPUTS TO CHAT MODELSHOW TO PASS RUN TIME VALUES TO TOOLSHOW TO STREAM EVENTS FROM A TOOLHOW TO STREAM TOOL CALLSHOW TO CONVERT TOOLS TO OPENAI FUNCTIONSHOW TO HANDLE TOOL ERRORSHOW TO USE FEW-SHOT PROMPTING WITH TOOL CALLINGHOW TO ADD A HUMAN-IN-THE-LOOP FOR TOOLSHOW TO BIND MODEL-SPECIFIC TOOLSHOW TO TRIM MESSAGESHOW TO CREATE AND QUERY VECTOR STORESCONCEPTUAL GUIDEAGENTSARCHITECTUREASYNC PROGRAMMING WITH LANGCHAINCALLBACKSCHAT HISTORYCHAT MODELSDOCUMENT LOADERSEMBEDDING MODELSEVALUATIONEXAMPLE SELECTORSFEW-SHOT PROMPTINGCONCEPTUAL GUIDEKEY-VALUE STORESLANGCHAIN EXPRESSION LANGUAGE (LCEL)MESSAGESMULTIMODALITYOUTPUT PARSERSPROMPT TEMPLATESRETRIEVAL AUGMENTED GENERATION (RAG)RETRIEVALRETRIEVERSRUNNABLE INTERFACESTREAMINGSTRUCTURED OUTPUTSTESTINGSTRING-IN, STRING-OUT LLMSTEXT SPLITTERSTOKENSTOOL CALLINGTOOLSTRACINGVECTOR STORESWHY LANGCHAIN?ECOSYSTEM🦜🛠️ LANGSMITH🦜🕸️ LANGGRAPHVERSIONSV0.3V0.2PYDANTIC COMPATIBILITYMIGRATING FROM V0.0 CHAINSHOW TO MIGRATE FROM V0.0 CHAINSMIGRATING FROM CONSTITUTIONALCHAINMIGRATING FROM CONVERSATIONALCHAINMIGRATING FROM CONVERSATIONALRETRIEVALCHAINMIGRATING FROM LLMCHAINMIGRATING FROM LLMMATHCHAINMIGRATING FROM LLMROUTERCHAINMIGRATING FROM MAPREDUCEDOCUMENTSCHAINMIGRATING FROM MAPRERANKDOCUMENTSCHAINMIGRATING FROM MULTIPROMPTCHAINMIGRATING FROM REFINEDOCUMENTSCHAINMIGRATING FROM RETRIEVALQAMIGRATING FROM STUFFDOCUMENTSCHAINUPGRADING TO LANGGRAPH MEMORYHOW TO MIGRATE TO LANGGRAPH MEMORYHOW TO USE BASECHATMESSAGEHISTORY WITH LANGGRAPHMIGRATING OFF CONVERSATIONBUFFERMEMORY OR CONVERSATIONSTRINGBUFFERMEMORYMIGRATING OFF CONVERSATIONBUFFERWINDOWMEMORY OR CONVERSATIONTOKENBUFFERMEMORYMIGRATING OFF CONVERSATIONSUMMARYMEMORY OR CONVERSATIONSUMMARYBUFFERMEMORYA LONG-TERM MEMORY AGENTRELEASE POLICYSECURITY POLICYHOW-TO GUIDESHOW TO CHAIN RUNNABLESON THIS PAGEHOW TO CHAIN RUNNABLES\n",
      "PREREQUISITESTHIS GUIDE ASSUMES FAMILIARITY WITH THE FOLLOWING CONCEPTS:\n",
      "LANGCHAIN EXPRESSION LANGUAGE (LCEL)\n",
      "PROMPT TEMPLATES\n",
      "CHAT MODELS\n",
      "OUTPUT PARSER\n",
      "\n",
      "ONE POINT ABOUT LANGCHAIN EXPRESSION LANGUAGE IS THAT ANY TWO RUNNABLES CAN BE \"CHAINED\" TOGETHER INTO SEQUENCES. THE OUTPUT OF THE PREVIOUS RUNNABLE'S .INVOKE() CALL IS PASSED AS INPUT TO THE NEXT RUNNABLE. THIS CAN BE DONE USING THE PIPE OPERATOR (|), OR THE MORE EXPLICIT .PIPE() METHOD, WHICH DOES THE SAME THING.\n",
      "THE RESULTING RUNNABLESEQUENCE IS ITSELF A RUNNABLE, WHICH MEANS IT CAN BE INVOKED, STREAMED, OR FURTHER CHAINED JUST LIKE ANY OTHER RUNNABLE. ADVANTAGES OF CHAINING RUNNABLES IN THIS WAY ARE EFFICIENT STREAMING (THE SEQUENCE WILL STREAM OUTPUT AS SOON AS IT IS AVAILABLE), AND DEBUGGING AND TRACING WITH TOOLS LIKE LANGSMITH.\n",
      "THE PIPE OPERATOR: |​\n",
      "TO SHOW OFF HOW THIS WORKS, LET'S GO THROUGH AN EXAMPLE. WE'LL WALK THROUGH A COMMON PATTERN IN LANGCHAIN: USING A PROMPT TEMPLATE TO FORMAT INPUT INTO A CHAT MODEL, AND FINALLY CONVERTING THE CHAT MESSAGE OUTPUT INTO A STRING WITH AN OUTPUT PARSER.\n",
      "\n",
      "SELECT CHAT MODEL:GROQ▾GROQOPENAIANTHROPICAZUREGOOGLE VERTEXAWSCOHERENVIDIAFIREWORKS AIMISTRAL AITOGETHER AIIBM WATSONXDATABRICKSXAIPIP INSTALL -QU \"LANGCHAIN[GROQ]\"IMPORT GETPASSIMPORT OSIF NOT OS.ENVIRON.GET(\"GROQ_API_KEY\"):  OS.ENVIRON[\"GROQ_API_KEY\"] = GETPASS.GETPASS(\"ENTER API KEY FOR GROQ: \")FROM LANGCHAIN.CHAT_MODELS IMPORT INIT_CHAT_MODELMODEL = INIT_CHAT_MODEL(\"LLAMA3-8B-8192\", MODEL_PROVIDER=\"GROQ\")\n",
      "FROM LANGCHAIN_CORE.OUTPUT_PARSERS IMPORT STROUTPUTPARSERFROM LANGCHAIN_CORE.PROMPTS IMPORT CHATPROMPTTEMPLATEPROMPT = CHATPROMPTTEMPLATE.FROM_TEMPLATE(\"TELL ME A JOKE ABOUT {TOPIC}\")CHAIN = PROMPT | MODEL | STROUTPUTPARSER()API REFERENCE:STROUTPUTPARSER | CHATPROMPTTEMPLATE\n",
      "PROMPTS AND MODELS ARE BOTH RUNNABLE, AND THE OUTPUT TYPE FROM THE PROMPT CALL IS THE SAME AS THE INPUT TYPE OF THE CHAT MODEL, SO WE CAN CHAIN THEM TOGETHER. WE CAN THEN INVOKE THE RESULTING SEQUENCE LIKE ANY OTHER RUNNABLE:\n",
      "CHAIN.INVOKE({\"TOPIC\": \"BEARS\"})\n",
      "\"HERE'S A BEAR JOKE FOR YOU:\\N\\NWHY DID THE BEAR DISSOLVE IN WATER?\\NBECAUSE IT WAS A POLAR BEAR!\"\n",
      "COERCION​\n",
      "WE CAN EVEN COMBINE THIS CHAIN WITH MORE RUNNABLES TO CREATE ANOTHER CHAIN. THIS MAY INVOLVE SOME INPUT/OUTPUT FORMATTING USING OTHER TYPES OF RUNNABLES, DEPENDING ON THE REQUIRED INPUTS AND OUTPUTS OF THE CHAIN COMPONENTS.\n",
      "FOR EXAMPLE, LET'S SAY WE WANTED TO COMPOSE THE JOKE GENERATING CHAIN WITH ANOTHER CHAIN THAT EVALUATES WHETHER OR NOT THE GENERATED JOKE WAS FUNNY.\n",
      "WE WOULD NEED TO BE CAREFUL WITH HOW WE FORMAT THE INPUT INTO THE NEXT CHAIN. IN THE BELOW EXAMPLE, THE DICT IN THE CHAIN IS AUTOMATICALLY PARSED AND CONVERTED INTO A RUNNABLEPARALLEL, WHICH RUNS ALL OF ITS VALUES IN PARALLEL AND RETURNS A DICT WITH THE RESULTS.\n",
      "THIS HAPPENS TO BE THE SAME FORMAT THE NEXT PROMPT TEMPLATE EXPECTS. HERE IT IS IN ACTION:\n",
      "FROM LANGCHAIN_CORE.OUTPUT_PARSERS IMPORT STROUTPUTPARSERANALYSIS_PROMPT = CHATPROMPTTEMPLATE.FROM_TEMPLATE(\"IS THIS A FUNNY JOKE? {JOKE}\")COMPOSED_CHAIN = {\"JOKE\": CHAIN} | ANALYSIS_PROMPT | MODEL | STROUTPUTPARSER()COMPOSED_CHAIN.INVOKE({\"TOPIC\": \"BEARS\"})API REFERENCE:STROUTPUTPARSER\n",
      "'HAHA, THAT\\'S A CLEVER PLAY ON WORDS! USING \"POLAR\" TO IMPLY THE BEAR DISSOLVED OR BECAME POLAR/POLARIZED WHEN PUT IN WATER. NOT THE MOST HILARIOUS JOKE EVER, BUT IT HAS A CUTE, GROAN-WORTHY PUN THAT MAKES IT MILDLY AMUSING. I APPRECIATE A GOOD PUN OR WORDPLAY JOKE.'\n",
      "FUNCTIONS WILL ALSO BE COERCED INTO RUNNABLES, SO YOU CAN ADD CUSTOM LOGIC TO YOUR CHAINS TOO. THE BELOW CHAIN RESULTS IN THE SAME LOGICAL FLOW AS BEFORE:\n",
      "COMPOSED_CHAIN_WITH_LAMBDA = (    CHAIN    | (LAMBDA INPUT: {\"JOKE\": INPUT})    | ANALYSIS_PROMPT    | MODEL    | STROUTPUTPARSER())COMPOSED_CHAIN_WITH_LAMBDA.INVOKE({\"TOPIC\": \"BEETS\"})\n",
      "\"HAHA, THAT'S A CUTE AND PUNNY JOKE! I LIKE HOW IT PLAYS ON THE IDEA OF BEETS BLUSHING OR TURNING RED LIKE SOMEONE BLUSHING. FOOD PUNS CAN BE QUITE AMUSING. WHILE NOT A TOTAL KNEE-SLAPPER, IT'S A LIGHT-HEARTED, GROAN-WORTHY DAD JOKE THAT WOULD MAKE ME CHUCKLE AND SHAKE MY HEAD. SIMPLE VEGETABLE HUMOR!\"\n",
      "HOWEVER, KEEP IN MIND THAT USING FUNCTIONS LIKE THIS MAY INTERFERE WITH OPERATIONS LIKE STREAMING. SEE THIS SECTION FOR MORE INFORMATION.\n",
      "THE .PIPE() METHOD​\n",
      "WE COULD ALSO COMPOSE THE SAME SEQUENCE USING THE .PIPE() METHOD. HERE'S WHAT THAT LOOKS LIKE:\n",
      "FROM LANGCHAIN_CORE.RUNNABLES IMPORT RUNNABLEPARALLELCOMPOSED_CHAIN_WITH_PIPE = (    RUNNABLEPARALLEL({\"JOKE\": CHAIN})    .PIPE(ANALYSIS_PROMPT)    .PIPE(MODEL)    .PIPE(STROUTPUTPARSER()))COMPOSED_CHAIN_WITH_PIPE.INVOKE({\"TOPIC\": \"BATTLESTAR GALACTICA\"})API REFERENCE:RUNNABLEPARALLEL\n",
      "\"I CANNOT REPRODUCE ANY COPYRIGHTED MATERIAL VERBATIM, BUT I CAN TRY TO ANALYZE THE HUMOR IN THE JOKE YOU PROVIDED WITHOUT QUOTING IT DIRECTLY.\\N\\NTHE JOKE PLAYS ON THE IDEA THAT THE CYLON RAIDERS, WHO ARE THE ANTAGONISTS IN THE BATTLESTAR GALACTICA UNIVERSE, FAILED TO LOCATE THE HUMAN SURVIVORS AFTER ATTACKING THEIR HOME PLANETS (THE TWELVE COLONIES) DUE TO USING AN OUTDATED AND POORLY PERFORMING OPERATING SYSTEM (WINDOWS VISTA) FOR THEIR TARGETING SYSTEMS.\\N\\NTHE HUMOR STEMS FROM THE JUXTAPOSITION OF A FUTURISTIC SCIENCE FICTION SETTING WITH A RELATABLE REAL-WORLD FRUSTRATION – THE USE OF BUGGY, SLOW, OR UNRELIABLE SOFTWARE OR TECHNOLOGY. IT POKES FUN AT THE PERCEIVED INADEQUACIES OF WINDOWS VISTA, WHICH WAS WIDELY CRITICIZED FOR ITS PERFORMANCE ISSUES AND OTHER PROBLEMS WHEN IT WAS RELEASED.\\N\\NBY ATTRIBUTING THE CYLONS' FAILURE TO LOCATE THE HUMANS TO THEIR USE OF VISTA, THE JOKE CREATES AN AMUSING AND UNEXPECTED CONNECTION BETWEEN A FICTIONAL ADVANCED RACE OF ROBOTS AND A FAMILIAR TECHNOLOGICAL ANNOYANCE EXPERIENCED BY MANY PEOPLE IN THE REAL WORLD.\\N\\NOVERALL, THE JOKE RELIES ON INCONGRUITY AND RELATABILITY TO GENERATE HUMOR, BUT WITHOUT REPRODUCING ANY COPYRIGHTED MATERIAL DIRECTLY.\"\n",
      "OR THE ABBREVIATED:\n",
      "COMPOSED_CHAIN_WITH_PIPE = RUNNABLEPARALLEL({\"JOKE\": CHAIN}).PIPE(    ANALYSIS_PROMPT, MODEL, STROUTPUTPARSER())\n",
      "RELATED​\n",
      "\n",
      "STREAMING: CHECK OUT THE STREAMING GUIDE TO UNDERSTAND THE STREAMING BEHAVIOR OF A CHAIN\n",
      "EDIT THIS PAGEWAS THIS PAGE HELPFUL?PREVIOUSHOW TO SPLIT TEXT BASED ON SEMANTIC SIMILARITYNEXTHOW TO SAVE AND LOAD LANGCHAIN OBJECTSTHE PIPE OPERATOR: |COERCIONTHE .PIPE() METHODRELATEDCOMMUNITYTWITTERGITHUBORGANIZATIONPYTHONJS/TSMOREHOMEPAGEBLOGYOUTUBECOPYRIGHT © 2025 LANGCHAIN, INC.\n",
      "\n",
      "\n",
      "          -------\n",
      "\n",
      "          THE PREVIOUS CODE ATTEMPT FAILED WITH THE FOLLOWING ERROR:\n",
      "          NAME 'QUERY_DATABASE' IS NOT DEFINED\n",
      "\n",
      "          YOUR CODING TASK:\n",
      "          HOW CAN I CREATE A LCEL CHAIN THAT QUERIES A SQL DATABASE?\n",
      "\n",
      "          PREVIOUS CODE ATTEMPT:\n",
      "          HERE IS A WORKING EXAMPLE OF HOW TO CREATE A LCEL CHAIN THAT QUERIES A SQL DATABASE USING LANGCHAIN. PLEASE NOTE THAT THE PREVIOUS ATTEMPT'S ERROR IS DUE TO SQLDATABASECHAIN NOT BEING AVAILABLE. SINCE LCEL ALLOWS FOR CHAINING BETWEEN VARIOUS COMPONENTS LIKE PROMPTS, MODELS, AND OUTPUT PARSERS, WE CAN USE AN ALTERNATIVE WAY TO EXECUTE SQL QUERIES WITHIN A LANGCHAIN PIPELINE.\n",
      "          FROM LANGCHAIN_CORE.PROMPTS IMPORT CHATPROMPTTEMPLATE\n",
      "FROM LANGCHAIN_CORE.OUTPUT_PARSERS IMPORT STROUTPUTPARSER\n",
      "FROM LANGCHAIN.CHAT_MODELS IMPORT INIT_CHAT_MODEL\n",
      "FROM SQLALCHEMY IMPORT CREATE_ENGINE, TEXT\n",
      "\n",
      "          CONNECTION_STRING = 'SQLITE:///EXAMPLE.DB'  # MODIFY THIS CONNECTION STRING TO MATCH YOUR SQL DATABASE\n",
      "DEF QUERY_DATABASE(QUERY):\n",
      "    ENGINE = CREATE_ENGINE(CONNECTION_STRING)\n",
      "    WITH ENGINE.CONNECT() AS CONNECTION:\n",
      "        RESULT = CONNECTION.EXECUTE(TEXT(QUERY))\n",
      "        RETURN STR([ROW FOR ROW IN RESULT])\n",
      "\n",
      "PROMPT = CHATPROMPTTEMPLATE.FROM_TEMPLATE('WHAT DATA DO YOU NEED FROM THE DATABASE?')\n",
      "MODEL = INIT_CHAT_MODEL('LLAMA3-8B-8192', MODEL_PROVIDER='GROQ')\n",
      "OUTPUT_PARSER = STROUTPUTPARSER()\n",
      "\n",
      "CHAIN = PROMPT | MODEL | (LAMBDA INPUT: QUERY_DATABASE(INPUT.GET('QUERY'))) | OUTPUT_PARSER\n",
      "\n",
      "RESULT = CHAIN.INVOKE({'QUERY': 'SELECT * FROM USERS WHERE AGE > 30;'})\n",
      "PRINT(RESULT)\n",
      "\n",
      "          ANSWER WITH A DESCRIPTION OF THE CODE SOLUTION, FOLLOWED BY THE IMPORTS, AND FINALLY THE FUNCTIONING CODE BLOCK.\n",
      "          ENSURE ALL IMPORTS ARE CORRECT AND THE CODE IS EXECUTABLE.]: 2025-03-13 15:39:49.475029\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:39:49][✅ CREW 'CREW' COMPLETED, DCFAFFC0-E2D0-47E1-B5A8-134571F8CE0D]: 2025-03-13 15:39:49.479715\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:39:49][👍 FLOW METHOD FINISHED: 'RE_RUN_FIX']: 2025-03-13 15:39:49.480120\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:39:49][🤖 FLOW METHOD STARTED: 'RE_RE_RUN_CHECK']: 2025-03-13 15:39:49.480381\u001b[00m\n",
      "---CHECKING CODE---\n",
      "---CODE BLOCK CHECK: FAILED---\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:39:49][👍 FLOW METHOD FINISHED: 'RE_RE_RUN_CHECK']: 2025-03-13 15:39:49.500730\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:39:49][👍 FLOW FINISHED: 'CODEGENFLOW', 7179E483-D6ED-4FA5-B747-E1979B2D008B]: 2025-03-13 15:39:49.500938\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:39:49][🌊 FLOW CREATED: 'CODEGENFLOW']: 2025-03-13 15:39:49.515779\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:39:49][🤖 FLOW STARTED: 'CODEGENFLOW', 96129923-6FCB-4D86-972D-6FB93F6ABC18]: 2025-03-13 15:39:49.515988\u001b[00m\n",
      "\u001b[1m\u001b[35m Flow started with ID: 96129923-6fcb-4d86-972d-6fb93f6abc18\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:39:49][🤖 FLOW METHOD STARTED: 'GENERATE_CODE']: 2025-03-13 15:39:49.516121\u001b[00m\n",
      "---GENERATING CODE SOLUTION---\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:39:49][🚀 CREW 'CREW' STARTED, 368F5772-413F-4BF5-BD01-847C2CD6098D]: 2025-03-13 15:39:49.517116\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:39:49][📋 TASK STARTED: ANSWER THE USER QUESTION BASED ON THE ABOVE PROVIDED DOCUMENTATION. ENSURE ANY CODE YOU PROVIDE CAN BE EXECUTED\n",
      "    WITH ALL REQUIRED IMPORTS AND VARIABLES DEFINED. STRUCTURE YOUR ANSWER:\n",
      "    1) A PREFIX DESCRIBING THE CODE SOLUTION\n",
      "    2) THE IMPORTS\n",
      "    3) THE FUNCTIONING CODE BLOCK\n",
      "\n",
      "    YOUR CODING TASK:\n",
      "    HOW DO I STRUCTURE OUTPUT OF AN LCEL CHAIN?\n",
      "    ]: 2025-03-13 15:39:49.518968\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:39:49][🤖 AGENT 'CODING ASSISTANT' STARTED TASK]: 2025-03-13 15:39:49.519320\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:39:49][🤖 LLM CALL STARTED]: 2025-03-13 15:39:49.519385\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:39:56][✅ LLM CALL COMPLETED]: 2025-03-13 15:39:56.018668\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:39:56][✅ AGENT 'CODING ASSISTANT' COMPLETED TASK]: 2025-03-13 15:39:56.019794\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:39:56][✅ TASK COMPLETED: ANSWER THE USER QUESTION BASED ON THE ABOVE PROVIDED DOCUMENTATION. ENSURE ANY CODE YOU PROVIDE CAN BE EXECUTED\n",
      "    WITH ALL REQUIRED IMPORTS AND VARIABLES DEFINED. STRUCTURE YOUR ANSWER:\n",
      "    1) A PREFIX DESCRIBING THE CODE SOLUTION\n",
      "    2) THE IMPORTS\n",
      "    3) THE FUNCTIONING CODE BLOCK\n",
      "\n",
      "    YOUR CODING TASK:\n",
      "    HOW DO I STRUCTURE OUTPUT OF AN LCEL CHAIN?\n",
      "    ]: 2025-03-13 15:39:56.020126\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:39:56][✅ CREW 'CREW' COMPLETED, 368F5772-413F-4BF5-BD01-847C2CD6098D]: 2025-03-13 15:39:56.024720\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:39:56][👍 FLOW METHOD FINISHED: 'GENERATE_CODE']: 2025-03-13 15:39:56.025039\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:39:56][🤖 FLOW METHOD STARTED: 'RUN_CHECK']: 2025-03-13 15:39:56.025181\u001b[00m\n",
      "---CHECKING CODE---\n",
      "Why did the bear go to the doctor?\n",
      "\n",
      "Because it had a grizzly cough!\n",
      "I see what you did there!\n",
      "\n",
      "While puns can be subjective, I think this one is a good example of a \"groan-inducing\" pun, which can be amusing in a guilty pleasure kind of way. The play on words with \"grizzly\" (a type of bear) and \"grisly\" (horrible or frightening) is clever, and the added pun on \"paws-itively terrible\" is a nice touch.\n",
      "\n",
      "The joke's humor also relies on the setup and delivery, which is well-executed. The use of \"Because it had a grizzly cough!\" as the punchline is unexpected and silly, which adds to the comedic effect.\n",
      "\n",
      "So, while it may not be a laugh-out-loud, tears-streaming-down-your-face kind of joke, it's definitely a fun and lighthearted pun that's likely to elicit a chuckle or a smile. Well done!\n",
      "---NO CODE TEST FAILURES---\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:39:57][👍 FLOW METHOD FINISHED: 'RUN_CHECK']: 2025-03-13 15:39:57.412011\u001b[00m\n",
      "\u001b[1m\u001b[94m \n",
      "[2025-03-13 15:39:57][👍 FLOW FINISHED: 'CODEGENFLOW', 96129923-6FCB-4D86-972D-6FB93F6ABC18]: 2025-03-13 15:39:57.415911\u001b[00m\n",
      "Why did the bear go to the doctor?\n",
      "\n",
      "Because it had a grizzly cough!\n",
      "I think it's a paws-itively hilarious joke! The play on words with \"grizzly\" (meaning fierce and aggressive, but also referencing the bear's species) and \"cough\" is clever and unexpected, making it a fun and silly joke. Well done!\n",
      "\n",
      "Evaluation Results:\n",
      "                                             question  import_check  \\\n",
      "0   How can I use a prompt and model to create a c...             1   \n",
      "1   How can I add memory to an arbitrary chain usi...             1   \n",
      "2   How can I make the output of my LCEL chain a s...             1   \n",
      "3   How can I apply a custom function to one of th...             1   \n",
      "4   With a RAG chain in LCEL, why are documents re...             1   \n",
      "5      How can I configure the temperature of an LLM?             1   \n",
      "6   How can we apply a function call to an LLM in ...             1   \n",
      "7   How can I run two LCEL chains in parallel and ...             1   \n",
      "8   How can I directly pass a string to a runnable...             1   \n",
      "9   How can I use a custom function to route betwe...             1   \n",
      "10  How do I set up a retrieval-augmented generati...             1   \n",
      "11  How can I create a LCEL chain that queries a S...             1   \n",
      "12        How do I structure output of an LCEL chain?             1   \n",
      "\n",
      "    execution_check  \n",
      "0                 1  \n",
      "1                 0  \n",
      "2                 1  \n",
      "3                 1  \n",
      "4                 1  \n",
      "5                 1  \n",
      "6                 1  \n",
      "7                 1  \n",
      "8                 1  \n",
      "9                 0  \n",
      "10                0  \n",
      "11                0  \n",
      "12                1  \n"
     ]
    }
   ],
   "source": [
    "# Store evaluation results\n",
    "results = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    question = row[\"question\"]\n",
    "    # Run the workflow for each question\n",
    "    code_flow = CodeGenFlow()\n",
    "    code_flow.kickoff(inputs={\"question\": question})\n",
    "\n",
    "    # Run evaluations\n",
    "    import_check = check_import(code_flow.state.generation)\n",
    "    execution_check = check_execution(code_flow.state.generation)\n",
    "\n",
    "    # Store results\n",
    "    result = {\n",
    "        \"question\": question,\n",
    "        \"import_check\": import_check[\"score\"],\n",
    "        \"execution_check\": execution_check[\"score\"]\n",
    "    }\n",
    "    results.append(result)\n",
    "\n",
    "# Convert results to dataframe\n",
    "ca_df = pd.DataFrame(results)\n",
    "print(\"\\nEvaluation Results:\")\n",
    "print(ca_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "question",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "import_check",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "execution_check",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "e1abd8bc-19c0-4df8-94bc-13fa2dc84019",
       "rows": [
        [
         "0",
         "How can I use a prompt and model to create a custom RAG example?",
         "1",
         "1"
        ],
        [
         "1",
         "How can I add memory to an arbitrary chain using LangChain?",
         "1",
         "0"
        ],
        [
         "2",
         "How can I make the output of my LCEL chain a string?",
         "1",
         "1"
        ],
        [
         "3",
         "How can I apply a custom function to one of the chains?",
         "1",
         "1"
        ],
        [
         "4",
         "With a RAG chain in LCEL, why are documents required?",
         "1",
         "1"
        ],
        [
         "5",
         "How can I configure the temperature of an LLM?",
         "1",
         "1"
        ],
        [
         "6",
         "How can we apply a function call to an LLM in a chain?",
         "1",
         "1"
        ],
        [
         "7",
         "How can I run two LCEL chains in parallel and sequentially?",
         "1",
         "1"
        ],
        [
         "8",
         "How can I directly pass a string to a runnable chain?",
         "1",
         "1"
        ],
        [
         "9",
         "How can I use a custom function to route between two chains?",
         "1",
         "0"
        ],
        [
         "10",
         "How do I set up a retrieval-augmented generation agent?",
         "1",
         "0"
        ],
        [
         "11",
         "How can I create a LCEL chain that queries a SQL database?",
         "1",
         "0"
        ],
        [
         "12",
         "How do I structure output of an LCEL chain?",
         "1",
         "1"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 13
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>import_check</th>\n",
       "      <th>execution_check</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How can I use a prompt and model to create a c...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How can I add memory to an arbitrary chain usi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How can I make the output of my LCEL chain a s...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How can I apply a custom function to one of th...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>With a RAG chain in LCEL, why are documents re...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>How can I configure the temperature of an LLM?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How can we apply a function call to an LLM in ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How can I run two LCEL chains in parallel and ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>How can I directly pass a string to a runnable...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>How can I use a custom function to route betwe...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>How do I set up a retrieval-augmented generati...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>How can I create a LCEL chain that queries a S...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>How do I structure output of an LCEL chain?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             question  import_check  \\\n",
       "0   How can I use a prompt and model to create a c...             1   \n",
       "1   How can I add memory to an arbitrary chain usi...             1   \n",
       "2   How can I make the output of my LCEL chain a s...             1   \n",
       "3   How can I apply a custom function to one of th...             1   \n",
       "4   With a RAG chain in LCEL, why are documents re...             1   \n",
       "5      How can I configure the temperature of an LLM?             1   \n",
       "6   How can we apply a function call to an LLM in ...             1   \n",
       "7   How can I run two LCEL chains in parallel and ...             1   \n",
       "8   How can I directly pass a string to a runnable...             1   \n",
       "9   How can I use a custom function to route betwe...             1   \n",
       "10  How do I set up a retrieval-augmented generati...             1   \n",
       "11  How can I create a LCEL chain that queries a S...             1   \n",
       "12        How do I structure output of an LCEL chain?             1   \n",
       "\n",
       "    execution_check  \n",
       "0                 1  \n",
       "1                 0  \n",
       "2                 1  \n",
       "3                 1  \n",
       "4                 1  \n",
       "5                 1  \n",
       "6                 1  \n",
       "7                 1  \n",
       "8                 1  \n",
       "9                 0  \n",
       "10                0  \n",
       "11                0  \n",
       "12                1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ca_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Results (%):\n",
      "                      Metric  CrewAI\n",
      "0     Import Check Pass Rate  100.00\n",
      "1  Execution Check Pass Rate   69.23\n"
     ]
    }
   ],
   "source": [
    "# Evaluation metrics for CrewAI approaches\n",
    "evaluation_df = pd.DataFrame({\n",
    "    'Metric': ['Import Check Pass Rate', 'Execution Check Pass Rate'],\n",
    "    'CrewAI': [\n",
    "        ca_df['import_check'].mean() * 100,\n",
    "        ca_df['execution_check'].mean() * 100\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Format percentages to 2 decimal places\n",
    "evaluation_df['CrewAI'] = evaluation_df['CrewAI'].round(2)\n",
    "\n",
    "print(\"\\nEvaluation Results (%):\")\n",
    "print(evaluation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_agenticai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
