{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AgenticRag Crew\n",
    "\n",
    "Source: Lorenze Jay, **Practical Multi Agent RAG using CrewAI, Weaviate, Groq and ExaTool.** https://lorenzejay.dev/articles/practical-agentic-rag\n",
    "\n",
    "Notebook:\n",
    "https://github.com/lorenzejay/agentic-rag-practical-example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(\"figures/practical_agentic_rag.png\", width=400, height=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal:**\n",
    "Given a query, find relevant docs to generate a report that includes businesses financial data as well as a graph visualizations as a completed report.\n",
    "\n",
    "**Steps:**\n",
    "- Fetching relevant docs based on a query.\n",
    "- Competitor Research\n",
    "- Generating a writen doc\n",
    "- Generating graphs for data analysis\n",
    "\n",
    "**Tech Stack:**\n",
    "- CrewAI: The leading multi-agent platform\n",
    "- Weaviate: The AI-native database for a new generation of software\n",
    "- Groq: Fast AI Inference\n",
    "- ExaSearchTool: The search engine for AI\n",
    "- WebsiteSearchTool: Built in web rag tool from crewai_tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### document_rag_agent.yaml:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "document_rag_agent:\n",
    "  role: >\n",
    "    Document RAG Agent\n",
    "  goal: >\n",
    "    Answer questions about the documents in the Weaviate database.\n",
    "    The question is {query}\n",
    "  backstory: >\n",
    "    You are a document retrieval agent that can answer questions about the documents in the Weaviate database.\n",
    "    Documents are internal documents regarding the company\n",
    "    You have tools that allow you to search the information in the Weaviate database.\n",
    "\n",
    "web_agent:\n",
    "  role: >\n",
    "    Web Agent\n",
    "  goal: >\n",
    "    Answer questions using the web like the EXASearchTool\n",
    "    The question is {query}\n",
    "  backstory: >\n",
    "    You're a web search agent that can answer questions using the web.\n",
    "    your ability to turn complex data into clear and concise reports, making\n",
    "    it easy for others to understand and act on the information you provide.\n",
    "    You have tools that allow you to search the information on the web.\n",
    "\n",
    "code_execution_agent:\n",
    "  role: >\n",
    "    Code Execution Agent for data visualization\n",
    "  goal: >\n",
    "    You are a senior python developer that can execute code to generate the output\n",
    "    Most of your tasks will be to generate python code to visualze data passed to you.  \n",
    "    Execute the code and return the output.\n",
    "    The output file should be valid python code only.\n",
    "  backstory: >\n",
    "    You are a senior python developer that can execute code to generate the output\n",
    "    You have tools that allow you to execute python code.\n",
    "    Execute the code and return the output.\n",
    "  allow_code_execution: true\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### code_execution_agent:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "code_execution_agent:\n",
    "  role: >\n",
    "    Code Execution Agent for data visualization\n",
    "  goal: >\n",
    "    You are a senior python developer that can execute code to generate the output\n",
    "    Most of your tasks will be to generate python code to visualze data passed to you.  \n",
    "    Execute the code and return the output.\n",
    "    The output file should be valid python code only.\n",
    "  backstory: >\n",
    "    You are a senior python developer that can execute code to generate the output\n",
    "    You have tools that allow you to execute python code.\n",
    "    Execute the code and return the output.\n",
    "  allow_code_execution: true\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tasks.yaml:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fetch_tax_docs_task:\n",
    "  description: >\n",
    "    Find the relevant tax documents according to the question: {query}\n",
    "    You can use the WeaviateTool to find the relevant documents.\n",
    "    You need to provide the query and generate an appropriate question for the WeaviateTool.\n",
    "  expected_output: >\n",
    "    The relevant tax documents according to the question and the query.\n",
    "\n",
    "answer_question_task:\n",
    "  description: >\n",
    "    Find our competitors and their financial data.\n",
    "    Use the WebsiteSearchTool and EXASearchTool to find the relevant information.\n",
    "  expected_output: >\n",
    "    The answer to the question.\n",
    "    The answer should be in markdown format\n",
    "\n",
    "business_trends_task:\n",
    "  description: >\n",
    "    Generate a report on the latest trends we found in our business. Take our tax data and compare them from year to year: [2020, 2021, 2022, 2023].\n",
    "    You might want to use WeaviateTool to find the relevant tax documents to generate the trends.\n",
    "  expected_output: >\n",
    "    The latest business trends data from all business years.\n",
    "    The report should describe the trends in the data.\n",
    "  output_file: \"outputs/business_trends.md\"\n",
    "\n",
    "graph_visualization_task:\n",
    "  description: >\n",
    "    Generate a graph based on the data generating trends from the business_trends_task.\n",
    "    Use matplotlib to generate the graphs.\n",
    "    You can use the code execution agent to execute the code and generate the output.\n",
    "    The output file should be a python file and not markdown.\n",
    "  expected_output: >\n",
    "    The graph as a png file.\n",
    "    The output file should be a python file and not markdown.\n",
    "  output_file: \"outputs/visualize.ipynb\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### main.py:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    \"\"\"\n",
    "    Run the crew.\n",
    "    \"\"\"\n",
    "    inputs = {\"query\": \"What was the year with the highest total expenses?\"}\n",
    "    result = AgenticRagCrew().crew().kickoff(inputs=inputs)\n",
    "\n",
    "    if isinstance(result, str) and result.startswith(\"```python\"):\n",
    "        code = result[9:].strip()\n",
    "        if code.endswith(\"```\"):\n",
    "            code = code[:-3].strip()\n",
    "\n",
    "        with open(\"outputs/visualize.ipynb\", \"w\") as f:\n",
    "            f.write(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import weaviate\n",
    "\n",
    "from crewai_tools import BaseTool\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Type, Optional, Any\n",
    "from weaviate.classes.config import Configure\n",
    "\n",
    "class WeaviateToolSchema(BaseModel):\n",
    "    \"\"\"Input for WeaviateTool.\"\"\"\n",
    "\n",
    "    query: str = Field(\n",
    "        ...,\n",
    "        description=\"The query to search retrieve relevant information from the Weaviate database. Pass only the query, not the question.\",\n",
    "    )\n",
    "\n",
    "class WeaviateTool(BaseTool):\n",
    "    \"\"\"Tool to search the Weaviate database\"\"\"\n",
    "\n",
    "    name: str = \"WeaviateTool\"\n",
    "    description: str = \"A tool to search the Weaviate database for relevant information on internal documents\"\n",
    "    args_schema: Type[BaseModel] = WeaviateToolSchema\n",
    "    query: Optional[str] = None\n",
    "\n",
    "    def _run(self, query: str) -> str:\n",
    "        \"\"\"Search the Weaviate database\n",
    "\n",
    "        Args:\n",
    "            query (str): The query to search retrieve relevant information from the Weaviate database. Pass only the query as a string, not the question.\n",
    "\n",
    "        Returns:\n",
    "            str: The result of the search query\n",
    "        \"\"\"\n",
    "        client = weaviate.connect_to_local()\n",
    "        internal_docs = client.collections.get(\"tax_docs\")\n",
    "\n",
    "        if not internal_docs:\n",
    "            internal_docs = client.collections.create(\n",
    "                name=\"tax_docs\",\n",
    "                vectorizer_config=Configure.Vectorizer.text2vec_ollama(  # Configure the Ollama embedding integration\n",
    "                    api_endpoint=\"http://host.docker.internal:11434\",  # Allow Weaviate from within a Docker container to contact your Ollama instance\n",
    "                    model=\"nomic-embed-text\",  # The model to use\n",
    "                ),\n",
    "                generative_config=Configure.Generative.ollama(\n",
    "                    model=\"llama3.2:1b\",\n",
    "                    api_endpoint=\"http://host.docker.internal:11434\",\n",
    "                ),\n",
    "            )\n",
    "\n",
    "        response = internal_docs.query.near_text(\n",
    "            query=query,\n",
    "            limit=3,\n",
    "        )\n",
    "        json_response = \"\"\n",
    "        for obj in response.objects:\n",
    "            json_response += json.dumps(obj.properties, indent=2)\n",
    "    \n",
    "        client.close()\n",
    "        return json_response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### docker-compose.yml:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "services:\n",
    "  weaviate:\n",
    "    command:\n",
    "    - --host\n",
    "    - 0.0.0.0\n",
    "    - --port\n",
    "    - '8080'\n",
    "    - --scheme\n",
    "    - http\n",
    "    image: cr.weaviate.io/semitechnologies/weaviate:1.27.2\n",
    "    ports:\n",
    "    - 8080:8080\n",
    "    - 50051:50051\n",
    "    volumes:\n",
    "    - weaviate_data:/var/lib/weaviate\n",
    "    restart: on-failure:0\n",
    "    environment:\n",
    "      QUERY_DEFAULTS_LIMIT: 25\n",
    "      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n",
    "      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n",
    "      DEFAULT_VECTORIZER_MODULE: 'none'\n",
    "      ENABLE_API_BASED_MODULES: 'true'\n",
    "      ENABLE_MODULES: 'text2vec-ollama,generative-ollama'\n",
    "      CLUSTER_HOSTNAME: 'node1'\n",
    "volumes:\n",
    "  weaviate_data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import weaviate\n",
    "import json\n",
    "from weaviate.classes.config import Configure\n",
    "\n",
    "client = weaviate.connect_to_local()\n",
    "\n",
    "print(client.is_ready())\n",
    "\n",
    "internal_docs = client.collections.get(\"tax_docs\")\n",
    "if not internal_docs:\n",
    "    internal_docs = client.collections.create(\n",
    "        name=\"tax_docs\",\n",
    "        vectorizer_config=Configure.Vectorizer.text2vec_ollama(  # Configure the Ollama embedding integration\n",
    "            api_endpoint=\"http://host.docker.internal:11434\",  # Allow Weaviate from within a Docker container to contact your Ollama instance\n",
    "            model=\"nomic-embed-text\",  # The model to use\n",
    "        ),\n",
    "        generative_config=Configure.Generative.ollama(\n",
    "            model=\"llama3.2:1b\",\n",
    "            api_endpoint=\"http://host.docker.internal:11434\",\n",
    "        ),\n",
    "    )\n",
    "\n",
    "docs_dir = os.path.join(\n",
    "    os.path.dirname(os.path.dirname(os.path.dirname(__file__))), \"internal_docs\"\n",
    ")\n",
    "markdown_files = [f for f in os.listdir(docs_dir) if f.endswith(\".md\")]\n",
    "\n",
    "with internal_docs.batch.dynamic() as batch:\n",
    "    for filename in markdown_files:\n",
    "        with open(os.path.join(docs_dir, filename), \"r\") as f:\n",
    "            content = f.read()\n",
    "            batch.add_object(\n",
    "                {\n",
    "                    \"content\": content,\n",
    "                    \"class_name\": filename.split(\".\")[0],\n",
    "                }\n",
    "            )\n",
    "            print([object Object], [object Object], [object Object])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text document:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[object Object], Year: 2020\n",
    "\n",
    "[object Object], Income Statement\n",
    "\n",
    "Gross Sales: $150,000\n",
    "Returns & Allowances: $3,000\n",
    "Net Sales: $147,000\n",
    "\n",
    "[object Object], Cost of Goods Sold\n",
    "\n",
    "Beginning Inventory: $10,000\n",
    "Purchases: $60,000\n",
    "Ending Inventory: $15,000\n",
    "COGS: $55,000\n",
    "\n",
    "[object Object], Expenses\n",
    "\n",
    "Rent: $30,000\n",
    "Utilities: $6,000\n",
    "Salaries & Wages: $50,000\n",
    "Marketing & Advertising: $4,000\n",
    "Miscellaneous (Supplies, Insurance): $5,000\n",
    "Total Expenses: $95,000\n",
    "\n",
    "[object Object], Net Income (Loss)\n",
    "\n",
    "Gross Profit: $92,000\n",
    "Net Income (before taxes): $(3,000) (Loss)\n",
    "\n",
    "[object Object], Balance Sheet (End of Year)\n",
    "\n",
    "[object Object], Assets\n",
    "\n",
    "Cash: $5,000\n",
    "Inventory: $15,000\n",
    "Equipment: $25,000\n",
    "\n",
    "[object Object], Liabilities\n",
    "\n",
    "Accounts Payable: $8,000\n",
    "\n",
    "[object Object], Owner's Equity\n",
    "\n",
    "Owner's Equity: $37,000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### crew.py:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from crewai import Agent, Crew, Process, Task, LLM\n",
    "from crewai.project import CrewBase, agent, crew, task\n",
    "from agentic_rag.tools.weaviate_tool import WeaviateTool\n",
    "from crewai_tools import EXASearchTool\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "@CrewBase\n",
    "class AgenticRagCrew:\n",
    "    \"\"\"AgenticRag crew\"\"\"\n",
    "\n",
    "    llm = LLM(model=\"groq/llama-3.1-70b-versatile\", api_key=os.getenv(\"GROQ_API_KEY\"))\n",
    "\n",
    "    @agent\n",
    "    def document_rag_agent(self) -> Agent:\n",
    "        return Agent(\n",
    "            config=self.agents_config[\"document_rag_agent\"],\n",
    "            tools=[WeaviateTool()],\n",
    "            verbose=True,\n",
    "            llm=self.llm,\n",
    "        )\n",
    "    @agent\n",
    "    def web_agent(self) -> Agent:\n",
    "        return Agent(\n",
    "            config=self.agents_config[\"web_agent\"],\n",
    "            tools=[EXASearchTool()],\n",
    "            verbose=True,\n",
    "            llm=self.llm,\n",
    "        )\n",
    "    @agent\n",
    "    def code_execution_agent(self) -> Agent:\n",
    "        return Agent(\n",
    "            config=self.agents_config[\"code_execution_agent\"],\n",
    "            verbose=True,\n",
    "            llm=self.llm,\n",
    "        )\n",
    "    @task\n",
    "    def fetch_tax_docs_task(self) -> Task:\n",
    "        return Task(\n",
    "            config=self.tasks_config[\"fetch_tax_docs_task\"],\n",
    "        )\n",
    "    @task\n",
    "    def answer_question_task(self) -> Task:\n",
    "        return Task(\n",
    "            config=self.tasks_config[\"answer_question_task\"], output_file=\"report.md\"\n",
    "        )\n",
    "    @task\n",
    "    def business_trends_task(self) -> Task:\n",
    "        return Task(config=self.tasks_config[\"business_trends_task\"])\n",
    "    @task\n",
    "    def graph_visualization_task(self) -> Task:\n",
    "        return Task(config=self.tasks_config[\"graph_visualization_task\"])\n",
    "    @crew\n",
    "    def crew(self) -> Crew:\n",
    "        \"\"\"Creates the AgenticRag crew\"\"\"\n",
    "        return Crew(\n",
    "            agents=self.agents,  # Automatically created by the @agent decorator\n",
    "            tasks=self.tasks,  # Automatically created by the @task decorator\n",
    "            process=Process.hierarchical,\n",
    "            verbose=True,\n",
    "            manager_llm=\"openai/gpt-4o\",\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_agenticai_frameworks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
